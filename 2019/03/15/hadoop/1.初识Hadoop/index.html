<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 01-初识Hadoop · fossi</title><meta name="description" content="01-初识Hadoop - fossi"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"></head><body><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">博客</a></li><li class="nav-list-item"><a href="/archives" target="_self" class="nav-list-link">归档</a></li><li class="nav-list-item"><a href="/tags" target="_self" class="nav-list-link">标签</a></li><li class="nav-list-item"><a href="http://bloghello.oursnail.cn/test.html" target="_blank" class="nav-list-link">爱情</a></li><li class="nav-list-item"><a href="https://github.com/sunweiguo" target="_blank" class="nav-list-link">GIT</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">01-初识Hadoop</h1><div class="post-meta"><span class="post-time">Mar 15, 2019</span></div><div class="post-content"><p>关于大数据的学习终于开始了，对java后台开发比较熟悉的同学会发现，部分的组件比如zookeeper就是从Hadoop生态圈中诞生的，但是纵观hadoop的生态圈，大多数还是比较陌生，本节来说一说比较核心的组件，找到学习的入口。</p>
<a id="more"></a>
<h2>一、概述</h2>
<p>我们来到它的官网来看看Hadoop到底是什么。</p>
<p><img src="http://bloghello.oursnail.cn/hadoop1-1.png" alt="image"></p>
<p>大概就是说：Haadoop项目旨在发展可靠的、可扩展的、分布式计算的开源软件。允许用简单的编程跨越集群来分布式处理大数据集。可以从单体服务扩展到上千台机器，每个机器都可以提供本地计算和存储。相比于依赖硬件来保证高可用，Hadoop是在应用层监测和处理错误从而保证可靠性，允许单个机器出现故障。</p>
<p>可以看到，Hadoop旨在提供高可用、可扩展、分布式计算一种能力，是应对海量数据的存储以及处理的一个方案。</p>
<p>这个<code>Hadoop project</code>包含了几个核心的子模块：</p>
<ul>
<li>Hadoop Common: 为其他的模块提供基础支持。</li>
<li>Hadoop Distributed File System (HDFS™): 一个高吞吐量的分布式文件系统</li>
<li>Hadoop YARN: 一个作业调度和集群资源管理的框架</li>
<li>Hadoop MapReduce: 基于YARN实线的用于并行处理大数据集的系统</li>
</ul>
<h2>二、核心组件之HDFS</h2>
<ul>
<li>源自于谷歌的GFS论文，论文发表于2003年10月</li>
<li>HDFS是GFS的克隆版</li>
<li>HDFS特点：扩展性&amp;容错性&amp;海量数据存储</li>
</ul>
<p>HDFS是一种分布式文件系统，文件系统是什么，我们需要知道他的基本功能是：管理和调度文件的存储空间，提供文件的逻辑结构、物理结构和存储方法;实现文件从标识到实际地址的映射。也就是对文件进行管理和调度的。</p>
<p>海量的数据，我们需要良好的扩展性来存放，也需要容错性来防止数据丢失，因此HDFS是在文件系统基本要求的基础上，实现更可靠的存储。</p>
<p>这里简单说一下的它的容错性是如何做到的：将文件切分为指定带线啊哦的数据块并以多副本的方式存储在多个机器上，而数据切分、多副本、容错等操作对用户是透明的。</p>
<h2>三、核心组件之资源调度系统YARN</h2>
<ul>
<li>负责整个集群资源的管理和调度：比如有一个作业要提交上来执行，需要占用多少CPU，多少内存都是YARN来计算完成的。</li>
<li>具有扩展性&amp;容错性&amp;多框架资源统一调度</li>
</ul>
<p>这里注意，YARN可以为上层应用提供统一的资源管理和调度，是什么意思呢？</p>
<p><img src="http://bloghello.oursnail.cn/hadoop1-2.png" alt="image"></p>
<p>这张图从下面开始，<code>HDFS2</code>其实就是表示<code>hadoop2.x</code>，他是做存储的，往上看有一个<code>YARN</code>，他就是做集群的资源管理的（<code>cluster resource management</code>），再往上看，对于批处理我们可以用<code>mapreduce</code>这种执行引擎，对于交互式的我们可以使用<code>tez</code>，在线的我们可以使用<code>hbase</code>，流处理可以采用<code>storm</code>，图计算用<code>giraph</code>，内存式的计算我们可以使用<code>spark</code>。。。。。</p>
<p>有了<code>YARN</code>之后就可以执行不同类型的计算框架，我们可以把<code>YARN</code>理解为操作系统级别的资源调度框架，可以让更多的计算框架<code>mapreduce</code>，<code>spark</code>，<code>storm</code>等等都运行在同一个集群里面，而且不同的计算框架可以共享同一个<code>hdfs</code>上的数据，享受整体的资源调度。</p>
<h2>四、核心组件之分布式计算框架MapReduce</h2>
<p>也是根据谷歌的论文实线的。不再赘述。下面我们来看看它是如何简单地统计单词出现频率的：</p>
<p><img src="http://bloghello.oursnail.cn/hadoop1-3.png" alt="image"></p>
<p>这是比较经典的一个案例。</p>
<p>大概是分成下面几个环节：</p>
<ul>
<li>Map阶段
<ul>
<li>主要完成<code>key-value</code>对生成，这里是每看到一个单词，就输出(单词，1)的kv对</li>
</ul>
</li>
<li>排序阶段
<ul>
<li>对刚才的kv对进行排序，这样相同单词就在一块儿了</li>
</ul>
</li>
<li>Reduce阶段
<ul>
<li>对同一个单词的次数进行汇总，得到(词，频次)对</li>
</ul>
</li>
</ul>
<p><img src="http://bloghello.oursnail.cn/hadoop1-4.png" alt="image"></p>
<h2>五、Hadoop优势</h2>
<ul>
<li>高可用性：
<ul>
<li>数据存储：数据块多副本</li>
<li>数据计算：发生异常的时候会重新调度作业计算</li>
</ul>
</li>
<li>高扩展性
<ul>
<li>可以横向增加机器</li>
</ul>
</li>
<li>其他
<ul>
<li>可以存储在廉价机器上，降低成本</li>
<li>成熟的生态圈</li>
</ul>
</li>
</ul>
<h2>六、狭义Hadoop和广义Hadoop</h2>
<p>狭义上的Hadoop：是一个适合大数据分布式存储(HDFS)、分布式计算(MapReduce)和资源调度(YARN)的平台。</p>
<p>广义上的Hadoop：指的是Hadoop生态系统。我们要知道，完成一些任务仅靠上面几个是不够的，比如<code>MapReduce</code>只能做离线批处理，要想做实时计算时无法完成的，所以需要其他的软件来完成。Hadoop生态系统是一个很庞大的概念，Hadoop是其中最重要最基础的一个部分；生态系统中的每一个子系统只解决某一个特定的问题域，不搞统一型的一个全能系统，而实小而精的多个小系统。</p>
<h2>七、Hadoop生态圈介绍</h2>
<p><img src="http://bloghello.oursnail.cn/hadoop1-5.png" alt="image"></p>
<p>我们从图中可以大概知道每个组件的用途。下面我们来简单说一说。</p>
<p><code>HDFS</code>是<code>GFS</code>的一种实现，他的完整名字是分布式文件系统，类似于<code>FAT32</code>，<code>NTFS</code>，是一种文件格式，是底层的。</p>
<p><code>Hive</code>与<code>Hbase</code>的数据一般都存储在<code>HDFS</code>上。<code>hadoop HDFS</code>为他们提供了高可靠性的底层存储支持。</p>
<p><code>hive</code>不支持更改数据的操作，<code>Hive</code>基于数据仓库，提供静态数据的动态查询。其使用类SQL语言，底层经过编译转为<code>MapReduce</code>程序，在<code>Hadoop</code>上运行，数据存储在<code>HDFS</code>上。</p>
<p><code>Hbase</code>是<code>Hadoop database</code>，即<code>Hadoop</code>数据库。它是一个适合于非结构化数据存储的数据库，<code>HBase</code>基于列的而不是基于行的模式。</p>
<p><code>HBase</code>是<code>Google Bigtable</code>的开源实现，类似<code>Google Bigtable</code>利用<code>GFS</code>作为其文件存储系统，<code>HBase</code>利用<code>Hadoop HDFS</code>作为其文件存储系统；<code>Google</code>运行<code>MapReduce</code>来处理<code>Bigtable</code>中的海量数据，<code>HBase</code>同样利用<code>Hadoop MapReduce</code>来处理<code>HBase</code>中的海量数据。</p>
<p><code>Pig</code>的语言层包括一个叫做<code>PigLatin</code>的文本语言,<code>Pig Latin</code>是面向数据流的编程方式。<code>Pig</code>和<code>Hive</code>类似更侧重于数据的查询和分析，底层都是转化成<code>MapReduce</code>程序运行。</p>
<p><code>Pig</code>和<code>Hive</code>的区别是<code>Hive</code>是类SQL的查询语言，要求数据存储于表中，而Pig是面向数据流的一个程序语言。</p>
<p>总结：</p>
<p><code>Hadoop HDFS</code>为<code>HBase</code>提供了高可靠性的底层存储支持，<code>Hadoop MapReduce</code>为<code>HBase</code>提供了高性能的计算能力，<code>Zookeeper</code>为<code>HBase</code>提供了稳定服务和<code>failover</code>机制(<code>zookeeper</code> = 通知机制 + 文件系统)。<code>Pig</code>和<code>Hive</code>还为<code>HBase</code>提供了高层语言支持，使得在<code>HBase</code>上进行数据统计处理变的非常简单。</p>
<h2>八、选型</h2>
<ul>
<li>Apache Hadoop</li>
<li>CDH:Cloudera Distributed Hadoop</li>
<li>HDP:Hortonworks Data Platform</li>
</ul>
<p>优先选择CDH，比较全，解决了版本冲突问题。</p>
<h2>九、总结</h2>
<p>我们可以看到，Hadoop的生态圈是极其庞大的，每个组件都是小而精，是为了解决特定问题而产生的，因此需要具体情况具体分析选用什么组件，也需要对核心的组件原理和使用了如指掌，下面我们先逐个来学习一下狭义Hadoop核心组件，从HDFS开始。</p>
</div></article></div></section><footer><div class="paginator"><a href="/2019/03/15/剑指offer/【面试题61-序列化二叉树】/" class="next">下一篇</a></div><div id="container"></div><link rel="stylesheet" href="https://jjeejj.github.io/css/gitment.css">
<script src="https://jjeejj.github.io/js/gitment.js"></script><script>var gitment = new Gitment({
    id: 'Fri Mar 15 2019 17:24:24 GMT+0800',
    owner: 'sunweiguo',
    repo: 'sunweiguo.github.io',
    oauth: {
        client_id: '56c422eddebac740f021',
        client_secret: 'fd1b1eff6dd6efc61b2a09650840be7aaab787fd',
    },
})
gitment.render('container')</script><div class="copyright"><p>© 2019 <a href="http://yoursite.com">fossi</a>, <a href="https://github.com/sunweiguo">contact with me!</a>.</p></div></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-134836068-1",'auto');ga('send','pageview');</script><script src="https://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>