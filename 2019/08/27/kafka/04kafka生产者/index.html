<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 04kafka生产者 · fossi</title><meta name="description" content="04kafka生产者 - fossi"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"></head><body><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">首页</a></li><li class="nav-list-item"><a href="https://sunweiguo.github.io/tags/" target="_blank" class="nav-list-link">标签</a></li><li class="nav-list-item"><a href="http://bloghello.oursnail.cn/test.html" target="_blank" class="nav-list-link">爱情</a></li><li class="nav-list-item"><a href="https://github.com/sunweiguo" target="_blank" class="nav-list-link">GIT</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">04kafka生产者</h1><div class="post-meta"><span class="post-time">Aug 27, 2019</span></div><div class="post-content"><p><img src="http://bloghello.oursnail.cn/kafka1-15.jpg" alt="image"></p>
<p>在完成kafka的入门以及基本的操作之后，相信已经对kafka有了基本认识，下面我们一起从kafka的生产者开始，深入学习一下。</p>
<a id="more"></a>
<h2>一、一个简单的生产者示例</h2>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducerAnalysis</span> </span>&#123;</span><br><span class="line">    <span class="comment">//注1：brokerList可以写多个，中间用逗号隔开</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String brokerList = <span class="string">"localhost:9092"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String topic = <span class="string">"topic-demo"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Properties <span class="title">initConfig</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, brokerList);</span><br><span class="line">        <span class="comment">//注2：消息在发送到broker之前需要将key和value序列化成字节数组</span></span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>,</span><br><span class="line">                <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>,</span><br><span class="line">                <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        <span class="keyword">return</span> props;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = initConfig();</span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">        ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(topic, <span class="string">"hello, Kafka!"</span>);</span><br><span class="line">        producer.send(record);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>注意，<code>KafkaProducer</code>是线程安全的，可以在多个线程中共享单个<code>KafkaProducer</code>实例，也可以将<code>KafkaProducer</code>实例进行池化来供其他线程调用。</strong></p>
<ul>
<li>生产逻辑的几个步骤：
<ul>
<li>配置生产者客户端参数并创建生产者实例</li>
<li>构建待发送消息</li>
<li>发送消息</li>
<li>关闭生产者实例</li>
</ul>
</li>
</ul>
<p>注意，我们发送消息的时候，可以指定消息的<code>topic</code>、<code>partition</code>、<code>headers</code>、<code>key</code>、<code>value</code>等字段。</p>
<ul>
<li><code>topic</code>：消息要发往的主题，不赘述</li>
<li><code>partition</code>：消息要发往的分区号，不赘述</li>
<li><code>headers</code>：指消息的头部，<code>Kafka 0.11.x</code>版本才引入此属性，它大多来设定一些与应用相关的信息，基本不用管他。</li>
<li><code>key</code>：指消息的键，它可以用来计算分区号进而可以让消息发往特定的分区，消息可以以主题进行分类，也可以用<code>key</code>进行二次归类，同一个<code>key</code>的消息会被划分到同一个分区。，有<code>key</code>的消息可以支持日志压缩功能。</li>
<li><code>value</code>：指消息体，一般不为空，如果为空则表示特定的消息-墓碑消息，后续介绍。</li>
</ul>
<h2>二、发送消息的三种模式</h2>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>发后即忘</strong>
<ul>
<li>只管发送消息，不关心信息是否正确到达。</li>
<li>优点：性能最高，吞吐量大</li>
<li>缺点：会造成数据丢失，可靠性低</li>
</ul>
</li>
<li><strong>同步</strong>
<ul>
<li>发送消息后返回<code>Future</code>对象，调用<code>get()</code>方法时阻塞等待，直到发送成功或出现异常</li>
<li>优点：可靠性高，如有异常可处理或进行消息重发</li>
<li>缺点：性能低，造成阻塞</li>
</ul>
</li>
<li><strong>异步</strong>
<ul>
<li>发送消息时指定回调函数，<code>Kafka</code>在返回响应时会调用该函数实现异步的发送确认。</li>
<li>在同一个分区中，如果消息<code>record1</code>比<code>record2</code>先发送，那么它会保证<code>callback1</code>在<code>callback2</code>之前调用。</li>
</ul>
</li>
</ul>
<p>这里推荐使用第三种即回调函数的方式来实现，但是针对<code>send()</code>方法的返回值是<code>Future</code>可能会有疑问：<code>Future</code>本身就是可以用作异步的逻辑处理。这样做不是不行，只不过<code>Future</code>里的<code>get()</code>方法在何时调用，以及怎么调用都是需要面对的问题，消息不停地发送，那么诸多消息的<code>Future</code>对象的处理难免会引起代码处理逻辑的混乱。因此推荐使用<code>Callback</code>这种回调函数的方式来处理，要么发送成功，要么抛出异常，回调函数示例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">producer.send(record,<span class="keyword">new</span> callback()&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception e)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span>!=e)&#123;</span><br><span class="line">        	e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">        	System.out.printf(metadata.topic()+<span class="string">"-"</span>+metadata.partition()+<span class="string">"-"</span>+metadata.offset());</span><br><span class="line">    	&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>注意，<code>metadata</code>和<code>e</code>是互斥的，消息发送成功时，<code>metadata</code>不为<code>null</code>而<code>e</code>为<code>null</code>；消息发送异常时，<code>metadata</code>为<code>null</code>为<code>e</code>不为<code>null</code>；</p>
<p>再来说说<code>Future</code>对象，它表示一个任务的生命周期，并提供了相应的方法来判断任务是否已经完成或取消，以及获取任务的结果和取消任务等。我们可以使用<code>Future</code>中的<code>get(long timeout,TimeUtil unit)</code>方法实现可超时的阻塞。</p>
<p><code>KafkaProducer</code>中一般会发生两种异常：可重试的异常和不可重试的异常。常见的可重试异常有：</p>
<ul>
<li><code>NetworkException</code>：表示网络异常，有可能由于网络瞬间故障而导致的异常，可以通过重试解决</li>
<li><code>LeaderNotAvailableException</code>表示分区的<code>leader</code>副本不可用，这个异常通常发生在<code>leader</code>副本下线而新的<code>leader</code>副本选举完成之前，重试之后可以重新恢复。</li>
</ul>
<p>不可重试的异常：比如<code>RecordTooLargeException</code>异常，暗示了所发送的消息太大，<code>KafkaProducer</code>对此不会进行任何重试，直接抛出异常。</p>
<h2>三、发送者整体架构原理分析</h2>
<p>整体架构如下：</p>
<p><img src="http://bloghello.oursnail.cn/kafka5-1.png" alt="image"></p>
<p>主要分为两个线程，一个主线程，一个发送线程，我们从左向右一一说明。</p>
<p>消息在发送到<code>kafka</code>之前，可能需要经历拦截器、序列化器和分区器。对应着图中是左边主线程中干的事情。下面一一介绍一下。</p>
<blockquote>
<p>1.拦截器</p>
</blockquote>
<p>拦截器早在<code>Kafka0.10.0.0</code>中已经引入的功能，一共有两种拦截器：生产者拦截器和消费者拦截器。这里当然主要关注生产者拦截器。</p>
<p>生产者拦截器既可以在消息发送之前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。</p>
<p>下面给出一个简单示例，<code>onSend()</code>方法给每条消息加一个前缀<code>prefix1-</code>，并且通过<code>onAcknowledgement</code>开统计发送消息的成功率：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerInterceptorPrefix</span> <span class="keyword">implements</span></span></span><br><span class="line"><span class="class">        <span class="title">ProducerInterceptor</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">long</span> sendSuccess = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">long</span> sendFailure = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProducerRecord&lt;String, String&gt; <span class="title">onSend</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            ProducerRecord&lt;String, String&gt; record)</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">        String modifiedValue = <span class="string">"prefix1-"</span> + record.value();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ProducerRecord&lt;&gt;(record.topic(),</span><br><span class="line">                record.partition(), record.timestamp(),</span><br><span class="line">                record.key(), modifiedValue, record.headers());</span><br><span class="line"><span class="comment">//        if (record.value().length() &lt; 5) &#123;</span></span><br><span class="line"><span class="comment">//            throw new RuntimeException();</span></span><br><span class="line"><span class="comment">//        &#125;</span></span><br><span class="line"><span class="comment">//        return record;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAcknowledgement</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            RecordMetadata recordMetadata,</span></span></span><br><span class="line"><span class="function"><span class="params">            Exception e)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (e == <span class="keyword">null</span>) &#123;</span><br><span class="line">            sendSuccess++;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            sendFailure++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">double</span> successRatio = (<span class="keyword">double</span>) sendSuccess / (sendFailure + sendSuccess);</span><br><span class="line">        System.out.println(<span class="string">"[INFO] 发送成功率="</span></span><br><span class="line">                + String.format(<span class="string">"%f"</span>, successRatio * <span class="number">100</span>) + <span class="string">"%"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; map)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>光有这个还不够，还需要在<code>KafkaProducer</code>的配置参数<code>interceptor.classes</code>中指定这个拦截器，此参数的默认值为“”，示例为：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">properties.put(ProducerConfig.INTERCEPTOR_CLASSED_CONFIG,</span><br><span class="line">        ProducerInterceptorPrefix.class.getName());</span><br></pre></td></tr></table></figure>
<p>当然了，也可以指定多个拦截器形成拦截链，多个的拦截器之间用逗号隔开，并且是有顺序的，排在前面的先执行。</p>
<p>总结一下就是：消息一发出首先就是经过拦截器链处理消息，如果消息发送失败会调用<code>onAcknowledgement</code>方法，这个方法优先于用户设定的<code>Callback</code>之前执行。一般情况下，拦截器是用不到的。</p>
<blockquote>
<p>2.序列化器</p>
</blockquote>
<p>关于序列化，没什么好说的，总结为以下三句话：</p>
<ul>
<li>生产者使用序列化器将对象转换为字节数组，才能通过网络发送给Kafka</li>
<li>消费者使用反序列化其把Kafka中收到的字节数组转换为相应的对象。</li>
<li>因此生产者的序列化器和消费者使用的反序列化器要一一对应。</li>
</ul>
<blockquote>
<p>3.分区器</p>
</blockquote>
<p>上面介绍了拦截器和序列化器，一般情况下拦截器是不需要的，序列化器是必需的，消息经过序列化之后就需要确定它发往的分区，如果消息<code>ProducerRecord</code>中指定了<code>partition</code>字段，那么就不需要分区器了，因为<code>partition</code>就是要发往的分区号。</p>
<p>如果消息<code>ProducerRecord</code>中没有指定<code>partition</code>字段，就需要依赖分区器，根据<code>key</code>这个字段来计算<code>partition</code>的值，分区器的作用就是为消息分配分区。此时有两种情况：</p>
<ul>
<li><code>key</code>为<code>null</code>：那么消息将以轮询的方式发往主题内各个可用分区</li>
<li><code>key</code>不为<code>null</code>：默认的分区器会对<code>key</code>进行哈希（采用<code>MurmurHash2</code>算法，具备高运算性能即低碰撞率），最终根据得到的哈希值来计算分区号，拥有相同的<code>key</code>的消息会被写入同一个分区下</li>
</ul>
<div class="tip">
注意：如果`key`不为`null`则计算处的分区号是所有分区号中的任意一个；如果`key`为`null`并且有可用分区时，那么计算得到的分区号仅为可用分区中的任意一个，注意两者之间的区别。
</div>
<p>好了，至此介绍了拦截器、序列化器以及分区器的作用之后，之后又会发生什么呢？</p>
<p>不得不再把整体架构图拿过来了：</p>
<p><img src="http://bloghello.oursnail.cn/kafka5-1.png" alt="image"></p>
<p>我们可用看到，整个生产者客户端由两个线程协调运行，这两个线程分别为主线程和<code>Sender</code>线程。</p>
<h2>四、主线程</h2>
<p>在主线程中由<code>kafkaProducer</code>创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到<strong>消息累加器</strong>（<code>RecordAccumulator</code>，也成为消息收集器）。<code>Sender</code>线程负责从<code>RecordAccumulator</code>中获取消息并将其发送到<code>Kafka</code>中。</p>
<p><code>RecordAccumulator</code>主要用来缓存消息以便<code>Sender</code>线程可用批量发送，进而减少网络传输的资源损耗以提升性能。<code>RecordAccumulator</code>缓存消息的可以通过<code>buffer.memory</code>进行配置，默认为32兆。</p>
<p>主线程中发送过来的消息都会被追加到<code>RecordAccumulator</code>的某个<strong>双端队列</strong>中，在<code>RecordAccumulator</code>的内部每个分区都维护了一个双端队列，队列中的内容就是<code>ProducerBatch</code>，即<code>Deque&lt;ProducerBatch&gt;</code>。</p>
<p><strong>消息写入缓存时，追加到双端队列的尾部；<code>Sender</code>线程获取消息时，从双端队列的头部读取。</strong></p>
<p>注意这里的<code>ProducerBatch</code>不是<code>ProducerRecord</code>，后者是一条消息，前者可以包含一个或多个<code>ProducerRecord</code>，即<code>ProducerBatch</code>是一个消息批次，<code>ProducerRecord</code>只是一条消息而已。<code>ProducerBatch</code>中包含多条<code>ProducerRecord</code>是为了使字节的使用更加紧凑，与此同时可以减少网络请求以提升整体的吞吐量。</p>
<p><code>ProducerBatch</code>与<code>batch.size</code>参数有一定的关系。当一条消息<code>ProducerRecord</code>流入<code>RecordAccumulator</code>时，会先寻找与消息分区所对应的双端队列（如果没有则新建），再从这个双端队列的尾部获取一个<code>ProducerBatch</code>（如果没有则新建），查看<code>ProducerBatch</code>中是否还可以写入这个<code>ProducerRecord</code>，如果可以则写入，如果不可以则需要创建一个新的<code>ProducerBatch</code>。</p>
<p>在新建<code>ProducerBatch</code>的时候评估这条消息是否超过<code>batch.size</code>参数的大小，如果不超过，就以<code>batch.size</code>参数的大小来创建<code>ProducerBatch</code>，这样在使用完这段内存区域之后，可以通过<code>BufferPool</code>的管理来进行复用；如果超过，就以评估的大小来创建<code>ProducerBatch</code>，这段内存区域不会被复用。</p>
<p>如果消息总是大于<code>batch.size</code>的大小，那么就会频繁地在内存中创建和释放这段区域，时比较浪费资源的。因此，<code>batch.size</code>的参数比较重要，默认是16K，我们可以适当调大以便多缓存一些消息。</p>
<h2>五、Sender线程</h2>
<p><code>Sender</code>从<code>RecordAccumulator</code>中获取缓存的消息之后，会进一步将原来<code>&lt;分区，Deque&lt;ProducerBatch&gt;&gt;</code>的保存形式转变成<code>&lt;node，List&lt;ProducerBatch&gt;&gt;</code>的形式，其中<code>node</code>表示kafka集群的<code>broker</code>节点。</p>
<p>对于网络连接来说，生产者客户端是与具体的<code>broker</code>节点建立的连接，也就是向具体的<code>broker</code>节点发送消息，而并不关心消息属于哪一个分区；而对于<code>KafkaProducer</code>的应用逻辑来说，我们只关注向哪个分区发送哪些消息，所以需要在这里做一个应用逻辑层面到IO层面的转换。</p>
<p>在转成<code>&lt;node，List&lt;ProducerBatch&gt;&gt;</code>的形式之后，<code>Sender</code>还会进一步封装成<code>&lt;node,Request&gt;</code>的形式，这样就可以将<code>Request</code>请求发往各个<code>node</code>了，这里的<code>Request</code>指kafka的各种协议请求，对于消息发送而言就是指具体的<code>producerRequest</code>，更多与kafka协议相关的内容后面章节再讨论。</p>
<p>请求从<code>Sender</code>线程发往kafka之前还会保存到<code>InFlightRequests</code>中，<code>InFlightRequests</code>保存对象的具体形式为<code>Map&lt;nodeId,Deque&lt;Request&gt;&gt;</code>，它的主要作用是缓存了已经发出去但还没收到响应的请求。<code>InFlightRequests</code>可以通过配置参数限制每个连接（客户端和kafka之间的连接）最多的缓存的请求数。默认值为5，即每个连接最多缓存5个未响应的请求，超过该数值之后就不能向这个连接发送更多的请求了，除非有缓存的请求收到了响应。通过比较<code>Deque&lt;Request&gt;</code>的<code>size</code>参数大小可以判断对应的<code>node</code>是否已经堆积了很多未响应的消息，如果堆积了很多，说明这个<code>node</code>节点负载比较大或者网络连接有问题，再继续对其发请求会增大超时的可能。</p>
<h2>六、元数据的更新</h2>
<p>我们使用如下的方式创建了一条消息<code>producerRecord</code>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(topic, <span class="string">"hello, Kafka!"</span>);</span><br></pre></td></tr></table></figure>
<p>我们只知道主题的名称，对于其他的必要信息一无所知。<code>KafkaProducer</code>要将此消息追加到指定主题的某个分区所对应的<code>leader</code>副本之前，首先需要知道主题的分区数量，然后经过计算得到（或者直接指定）目标分区，之后<code>KafkaProducer</code>需要知道目标分区的<code>leader</code>副本所在的<code>broker</code>节点的地址、端口等信息才能建立连接，最终才能将消息发送到kafka。这一过程需要的信息属于元数据信息。</p>
<p>元数据是指Kafka集群中的元数据，这些元数据记录了集群中有哪些主题，这些主题有哪些分区，每个分区的<code>leader</code>副本分配在哪个节点上，<code>follwer</code>副本分配在哪些节点上，哪些副本在<code>AR</code>,<code>ISR</code>集合中，集群有哪些节点，控制节点又是哪一个等信息。</p>
<p>与此同时，我们知道<code>bootstrap.servers</code>参数只需要配置部分kafka节点的地址即可，不需要配置所有<code>broker</code>节点的地址，因为客户端可以自己发现其他<code>broker</code>节点的地址，这一过程属于元数据相关的更新操作；分区数量及<code>leader</code>副本的分布都会动态地变化，客户端需要动态捕捉这些变化。这里想说的是，在客户端的内部会进行元数据的更新操作（计算元数据都没变过，但是超过一段时间也会自动更新），当客户端需要更新元数据时，会挑选 <code>InFlightRequests</code> 中当前负载最小的节点发送更新元数据请求。</p>
<p>元数据虽然由<code>Sender</code>线程负责更新，但是主线程也需要读取这些信息，因此数据同步问题也要考虑，使用<code>synchronized</code>和<code>final</code>保证。</p>
<h2>七、重要的生产者参数</h2>
<ul>
<li><code>acks</code> : <strong>用来指定分区中必须要有多少个副本收到这条消息，这样生产者才认为消息写入成功</strong>
<ul>
<li>取值为1 : 只要<code>leader</code>副本成功写入消息，就会收到kafka的成功响应</li>
<li>取值为0： 不需要等待任何服务器响应，写入就认为成功</li>
<li>取值为-1或all：需要等待<code>ISR</code>中的所有副本都成功写入消息，才会收到kafka的成功响应</li>
</ul>
</li>
<li><code>max.request.size</code>
<ul>
<li>限制生产者客户端能发送消息最大值</li>
</ul>
</li>
<li><code>retires</code> 、<code>retry.backoff.ms</code>
<ul>
<li>配置生产者重试次数 、 两次重试的时间间隔</li>
</ul>
</li>
<li><code>max.in.flight.requests.per.connection</code>
<ul>
<li>默认值为5，即每个连接最多只能缓存5个未响应的请求。</li>
<li>当此参数 &gt; 1 ，则会因为重发而出现错序的问题</li>
</ul>
</li>
</ul>
</div></article></div></section><footer><div class="paginator"><a href="/2019/09/01/kafka/05kafka消费者上/" class="prev">PRVE</a><a href="/2019/08/10/miscellany/19SpringTask的基本使用/" class="next">NEXT</a></div><div id="container"></div><link rel="stylesheet" href="//billts.site/extra_css/gitment.css">
<script src="//billts.site/js/gitment.js"></script><script>var gitment = new Gitment({
    id: 'Tue Aug 27 2019 21:59:22 GMT+0800',
    owner: 'sunweiguo',
    repo: 'sunweiguo.github.io',
    oauth: {
        client_id: '56c422eddebac740f021',
        client_secret: 'b0520b7f71d5d883e029133f06c3328e3d3168e1',
    },
})
gitment.render('container')</script><div class="copyright"><p>© 2019 - 2020 <a href="http://yoursite.com">fossi</a>,苏ICP备17064972号.</p></div></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-134836068-1",'auto');ga('send','pageview');</script><script src="https://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>