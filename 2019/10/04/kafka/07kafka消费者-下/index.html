<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 07kafka消费者-下 · fossi</title><meta name="description" content="07kafka消费者-下 - fossi"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"></head><body><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">首页</a></li><li class="nav-list-item"><a href="https://sunweiguo.github.io/tags/" target="_blank" class="nav-list-link">标签</a></li><li class="nav-list-item"><a href="http://bloghello.oursnail.cn/test.html" target="_blank" class="nav-list-link">爱情</a></li><li class="nav-list-item"><a href="https://github.com/sunweiguo" target="_blank" class="nav-list-link">GIT</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">07kafka消费者-下</h1><div class="post-meta"><span class="post-time">Oct 4, 2019</span></div><div class="post-content"><p><img src="http://bloghello.oursnail.cn/kafka1-15.jpg" alt="image"></p>
<p>之前学习了如何进行消费位移的提交，正是有了消费位移的持久化，才能使消费者在关闭、崩溃或者遇到再均衡的时候，可以让接替的消费者根据存储的消费位移继续继续进行消费。</p>
<a id="more"></a>
<h2>一、指定位移消费</h2>
<p>当一个新的消费组建立的时候，它根本没有可以查找的消费位移；或者消费组内的一个新消费者订阅了一个新的主题，此时没有可以查找的消费位移；当<code>_consumer_offsets</code>主题中有关这个消费组的位移信息过期而被删除后，他也没有可以查找的消费位移。</p>
<p>在kafka中，每当消费者找不到所记录的消费位移时，就会根据消费者客户端参数<code>auto.offset.reset</code>的配置来决定从何处开始消费，默认值为<code>latest</code>，表示从分区末尾开始消费消息。如果配置成<code>earliest</code>，那么消费者就会从起始处开始消费。如果配置为<code>none</code>，表示当出现查不到消费位移的时候，既不从最新的消息位置处开始消费，也不从最早的消息位置处开始消费，此时会报出<code>NoOffsetForPartitionException</code>异常。</p>
<p>如果能够找到消费位移，那么配置成<code>none</code>也不会出现任何异常。如果配置的不是<code>latest</code>或者<code>earliest</code>或者<code>node</code>，就会报出<code>ConfigException</code>异常。</p>
<p>到目前为止，我们知道消息的拉取时根据<code>poll</code>方法的逻辑来处理的，对于我们来说是一个黑盒，无法精确控制其消费的起始位置。提供的<code>auto.offset.reset</code>参数也只能在找不到位移或者位移越界的情况下粗粒度地从开头或者末尾开始消费。有的时候我们需要一种更细粒度的掌控，可以让我们从特定的位移处开始拉取消息。下面<code>seek</code>方法隆重登场，让我们得以追前消费或回溯消费。</p>
<p>具体定义为：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">seek</span><span class="params">(TopicPartition partition,<span class="keyword">long</span> offset)</span></span>;</span><br></pre></td></tr></table></figure>
<p><code>partition</code>表示分区，<code>offset</code>参数用来指定从分区的哪个位置开始消费。下面为一个示例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">consumer.subscribe(Arrays.asList(topic));</span><br><span class="line">consumer.poll(Duration.ofMillis(<span class="number">2000</span>));<span class="comment">// ①</span></span><br><span class="line">Set&lt;TopicPartition&gt; assignment = consumer.assignment();<span class="comment">// ②</span></span><br><span class="line">System.out.println(assignment);</span><br><span class="line"><span class="keyword">for</span> (TopicPartition tp : assignment) &#123;</span><br><span class="line">    consumer.seek(tp, <span class="number">10</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//        consumer.seek(new TopicPartition(topic,0),10);</span></span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    ConsumerRecords&lt;String, String&gt; records =</span><br><span class="line">            consumer.poll(Duration.ofMillis(<span class="number">1000</span>));</span><br><span class="line">    <span class="comment">//consume the record.</span></span><br><span class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">        System.out.println(record.offset() + <span class="string">":"</span> + record.value());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>⭐⭐<strong>如果将第①行改为<code>consumer.poll(Duration.ofMillis(0));</code>，会发现<code>seek()</code>方法并未有任何作用，因为当<code>poll</code>方法的参数为0时，此方法会立刻返回，那么<code>poll</code>方法内部进行分区分配的逻辑就会来不及实施。也就是说，消费者此时并未分配到任何分区，就会导致②中<code>assignment</code>是个空列表，后续的代码不会执行。</strong></p>
<p>那么这里分配的<code>timeout</code>参数设置未多少合适呢？太短则使分配分区的动作失败，太长又有可能造成一些不必要的等待。一个好的解决方法就是判断到分区分配成功为止：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">consumer.subscribe(Arrays.asList(topic));</span><br><span class="line">consumer.poll(Duration.ofMillis(<span class="number">2000</span>));<span class="comment">// ①</span></span><br><span class="line">Set&lt;TopicPartition&gt; assignment = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line"><span class="comment">// 如果不为0，说明已经成功分配到了分区</span></span><br><span class="line"><span class="keyword">while</span>(assignment.size == <span class="number">0</span>)&#123;</span><br><span class="line">    consumer.poll(Duration.ofMillis(<span class="number">100</span>));</span><br><span class="line">    assignment = consumer.assignment();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">System.out.println(assignment);</span><br><span class="line"><span class="keyword">for</span> (TopicPartition tp : assignment) &#123;</span><br><span class="line">    consumer.seek(tp, <span class="number">10</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//        consumer.seek(new TopicPartition(topic,0),10);</span></span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    ConsumerRecords&lt;String, String&gt; records =</span><br><span class="line">            consumer.poll(Duration.ofMillis(<span class="number">1000</span>));</span><br><span class="line">    <span class="comment">//consume the record.</span></span><br><span class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">        System.out.println(record.offset() + <span class="string">":"</span> + record.value());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果未分配到分区执行<code>seek()</code>方法，就会报出<code>IllegalStateException</code>异常。如果消费组内的消费者在启动的时候能够找到消费位移，除非发生位移越界，否则<code>auto.offset.reset</code>参数并不会奏效，此时如果想指定从开头或者末尾开始消费，就需要<code>seek()</code>方法的帮助了。下面使从分区末尾开始消费：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">consumer.subscribe(Arrays.asList(topic));</span><br><span class="line">Set&lt;TopicPartition&gt; assignment = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line"><span class="keyword">while</span> (assignment.size() == <span class="number">0</span>) &#123;</span><br><span class="line">    consumer.poll(Duration.ofMillis(<span class="number">100</span>));</span><br><span class="line">    assignment = consumer.assignment();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// endOffsets()就是获取指定分区的末尾的消息位置</span></span><br><span class="line">Map&lt;TopicPartition, Long&gt; offsets = consumer.endOffsets(assignment);</span><br><span class="line"><span class="keyword">for</span> (TopicPartition tp : assignment) &#123;</span><br><span class="line">    consumer.seek(tp, offsets.get(tp) + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(assignment);</span><br><span class="line">System.out.println(offsets);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    ConsumerRecords&lt;String, String&gt; records =</span><br><span class="line">            consumer.poll(Duration.ofMillis(<span class="number">1000</span>));</span><br><span class="line">    <span class="comment">//consume the record.</span></span><br><span class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">        System.out.println(record.offset() + <span class="string">":"</span> + record.value());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>与<code>endOffsets()</code>对应的就是<code>beginningOffsets()</code>方法。起始<code>KafkaConsumer</code>中直接提供了<code>seekToBeginning()</code>方法和<code>seekToEnd()</code>方法来实现这两个功能。这两个方法的定义为：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">seekToBeginning</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">seekToEnd</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span>;</span><br></pre></td></tr></table></figure>
<p>当然了，消费位移可以存储在任何介质，比如数据库：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">consumer.subscribe(Arrays.asList(topic));</span><br><span class="line"><span class="comment">//省略poll()方法以及assignment的逻辑</span></span><br><span class="line"><span class="keyword">for</span>(TopicPartition tp: assignment)&#123;</span><br><span class="line">    <span class="keyword">long</span> offset = getOffsetFromDB(tp);<span class="comment">//从DB中读取消费位移</span></span><br><span class="line">    consumer.seek(tp, offset);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">    ConsumerRecords&lt;String, String&gt; records =</span><br><span class="line">            consumer.poll(Duration.ofMillis(<span class="number">1000</span>));</span><br><span class="line">    <span class="keyword">for</span> (TopicPartition partition : records.partitions()) &#123;</span><br><span class="line">        List&lt;ConsumerRecord&lt;String, String&gt;&gt; partitionRecords =</span><br><span class="line">                records.records(partition);</span><br><span class="line">        <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : partitionRecords) &#123;</span><br><span class="line">            <span class="comment">//process the record.</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> lastConsumedOffset = partitionRecords</span><br><span class="line">                .get(partitionRecords.size() - <span class="number">1</span>).offset();</span><br><span class="line">         <span class="comment">//将消费位移存储在DB中</span></span><br><span class="line">        storeOffsetToDB(partition, lastConsumedOffset+<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>seek()</code>方法为我们提供了从特定位置读取消息的能力，我们可以通过这个方法来向前跳过若干消息，也可以通过这个方法来向后回溯瑞干消息，这样为消息的消费提供了很大的灵活性。<code>seek()</code>方法也为我们提供了将消费位移保存在外部存储介质的能力，还可以通过再均衡监听器来提供更加精准的消费能力。</p>
<h2>二、再均衡</h2>
<p>再均衡是指：分区的所属权从一个消费者转移到另一个消费者的行为，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便又安全地删除消费组内的消费者或者添加消费者。</p>
<p>不过在再均衡发生期间，消费组内的消费者是无法读取消息的，也就是说，在再均衡发生期间的这一小段时间内，消费组会变得不可用。</p>
<p>另外，当一个分区被重新分配给另一个消费者时，消费者当前的状态也会丢失。比如消费者消费完某个分区中的一部分消息时还没有来得及提交消费位移就发生了再均衡操作，之后这个分区又被分配到了消费组内的另一个消费者，原来被消费完的那部分消息又被重新消费一遍，也就是发生了重复消费。</p>
<p>所以，一般情况下，应尽量避免不必要的再均衡的发生。</p>
<p>在之前说明<code>subscribe()</code>方法时提及再均衡监听器<code>ConsumerRebalanceListener</code>，再均衡监听器用来设定再均衡动作前后的一些准备工作或收尾动作。它是一个接口，有两个方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">onPartitionsRevoked</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span></span><br></pre></td></tr></table></figure>
<p>这个方法会在再均衡开始之前和消费者停止读取消息之后被调用。可以通过这个回调方法来处理消费位移的提交，以此来避免一些不必要的重复消费现象的发生。<code>partitions</code>表示再均衡前所分配到的分区。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">onPartitionsAssigned</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span></span><br></pre></td></tr></table></figure>
<p>这个方法会在重新分配分区之后和消费者开始读取消费之前被调用。<code>partitions</code>表示再均衡后所分配到的分区。</p>
<h2>三、消费者拦截器</h2>
<p>生产者有拦截器，消费者也有拦截器，主要在消费到消息或在提交位移时进行一些定制化的操作。</p>
<p>消费者拦截器需要自定义实现<code>org.apache.kafka.clients.consumer.ConsumerInterceptor</code>接口。包含3个方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ublic ConsumerRecords&lt;String, String&gt; <span class="title">onConsume</span><span class="params">(ConsumerRecords&lt;String, String&gt; records)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCommit</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>
<p><code>KafkaConsumer</code>会在<code>poll()</code>方法返回之前调用拦截器的<code>onConsume</code>方法来对消息进行相应的定制化操作，比如修改返回的消息内容、按照某种规则过滤消息。这个方法如果发生异常，那么会被捕获并记录到日志里，但是异常不会向上传递。</p>
<p><code>KafkaConsumer</code>会在提交消费位移之后调用拦截器的<code>onCommit</code>方法，可以使用这个方法来记录跟踪所提交的位移消息。</p>
<p>在某些业务场景中会对消息设置一个有效期的属性，如果某条消息在既定的时间窗口内无法到达，则被视为无效，它也就不需要再被继续处理了。下面为一个例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerInterceptorTTL</span> <span class="keyword">implements</span></span></span><br><span class="line"><span class="class">        <span class="title">ConsumerInterceptor</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> EXPIRE_INTERVAL = <span class="number">10</span> * <span class="number">1000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ConsumerRecords&lt;String, String&gt; <span class="title">onConsume</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            ConsumerRecords&lt;String, String&gt; records)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"before:"</span> + records);</span><br><span class="line">        <span class="keyword">long</span> now = System.currentTimeMillis();</span><br><span class="line">        Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;String, String&gt;&gt;&gt; newRecords</span><br><span class="line">                = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (TopicPartition tp : records.partitions()) &#123;</span><br><span class="line">            <span class="comment">//根据分区分类消息</span></span><br><span class="line">            List&lt;ConsumerRecord&lt;String, String&gt;&gt; tpRecords = records.records(tp);</span><br><span class="line">            <span class="comment">//存放未过期的消息</span></span><br><span class="line">            List&lt;ConsumerRecord&lt;String, String&gt;&gt; newTpRecords = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            <span class="comment">//判断是否过期</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : tpRecords) &#123;</span><br><span class="line">                <span class="keyword">if</span> (now - record.timestamp() &lt; EXPIRE_INTERVAL) &#123;</span><br><span class="line">                    newTpRecords.add(record);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (!newTpRecords.isEmpty()) &#123;</span><br><span class="line">                newRecords.put(tp, newTpRecords);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ConsumerRecords&lt;&gt;(newRecords);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCommit</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets)</span> </span>&#123;</span><br><span class="line">        offsets.forEach((tp, offset) -&gt;</span><br><span class="line">                System.out.println(tp + <span class="string">":"</span> + offset.offset()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此外，在消费者中也有拦截链的概念，和生产者的拦截链一样，也是按照<code>interceptor.classes</code>参数配置的拦截器的顺序来一一执行的（配置的时候，各个拦截器之间用逗号隔开）。同样也要提防副作用的发生。如果在拦截器中某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行。</p>
<h2>四、多线程实现</h2>
<p><code>KafkaProducer</code>是线程安全的，<code>KafkaConsumer</code>是非线程安全的。<code>KafkaConsumer</code>中定义了一个<code>acquire()</code>方法，用来检测当前是否只有一个线程在操作，若有其他线程正在操作会抛出<code>ConcurrentModificationException</code>异常。<code>KafkaConsumer</code>的每个公用方法在执行之前都会调用<code>acquire</code>方法，至于<code>wakeup</code>是个例外。</p>
<p><code>acquire</code>跟我们通常说的锁（<code>synchronized</code>或<code>lock</code>等）不同，它不会造成阻塞等待，我们可以将其看作一个轻量级锁，它仅通过线程操作计数标记的方式来检测线程是否发生了并发操作，以此保证只有一个线程在操作。</p>
<p><code>KafkaConsumer</code>非线程安全并非意味着我们在消费消息的时候只能以单线程的方式执行，我们可以通过多线程的方式来实现消息消费，多线程的目的是为了提高整体的消费能力。多线程的实现方式有多种，第一种也是最常见的方式：线程封闭，即为每个线程实例化一个<code>KafkaConsumer</code>对象。</p>
<p><img src="http://bloghello.oursnail.cn/kafka7-4.png" alt="image"></p>
<p>一个例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FirstMultiConsumerThreadDemo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String brokerList = <span class="string">"localhost:9092"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String topic = <span class="string">"topic-demo"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String groupId = <span class="string">"group.demo"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Properties <span class="title">initConfig</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,</span><br><span class="line">                StringDeserializer.class.getName());</span><br><span class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,</span><br><span class="line">                StringDeserializer.class.getName());</span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);</span><br><span class="line">        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);</span><br><span class="line">        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">return</span> props;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = initConfig();</span><br><span class="line">        <span class="keyword">int</span> consumerThreadNum = <span class="number">4</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; consumerThreadNum; i++) &#123;</span><br><span class="line">            <span class="keyword">new</span> KafkaConsumerThread(props, topic).start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConsumerThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> KafkaConsumer&lt;String, String&gt; kafkaConsumer;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">KafkaConsumerThread</span><span class="params">(Properties props, String topic)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.kafkaConsumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">            <span class="keyword">this</span>.kafkaConsumer.subscribe(Arrays.asList(topic));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                    ConsumerRecords&lt;String, String&gt; records =</span><br><span class="line">                            kafkaConsumer.poll(Duration.ofMillis(<span class="number">100</span>));</span><br><span class="line">                    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                        <span class="comment">//process record.</span></span><br><span class="line">                        System.out.println(record.value());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                kafkaConsumer.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果对消息的处理很快，那么<code>poll</code>拉起的频次也会更高，进而整体消费的性能也会提升；不过，如果消息处理比较慢，比如进行一个事务性操作，或者等待一个RPC的同步相应，那么<code>poll</code>频次就会降低，造成整体消费性能的下降。这边考虑优化，提升整体性能，将处理消息模块改成多线程的实现方式。</p>
<p><img src="http://bloghello.oursnail.cn/kafka7-5.png" alt="image"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThirdMultiConsumerThreadDemo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String brokerList = <span class="string">"localhost:9092"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String topic = <span class="string">"topic-demo"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String groupId = <span class="string">"group.demo"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Properties <span class="title">initConfig</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,</span><br><span class="line">                StringDeserializer.class.getName());</span><br><span class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,</span><br><span class="line">                StringDeserializer.class.getName());</span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);</span><br><span class="line">        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);</span><br><span class="line">        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">return</span> props;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = initConfig();</span><br><span class="line">        KafkaConsumerThread consumerThread = <span class="keyword">new</span> KafkaConsumerThread(props, topic,</span><br><span class="line">                Runtime.getRuntime().availableProcessors());</span><br><span class="line">        consumerThread.start();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConsumerThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> KafkaConsumer&lt;String, String&gt; kafkaConsumer;</span><br><span class="line">        <span class="keyword">private</span> ExecutorService executorService;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> threadNumber;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">KafkaConsumerThread</span><span class="params">(Properties props, String topic, <span class="keyword">int</span> threadNumber)</span> </span>&#123;</span><br><span class="line">            kafkaConsumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">            kafkaConsumer.subscribe(Collections.singletonList(topic));</span><br><span class="line">            <span class="keyword">this</span>.threadNumber = threadNumber;</span><br><span class="line">            executorService = <span class="keyword">new</span> ThreadPoolExecutor(threadNumber, threadNumber,</span><br><span class="line">                    <span class="number">0L</span>, TimeUnit.MILLISECONDS, <span class="keyword">new</span> ArrayBlockingQueue&lt;&gt;(<span class="number">1000</span>),</span><br><span class="line">                    <span class="keyword">new</span> ThreadPoolExecutor.CallerRunsPolicy());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                    ConsumerRecords&lt;String, String&gt; records =</span><br><span class="line">                            kafkaConsumer.poll(Duration.ofMillis(<span class="number">100</span>));</span><br><span class="line">                    <span class="keyword">if</span> (!records.isEmpty()) &#123;</span><br><span class="line">                        executorService.submit(<span class="keyword">new</span> RecordsHandler(records));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                kafkaConsumer.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">RecordsHandler</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">final</span> ConsumerRecords&lt;String, String&gt; records;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">RecordsHandler</span><span class="params">(ConsumerRecords&lt;String, String&gt; records)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.records = records;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">//处理records.</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.println(record.value());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>RecordsHandler</code>就是用来处理消息的，<code>KafkaConsumerThread</code>类对应的是一个消费线程，里面通过线程池的方式来调用<code>RecordsHandler</code>处理一批批的消息。注意<code>KafkaConsumerThread</code>中的<code>ThreadPoolExecutor</code>里的最后一个参数设置的是<code>CallerRunsPolicy</code>，这样可以防止线程池的总体消费能力根本不上<code>poll</code>拉取的能力，从而导致异常现象的发生。这个方法具有横向扩展能力，可以通过开启多个<code>KafkaConsumerThread</code>实例来进一步提高整体的消费能力。</p>
<p>下表总结了两种方法的优缺点：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>方法1</strong>(每个线程维护一个KafkaConsumer)</td>
<td>①方便实现<br>②速度较快，因为不需要任何线程间交互<br>③易于维护分区内的消息顺序</td>
<td>①更多的TCP连接开销(每个线程都要维护若干个TCP连接)<br>②consumer数受限于topic分区数，扩展性差<br>③频繁请求导致吞吐量下降<br>④线程自己处理消费到的消息可能会导致超时，从而造成rebalance</td>
</tr>
<tr>
<td><strong>方法2</strong> (单个(或多个)consumer，多个worker线程)</td>
<td>①可独立扩展consumer数和worker数，伸缩性好</td>
<td>①实现麻烦<br>②通常难于维护分区内的消息顺序<br>③处理链路变长，导致难以保证提交位移的语义正确性</td>
</tr>
</tbody>
</table>
<p>对于第二种方式，消息的顺序性不能保证，考虑使用一个共享变量<code>offsets</code>来参与提交。每一个处理消息的<code>RecordHandler</code>类在处理完消息后都将对应的消费位移保存到共享变量<code>offsets</code>中（注意，这里的offsers是一个map结构，即&lt;分区，offset&gt;的结构），每次消费完分区消息后，就记录一下。这里为防止出现并发问题，需要对<code>offsers</code>的读写进行加锁处理。</p>
</div></article></div></section><footer><div class="paginator"><a href="/2019/11/17/miscellany/20关于多CPU和多核CPU的区别/" class="prev">PRVE</a><a href="/2019/09/22/kafka/06kafka消费者中/" class="next">NEXT</a></div><div id="container"></div><link rel="stylesheet" href="https://jjeejj.github.io/css/gitment.css">
<script src="https://jjeejj.github.io/js/gitment.js"></script><script>var gitment = new Gitment({
    id: 'Fri Oct 04 2019 11:16:52 GMT+0800',
    owner: 'sunweiguo',
    repo: 'sunweiguo.github.io',
    oauth: {
        client_id: '56c422eddebac740f021',
        client_secret: 'fd1b1eff6dd6efc61b2a09650840be7aaab787fd',
    },
})
gitment.render('container')</script><div class="copyright"><p>© 2019 - 2020 <a href="http://yoursite.com">fossi</a>,苏ICP备17064972号.</p></div></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-134836068-1",'auto');ga('send','pageview');</script><script src="https://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>